
# 中文整理稿

## **引言**

**提问者：** 欢迎大家来到这个特别的对话系列，我们邀请了来自包括斯坦福大学在内的多个校园的人物。这个系列的目的是释放出我认为对你们极具价值的发人深省的想法。感谢你们迄今为止的支持，并欢迎来到这个特别的系列。

## **成为谷歌首席科学家**

**提问者：** 我们很荣幸邀请到谷歌的首席科学家Jeff Dean。Jeff，非常感谢你来到我们的节目《Endgame》。你在谷歌待了很长时间了；你是第29号员工。我想让你谈谈你的成长经历。你在夏威夷出生。请告诉我们你是如何长大的，你是如何对计算机产生兴趣的，以及你是如何帮助谷歌发展成为今天的这个样子的。

## **Jeff Dean的童年和对计算机的兴趣**

**Jeff Dean：** 我的童年有点有趣，因为我爸爸从事热带病研究，我童年的前半段他就在做这个，然后转而成为公共卫生流行病学家。我妈妈做医学人类学，所以他们喜欢经常搬家。我是独生子，所以我们每隔一段时间就会搬家。我在12年里上了11所学校。我在夏威夷出生，然后我们搬到波士顿，然后是乌干达和波士顿、阿肯色州和夏威夷、明尼苏达和索马里。然后是明尼苏达和亚特兰大，我在高中最后两年在那里，然后我回到明尼苏达上大学。之后我在日内瓦的世界卫生组织工作了一年零六个月，然后去西雅图读研究生，之后我来到了湾区，从那以后我就没有再搬过家。我的孩子没有像我那样周游世界，但...看到这么多不同的环境、不同的学校、不同的教学方式等等，这与许多人的成长经历不同。

## **影响和追求医学**

**提问者：** 有没有一段时间，你被推动或尝试去追求医学，这是你父母专业领域？

**Jeff Dean：** 我想我对医学并不是作为医生那样感兴趣，而是像...显然，我成长过程中的餐桌上的谈话总是关于公共卫生的。实际上，我进入计算机领域的原因是因为我爸爸一直对如何使用更好的信息来帮助做出更好的公共卫生决策感兴趣。所以当时他有点沮丧，这是70年代中后期，当时大多数人无法自己使用计算机。有一个大型机在某个地下室，你会告诉某个程序员... - 不，这实际上是在夏威夷。- 好的。然后你会告诉别人你想让计算机做什么，他们会去做，然后你不会有那种现在个人计算机带来的自然互动体验。但是，我爸爸在一本杂志的背面看到了一个广告，是一个自己焊接的套件计算机，叫做IMSAI 8080。当我九岁的时候，他买了一个，我可能帮不上什么忙。但我稍微拿了一下焊烙铁，帮他焊接在一起。起初它并没有做太多，因为它没有键盘或屏幕。真的，你可以切换单个比特。然后像输入它们到内存中，你可以通过这种方式启动小程序。然后我们得到了一个键盘，这是一个巨大的改进。所以你可以实际输入字符等等。但随着我们获得更多的外围设备，你可以开始用BASIC输入电脑游戏。你有一本书，里面有一堆不同游戏的源代码，你可以输入，然后你可以玩游戏。然后我开始对修改游戏感兴趣。我认为这是让孩子们对编程产生兴趣的好方法：让他们想要计算机做什么，这非常激励人。因为你可以在某种程度上自己弄清楚，或者像，我该如何让这个游戏的鱼雷速度翻倍？

## **加入谷歌及其成长**

**Jeff Dean：** 那么我来到湾区为Digital Equipment Corporation工作。一个位于帕洛阿尔托市中心的小研究实验室。实际上，那个实验室创造了AltaVista，这是一个早期的搜索引擎。所以我的一些同事在那里做了那个系统的关键工作。当时AltaVista的索引比大多数人的大得多。它是一个非常快速响应的系统。我的一个同事从AltaVista索引中爬取的页面整理了一个系统。你可以以编程形式查看哪些页面指向哪些其他页面。所以你可以以某种方式导航这个计算图，向前和向后。有了这套API调用，这证明非常有趣。所以一位同事Monika Henzinger和我正在研究如何找到任何给定网页的相关页面。我们认为我们必须尝试相当复杂的事情，但我们说，“哦，让我们先尝试一些非常简单的事情。”那就是让我们看看一个页面，然后看看哪些页面指向该页面。然后其他页面又指向哪些页面，然后你只是做一些计数和频繁的事情。然后你除以以规范化概率。”突然间，从《华盛顿邮报》。你会得到一份像CNN、《华尔街日报》、《纽约时报》这样的列表。或者某个关于湾区徒步旅行的页面。你会得到一堆其他关于湾区徒步旅行的页面。这让我意识到网络的链接结构中实际上有很多信息。我最终决定我想在一个小公司工作。有时候在一家大公司里很难把你所做的研究传播到世界上。我发现这有点间接，所以我决定去谷歌。我知道...一个小公司。- 是的。实际上，当我们开始的时候，我们被挤在一个非常小的区域。在帕洛阿尔托市中心现在是T-Mobile商店的上方。但我认识Urs Hölzle，他是我们的早期员工之一；他是我学术上的叔叔，我想。所以我在不同的计算机会议上多次与他交谈。因为我们都有计算机和程序优化的背景。你是什么时候感觉到谷歌会像今天这样大的？你已经在1999年就这样想了吗？是的。我的意思是，我们当时显然有一个非常成功且不断增长的服务。你可以看到，就像整个公司都可以看到我们的流量每周增长6%、7%、10%。如果你做1.1的52次方，那是一年内巨大的增长。而且前几年的很多时间都是在想我们如何在高峰交通时间避免每周二的熔断。所以我们有一大堆部署新硬件的工作，但这还不够。我们必须进行软件性能优化，我们必须重新设计系统。因为当你的软件在规模x上工作时，它突然在规模10x或50x上不起作用。所以你不断地重新设计这部分系统。因为现在这是一个大问题，而以前它不是。所以你是什么时候意识到这将会变得很大？我们的一位早期员工...我们实际上有一面巨大的墙。他在这堵墙上贴了一张屠夫纸的图表。它被称为蜡笔图表，因为每天他都会绘制我们周三得到了多少查询。可能像这样。用不同的颜色标记不同的合作伙伴，然后你会稍微前进一点。然后他会在纸的顶部用完空间，所以你必须按五倍的比例缩小。然后重新开始，它会再次长到纸的顶部，然后他会再按另一个五倍的比例缩小。他做了很多这样的缩放，我们从我刚开始时每天很少的查询。到更多的查询，然后显然扩展到很多其他产品领域。这样的事情。你认为自从谷歌成立以来，有什么可以做的不一样的地方吗？哦，有很多。我认为反思我们做得好的地方总是很好的。但我们也可以做得更好。我认为一个突出的教训是，每当一个组织快速增长时。我们也在快速招聘人员，我感觉公司规模每翻一番。就会导致以前工作得很好的事情不再有效。而且有些变化会导致这种情况；有时候你们都在一层楼，现在你们在同一栋建筑的多个楼层。然后有时候你们去了多个建筑，突然间，而不是所有的工程都在山景城完成。我们开了纽约办公室和苏黎世办公室。现在我们必须弄清楚，好的，你让人们。在许多不同的地方一起工作？这是在我们现在拥有的视频聊天技术之前。这有点更具挑战性，要弄清楚谁应该做什么，谁在做什么。但我们解决了这个问题；我们有一段时间大约有五个工程地点。我认为我们可以做得更好的一个时期是当我们决定扩大我们拥有的工程地点数量时。所以我们从大约5个增加到30个，只用了几年时间，这实际上是为了雇佣不同地方的优秀人才。他们不一定想搬到我们的某个地点，但我们想，“哦，是的，那个人和这个五人团队，我们应该围绕他们开一个办公室。”需要一段时间来消化我们应该如何工作在30个工程地点而不是5个。因为这些小地点中的每一个都会看着纽约和山景城的主要工程中心说，“我们应该像他们一样做事，” 这意味着处理一切。我认为如果你在处理一切，但你只有15个人，那这真的行不通。所以我们试图在一些中心创建一点专业性和专注。他们可以在一些非常突出和重要的事情上工作，但我们所做的不同产品只有少数几种。

## **AI的支柱和计算能力**

**提问者：** 你在1990年开始研究神经网络；我们之前谈到过，那时它受到计算能力不足的极大限制。你认为计算能力的增长像你当时想象的那样呈指数级增长了吗？

**Jeff Dean：** 是的。我的意思是，我在大学的最后一年开始接触神经网络。那是我上的某个课程中的一周模块，但我对它们非常感兴趣；它们看起来像是正确的抽象。所以我决定和那位教员一起做一个本科研究项目，一个关于...我觉得我们只是需要更多的计算能力。所以也许我们可以并行训练神经网络。所以我们可以使用部门里的32处理器机器来训练一个神经网络，而不是只使用一个处理器。我确信如果我们能使用32倍的计算能力，那将是惊人的。这会很棒。结果我错了。 - 我们需要的像... - 我们一直在说一百万倍。是的，大约是20年来通用计算产生的一般进步。然后通过一般的改进，计算机架构改进在半导体制造[听不清]。制造收缩等等。所有这些都是由于我们的手机现在比我们过去使用的巨型台式机器强大一百倍或一千倍。所以我觉得一旦我们开始拥有大约一百万倍的计算能力，也许在2008年，2009年或2010年，神经网络就能解决真正的问题；不仅仅是最多小规模的玩具问题，但实际上开始被应用到真正的问题上。在计算机视觉中。语音识别是一些我们开始关注的早期领域。然后是各种语言任务；他们能否以一种不同的方式理解单词。而不仅仅是单词的表面形式？但是，这个词在这种情境下真的有意义吗？还有其他与这个词相似的词吗？这个词的过去式是什么，你真的能比它只是一系列字符更深入地理解语言吗？

## **TPU的演变和未来前景**

**提问者：** 你如何看待TPU未来的演变？它会变得比过去十年或二十年我们看到的更指数级吗？你现在是TPU v4还是什么？

**Jeff Dean：** 我们刚刚通过我们的云TPU程序宣布了我们的v5。所以我们已经为机器学习，特别是神经网络，构建了专门的硬件。我认为我们的第一个TPU v1是在2015年讨论的。但神经网络的一个好特性是它们被描述为不同序列的线性代数风格的操作。不同种类的矩阵乘法，或向量操作，这是你需要计算机做的非常有限的一组事情；它不像你需要做所有不同的事情，像通用计算代码。通用CPU非常适合运行你的字处理器，但它们并不是运行机器学习计算的最佳选择。因为它们太通用了；这种通用性会让你付出性能的代价。相反，如果你构建专门针对神经网络所体现的计算类型的硬件。你将能够获得巨大的性能提升：每瓦特的性能更好，每美元的性能更好，以及整体芯片的性能更好。神经网络的另一个特性是，与许多传统科学计算不同。你需要相当多的精度，它们实际上对减少精度的算术非常宽容，所以你可以在8位数字格式或16位浮点格式中进行计算。而不是通常用于天气模拟代码或其他东西的32位或64位浮点格式。这意味着你可以在相同的芯片区域内塞入更多的乘法器，并获得更高的性能。

## **神经网络和学习过程**

**提问者：** 你经常谈到神经网络的一些限制。谈谈多任务与单任务，稀疏性与密度。

**Jeff Dean：** 神经网络在某种程度上是受到真实生物神经网络神经元工作的启发。人工神经网络中的单个单元接收一些输入，然后对这些输入进行加权。重要的是这个输入有多重要，那个输入有多重要？而且重要的是，这些权重是通过学习过程学习的，然后神经元接收所有输入。然后决定... 

**提问者：** 人工神经元？

**Jeff Dean：** 人工神经元。并受到真实神经元的启发。它应该产生什么输出；它应该以某种方式发射还是不产生任何输出。它应该如何强烈地发射。所以这就是神经网络：它由许多这样的人工神经元组成，通常按层排列。所以你有最低层接收非常原始形式的数据。无论是图像的小补丁，一点音频数据，还是几个文本字符。然后它们构建有趣的特征。让我们讨论图像，因为我认为这是思考通过这个学习过程构建的特征的一种容易的方式。最低级的特征倾向于学习非常简单的事情，比如这部分图像是否有这个方向的线，或者这部分图像是否主要是灰色，或者主要是红色，或者像不同的颜色？所以不同的神经元会在看到不同模式时变得兴奋，比如这个神经元变得非常兴奋，“它是鲜红色。哇！令人兴奋！”这个神经元有一条像这样的线。”所以当你向上移动层次时，这些神经元接收来自低级神经元的输入，它们学习基于引起这些低级神经元兴奋的特征的组合的更有趣和复杂的模式。所以现在，就像，“哦，它是红色的，并且有一条像这样的线穿过它。那真的很令人兴奋，”或者它有一条边缘，红色主要在一边而不是另一边。随着你越来越往上，特征变得越来越复杂，所以你可能有一些看起来像轮子或像鼻子或眉毛的东西。甚至更高，你得到完全特征化的东西，就像，“哦，是的，这个在正面视图中的汽车。”或者类似的东西。”我认为这种过程是因为你通常在训练神经网络。有很多不同的训练方式，但最简单的一种是所谓的监督学习，你有图像数据，然后你有与这些图像相关的标签。你说，“好的，那个是汽车，那个是猎豹，那个是树。”所以模型在顶层的输出是试图预测这些许多不同类别的图像中哪一个。训练过程的工作方式是你通过模型进行一次前向传递；你看看模型预测了什么，它说，“好的，看起来像一座塔。”但也许它实际上是一棵树。所以你能做的就是对模型中的所有权重进行微小的调整。这样当它看到这张图像或类似的图像时，它更有可能给出正确的答案，说，“实际上是一棵树，而不是塔。” 训练过程就是重复这种观察真实数据。和它应该是什么，然后对模型的权重进行调整。

## **解决偏见和从数据中学习**

**提问者：** 你如何确保你实际上可以通过淘汰较弱的神经元并提升或促进更强的影响来消除这种看似的偏见？这听起来就像一种固有的偏见。单个神经元还是？

**Jeff Dean：** 正确的。我认为实际发生的情况是不同的神经元会抓住不同种类的模式，其中一些模式对任何特定图像都是无关紧要的。比如如果它是一张户外场景的图像，所有检测车辆部件的东西都是静音的，就像它们实际上没有产生大的输出，但所有关于植被和绿色、树干等等的东西。都非常兴奋。所以我认为训练神经网络的一部分是，你希望这个模型能够学习到各种不同模式的多样性，同时你还需要模型有足够的容量，足够多的神经元和参数，这样它就能从你暴露给它的数据中吸收并学习。如果你只有五个神经元，却给它一百万张图像，它将无法很好地泛化新的示例。我的意思是，这真的是机器学习中的一件事；你试图从代表性的数据中学习，但不仅仅是完全记住那些数据，因为你希望在面对新的图像或新的文本时能够泛化这些示例。


## **多模态和稀疏模型的进步**

**提问者：** 你有多乐观，能够基本上解决这些三个限制或约束，即模态、密度和单任务？或者你认为这些将通过指数增长和TPU能力得到最佳解决需要多久？

**Jeff Dean：** 我认为我们在这些方面取得了很多进展。我们已经相当远地将一些模型泛化了，这些模型以前主要是文本或类似软件代码的，变成了能够实际理解文本代码、音频输入和图像输入的模型，所以我认为，通过我的同事和社区其他人在过去三四五年中所做的研究，已经开始很好地理解了。我认为在多任务能力方面，我们看到的这些模型是通过在大量通用文本或图像和文本的语料库上训练的，这给了它们实际泛化到新事物的能力，就像你说，“好的，给我起草一封给兽医的信，关于我的狗？狗感觉不舒服。” 模型从未见过确切的要求或请求，但它能够理解你想要的是什么，并产生听起来合理的文本，实际满足那个人的需求。你开始看到，不仅仅是从一个数据示例泛化到另一个同一类别的数据示例。就像10年前，你想要的泛化是拿一张图像，能够预测它属于哪些类别，从训练了一堆图像和这些类别开始。现在你看到的是跨任务的泛化能力，就像让模型做一些它从未被要求做过的事情，但这些事情足够接近它知道如何做的事情，并且能够泛化。第三个是稀疏性。所以现在的大多数机器学习模型都是密集的，这意味着你有所有这些人工神经元，整个模型对每个示例或输入都是激活的。我们做了很多工作的一种模型，叫做稀疏模型，实际上有不同的模型部分，模型可以打开和关闭不同的部分。并且实际上可以学习哪些部分对哪些类型的输入最相关。所以你可能会有一些关于莎士比亚的输入，所以也许有一个部分非常擅长处理莎士比亚的东西，但关于C++代码或Java编程的部分。可能在那里不活跃。还有另一个部分非常擅长识别视觉图像中的垃圾车。那部分可能也不活跃，但你希望这个模型有足够的容量，所以它有很多部分可以调用，但它不需要为所有事情调用所有部分。这创造了一个更高效的模型，因为现在不是激活整个模型，你可能会激活它的5%，这使得它更加节能，但你仍然有这个容量来记住很多东西。

**提问者：** 可能不会太远的未来，你会认为你将能够解决这些约束？

**Jeff Dean：** 哦，是的。我认为我们已经看到谷歌研究和谷歌DeepMind在多模态模型方面做了很多工作。这些模型可以接收视觉输入和语言，并以文本形式回答问题，或者可以生成...我们已经看到很多关于从各种其他输入生成图像或音频的工作，你可以拿一个文本提示并生成一个图像，这些模型在这方面已经稳步改进。现在你可以拿文本加上一个图像，然后说，“好的，给我生成一个有这条狗在前面的巨型城堡的图片。”它能生成一个城堡和狗的图片很酷，但你真正想要的是你的狗在城堡前面。

## **机器学习和感官知觉**

**提问者：** 我们能够... 我的意思是，机器学习在阅读文本、理解到一定程度的音频方面做得如此之多、如此之快，还有视觉，各种各样的视觉，对吧？那么嗅觉呢？

**Jeff Dean：** 我们实际上已经做了一些研究。温度，你已经可以做到了。所以在谷歌研究中，我们大约四五年前开始在这方面做了一些工作。结果发现有各种仪器可以感知空气的旧工厂特性，可以给你关于空气中悬挂着什么的非常原始的数据，但是要真正给这些数据贴上高层次的标签是很难的。所以同样地，你有图像的像素，你可以训练一个神经网络说，“好的，当我看到那种东西时，那是一只豹子。”你可以用这些旧工厂信号做同样的事情，说，“好的，那很像柠檬加一点松针的味道。”这实际上是有效的。收集数据的实际设备还是有点大，所以它不像是可以放在手机里的便携式东西，但事实证明这是一个重要的问题，原因有很多。其中一个原因是，有很多行业想要创造特定的气味，他们想要能够理解气味，但也要做相反的事情：创建气味，就像你已经看到这些图像模型一样，你可以说出，“请给我一个狗在城堡前的图像”，你会想说出，“请给我我需要混合的东西，来制造... - 一个女人的香味。或者是炖肉和肉桂的香味。”所以这在香水行业或消费品行业是一个应用。但另一个是在医疗保健相关的事情上。有证据表明，狗的鼻子特别敏感，它们实际上可以在某些情况下察觉到癌症的微妙迹象，这表明在这些旧工厂原始数据中可能有一个信号，这实际上可以用于健康目的。

**提问者：** 关于机器学习可以为人类做些什么，我们还应该期待什么酷炫的事情？

**Jeff Dean：** 我对许多不同的应用领域非常乐观。我认为一个是在教育领域。我们还没到那一步，但快了，可以说是，“你能教我这个吗？” 你拿一章教科书，你可以想象一个系统吸收那一章或不同书籍的多章，然后问你问题，评估你回答的正确性，确定你可能需要更多深度的领域，并就那些问题问你更多问题，而对那些你似乎已经很好地了解的东西问更少的问题。所以想象一下，对于你想学的任何东西，无论是在学校的孩子还是成年人，或者英语。是的，英语很棒。有很多有趣的语言学习应用。我认为你可能会创造出真正有趣的对话，帮助人们学习语言，它们会比你现在能说的相当基础的东西更有趣，比如，“我想学英语，我想谈谈今天的森林徒步旅行或其他什么，” 它可能实际上可以帮助你实现这两个目标：愉快的关于徒步旅行的对话，同时你在学习英语。

**提问者：** 我来自一个叫做东南亚的地区，它有点... 它有点被忽视了。硅谷的人们倾向于谈论世界其他地方，而不是东南亚，我认为这部分结构性问题是因为我们就是不会说英语。不够多。新加坡人都会说英语；菲律宾人中有很大一部分会说，但东南亚其他地方不会。如果我们在五年前进行这次对话，我会对我们能够与国际社会沟通的未来更加悲观。现在，随着机器学习或AI的出现，我对让印度尼西亚的1亿人，能够说英语更加乐观。也许东南亚的4亿人，从总人口7亿中，能够说英语。这是一个突破；这是改变生活的。

**Jeff Dean：** 是的，让人们能够相互沟通，我认为这是一件极具影响力的事情，无论是通过教人们学习第二或第三语言，还是通过让不说同一种语言的人能够有效沟通。我们的一些产品，比如谷歌翻译，实际上可以（帮助）；你把手机放在桌子上，你说一种语言，我说另一种语言，它实际上会产生我们所说的内容的转录版本。我们还有可以转录成人们耳朵里实际音频的版本，我认为这是一个非常重要的能力，因为我们能够与所有人沟通得越多，就越好。这也是机器学习实际上可以真正帮助的地方，因为我们看到了通过这些更大的基于神经网络的模型，以及不仅仅是五种或十种语言，实际上是一百种语言的翻译质量的戏剧性改进。谷歌翻译今天支持超过100种语言，这我认为非常重要。我们实际上有一个雄心勃勃的目标，在我们的产品中支持一千种语言，这有点像是... 嗯，我们在一个国家，印度尼西亚，就有700种。

**提问者：** 我们称之为方言。

**Jeff Dean：** 是的。我的意思是，一千种语言并不是... 我认为世界上有大约7000种口语，覆盖前一千种（语言）将是惊人的。即使是前一百种也涵盖了很多，但如果我们不支持那些语言，仍有900种语言的许多使用者被排除在外，所以我们绝对想要做到这一点。

## **可持续性**

**提问者：** 我想和你谈谈可持续性。我想从发展中国家的角度来描绘一下，事情有点不同。我一直在说可持续性叙事是精英主义的，因为它与世界约15%的人口产生共鸣，而85%的人更担心的是把食物放在桌子上，对吧？他们不介意今天停止使用煤炭，只要替代品是负担得起的。技术上，替代品是可用的，但经济上，对地球上大多数人来说并不负担得起。你认为谷歌或你作为一个科学家，能思考什么来弥合可持续性叙事和发展叙事之间的差距？因为我认为对于地球来说，集体实现2050年或2060年的碳中和是很重要的。当我们听到这些人口中的一些人说2050年实现碳中和时，似乎没有现实性，我们以我们看到的这些人的速度，他们就是买不起这些技术。我相信你们这栋楼里有很多聪明人可以想出如何通过技术创新让事情变得更便宜。经济上更便宜。我认为这是一个星球范围内的问题，我们都需要共同努力解决它。

**Jeff Dean：** 情况肯定是这样的，经济更发达的国家在历史上产生了更多的排放。

**提问者：** 我们不必到达那里。

**Jeff Dean：** 是的。但我认为有几个积极的信号，所以一个是太阳能电池板等可再生能源的成本一直在急剧改善，有点像15年前的计算，我们现在看到... 

**提问者：** 仍然很高。

**Jeff Dean：** 仍然很高。电池技术也在大幅改进，所以太阳能和电池加上风能，正在变得更加负担得起。事实上，在世界上许多地方，我认为如果你看看安装新的电力产能，那实际上成为了经济合理的选择。所以这是个好事，因为我认为我们世界上一直存在的问题是，有些事情没有被纳入人们的决策中，比如如果我再安装一个燃煤电厂，它对我来说更便宜，即使它必然导致间接排放，影响每个人。所以我们一直在研究我们能做些什么来通过技术解决方案改善可持续性和减少排放。所以其中一个项目叫做Green Light，基本上，通过使用我们可以通过谷歌地图观察到的交通模式，我们实际上可以识别世界各地的城市可以如何改进他们的交通基础设施，信号等，以实际减少在十字路口的空闲时间。这实际上是排放的一个主要来源，就是汽车不动；这也是一个非常情况，人们不喜欢不动；你坐在车里是为了去某个地方，而空闲发动机的排放实际上相当有害。所以通过Green Light，我们实际上可以向世界各地的不同城市提出建议。让他们调整红绿灯定时。世界上大多数红绿灯都有相当简单的方法；它有点像，是高峰时段还是不是？这是许多红绿灯的精细程度，但现在我们实际上可以说，“好的，星期二上午10:37到11:30，你应该将信号定时设置为42秒而不是35秒，你将在你的道路上获得更多的吞吐量，一个90%的减少，人们需要等待第二个红绿灯周期的数量，” 例如。所以我们实际上已经在四个或五个大陆上的12个城市进行了试点。我认为这是一个很好的结果，我们正在从这个早期经验中学习。与这些城市合作，尝试扩大那个项目。但这个项目已经更广泛地推广了。并且将对减少排放产生巨大的潜在影响，它也会通过让人们快速到达他们想去的地方来帮助人们，这也是一个不错的副作用。我们正在讨论的另一个领域是飞机尾迹。所以你有时看到的飞机后面的长长的线性云；事实证明，这些实际上对碳排放相当有害，因为它们在一天中的某些时候会捕获热量，事实上，由飞机产生的飞机尾迹约占航空业总贡献的三分之一。


**提问者：** 真的吗？航空业的全部。有点惊讶。

**Jeff Dean：** 三分之一的碳燃烧。飞机尾迹实际上是可以避免的。如果你是一架飞机，在飞行的这个高度会产生飞机尾迹，而且这个条件似乎不好，因为那个飞机尾迹可能会造成伤害，你可以实际上改变你的高度，或者稍微上升或下降一点，你就可以到达一个情况，你不会形成飞机尾迹，因为它真的只是围绕飞机排气的小冰晶形成的飞机尾迹。我们实际上已经和美国航空公司合作进行了一个控制研究，我们拿了大约100个航班，我们给其中50个航班下达了命令，关于我们认为飞机尾迹会在哪些地方产生，以及他们是否应该上升或下降飞行路径，我们所看到的是，在我们控制的航班中，飞机尾迹减少了50%，而没有控制的航班则没有减少。

**提问者：** 你们是如何控制的？

**Jeff Dean：** 我们通过说，好吧，美国航空公司的航班运营会告诉他们上升到31,000英尺而不是30,000英尺之类的，然后实际上，我们如何闭环并弄清楚这一点是很酷的。现在你有所有这些航班，所以我们使用实时卫星图像来观察航班发生的时间以及它们所走的路径，然后你可以使用计算机视觉来检测这个航班是否产生了飞机尾迹，而不是那个航班。如果你看一下能源专家的一些出版物，他们预测汽车行业的化石燃料需求将继续下降，但航空业的化石燃料需求正在上升，因为你就是不能电气化长途飞行的飞机。这种方法似乎可以减少大约一半的飞机尾迹造成的变暖，这是航空业影响的三分之一，所以这可能是航空业影响的六分之一。

**提问者：** 那么食品安全呢？我的意思是，技术上或科学上有很多可以做的来改善现有的惯例。

**Jeff Dean：** 我认为这是一个非常广泛的途径，你可以通过很多方式来解决这个问题。一个是帮助农民了解他们的作物，比如：“我在这个特定作物的叶子上得到了这些奇怪的图案。这是不是我需要担心的疾病，还是没关系？”计算机视觉模型实际上可以在这方面的帮助。我们已经和其他非营利组织合作部署了一些项目，我想是在肯尼亚或坦桑尼亚，帮助理解木薯叶图像，帮助木薯农民了解如果这是他们需要担心的疾病，如果是的话，他们应该如何治疗。另一个就是预测食物不安全可能发生的地方，因为我们知道，当你等到一个人口处于危机时，实际上已经有点晚了。你宁愿直接给那些还没有陷入危机的人提供帮助，这样他们就可以种植更多的作物或者做一些可以帮助他们避免最糟糕情况的事情。使用机器学习来帮助做出预测，这是谷歌研究与粮农组织合作的事情。

**提问者：** 让我们谈谈AI。说服我们，它将导致一个好的未来。

**Jeff Dean：** 我绝对同意这一点。我认为，每当你考虑将技术应用于某个问题时，你想引入那些对该领域有很多了解的人，并且与他们合作。我参与过的一些最有趣的项目是我可能有一些技术专长，但我从其他领域的同事那里学到了很多东西；他们是临床医生，他们非常了解这种医疗保健问题。他们可以说，“是的，如果我们能做到这一点，那将非常有帮助。这一点没有那么有帮助。这是一个大问题。这不是一个大问题。我们应该小心这一点。”所以每当我们考虑在不同领域使用AI和机器学习时，我们想把那些全面的人纳入考虑，他们正在思考那个领域，并且正在思考代表性和公平性的问题。如果技术将影响某个社区的人，你想要有来自那个社区的人，说那种语言，或者更深入地了解那个城市或国家的情况，这样他们就可以提供反馈和建议，并共同努力改善事物。这是谷歌做的一件事，因为我们看到AI在我们的产品中使用得越来越多，并且在考虑它在其他领域如何应用。我们实际上制定了一套原则，我们通过这些原则来思考，我们如何确保以负责任的方式应用AI到不同的问题上。我们想要避免产生不公平的偏见，我们想要避免造成伤害，我们想要专注于积极的用例。我们的AI原则，我们在2018年公布，有一套七个原则，我们通过这些原则来思考，我们评估机器学习和AI在这些原则下的后续用途。我认为这实际上是对我们非常有帮助的一件事，因为我们已经考虑AI一段时间了，但其他组织开始考虑在他们的环境、他们的学科或他们的领域中使用机器学习或AI，我认为这对我们来说很有帮助，我们把这些原则公布出去，这样其他组织或其他人就可以反思它们，说，“是的，这很有道理”，或者“在我们的行业中，这个原则不一定那么有意义，但这些原则是共鸣的。”

**提问者：** 你如何确保你能够找到正确的平衡点，既能保持人性又能保持盈利能力？

**Jeff Dean：** 这很棘手。我们实际上做了很多工作，我们不太担心这是否会盈利，因为这只是为了这个星球做正确的事情，比如我们的飞机尾迹或Green Light工作，我们并不真正担心那是否会盈利；这只是为了这个星球做正确的事情。或者我们在发展中国家做的很多与医疗保健相关的工作，我认为这些是低收入和中等收入国家。我们已经部署了一些基于视网膜图像的机器学习系统，与印度或其他地点的医院合作，帮助诊断像糖尿病视网膜病变这样的疾病。我认为这是一件好事，不管它是否盈利。在其他领域，我们认为AI和机器学习的重要用途，它们提供了经济利益，我们围绕这个创建了商业模式，所以像我们的一些基于云的AI产品，人们会付钱使用它们，因为它们很有用，那很好。所以我认为正确地平衡这两件事很重要，但它不必是非此即彼。

**提问者：** 今天有一个关于AI领域一位领导者的公告。哦，是的。不提名字，我想把这放在我想从你这里听到的背景下，就目前对人类的利益而言，这应该是开源还是闭源。AI。总的来说。

**Jeff Dean：** 好的，是的。我的意思是，这是一个复杂的问题。我认为我们实际上有很长一段时间的开源发布历史，比如AI工具包的基本构建块，所以我们已经研究了很多年并发布的TensorFlow或JAX，实际上世界上有很多开发者使用TensorFlow创建了各种令人惊奇的东西。我认为这个系统有4000万次下载，现在可能更多了，这使得像我提到的木薯检测示例成为可能。同时，我认为最有能力的一些模型...我认为确保它们以安全的方式部署是很重要的，当你完全向世界发布模型时，它可以有很多惊人的用途，但它也可以以可能不太理想的方式被使用，你无法真的控制这一点。这并不意味着我们不应该开源模型。我认为这是一种平衡，我们希望有令人惊奇的开源模型，人们可以用它们做各种好事，但最有能力的一些模型，我会稍微谨慎一些；你可以向人们提供API访问，他们可以在其上构建东西，但这并不一定意味着我们希望它们完全开放和可用。

**提问者：** 中国有一个很大的人口，对吧？如果你听到一些来自中国的AI专家的意见，他们似乎认为他们将领先于美国在AI方面，因为他们有更多的数据点。这是关于AI将如何发展的正确的逻辑方式，还是有其他需要考虑的变量？

**Jeff Dean：** 我认为显然AI正在全世界范围内被研究，包括在美国，包括在中国，欧洲的许多人，亚洲和东南亚各地。我认为这是一种与许多事情都密切相关的技术，所以很自然地，到处都有很多人在研究它。我认为这不仅仅是关于领先；而是让每个人都在提高这些系统能做什么的能力，确保它们以有益于人们、公民或公司产品用户的方式部署，或者改善患者或临床医生的生活。我认为有很多事情可以用AI来做，我认为有一个负责任的方法，你正在查看这种技术被使用和部署的方式，并思考它应该如何在未来被使用，这是一件非常有帮助的事情。

**提问者：** 如果你看一下一些关于AI价值主张的报告，一些预测可能会说，在未来10到15年内，它将带来50到100万亿美元的经济价值。我来自一个发展中国家，你成长于非洲的一些发展中国家等等。从直觉上看，大多数价值似乎会流向美国和中国，对吧？我的意思是，这是我的观点。我想听听你的看法，关于东南亚人民如何能够确信他们能够捕捉到一些价值主张，这可能在全球范围内达到50到100万亿美元，在未来10到15年内。我们该怎么做才能确保我们相关，并且我们参与到这个叙事中？

**Jeff Dean：** 我认为AI和机器学习日益增长的兴趣是你希望你的国家和其他国家的人们学习这些技术，识别它们可以如何被本地公司、本地大学和开发者应用的方式。我认为这是确保每个人都能参与到AI潜在好处的一种方式，无论是在社会上还是在经济上。

**提问者：** 你感觉到你没有像你想要的那样快速地招聘到优秀的工程师，还是你觉得工程师的供应节奏在谷歌是正确的？

**Jeff Dean：** 我认为这个转变在过去十年左右的时间里，由于对AI和机器学习的兴趣增加，计算机科学总体上发生了变化。十年前，机器学习是一些人从大学毕业时了解一点的东西，但不是每个人。我认为在过去十年中发生的事情是，由于这些技术能做什么产生了如此大的兴趣，大学真的对此做出了反应，所以现在很难从本科课程中毕业，至少没有上过机器学习课程或以某种方式接触过它。我认为这很有帮助，因为现在我们有更多的人至少对这项技术有所了解，可以理解一些潜在的危害，可能会因为应用它而产生，基本技术，现在可能的事情，以及不太可能但可能很快就会可能的事情。而且这个领域发展得很快，所以你需要人们有这种理解，然后也要跟上变化的步伐。

**提问者：** 我们已经谈了一个多小时。我感觉就像刚刚上了一个学期的计算机科学课。这很难，伙计。你给我的印象是一个硬核科学家，但就个人而言，你做什么来放松？

**Jeff Dean：** 我喜欢做各种运动。我在两个不同的足球联赛中踢球。我坚持在我的联赛的25岁以上年龄组。25岁的孩子似乎每年都变得更快，这很烦人。我必须问你：罗纳尔
多还是梅西？

**Jeff Dean：** 梅西。尤其是巴塞罗那的巅峰梅西，就像... 还有世界杯。我很高兴他赢得了世界杯。看到他赢得世界杯很高兴。他显然是世界上最棒的球员，很高兴看到他赢得世界杯。

**提问者：** Jeff，非常感谢你抽出时间。你很亲切。

**Jeff Dean：** 谢谢你。我很感激。

# 中文译稿

**Intro**
1:05 - 欢迎朋友们和同事们来到这个特别的对话系列，我们邀请了来自包括斯坦福大学在内的多个校园的人物。
1:10 - 这个系列的目的是释放出我认为对你们极具价值的发人深省的想法。
1:15 - 感谢你们迄今为止的支持，并欢迎来到这个特别的系列。

**Becoming Google's Chief Scientist**
1:37 - 我们很荣幸邀请到谷歌的首席科学家Jeff Dean。Jeff，非常感谢你来到我们的节目《Endgame》。
1:43 - 感谢邀请。你在谷歌待了很长时间了；你是第29号员工。
1:49 - 我想让你谈谈你的成长经历。你在夏威夷出生。
1:57 - 请告诉我们你是如何长大的，你是如何对计算机产生兴趣的，以及你是如何帮助谷歌发展成为今天的这个样子的。

**Jeff Dean's Childhood and Interest in Computers**
2:05 - 我的童年有点有趣，因为我爸爸从事热带病研究，我童年的前半段他就在做这个，然后转而成为公共卫生流行病学家。
2:13 - 我妈妈做医学人类学，所以他们喜欢经常搬家。
2:18 - 我是独生子，所以我们每隔一段时间就会搬家。我在12年里上了11所学校。
2:26 - 我在夏威夷出生，然后我们搬到波士顿，然后是乌干达和波士顿、阿肯色州和夏威夷、明尼苏达和索马里。
2:35 - 然后是明尼苏达和亚特兰大，我在高中最后两年在那里，然后我回到明尼苏达上大学。
2:41 - 之后我在日内瓦的世界卫生组织工作了一年零六个月，然后去西雅图读研究生，之后我来到了湾区，从那以后我就没有再搬过家。
2:52 - 我的孩子没有像我那样周游世界，但...看到这么多不同的环境、不同的学校、不同的教学方式等等，这与许多人的成长经历不同。

**Influences and Pursuing Medicine**
3:00 - 有没有一段时间，你被推动或尝试去追求医学，这是你父母专业领域？
3:19 - 我想我对医学并不是作为医生那样感兴趣，而是像...
3:29 - 显然，我成长过程中的餐桌上的谈话总是关于公共卫生的。
3:36 - 实际上，我进入计算机领域的原因是因为我爸爸一直对如何使用更好的信息来帮助做出更好的公共卫生决策感兴趣。
3:45 - 所以当时他有点沮丧，这是70年代中后期，当时大多数人无法自己使用计算机。
4:01 - 有一个大型机在某个地下室，你会告诉某个程序员... - 不，这实际上是在夏威夷。- 好的。
4:08 - 然后你会告诉别人你想让计算机做什么，他们会去做，然后你不会有那种现在个人计算机带来的自然互动体验。
4:15 - 但是，我爸爸在一本杂志的背面看到了一个广告，是一个自己焊接的套件计算机，叫做IMSAI 8080。
4:30 - 当我九岁的时候，他买了一个，我可能帮不上什么忙。
4:37 - 但我稍微拿了一下焊烙铁，帮他焊接在一起。起初它并没有做太多，因为它没有键盘或屏幕。
4:48 - 真的，你可以切换单个比特。
4:55 - 然后像输入它们到内存中，你可以通过这种方式启动小程序。然后我们得到了一个键盘，这是一个巨大的改进。
5:01 - 所以你可以实际输入字符等等。但随着我们获得更多的外围设备，你可以开始用BASIC输入电脑游戏。
5:08 - 你有一本书，里面有一堆不同游戏的源代码，你可以输入，然后你可以玩游戏。
5:14 - 然后我开始对修改游戏感兴趣。我认为这是让孩子们对编程产生兴趣的好方法：
5:28 - 让他们想要计算机做什么，这非常激励人。
5:34 - 因为你可以在某种程度上自己弄清楚，或者像，我该如何让这个游戏的鱼雷速度翻倍？

**Joining Google and Its Growth**
7:11 - 那么我来到湾区为Digital Equipment Corporation工作。
7:18 - 一个位于帕洛阿尔托市中心的小研究实验室。
7:23 - 实际上，那个实验室创造了AltaVista，这是一个早期的搜索引擎。
7:28 - 所以我的一些同事在那里做了那个系统的关键工作。
7:34 - 当时AltaVista的索引比大多数人的大得多。它是一个非常快速响应的系统。
7:41 - 我的一个同事从AltaVista索引中爬取的页面整理了一个系统。
7:48 - 你可以以编程形式查看哪些页面指向哪些其他页面。
8:02 - 所以你可以以某种方式导航这个计算图，向前和向后。
8:10 - 有了这套API调用，这证明非常有趣。
8:16 - 所以一位同事Monika Henzinger和我正在研究如何找到任何给定网页的相关页面。
8:26 - 我们认为我们必须尝试相当复杂的事情，但我们说，“哦，让我们先尝试一些非常简单的事情。”
8:33 - 那就是让我们看看一个页面，然后看看哪些页面指向该页面。
8:38 - 然后其他页面又指向哪些页面，然后你只是做一些计数和频繁的事情。
8:44 - 然后你除以以规范化概率。”突然间，从《华盛顿邮报》。
8:51 - 你会得到一份像CNN、《华尔街日报》、《纽约时报》这样的列表。
9:00 - 或者某个关于湾区徒步旅行的页面。你会得到一堆其他关于湾区徒步旅行的页面。这让我意识到网络的链接结构中实际上有很多信息。
9:07 - 我最终决定我想在一个小公司工作。
9:15 - 有时候在一家大公司里很难把你所做的研究传播到世界上。
9:22 - 我发现这有点间接，所以我决定去谷歌。我知道...
9:30 - 一个小公司。- 是的。实际上，当我们开始的时候，我们被挤在一个非常小的区域。
9:37 - 在帕洛阿尔托市中心现在是T-Mobile商店的上方。
9:42 - 但我认识Urs Hölzle，他是我们的早期员工之一；他是我学术上的叔叔，我想。
9:47 - 所以我在不同的计算机会议上多次与他交谈。
9:57 - 因为我们都有计算机和程序优化的背景。你是什么时候感觉到谷歌会像今天这样大的？
10:06 - 你已经在1999年就这样想了吗？是的。我的意思是，我们当时显然有一个非常成功且不断增长的服务。
10:16 - 你可以看到，就像整个公司都可以看到我们的流量每周增长6%、7%、10%。
10:24 - 如果你做1.1的52次方，那是一年内巨大的增长。
10:31 - 而且前几年的很多时间都是在想我们如何在高峰交通时间避免每周二的熔断。
10:40 - 所以我们有一大堆部署新硬件的工作，但这还不够。
10:45 - 我们必须进行软件性能优化，我们必须重新设计系统。
10:51 - 因为当你的软件在规模x上工作时，它突然在规模10x或50x上不起作用。
11:00 - 所以你不断地重新设计这部分系统。
11:05 - 因为现在这是一个大问题，而以前它不是。所以你是什么时候意识到这将会变得很大？
11:14 - 我们的一位早期员工...我们实际上有一面巨大的墙。
11:20 - 他在这堵墙上贴了一张屠夫纸的图表。
11:25 - 它被称为蜡笔图表，因为每天他都会绘制我们周三得到了多少查询。
11:32 - 可能像这样。用不同的颜色标记不同的合作伙伴，然后你会稍微前进一点。
11:38 - 然后他会在纸的顶部用完空间，所以你必须按五倍的比例缩小。
11:43 - 然后重新开始，它会再次长到纸的顶部，然后他会再按另一个五倍的比例缩小。
11:49 - 他做了很多这样的缩放，我们从我刚开始时每天很少的查询。
11:56 - 到更多的查询，然后显然扩展到很多其他产品领域。
12:01 - 这样的事情。你认为自从谷歌成立以来，有什么可以做的不一样的地方吗？
12:08 - 哦，有很多。我认为反思我们做得好的地方总是很好的。
12:14 - 但我们也可以做得更好。我认为一个突出的教训是，每当一个组织快速增长时。
12:24 - 我们也在快速招聘人员，我感觉公司规模每翻一番。
12:30 - 就会导致以前工作得很好的事情不再有效。而且有些变化会导致这种情况；
12:42 - 有时候你们都在一层楼，现在你们在同一栋建筑的多个楼层。
12:47 - 然后有时候你们去了多个建筑，突然间，而不是所有的工程都在山景城完成。
12:55 - 我们开了纽约办公室和苏黎世办公室。现在我们必须弄清楚，好的，你让人们。
13:01 - 在许多不同的地方一起工作？这是在我们现在拥有的视频聊天技术之前。
13:09 - 这有点更具挑战性，要弄清楚谁应该做什么，谁在做什么。
13:15 - 但我们解决了这个问题；我们有一段时间大约有五个工程地点。
13:22 - 我认为我们可以做得更好的一个时期是当我们决定

扩大我们拥有的工程地点数量时。
13:31 - 所以我们从大约5个增加到30个，只用了几年时间，这实际上是为了雇佣不同地方的优秀人才。
13:40 - 他们不一定想搬到我们的某个地点，但我们想，“哦，是的，那个人和这个五人团队，
13:47 - 我们应该围绕他们开一个办公室。” 需要一段时间来消化我们应该如何工作在30个工程地点而不是5个。
13:57 - 因为这些小地点中的每一个都会看着纽约和山景城的主要工程中心说，
14:03 - “我们应该像他们一样做事，” 这意味着处理一切。
14:11 - 我认为如果你在处理一切，但你只有15个人，那这真的行不通。
14:17 - 所以我们试图在一些中心创建一点专业性和专注。
14:23 - 他们可以在一些非常突出和重要的事情上工作，
14:29 - 但我们所做的不同产品只有少数几种。

**AI's Backbone and Computational Power**
14:52 - 你在1990年开始研究神经网络；我们之前谈到过，
14:58 - 那时它受到计算能力不足的极大限制。
15:04 - 你认为计算能力的增长像你当时想象的那样呈指数级增长了吗？
15:11 - 是的。我的意思是，我在大学的最后一年开始接触神经网络。
15:17 - 那是我上的某个课程中的一周模块，但我对它们非常感兴趣；它们看起来像是正确的抽象。
15:24 - 所以我决定和那位教员一起做一个本科研究项目，一个关于...
15:31 - 我觉得我们只是需要更多的计算能力。所以也许我们可以并行训练神经网络。
15:39 - 所以我们可以使用部门里的32处理器机器来训练一个神经网络，而不是只使用一个处理器。
15:44 - 我确信如果我们能使用32倍的计算能力，那将是惊人的。这会很棒。
15:53 - 结果我错了。 - 我们需要的像... - 我们一直在说一百万倍。是的，大约是20年来通用计算产生的一般进步。
16:06 - 然后通过一般的改进，计算机架构改进在半导体制造[听不清]。
16:13 - 制造收缩等等。所有这些都是由于我们的手机现在
16:21 - 比我们过去使用的巨型台式机器强大一百倍或一千倍。
16:28 - 所以我觉得一旦我们开始拥有大约一百万倍的计算能力，
16:35 - 也许在2008年，2009年或2010年，神经网络就能解决真正的问题；
16:41 - 不仅仅是最多小规模的玩具问题，但实际上开始被应用到真正的问题上。
16:48 - 在计算机视觉中。语音识别是一些我们开始关注的早期领域。
16:54 - 然后是各种语言任务；他们能否以一种不同的方式理解单词。
17:04 - 而不仅仅是单词的表面形式？但是，这个词在这种情境下真的有意义吗？
17:11 - 还有其他与这个词相似的词吗？这个词的过去式是什么，你真的能比它只是一系列字符更深入地理解语言吗？

**Evolution of TPU and Future Prospects**
17:17 - 你如何看待TPU未来的演变？
17:34 - 它会变得比过去十年或二十年我们看到的更指数级吗？
17:41 - 你现在是TPU v4还是什么？我们刚刚通过我们的云TPU程序宣布了我们的v5。
17:52 - 所以我们已经为机器学习，特别是神经网络，构建了专门的硬件。
18:00 - 我认为我们的第一个TPU v1是在2015年讨论的。
18:05 - 但神经网络的一个好特性是它们被描述为不同序列的线性代数风格的操作。
18:11 - 不同种类的矩阵乘法，或向量操作，这是你需要计算机做的非常有限的一组事情；
18:20 - 它不像你需要做所有不同的事情，像通用计算代码。
18:28 - 通用CPU非常适合运行你的字处理器，但它们并不是运行机器学习计算的最佳选择。
18:34 - 因为它们太通用了；这种通用性会让你付出性能的代价。相反，如果你构建专门针对神经网络所体现的计算类型的硬件。
18:41 - 你将能够获得巨大的性能提升：每瓦特的性能更好，每美元的性能更好，
18:49 - 以及整体芯片的性能更好。
18:55 - 神经网络的另一个特性是，与许多传统科学计算不同。
19:04 - 你需要相当多的精度，它们实际上对减少精度的算术非常宽容，
19:11 - 所以你可以在8位数字格式或16位浮点格式中进行计算。
19:17 - 而不是通常用于天气模拟代码或其他东西的32位或64位浮点格式。
19:23 - 这意味着你可以在相同的芯片区域内塞入更多的乘法器，并获得更高的性能。

**Neural Networks and Learning Processes**
19:31 - 你经常谈到神经网络的一些限制。
19:38 - 谈谈多任务与单任务，稀疏性与密度。
19:49 - 神经网络在某种程度上是受到真实生物神经网络神经元工作的启发。
19:58 - 人工神经网络中的单个单元接收一些输入，然后对这些输入进行加权。
20:05 - 重要的是这个输入有多重要，那个输入有多重要？
20:14 - 而且重要的是，这些权重是通过学习过程学习的，然后神经元接收所有输入。
20:22 - 然后决定... - 人工神经元？- 人工神经元。并受到真实神经元的启发。
20:31 - 它应该产生什么输出；它应该以某种方式发射还是不产生任何输出。
20:37 - 它应该如何强烈地发射。所以这就是神经网络：
20:40 - 它由许多这样的人工神经元组成，通常按层排列。
20:48 - 所以你有最低层接收非常原始形式的数据。
20:53 - 无论是图像的小补丁，一点音频数据，还是几个文本字符。
20:58 - 然后它们构建有趣的特征。
21:03 - 让我们讨论图像，因为我认为这是思考通过这个学习过程构建的特征的一种容易的方式。
21:11 - 最低级的特征倾向于学习非常简单的事情，
21:17 - 比如这部分图像是否有这个方向的线，或者这部分图像是否主要是灰色，或者主要是红色，或者像不同的颜色？
21:26 - 所以不同的神经元会在看到不同模式时变得兴奋，比如这个神经元变得非常兴奋，“它是鲜红色。哇！令人兴奋！
21:34 - 这个神经元有一条像这样的线。”所以当你向上移动层次时，
22:05 - 这些神经元接收来自低级神经元的输入，它们学习基于引起这些低级神经元兴奋的特征的组合的更有趣和复杂的模式。
22:13 - 所以现在，就像，“哦，它是红色的，并且有一条像这样的线穿过它。
22:22 - 那真的很令人兴奋，”或者它有一条边缘，红色主要在一边而不是另一边。
22:28 - 随着你越来越往上，特征变得越来越复杂，
22:33 - 所以你可能有一些看起来像轮子或像鼻子或眉毛的东西。
22:42 - 甚至更高，你得到完全特征化的东西，就像，“哦，是的，这个在正面视图中的汽车。
22:50 - 或者类似的东西。”我认为这种过程是因为你通常在训练神经网络。
23:00 - 有很多不同的训练方式，但最简单的一种是所谓的监督学习，
23:06 - 你有图像数据，然后你有与这些图像相关的标签。
23:11 - 你说，“好的，那个是汽车，那个是猎豹，那个是树。”
23:17 - 所以模型在顶层的输出是试图预测这些许多不同类别的图像中哪一个。
23:25 - 训练过程的工作方式是你通过模型进行一次前向传递；
23:33 - 你看看模型预测了什么，它说，“好的，看起来像一座塔。”
23:43 - 但也许它实际上是一棵树。所以你能做的就是对模型中的所有权重进行微小的调整。
23:49 - 这样当它看到这张图像或类似的图像时，它更有可能给出正确的答案，说，“实际上是一棵树，而不是塔。” 训练过程就是重复这种观察真实数据。
24:07 - 和它应该是什么，然后对模型的权重进行调整。

**Addressing Bias and Learning from Data**
24:13 - 你如何确保你实际上可以通过淘汰较弱的神经元并提升或促进更强的影响来消除这种看似的偏见？
24:22 - 这听起来就像一种固有的偏见。- 单个神经元还是？- 正确的。
24:31 - 我认为实际发生的情况是不同的神经元会抓住不同种类的模式，其中一些模式对任何特定图像都是无关紧要的。
24:46 - 比如如果它是一张户外场景的图像，所有检测车辆部件的东西都是静音的，
24:51 - 就像它们实际上没有产生大的输出，但所有关于植被和绿色、树干等等的东西。
25:07 - 都非常兴奋。所以我认为
训练神经网络的一部分是，你希望这个模型能够学习到各种不同模式的多样性，
25:16 - 同时你还需要模型有足够的容量，足够多的神经元和参数，
25:22 - 这样它就能从你暴露给它的数据中吸收并学习。如果你只有五个神经元，却给它一百万张图像，
25:29 - 它将无法很好地泛化新的示例。我的意思是，这真的是机器学习中的一件事；
25:37 - 你试图从代表性的数据中学习，但不仅仅是完全记住那些数据，
25:45 - 因为你希望在面对新的图像或新的文本时能够泛化这些示例。
25:52 - 你有多乐观，能够基本上解决这些三个限制或约束，即模态、密度和单任务？
26:07 - 或者你认为这些将通过指数增长和TPU能力得到最佳解决需要多久？
26:17 - 我认为我们在这些方面取得了很多进展。我们已经相当远地将一些模型泛化了，
26:35 - 这些模型以前主要是文本或类似软件代码的，
26:43 - 变成了能够实际理解文本代码、音频输入和图像输入的模型，
26:51 - 所以我认为，通过我的同事和社区其他人在过去三四五年中所做的研究，
26:58 - 已经开始很好地理解了。我认为在多任务能力方面，
27:07 - 我们看到的这些模型是通过在大量通用文本或图像和文本的语料库上训练的，
27:18 - 这给了它们实际泛化到新事物的能力，
27:25 - 就像你说，“好的，给我起草一封给兽医的信，关于我的狗？
27:32 - 狗感觉不舒服。” 模型从未见过确切的要求或请求，
27:40 - 但它能够理解你想要的是什么，并产生听起来合理的文本，实际满足那个人的需求。
27:51 - 你开始看到，不仅仅是从一个数据示例泛化到另一个同一类别的数据示例。
27:56 - 就像10年前，你想要的泛化是拿一张图像，
28:06 - 能够预测它属于哪些类别，从训练了一堆图像和这些类别开始。
28:12 - 现在你看到的是跨任务的泛化能力，
28:18 - 就像让模型做一些它从未被要求做过的事情，
28:26 - 但这些事情足够接近它知道如何做的事情，
28:36 - 并且能够泛化。第三个是稀疏性。所以现在的大多数机器学习模型都是密集的，
28:36 - 这意味着你有所有这些人工神经元，整个模型对每个示例或输入都是激活的。
28:45 - 我们做了很多工作的一种模型，
28:52 - 叫做稀疏模型，实际上有不同的模型部分，模型可以打开和关闭不同的部分。
29:00 - 并且实际上可以学习哪些部分对哪些类型的输入最相关。所以你可能会有一些关于莎士比亚的输入，
29:10 - 所以也许有一个部分非常擅长处理莎士比亚的东西，但关于C++代码或Java编程的部分。
29:18 - 可能在那里不活跃。还有另一个部分非常擅长识别视觉图像中的垃圾车。
29:24 - 那部分可能也不活跃，但你希望这个模型有足够的容量，
29:29 - 所以它有很多部分可以调用，但它不需要为所有事情调用所有部分。
29:35 - 这创造了一个更高效的模型，因为现在不是激活整个模型，
29:41 - 你可能会激活它的5%，这使得它更加节能，但你仍然有这个容量来记住很多东西。
29:49 - 可能不会太远的未来，你会认为你将能够解决这些约束？

**Advancements in Multimodal and Sparse Models**
29:56 - 哦，是的。我认为我们已经看到谷歌研究和谷歌DeepMind在多模态模型方面做了很多工作。
30:03 - 这些模型可以接收视觉输入和语言，
30:08 - 并以文本形式回答问题，或者可以生成...我们已经看到很多关于从各种其他输入生成图像或音频的工作，
30:18 - 你可以拿一个文本提示并生成一个图像，
30:24 - 这些模型在这方面已经稳步改进。现在你可以拿文本加上一个图像，然后说，
30:33 - “好的，给我生成一个有这条狗在前面的巨型城堡的图片。”
30:41 - 它能生成一个城堡和狗的图片很酷，但你真正想要的是你的狗在城堡前面。
30:50 - 你最近或者某个时候在很多计算机科学学生或专家面前做了演讲或讲座。
30:59 - 你谈到了关于机器学习的五个趋势：通用目的、效率、
31:06 - 造福社会、社区和个人，造福工程、科学和健康，
31:12 - 更广泛和更深入。谈谈这些。当然。我认为...
31:20 - 第一部分是关于这些趋势的改进，比如多模态能力、稀疏性等等，
31:29 - 以及我们用来训练它们的底层硬件和系统变得更加强大。
31:37 - 演讲的另一部分是关于这些AI系统今天正在做的事情，
31:46 - 因为我认为很多时候人们在使用各种AI模型，却没有意识到。
31:52 - 例如，在Android手机中，有很多功能是由各种类型的模型驱动的，
32:06 - 所以它可以为你筛选电话，你可以说，“好的，我现在不想接电话。
32:12 - 我只想知道这个人想要什么。” 然后它可以传达他们说的内容。
32:17 - 然后他们说，“哦，嗨，我在前门有个包裹给你，或者什么的，”
32:23 - 或者在电话上，
32:29 - 对各种计算摄影技术进行操作，以增强图像，
32:34 - 能够移除背景中烦人的丑陋电话线，
32:43 - 或者许多其他事情。我认为这些功能通常感觉很神奇，
32:43 - 但它们实际上是由这些机器学习模型驱动的。然后另一部分是关于AI和机器学习，
32:53 - 真正加速了许多科学发现的方面。我认为其中一件事是，
33:02 - 特别是在有大量数据的领域，你正在尝试理解复杂的模式，
33:10 - 比如遗传学或医疗保健或各种天气预测，
33:19 - 很多事情都有大量关于这些问题或领域的数据，
33:27 - 但我们并不一定有深入的理解来理解这些数据，
33:35 - 所以这就是神经网络可以学习数据中的复杂模式的地方，
33:47 - 并且可以创造出以前不存在的新见解或新能力。也许我可以用天气预测作为一个好例子。
33:56 - 所以传统的数值天气预报有一套基于物理的方程式，
34:02 - 关于天气、风和大气如何相互作用，
34:08 - 以预测12小时后或3天后的地面天气会是什么样子。
34:13 - 这很好，但那些简化的方程式可能遗漏了很多东西，
34:21 - 我们并不完全理解。所以当你实际上尝试将神经网络应用于天气预测时，
34:30 - 你以非常不同的方式解决问题。你实际上有大量关于天气条件的历史数据。
34:36 - 四天前，它们是这样的，现在，三天半前，它们是这样的，
34:42 - 甚至三年零一天前，它们是这样的，现在，三年前，它们是这样的。
34:48 - 这给你提供了你的模型应该预测的地面真相。所以给定一千天前的天气，
34:57 - 你能预测999天前的天气吗？事实证明，这是一种相当成功的天气预报方法，
35:03 - 你有大量数据可以训练，然后你想要泛化到你从未见过的新天气情况，
35:09 - 也要泛化到未来。

**Machine Learning and Sensory Perception**
35:17 - 我们能够... 我的意思是，机器学习在阅读文本、理解到一定程度的音频方面做得如此之多、如此之快，
35:24 - 还有视觉，各种各样的视觉，对吧？那么嗅觉呢？我们实际上已经做了一些研究。
35:42 - 温度，你已经可以做到了。所以在谷歌研究中，我们大约四五年前开始在这方面做了一些工作。
35:51 - 结果发现有各种仪器可以感知空气的旧工厂特性，
36:02 - 可以给你关于空气中悬挂着什么的非常原始的数据，
36:07 - 但是要真正给这些数据贴上高层次的标签是很难的。所以同样地，你有图像的像素，
36:14 - 你可以训练一个神经网络说，“好的，当我看到那种东西时，那是一只豹子。”
36:22 - 你可以用这些旧工厂信号做同样的事情，说，“好的，那很像柠檬加一点松针的味道。”
36:27 - 这实际上是有效的。收集数据的实际设备还是有点大，
36:40 - 所以它不像是可以放在手机里的便携式东西，但事实证明这是一个重要的问题，原因有很多。
36:47 - 其中一个原因是，有很多行业想要创造特定的气味，
36:54 - 他们想要能够理解气味，但也要做相反的事情：
37:00 - 创建气味，就像
你已经看到这些图像模型一样，
37:13 - 你可以说出，“请给我一个狗在城堡前的图像”，你会想说出，“请给我我需要混合的东西，
37:19 - 来制造... - 一个女人的香味。或者是炖肉和肉桂的香味。”
37:27 - 所以这在香水行业或消费品行业是一个应用。
37:32 - 但另一个是在医疗保健相关的事情上。有证据表明，狗的鼻子特别敏感，
37:41 - 它们实际上可以在某些情况下察觉到癌症的微妙迹象，
37:46 - 这表明在这些旧工厂原始数据中可能有一个信号，
37:52 - 这实际上可以用于健康目的。关于机器学习可以为人类做些什么，
37:59 - 我们还应该期待什么酷炫的事情？
38:05 - 我对许多不同的应用领域非常乐观。我认为一个是在教育领域。
38:12 - 我们还没到那一步，但快了，可以说是，
38:18 - “你能教我这个吗？” 你拿一章教科书，
38:24 - 你可以想象一个系统吸收那一章或不同书籍的多章，
38:32 - 然后问你问题，评估你回答的正确性，
38:39 - 确定你可能需要更多深度的领域，
38:45 - 并就那些问题问你更多问题，而对那些你似乎已经很好地了解的东西问更少的问题。
38:50 - 所以想象一下，对于你想学的任何东西，无论是在学校的孩子还是成年人，
38:58 - 或者英语。是的，英语很棒。有很多有趣的语言学习应用。
39:04 - 我认为你可能会创造出真正有趣的对话，帮助人们学习语言，
39:10 - 它们会比你现在能说的相当基础的东西更有趣，比如，“我想学英语，
39:17 - 我想谈谈今天的森林徒步旅行或其他什么，”
39:23 - 它可能实际上可以帮助你实现这两个目标：愉快的关于徒步旅行的对话，同时你在学习英语。
39:32 - 我来自一个叫做东南亚的地区，
39:38 - 它有点... 它有点被忽视了。硅谷的人们倾向于谈论世界其他地方，
39:48 - 而不是东南亚，我认为这部分结构性问题是因为我们就是不会说英语。不够多。
40:00 - 新加坡人都会说英语；菲律宾人中有很大一部分会说，
40:08 - 但东南亚其他地方不会。如果我们在五年前进行这次对话，
40:15 - 我会对我们能够与国际社会沟通的未来更加悲观。
40:26 - 现在，随着机器学习或AI的出现，我对让印度尼西亚的1亿人，
40:32 - 能够说英语更加乐观。也许东南亚的4亿人，
40:40 - 从总人口7亿中，能够说英语。这是一个突破；这是改变生活的。
40:45 - 是的，让人们能够相互沟通，我认为这是一件极具影响力的事情，
40:50 - 无论是通过教人们学习第二或第三语言，
40:56 - 还是通过让不说同一种语言的人能够有效沟通。
41:01 - 我们的一些产品，比如谷歌翻译，实际上可以（帮助）；
41:10 - 你把手机放在桌子上，你说一种语言，我说另一种语言，它实际上会产生我们所说的内容的转录版本。
41:16 - 我们还有可以转录成人们耳朵里实际音频的版本，
41:23 - 我认为这是一个非常重要的能力，因为我们能够与所有人沟通得越多，
41:32 - 就越好。这也是机器学习实际上可以真正帮助的地方，因为我们看到了通过这些更大的基于神经网络的模型，
41:40 - 以及不仅仅是五种或十种语言，实际上是一百种语言的翻译质量的戏剧性改进。
41:51 - 谷歌翻译今天支持超过100种语言，这我认为非常重要。
41:56 - 我们实际上有一个雄心勃勃的目标，在我们的产品中支持一千种语言，这有点像是...
42:01 - 嗯，我们在一个国家，印度尼西亚，就有700种。- 我们称之为方言。- 是的。
42:08 - 我的意思是，一千种语言并不是... 我认为世界上有大约7000种口语，
42:14 - 覆盖前一千种（语言）将是惊人的。即使是前一百种也涵盖了很多，
42:21 - 但如果我们不支持那些语言，仍有900种语言的许多使用者被排除在外，
42:28 - 所以我们绝对想要做到这一点。我想和你谈谈可持续性。我想从发展中国家的角度来描绘一下，
42:39 - 事情有点不同。我一直在说可持续性叙事是精英主义的，
42:46 - 因为它与世界约15%的人口产生共鸣，
42:52 - 而85%的人更担心的是把食物放在桌子上，对吧？
42:58 - 他们不介意今天停止使用煤炭，只要替代品是负担得起的。
43:06 - 技术上，替代品是可用的，但经济上，对地球上大多数人来说并不负担得起。
43:14 - 你认为谷歌或你作为一个科学家，
43:19 - 能思考什么来弥合可持续性叙事和发展叙事之间的差距？
43:28 - 因为我认为对于地球来说，集体实现2050年或2060年的碳中和是很重要的。
43:33 - 我认为当我们听到这些人口中的一些人说2050年实现碳中和时，似乎没有现实性，
43:43 - 我们以我们看到的这些人的速度，他们就是买不起这些技术。
43:50 - 我相信你们这栋楼里有很多聪明人可以想出如何通过技术创新让事情变得更便宜。
44:04 - 经济上更便宜。我认为这是一个星球范围内的问题，
44:15 - 我们都需要共同努力解决它。
44:21 - 情况肯定是这样的，经济更发达的国家在历史上产生了更多的排放。
44:27 - - 我们不必到达那里。- 是的。但我认为有几个积极的信号，
44:35 - 所以一个是太阳能电池板等可再生能源的成本一直在急剧改善，
44:43 - 有点像15年前的计算，我们现在看到... - 仍然很高。- 仍然很高。
44:49 - 电池技术也在大幅改进，所以太阳能和电池加上风能，
44:55 - 正在变得更加负担得起。事实上，在世界上许多地方，我认为如果你看看安装新的电力产能，
45:01 - 那实际上成为了经济合理的选择。所以这是个好事，因为我认为我们世界上一直存在的问题是，
45:13 - 有些事情没有被纳入人们的决策中，
45:19 - 比如如果我再安装一个燃煤电厂，它对我来说更便宜，即使它必然导致间接排放，影响每个人。
45:31 - 所以我们一直在研究我们能做些什么来通过技术解决方案改善可持续性和减少排放。
45:40 - 所以其中一个项目叫做Green Light，基本上，通过使用我们可以通过谷歌地图观察到的交通模式，
45:52 - 我们实际上可以识别世界各地的城市可以如何改进他们的交通基础设施，信号等，
46:01 - 以实际减少在十字路口的空闲时间。
46:06 - 这实际上是排放的一个主要来源，就是汽车不动；这也是一个非常情况，人们不喜欢不动；
46:13 - 你坐在车里是为了去某个地方，而空闲发动机的排放实际上相当有害。
46:20 - 所以通过Green Light，我们实际上可以向世界各地的不同城市提出建议。
46:27 - 让他们调整红绿灯定时。世界上大多数红绿灯都有相当简单的方法；
46:35 - 它有点像，是高峰时段还是不是？这是许多红绿灯的精细程度，
46:42 - 但现在我们实际上可以说，“好的，星期二上午10:37到11:30，
46:48 - 你应该将信号定时设置为42秒而不是35秒，你将在你的道路上获得更多的吞吐量，
46:57 - 一个90%的减少，人们需要等待第二个红绿灯周期的数量，” 例如。
47:04 - 所以我们实际上已经在四个或五个大陆上的12个城市进行了试点。
47:11 - 我认为这是一个很好的结果，我们正在从这个早期经验中学习。
47:19 - 与这些城市合作，尝试扩大那个项目。但这个项目已经更广泛地推广了。
47:26 - 并且将对减少排放产生巨大的潜在影响，它也会通过让人们快速到达他们想去的地方来帮助人们，
47:34 - 这也是一个不错的副作用。我们正在讨论的另一个领域是飞机尾迹。
47:41 - 所以你有时看到的飞机后面的长长的线性云；
47:46 - 事实证明，这些实际上对碳排放相当有害，因为它们在一天中的某些时候会捕获热量，
47:55 - 事实上，由飞机产生的飞机尾迹约占航空业总贡献的三分之一。
48:05 - 真的吗？ - 航空业的全部。有点惊讶。三分之一的碳燃烧。
48:10 - 飞机尾迹
实际上是可以避免的。所以如果你是一架飞机，你在飞行，这个高度会产生飞机尾迹，而且这个条件似乎不好，因为那个飞机尾迹可能会造成伤害，你可以实际上改变你的高度，或者稍微上升或下降一点，你就可以到达一个情况，你不会形成飞机尾迹，因为它真的只是围绕飞机排气的小冰晶形成的飞机尾迹。所以我们实际上已经和美国航空公司合作进行了一个控制研究，我们拿了——我忘了确切的数量；大约100个航班，我们给其中50个航班下达了命令，关于我们认为飞机尾迹会在哪些地方产生，以及他们是否应该上升或下降飞行路径，我们所看到的是，在我们控制的航班中，飞机尾迹减少了50%，而没有控制的航班则没有减少。你们是如何控制的？所以我们通过说，好吧，美国航空公司的航班运营会告诉他们上升到31,000英尺而不是30,000英尺之类的，然后实际上，我们如何闭环并弄清楚这一点是很酷的。所以现在你有所有这些航班，所以我们使用实时卫星图像来观察航班发生的时间以及它们所走的路径，然后你可以使用计算机视觉来检测这个航班是否产生了飞机尾迹，而不是那个航班。如果你看一下能源专家的一些出版物，他们预测汽车行业的化石燃料需求将继续下降，但航空业的化石燃料需求正在上升，因为你就是不能电气化长途飞行的飞机。这种方法似乎可以减少大约一半的飞机尾迹造成的变暖，这是航空业影响的三分之一，所以这可能是航空业影响的六分之一。那么食品安全呢？我的意思是，技术上或科学上有很多可以做的来改善现有的惯例。是的，绝对有。我认为这是一个非常广泛的途径，你可以通过很多方式来解决这个问题。所以一个是帮助农民了解他们的作物，比如：“我在这个特定作物的叶子上得到了这些奇怪的图案。这是不是我需要担心的疾病，还是没关系？”计算机视觉模型实际上可以在这方面的帮助。我们已经和其他非营利组织合作部署了一些项目，我想是在肯尼亚或坦桑尼亚，帮助理解木薯叶图像，帮助木薯农民了解如果这是他们需要担心的疾病，如果是的话，他们应该如何治疗。另一个就是预测食物不安全可能发生的地方，因为我们知道，当你等到一个人口处于危机时，实际上已经有点晚了。你宁愿直接给那些还没有陷入危机的人提供帮助，这样他们就可以种植更多的作物或者做一些可以帮助他们避免最糟糕情况的事情。使用机器学习来帮助做出预测，这是谷歌研究与粮农组织合作的事情。AI：人类与盈利能力 - 让我们谈谈AI。 - 好的。说服我们，它将导致一个好的未来。我只是一个普通人，但我认为，显然围绕这个有很多讨论，AI并没有以足够多学科的方式被推进；它只是技术上的，没有引入那些文化、经济、环境、灵性、哲学等方面的专家。我只是认为，这些是重要的，以确保它以良性、明智或明智的方式走到管道的尽头。我绝对同意这一点。我认为，每当你考虑将技术应用于某个问题时，你想引入那些对该领域有很多了解的人，并且与他们合作。我参与过的一些最有趣的项目是我可能有一些技术专长，但我从其他领域的同事那里学到了很多东西；他们是临床医生，他们非常了解这种医疗保健问题。他们可以说，“是的，如果我们能做到这一点，那将非常有帮助。这一点没有那么有帮助。这是一个大问题。这不是一个大问题。我们应该小心这一点。”所以每当我们考虑在不同领域使用AI和机器学习时，我们想把那些全面的人纳入考虑，他们正在思考那个领域，并且正在思考代表性和公平性的问题。如果技术将影响某个社区的人，你想要有来自那个社区的人，说那种语言，或者更深入地了解那个城市或国家的情况，这样他们就可以提供反馈和建议，并共同努力改善事物。这是谷歌做的一件事，因为我们看到AI在我们的产品中使用得越来越多，并且在考虑它在其他领域如何应用。我们实际上制定了一套原则，我们通过这些原则来思考，我们如何确保以负责任的方式应用AI到不同的问题上。我们想要避免产生不公平的偏见，我们想要避免造成伤害，我们想要专注于积极的用例。我们的AI原则，我们在2018年公布，有一套七个原则，我们通过这些原则来思考，我们评估机器学习和AI在这些原则下的后续用途。我认为这实际上是对我们非常有帮助的一件事，因为我们已经考虑AI一段时间了，但其他组织开始考虑在他们的环境、他们的学科或他们的领域中使用机器学习或AI，我认为这对我们来说很有帮助，我们把这些原则公布出去，这样其他组织或其他人就可以反思它们，说，“是的，这很有道理”，或者“在我们的行业中，这个原则不一定那么有意义，但这些原则是共鸣的。”你如何确保你能够找到正确的平衡点，既能保持人性又能保持盈利能力？这很棘手。我们实际上做了很多工作，我们不太担心这是否会盈利，因为这只是为了这个星球做正确的事情，比如我们的飞机尾迹或Green Light工作，我们并不真正担心那是否会盈利；这只是为了这个星球做正确的事情。或者我们在发展中国家做的很多与医疗保健相关的工作，我认为这些是低收入和中等收入国家。我们已经部署了一些基于视网膜图像的机器学习系统，与印度或其他地点的医院合作，帮助诊断像糖尿病视网膜病变这样的疾病。我认为这是一件好事，不管它是否盈利。在其他领域，我们认为AI和机器学习的重要用途，它们提供了经济利益，我们围绕这个创建了商业模式，所以像我们的一些基于云的AI产品，人们会付钱使用它们，因为它们很有用，那很好。所以我认为正确地平衡这两件事很重要，但它不必是非此即彼。今天有一个关于AI领域一位领导者的公告。哦，是的。不提名字，我想把这放在我想从你这里听到的背景下，就目前对人类的利益而言，这应该是开源还是闭源。AI。总的来说。好的，是的。我的意思是，这是一个复杂的问题。我认为我们实际上有很长一段时间的开源发布历史，比如AI工具包的基本构建块，所以我们已经研究了很多年并发布的TensorFlow或JAX，实际上世界上有很多开发者使用TensorFlow创建了各种令人惊奇的东西。我认为这个系统有4000万次下载，现在可能更多了，这使得像我提到的木薯检测示例成为可能。同时，我认为最有能力的一些模型...我认为确保它们以安全的方式部署是很重要的，当你完全向世界发布模型时，它可以有很多惊人的用途，但它也可以以可能不太理想的方式被使用，你无法真正控制这一点。这并不意味着我们不应该开源模型。我认为这是一种平衡，我们希望有令人惊奇的开源模型，人们可以用它们做各种好事，但最有能力的一些模型，我会稍微谨慎一些；你可以向人们提供API访问，他们可以在其上构建东西，但这并不一定意味着我们希望它们完全开放和可用。中国有一个很大的人口，对吧？如果你听到一些来自中国的AI专家的意见，他们似乎认为他们将领先于美国在AI方面，因为他们有更多的数据点。这是关于AI将如何发展的正确的逻辑方式，还是有其他需要考虑的变量？我认为显然AI正在全世界范围内被研究，包括在美国，包括在中国，欧洲的许多人，亚洲和东南亚各地。我认为这是一种与许多事情都密切相关的技术，所以很自然地，到处都有很多人在研究它。我认为这不仅仅是关于领先；而是让每个人都在提高这些系统能做什么的能力，确保它们以有益于人们、公民或公司产品用户的方式部署，或者改善患者或临床医生的生活。我认为有很多事情可以用AI来做，我认为有一个负责任的方法，你正在查看这种技术被使用和部署的方式，并思考它应该如何在未来被使用，这是一件非常有帮助的事情。如果你看一下一些关于AI价值主张的报告，一些预测可能会说，在未来10到15年内，它将带来50到100万亿美元的经济价值。我来自一个发展中国家，你成长于非洲的一些发展中国家等等。从直觉上看，大多数价值似乎会流向美国和中国，对吧？我的意思是，这是我的观点。我想听听你的看法，关于东南亚人民如何能够确信他们能够捕捉到一些价值主张，这可能在全球范围内达到50到100万亿美元，在未来10到15年内。我们该怎么做才能确保我们相关，并且我们参与到这个叙事中？这实际上是一个很好的问题。我认为AI和机器学习日益增长的兴趣是你希望你的国家和其他国家的人们学习这些技术，识别它们可以如何被本地公司、本地大学和开发者应用的方式。我认为这是确保每个人都能参与到AI潜在好处的一种方式，无论是在社会上还是在经济上。你在一个TED演讲中被问到这个问题，我会再问你一次：你如何确保你不会将固有技术中的负面因素带入未来？我们如何确保不会带入？我的意思是，本质上，如果固有技术中有负面偏见。你怎么做才能确保这不是随着而来的？嗯，我认为这绝对是AI和机器学习的风险之一。这些系统从对世界的观察中学习，如果它们观察到世界的工作方式，而我们对某些方式不满意，这些系统将学习复制这种行为，甚至可能加速它，因为你现在可以有一个自动化的决策，比如谁应该获得住房贷款或不应该获得。我们知道这些并不总是完全基于公平的决策；它们有时因为人类的弱点而有偏见，如果你在有偏见的住房贷款决策上训练一个机器学习模型，你现在将有一个自动化的系统，做出有偏见的住房贷款决策。所以有很多工作是在如何处理数据本身有偏见的情况下进行的。确保你可以修正模型，使其不会有那种形式的偏见，但它确实有其他属性。很多这些事物都是学习事物之间的统计关联，有些偏见完全是适当的，比如如果你想让
模型知道单词“purr”与猫有关，
1:05:24 - 那是偏见。 - 呼噜或喵 - 喵。
1:05:29 - 但这不是我们特别关心的偏见，但模型中有些偏见是关于谁获得住房贷款的，
1:05:39 - 我们对此很关心，我认为这部分回到了我们的AI原则。
1:05:47 - 你想寻找并避免有害或不公平的偏见，
1:05:52 - 有很多这样的问题和我们列出的AI原则，
1:06:01 - 其中一些是积极研究的领域，我们有一些技术可以消除或减少偏见，
1:06:09 - 但并没有完全解决这个问题，所以我们想继续确保我们在这些领域进行尖端研究，
1:06:16 - 但也应用我们现有最佳已知技术来解决今天的问题。
1:06:24 - 关于AI的最后一个问题：你从政策制定的角度如何看待它？
1:06:30 - 我有一种感觉，再次作为一个外行，技术人员在世界上许多国家都远远领先于监管者，
1:06:37 - 我认为这对你们的长期利益来说，确保有智慧、知识和知情的一致性非常重要。
1:06:51 - 我们如何将这两者对齐？在发展中国家更有趣，
1:06:57 - 更不用说欠发达国家了。你认为未来会如何发展？
1:07:03 - 我认为总的来说，AI领域的发展速度非常快，
1:07:08 - 这通常与政治和监管决策中固有的谨慎审议过程不相符。
1:07:15 - 我认为让技术人员帮助政策制定者了解目前的可能性是非常有用的，
1:07:30 - 从现在起5年后可能会发生什么，以及5年和10年后可能有哪些潜在路径，
1:07:36 - 这样他们就可以做出明智的决策，比如“我们应该以这种方式规范这种事情；也许我们不应该规范另一种潜在应用。”
1:07:43 - 我经常从AI的实际应用角度考虑这些问题，因为它是一个非常广泛的技术，
1:07:59 - 所以在一个环境中合适的，在另一个环境中可能没有意义，而且通常在特定领域已经存在监管框架，
1:08:11 - 通过一些适度的调整或了解AI如何在该领域中使用，可以修改监管框架，
1:08:25 - 但不需要完全改造。我认为医疗保健是一个很好的例子。世界上很多地方都有医疗保健法规，
1:08:34 - 现在AI正在被应用于一些诊断方法，但监管机构已经存在于这些领域。
1:08:46 - 并且正在思考这些问题。还有一些全新的领域，AI使其成为可能，
1:08:53 - 那里没有现有的监管框架，我认为政策制定者有必要看看，
1:08:59 - “这项技术是什么？它能做什么？可能会发生什么伤害，
1:09:08 - 可能会伤害我们的人口或人民？我们想做什么？”
1:09:15 - 但我也认为，重要的是看看我们如何不阻碍这些方法的潜力，
1:09:28 - 同时仍然保护公共利益免受各种伤害。
1:09:35 - 我认为，总的来说，AI领域的发展速度非常快，
1:09:40 - 这通常与政治和监管决策中固有的谨慎审议过程不相符。
1:09:49 - 我认为让技术人员帮助政策制定者了解目前的可能性是非常有用的，
1:09:55 - 从现在起5年后可能会发生什么，以及5年和10年后可能有哪些潜在路径，
1:10:02 - 这样他们就可以做出明智的决策，比如“我们应该以这种方式规范这种事情；也许我们不应该规范另一种潜在应用。”
1:10:09 - 我经常从AI的实际应用角度考虑这些问题，因为它是一个非常广泛的技术，
1:10:20 - 所以在一个环境中合适的，在另一个环境中可能没有意义，而且通常在特定领域已经存在监管框架，
1:10:34 - 通过一些适度的调整或了解AI如何在该领域中使用，可以修改监管框架，
1:10:41 - 但不需要完全改造。我认为医疗保健是一个很好的例子。世界上很多地方都有医疗保健法规，
1:10:54 - 现在AI正在被应用于一些诊断方法，但监管机构已经存在于这些领域。
1:11:01 - 并且正在思考这些问题。还有一些全新的领域，AI使其成为可能，
1:11:08 - 那里没有现有的监管框架，我认为政策制定者有必要看看，
1:11:15 - “这项技术是什么？它能做什么？可能会发生什么伤害，
1:11:23 - 可能会伤害我们的人口或人民？我们想做什么？”
1:11:30 - 但我也认为，重要的是看看我们如何不阻碍这些方法的潜力，
1:11:37 - 同时仍然保护公共利益免受各种伤害。

**Recruiting Engineers and Personal Life**
1:11:40 - 你感觉到你没有像你想要的那样快速地招聘到优秀的工程师，还是你觉得工程师的供应节奏在谷歌是正确的？
1:11:49 - 我认为这是一个很好的问题。我认为这个转变在过去十年左右的时间里，
1:11:55 - 由于对AI和机器学习的兴趣增加，计算机科学总体上发生了变化...
1:12:02 - 十年前，机器学习是一些人从大学毕业时了解一点的东西，但不是每个人。我认为在过去十年中发生的事情是，
1:12:20 - 由于这些技术能做什么产生了如此大的兴趣，大学真的对此做出了反应，
1:12:34 - 所以现在很难从本科课程中毕业，
1:12:46 - 至少没有上过机器学习课程或以某种方式接触过它。我认为这很有帮助，
1:12:53 - 因为现在我们有更多的人至少对这项技术有所了解，可以理解一些潜在的危害，
1:13:05 - 可能会因为应用它而产生，基本技术，现在可能的事情，
1:13:11 - 以及不太可能但可能很快就会可能的事情。而且这个领域发展得很快，
1:13:17 - 所以你需要人们有这种理解，然后也要跟上变化的步伐。

**Personal Interests and Relaxation**
1:13:24 - 我们已经谈了一个多小时。我感觉就像刚刚上了一个学期的计算机科学课。
1:13:33 - 这很难，伙计。我的意思，你给我的印象是一个硬核科学家，
1:13:38 - 但就个人而言，你做什么来放松？我喜欢和家人在一起。
1:13:46 - 我有两个很棒的女儿，现在她们已经成年了。你听起来像是有猫，因为你经常谈论猫。
1:13:52 - 不，我曾经有猫。我现在已经没有猫了。但我们谈论猫的原因之一是，
1:14:02 - 因为我们以前做过一些无监督学习。基本上，我们拿了YouTube上的1000万个随机帧，
1:14:10 - 随机的YouTube视频，我们在没有任何标签的情况下训练了神经网络。所以系统会学习识别的模式，
1:14:18 - 然后我们就想，“好吧，它学会了识别什么？” 因为这是YouTube，其中之一就是猫。
1:14:26 - 所以我们有一个神经元，当图像中有猫脸时就会触发，
1:14:31 - 尽管它从未被告知什么是猫，这很酷；这有点像人类的学习方式，
1:14:38 - 你主要是作为一个小孩接受世界的，然后你偶尔会得到一点监督，你会像，
1:14:45 - “好吧，那是一只猫。” 然后小孩将他们已经学会的关于构成猫的模糊模式与“猫”这个词联系起来。
1:14:52 - 无论如何，对不起，那是有点离题了。出生在夏威夷，
1:15:03 - 并在非洲和世界其他地方长大，你做任何户外活动吗？- 哦，是的。
1:15:10 - 所以我喜欢做各种运动。我在两个不同的足球联赛中踢球。
1:15:17 - 我坚持在我的联赛的25岁以上年龄组。25岁的孩子似乎每年都变得更快，这很烦人。
1:15:26 - 我必须问你：罗纳尔多还是梅西？- 梅西。- 对不起，罗纳尔多。- 哦，是的。我和你一样。
1:15:33 - 是的，尤其是巴塞罗那的巅峰梅西，就像... - 还有世界杯。- 是的，还有世界杯。
1:15:39 - - 我很高兴他赢得了世界杯。这很棒。看到他赢得世界杯很高兴。他显然是世界上最棒的球员，
1:15:44 - 很高兴看到他赢得世界杯。Jeff，非常感谢你抽出时间。你很亲切。
1:15:49 - 谢谢你。我很感激。- 谢谢你。那是Jeff Dean，谷歌的首席科学家。
1:15:55 - 谢谢你。

# 英文文本

Intro
1:05
Hi friends and fellows. Welcome to this special series of conversations
1:10
involving personalities coming from a number of campuses, including Stanford University.
1:15
The purpose of the series is really to unleash thought-provoking ideas that I think would be of tremendous value to you.
1:22
I wanna thank you of your support so far, and welcome to this special series.
1:29
Hi, we're honored to have Jeff Dean, who's the chief scientist at Google. Jeff, thank you so much for coming on to our show, Endgame.
1:37
Thank you for having me. You've been at Google for a very long time; you're employee number 29 point something.
1:43
I want to ask you about how you grew up. You were born in Hawaii.
1:49
Tell us about how you grew up, how you got interested in computers, and how you've transformed Google into what it is today.
1:57
- Sure. - That's a loaded question, but start with your childhood. Yeah. I think I had a somewhat interesting childhood
Becoming Google's Chief Scientist
2:05
in that my dad did tropical disease research for the first part of my childhood and then switched to being a public health epidemiologist,
2:13
and my mom did medical anthropology, and so they somehow like to move a lot.
2:18
I'm an only child, so every so often we would move. I went to 11 schools in 12 years.
2:26
I was born in Hawaii, then we moved to Boston, then Uganda and Boston and Arkansas and Hawaii and Minnesota and Somalia
2:35
and Minnesota and Atlanta for the last two years of high school, then I went back to Minnesota for college,
2:41
and then I ended up working for the World Health Organization in Geneva for a year and a half
2:46
before going to graduate school in Seattle, and then I came to the Bay Area, and I haven't moved since.
2:52
My kids did not get the same tour of the world that I did, but… It was interesting because seeing a lot of different environments,
3:00
a lot of different schools, a lot of different ways of teaching, and so on, it was different than many people's upbringing.
3:07
Was there a time or a few times when you were pushed or attempted
3:14
to pursue medicine, the area of expertise of both your parents?
3:19
I think I have had an interest in not as a doctor but as like…
3:29
Obviously, conversations around the table growing up were always about public health.
3:36
Actually, the way I got into computing, which is something you asked, was because my dad was always interested in how you could use better information
3:45
to help make better public health decisions. And so he was kind of frustrated at the time.
3:52
This was kind of the mid- to late-70s, when mostly people didn't get to use computers themselves.
4:01
There was a big mainframe in the basement of something, and you would go tell some programmer... - No this was actually in Hawaii. - Okay.
4:08
And you would go tell someone what you wanted the computer to do, and they would do it, and then you would not have this nice
4:15
kind of more natural interactive experience with computing that has come to pass with personal computing,
4:21
but my dad saw an ad in the back of a magazine for a solder it together yourself kind of kit computer called an IMSAI 8080
4:30
that when I was nine, he bought one of these, and I was probably not much help,
4:37
but I held the soldering iron a little bit and helped him solder it together. It didn't do much at first because it didn't have a keyboard or a screen.
4:48
Really, you could toggle together individual bits
4:55
and then like enter them into memory, and you could get little programs going that way. Then we got a keyboard, that was a huge improvement,
5:01
so you could actually type actual characters and so on. But I kind of got interested in that as we got a couple more peripherals;
5:08
you could start to type in computer games in basic, so you type in the source code of a game.
5:14
There was a book I got with a source code for a whole bunch of different games, and you could type it in, and then you could play the game,
5:20
and then I started to get interested in modifying the game a little. This is a good way for, I think, young kids to get interested in programming:
5:28
to have something they want the computer to do, and it's kind of very motivating
5:34
because you can kind of figure it out on your own or like, how would I make the torpedoes go twice as fast in this game or whatever?
5:43
So that was my introduction to computing. And then we were actually quite fortunate to move to Minnesota,
5:51
which at the time had an interactive time-sharing system for all the middle and high schools in the state.
5:58
And so every school got a computer account and some computing hardware
6:03
to dial into this centralized system, and actually they had kind of these interactive chat rooms at the time,
6:13
so it was sort of like what the internet has become, but 20 years before that,
6:18
and so kids in Minnesota were living the internet dream earlier than most.
6:25
Then you moved on to Seattle for your graduate studies after Minnesota?
6:31
Why Seattle? Well, my wife and I were applying to graduate schools together,
6:37
and the complexity of matching programs that were good in her field and my field,
6:43
the University of Washington, was an awesome pick for us. We love Seattle; it's a little gray sometimes and a little rainy.
6:50
My Hawaiian upbringing kind of spoils the weather for most other places,
6:56
but Seattle was great. I really liked my time in graduate school there, and I learned a ton,
7:02
and then I came to the Bay Area. Now, what made you join Google in 1999?
7:11
So I'd actually come down to the Bay Area to work for Digital Equipment Corporation,
7:18
a small research lab in downtown Palo Alto.
7:23
And actually, that was the lab that created AltaVista, which was an early search engine.
7:28
So some of my colleagues there did the early sort of key work on that system,
7:34
and Alta Vista at the time had a much larger index than most people. It was a very fast-responding system,
7:41
and one of my colleagues put together from the crawled pages in the AltaVista index
7:48
a system where you could actually, in sort of programmatic form, see what pages point to which other pages,
7:55
which is not so hard because you could just look at the contents of the page but also what pages point to each page,
8:02
so going backwards in some sense. And so you can navigate this sort of computational graph forwards and backwards
8:10
with this kind of set of API calls, and that proved to be quite interesting.
8:16
So a colleague, Monika Henzinger, and I were working on how you could find related pages to any given web page on the web,
8:26
and we thought we'd have to try fairly complicated things, but we said, "Oh, let's just try something really simple first,
8:33
which is let's look at a page and let's look at what pages point to that page
8:38
and then what other pages do they point to, and then you just do some counting and frequent things,
8:44
and then you divide by to normalize the probabilities.” and all of a sudden, from The Washington Post,
8:51
you would get a list of like CNN and the Wall Street Journal, and the New York Times, or some page about hiking in the Bay Area.
9:00
You'd get a bunch of other pages about hiking in the Bay Area. And that caused me to think there's actually a lot of information
9:07
in the link structure of the web. And ultimately, I decided I wanted to be at a smaller company.
9:15
It was actually a little challenging sometimes to get research you've done out into the world
9:22
through a very big company. I found it was just a little indirect, and so I decided I would come to Google. I knew...
9:30
- A small company. - Yeah. Actually, we were wedged in this tiny little area
9:37
above what's now a T-Mobile store in downtown Palo Alto when I started.
9:42
But I knew Urs Hölzle, who's one of our earlier employees; I knew he'd come here.
9:47
He was sort of my academic uncle, I guess. And so I had chatted with him many times at different computer conferences
9:57
because we both had a background in computers and program optimization. When did you get the sense that Google was going to be as big as it is today?
10:06
Did you think like that already in 1999? Yeah. I mean, we clearly at that time had a really successful and growing service,
10:16
and you could see it, like the whole company could see that our traffic was growing 6, 7, 10% a week at times
10:24
and if you do 1.1 to the 52 that's a huge amount of growth in a year.
10:31
And a lot of the first couple of years were really how can we avoid melting every Tuesday at Peak traffic time.
10:40
So there was a whole bunch of work deploying new hardware, but that wasn't enough.
10:45
We had to do software performance optimization, and we had to sort of redesign the system
10:51
because often when you have software that works at scale x, it suddenly doesn't work at scale 10x or 50x,
11:00
and so you're constantly refiguring out how we're going to redesign this part of the system
11:05
because now it's a big problem whereas it didn't used to be. So when was it that you realized that this was going to be this big?
11:14
One of our early employees… We actually had a giant wall, really long wall,
11:20
and he put up a butcher paper kind of chart on the wall,
11:25
and it was called the crayon chart because every day he would plot, like how many queries we got on Wednesday
11:32
Probably like this. in different colors by different partners, and then you would go along a bit
11:38
and then he would run out of room at the top of the paper so you'd have to scale it down by a factor of five
11:43
and then start over again and it would grow again to the top of the paper and then he would scale it down by another factor of five.
11:49
And so he did many, many scalings, and we went from very few queries per day when I started
11:56
to a lot more queries and then obviously expanded into a bunch of other product areas
12:01
and things like that. Anything that you think could have been done differently since the start of Google?
12:08
Oh so many things. I think it's always good to reflect on what are we doing well,
12:14
but also what could we do better. I mean, I think one lesson that sticks out is that whenever an organization is growing quickly,
12:24
we were also hiring people pretty quickly, and I feel like every kind of doubling in company size
12:30
causes something that used to work well to no longer work. And there's kind of like these leaps of change that cause that;
12:42
sometimes it's you were all on one floor and now you're on multiple floors in the same building,
12:47
and then sometimes then you go to multiple buildings, and then all of a sudden instead of all of your engineering being done in Mountain View,
12:55
we opened a New York office and a office in Zurich. Now we have to figure out, okay, how do you have people
13:01
in many different locations working together? This was before obviously all the technology we have today of video chatting
13:09
and that kind of thing. It was more challenging to figure out who should do what and who is doing what.
13:15
But we worked through that; we had about five engineering locations for a while.
13:22
One period that I think we could have done a little better was when we decided to greatly expand the number of engineering locations we had.
13:31
So we went from about 5 to 30 in a couple of years, and really that was about hiring great people in different places
13:40
who didn't necessarily want to move to one of our locations, but we're like, "Oh yeah, that person and this team of five people,
13:47
we should start an office around them." It took a while to digest how we should work in 30 engineering locations instead of 5
13:57
because each one of these small locations would kind of look at the main engineering centers in New York and Mountain View and say,
14:03
“We should do stuff just like they do," which means work on everything, and I think that doesn't really work if you're working on everything
14:11
but you're 15 people. So we tried to create a little bit of a specialty and focus
14:17
in some of these centers where they get to work on really prominent and important things,
14:23
but on just a handful of the different products we have done.
AI's Backbone
14:52
You started studying neural networks in 1990; we've been talking about that,
14:58
and at that time it was hugely inhibited by the lack of computational power.
15:04
Do you see the computational power having grown as exponentially
15:11
as you would have thought then today? Yeah. I mean, I got introduced to neural networks
15:17
in my senior year as an undergraduate. It was kind of a one-week module in some class I took,
15:24
but I was very intrigued by them; it seemed like kind of the right abstraction, and so I decided to then work with that faculty member
15:31
to do an undergraduate research project, an undergraduate honors thesis on...
15:39
I felt like we just needed more computation. So maybe we could do parallel training of neural networks
15:44
so we could get the sort of 32-processor machine in the department, training a single neural network rather than just using one processor.
15:53
I was convinced that if we could use 32 times as much computational power, it'd be amazing. It would be so great.
16:01
It turns out I was wrong. - We needed like… - We keep saying a million times. Yeah, a million times as much computational power,
16:06
which is sort of what the progress in general computation produced over 20 years or so,
16:13
and then through just general improvements, computer architecture improvements in semiconductor manufacturing [inaudible],
16:21
fabrication shrinks, and so on. All of that is compounded by the fact that our phones are now
16:28
a hundred times or a thousand times as powerful as the giant desktop machines we used to use.
16:35
So I feel like once we started to have about a million times as much computational power,
16:41
maybe in 2008, 2009, or 2010, then it started to be the case that neural networks could solve real problems;
16:51
not just kind of interesting small-scale toy problems at most, but they could actually start being applied to real problems
16:58
in computer vision. And speech recognition was like some of the earlier areas we started to look at
17:04
and then various kinds of language tasks; could they understand words in a way that was different
17:11
than the way the surface form of the word? But really, in what context does this kind of word make sense,
17:17
and are there other words that are similar to that, and what is the past tense of this word, and can you really understand language more deeply
17:26
than if it's just a sequence of characters? How do you see the evolution of the TPU going forward?
17:34
Is it going to get much more exponential than what we might have seen in the last decade or two?
17:41
You are now in TPU v4 or what? We've just announced our v5 through our cloud TPU program.
17:52
So we've been building specialized hardware for machine learning, and in particular neural networks, for quite a while now.
18:00
I think our first TPU v1 was discussed in 2015.
18:05
But really, one of the nice properties that neural networks have
18:11
is that they're sort of all described by different sequences of kind of linear algebra-style operations,
18:20
different kinds of matrix multiplies, or vector operations, and that's a very restricted set of things you need the computer to do;
18:28
it's not like you need to do all kinds of different things like general-purpose computing code.
18:34
And so the general purpose CPUs are great for running your word processor, but they're not exactly what you want for running machine learning computations
18:41
because they're too general; that generality costs you performance. Instead, if you build hardware that is very specialized
18:49
to exactly what kinds of computations neural networks embody,
18:55
you will be able to get huge performance improvements: better performance per watt, better performance per dollar,
19:04
and better performance per overall chip.
19:10
And the other property that neural networks have is that unlike a lot of traditional scientific computing
19:17
where you actually need a fair amount of precision, they're actually very tolerant of reduced precision arithmetic,
19:23
so you could do computations in 8-bit numerical format or 16-bit floating point format,
19:31
unlike 32- or 64-bit floating point format, which is typically used for weather simulation code or whatever,
19:38
and that means you can squeeze more multipliers into the same chip area and get higher performance.
19:45
You've talked quite frequently about some of the constraints with respect to the neural network,
19:51
the modalities of multitasking versus single tasking, and sparsity versus density.
19:58
Talk about those. Sure. I mean, neural networks are sort of loosely inspired
20:05
by how real biological neural network neurons work in that the individual unit in an artificial neural network
20:14
is something that takes in some inputs and then has weights on those inputs. How important does it think this input is versus that one?
20:22
And importantly, those weights are learned through a learning process, and then the neuron takes all that input and then decides...
20:31
- The artificial neurons? - The artificial neuron. And loosely inspired by real neurons.
20:37
It decides what output it should produce; should it fire in some sense or should it produce nothing
20:44
and how strongly should it fire. And so that's really what a neural network is:
20:50
it's composed of a whole bunch of these individual artificial neurons, all typically arranged in layers.
20:58
So you have the lowest layers that take in very raw forms of data,
21:03
be it a small patch of pixels of an image, a little bit of audio data in audio form,
21:12
or a few characters of textual input,
21:17
and then they sort of build interesting features.
21:22
Let's discuss images, because I think that's a very easy way to think about the kinds of features
21:29
that get built up through this learning process. The lowest-level features tend to learn very simple things,
21:38
like is there a line at this orientation in this part of the image or this orientation
21:43
or is it mostly gray or is it mostly red or is it like a different color?
21:51
And so different neurons will get excited when they see different patterns, like this one gets really excited, "It's like bright red. Wow! Exciting!
21:59
And this one has a line like this.” And so as you move up the layers,
22:05
what's happening is that these neurons are taking input from the lower-level ones, and they're learning kind of more interesting and intricate patterns
22:13
that are based on combinations of the features that cause these lower-layer neurons to get excited, so now, it's like, "Oh, it's red, and it's got a line through it like this
22:22
that's really exciting," or it's got an edge with red mostly on one side and not on the other.
22:28
And as you move up farther and farther, the features become more and more complex,
22:33
so you might have something that looks like a wheel or something that looks like a nose or an eyebrow or things like that.
22:42
And even higher, you get sort of fully featured things like, "Oh yeah, this one fires when there's a car with a front-on view of the car
22:50
or something like that." And I think that kind of process happens because typically you are training the neural network.
23:00
There's a lot of different ways of training it, but one of the simplest is what's called supervised learning,
23:06
where you have some image data and then you have labels associated with those images.
23:11
You say, “Okay, that one's a car, that one's a cheetah, that one's a tree.”
23:17
And so the output of the model at the top level is trying to predict which of these many different categories of images is it.
23:25
And the way the training process works is that you make a pass upwards
23:33
through the model—forward pass, it's called; and you see what the model predicts, and it says, “Okay, well, that looks like a tower,”
23:43
but maybe it's really a tree. And so what you can do is then make little teeny adjustments
23:49
to all the weights in the model so that it is more likely when it sees this image or a similar image
23:56
to give the right answer, to say "It's a tree actually, not a tower." And the training process is just repetition of that observation of real data
24:07
and what it should be, and then producing adjustments to the weights of the model.
24:13
How do you make sure that you can actually weed out this seeming bias
24:22
by way of the weaker ones get weeded out and then the stronger ones or influences get promoted?
24:31
That just sounds like an inherent bias. - Individual neurons or? - Correct.
24:37
I think what actually tends to happen is that different neurons will latch on
24:46
to different kinds of patterns, and some of those patterns are irrelevant for any particular image,
24:51
like if it's an image of an outdoor scene, all the things that detect vehicle parts are kind of mute,
24:59
like they don't actually produce large outputs, but all the things that are about foliage and green, trunks of trees, and so on,
25:07
are very exciting. And so I think part of training a neural network
25:16
is that you want this diversity of different kinds of patterns that the model can learn,
25:22
and you also need the model to have enough capacity, enough neurons, and enough parameters
25:29
that it can absorb and learn from the data that you're exposing it to. Like if you have only five neurons and you give it a million images,
25:37
it's not going to do very well to generalize new examples. I mean, that's really one of the things in machine learning;
25:45
you're trying to do is learn from representative data, but not just completely remember exactly what that data was
25:52
because you want to learn when you're confronted with a new image or a new piece of text to generalize those examples.
26:01
How optimistic are you with respect to being able to basically address
26:07
these three concerns or constraints with respect to modality, density, and single-tasking?
26:17
Or how soon do you think those are going to get optimally remedied by way of exponential growth and TPU capabilities?
26:25
I think we're making a lot of progress on them. So we're actually pretty far along at generalizing some models
26:35
that were previously mostly text-only or sort of software code-like
26:43
into models that can actually understand text code, audio input, and image inputs,
26:51
and so that, I think, is starting to be well understood through the research my colleagues and others in the community
26:58
have been doing over the last three, four, or five years. I think in terms of multitask capability,
27:07
one of the things we're seeing with these models that are trained on large corpus of general text or images and text or whatever
27:18
is that that gives them the ability to actually generalize quite well to new things you ask them to do,
27:25
like you say, “Okay, can you draft me a letter to my veterinarian about my dog?
27:32
The dog is not feeling well.” And the model has never seen exactly that requirement or request,
27:40
but it is able to sort of understand what it is you want and to produce plausible-sounding text that actually fulfills that person's need.
27:51
And you're starting to see, not just generalizing from one data example to another
27:56
in the same kind of overall category. Like 10 years ago, the generalization you wanted was to take an image
28:06
and be able to predict which category it's in from having trained on a bunch of images and those categories.
28:12
Now you're seeing the ability to generalize across tasks in some sense,
28:18
like asking the model to do something it's never been asked to do but is kind of close enough to things it knows how to do
28:26
and is able to generalize. And then the third one is sparsity. So most machine learning models these days are dense,
28:36
which means you have all these artificial neurons, and the entire model is kind of activated for every example or every input.
28:45
And there's a form of model that we've done a fair amount of work on,
28:52
called sparse models, where you actually have different pieces of the model, and the model can turn on and off different pieces
29:00
and can actually learn which pieces are most relevant for which kinds of inputs. So you might have some inputs that are about Shakespeare,
29:10
and so maybe there's a part that's really good at kind of Shakespeare stuff, but the part that knows about C++ code or Java programming
29:18
is probably not active there. And there's another part that is really good at identifying garbage trucks in visual images
29:24
that's probably not active either, but you want this model to have a lot of capacity,
29:29
so it's got a lot of pieces of it that it can call on, but it doesn't need to call on all of them for everything.
29:35
And that creates a much more efficient model because now instead of activating the whole model,
29:41
you may be activating 5% of it, and that makes it much more energy efficient, but you still have this capacity to remember a lot of stuff.
29:49
It's probably not going to be too far in the future when you think you're going to be able to address these constraints?
29:56
Oh yeah. I think the multimodal stuff we've already seen a bunch of work from Google Research and Google DeepMind
30:03
on multimodal models of various kinds that can take in visual inputs and language
30:08
and answer questions in text form or that can generate... We've seen a lot of work on generating images or audio
30:18
from various kinds of other inputs, like you can take a text prompt and generate an image,
30:24
and those models for that have been improving steadily. You now can take text plus an image and say,
30:33
“Okay, generate me a picture of a giant castle with this dog in front of it.”
30:41
It's cool that it can generate a picture of a castle with a dog in front of it, but often what you really want is your dog in front of a castle.
30:50
You've recently or some time ago gave a lecture or a talk in front of quite a bunch of computer science students or experts.
30:59
You talked about the five trends with respect to machine learning: general purpose, efficiency,
31:06
benefit to society, community, and people, benefit to engineering, science, and health,
31:12
and broader and deeper. Talk about those. Sure. I think…
31:20
The first part was about these trends of improving the multimodal capabilities of these models, sparsity, and so on,
31:29
and the underlying hardware and systems we use to train them getting more capable.
31:37
Another part of the talk was about what these AI systems are doing today,
31:46
because I think a lot of times people are using various AI models without necessarily realizing it.
31:52
So for example, in the Android phone, there's a lot of capabilities in that phone that are powered by various kinds of models,
31:59
so it can like screen your calls for you, and you can say, "Yeah, I don't want to pick up my phone yet.
32:06
I just want to understand what it is this person wants.” And then it can relay a transcript of what they said.
32:12
Then they say, “Oh hi, I've got a delivery for you at the front door or whatever,”
32:17
or that on the phone,
32:23
do various kinds of computational photography techniques to enhance the images
32:29
to be able to remove that annoying unsightly telephone pull in the background
32:34
when you took your photo, or a variety of other things. And I think these features often feel pretty magical,
32:43
but they're actually often powered by these machine learning models. And then another part was about how AI and machine learning
32:53
are really accelerating a lot of aspects of scientific discovery. I think one of the things that,
33:02
particularly in fields where there's a fair amount of data and you're trying to pick up on complicated patterns
33:10
that are not well understood, like genetics or health care or various kinds of weather prediction,
33:19
a lot of these things have the property that there is lots of data
33:27
about some of these problems or domains, but we don't necessarily have the deep understanding
33:35
to make sense of that data, and so this is where sometimes neural networks that can learn fairly complex patterns from data can actually be useful
33:47
and can create new insights or new capabilities that didn't exist before. Maybe I can use weather prediction as a good example.
33:56
So traditional numerical weather forecasting has like a set of physics-based equations about
34:02
how the weather, the wind, and the atmosphere interact
34:08
in order to make predictions of what's the on-the-ground weather going to be like
34:13
12 hours from now or 3 days from now. And that's great, but those simplified equations probably leave out a lot of things
34:21
that we don't fully understand. And so when you actually try to apply neural networks to weather forecasting,
34:30
you approach the problem very differently. You actually have a fair amount of historical data about the weather conditions.
34:36
Four days ago, they were this, and now, three and a half days ago, they're this,
34:42
or even three years and one day ago, they were this, and now, three years ago, they were this.
34:48
And this sort of gives you the ground truth of what your model should predict. So given the weather a thousand days ago,
34:57
can you predict the weather 999 days ago? And that actually turns out to be a fairly successful approach
35:03
for weather prediction, and you have ample amounts of data to train on, and then you want to generalize
35:09
to new weather situations you've never seen before and also to the future.
35:17
How soon do you think we're going to be able to… I mean, machine learning has done so much, so well, so fast
35:24
with respect to reading text, understanding to some extent, then audio, then visuals,
35:35
all kinds of visuals, right? What about smell? So we actually have done some research.
35:42
Temperature, you can do that already. So within Google Research, we've done some work in this space
35:51
starting about four or five years ago. And it turns out that there are various kinds of instruments
36:02
that can sense the old factory characteristics of the air
36:07
and can give you very raw data about what things are hanging in the air,
36:14
but it's hard to really then put high-level labels on that. So in the same way, you have the pixels of an image,
36:22
and you can train a neural network to say, “Okay, well, when I see that kind of thing, that's a leopard.”
36:27
You can do the same thing with these old factory signals to say, “Okay, that's a lot like lemon with a hint of pine needles or something.”
36:40
And this actually works. The actual device that gathers the data is still a little big,
36:47
so it's not like a portable thing put in a cell phone yet, but it turns out this is an important problem for a variety of reasons.
36:54
One is that there's actually a lot of industries that want to create particular scents,
37:00
and they want to be able to understand a scent but also do the reverse:
37:07
create a scent in the same way you've seen these image models,
37:13
where you can say, "Please give me a dog in front of a castle," You'd like to say, "Please give me what I would need to mix together
37:19
to make a scent of... - Of a woman. of goulash and cinnamon or something."
37:27
And so that's one application is for perfume industries or consumer packaged goods.
37:32
But another one is potentially in healthcare-related things. There's some evidence that dogs which have particularly sensitive noses
37:41
can actually pick up on subtle signs of cancer in some cases,
37:46
and so that indicates that maybe there's a signal in these old factory raw data
37:52
that could actually be used for health purposes. Anything else that we should anticipate in terms of what could be cool
37:59
about what machine learning could be doing to humanity?
38:05
I'm pretty optimistic about a bunch of different application domains. I think one is in the area of education.
38:12
We're not quite there yet, but it's close to being able to say,
38:18
"Can you please tutor me on this?" and you take in a chapter of a textbook,
38:24
and you can imagine a system that absorbs that chapter or maybe multiple chapters from different books
38:32
and then asks you questions, assesses the correctness of what you answered,
38:39
identifies areas where you could use more depth,
38:45
and asks you more questions about that kind of thing and fewer questions about stuff that you seem to already know pretty well.
38:50
So imagine being able to do that for anything you want to learn, either as a kid in school
38:58
- or as an adult. - Or English. Yeah, English is great. There's all kinds of interesting language learning applications.
39:04
I think you might be able to create really interesting dialogues that help people learn language,
39:10
and they're going to be more interesting than the kind of pre-crafted fairly rudimentary things like you could say, “I want to learn English
39:17
and I want to talk about hiking in the forest or something today or whatever,”
39:23
and it could probably help you achieve those two objectives: a pleasant conversation about hiking and you're learning English at the same time.
39:32
I come from a region that's called Southeast Asia,
39:38
and it kind of gets... It's a bit under-narrated. People here in Silicon Valley tend to talk about other places around the world
39:48
as opposed to Southeast Asia, and I think part of the structural problem with that
39:53
is that we just don't speak English. Not enough of us. I mean, Singaporeans, all of them speak English;
40:00
a good chunk of the Filipinos speak it, but the rest of Southeast Asia does not. If we had had this conversation five years ago,
40:08
I would have been a lot more pessimistic about the future where we could actually communicate with the international community.
40:15
Now, with the advent of machine learning, or AI, and all that stuff, I'm a lot more optimistic about getting 100 million people in Indonesia
40:26
to be able to speak English. Maybe 400 million people in Southeast Asia out of the total population of 700 million people
40:32
to be able to speak English. It's a breakthrough; it's lifechanging.
40:40
Yeah, enabling people to communicate with each other, I think, is a hugely impactful thing,
40:45
whether that's through teaching people to learn a second or third language
40:50
or whether it's enabling people who don't speak the same language to communicate effectively.
40:56
Some of our products, like Google Translate, can actually (help);
41:01
you put the phone on the table and you're speaking one language and I'm speaking another, and it will actually produce transcribed versions of what we're saying.
41:10
We also have versions that can be transliterated into actual audio in people's ears,
41:16
and I think that's a really important capability because the more we're able to communicate with all people,
41:23
the better it is. And it's also something where machine learning can actually really help because we've seen just dramatic improvements
41:32
in the capabilities of the quality of translations through these larger neural network-based models
41:40
as well as speech recognition and speech production for not just five or 10 languages but actually for 100 languages.
41:51
Google Translate supports more than 100 languages today, which I think is really important.
41:56
We actually have an ambitious goal to support a thousand languages in our products, and this is sort of a…
42:01
Well, we have 700 of those in just one country, Indonesia. - We call them dialects. - Yeah.
42:08
I mean, a thousand languages is not… I think there's something like 7,000 spoken languages in the world,
42:14
and covering the top thousand (languages) would be amazing. Even the top 100 covers a lot,
42:21
but there's still a lot of speakers in the next 900 who are sort of left out if we don't support those languages,
42:28
so we definitely want to do that. I want to talk to you about sustainability. And I'll draw a picture in terms of how things are a little bit different
Approaching Sustainability with Tech
42:39
in developing countries. I've been saying the narrative of sustainability is elitist
42:46
because it resonates with about 15% of the population of the world,
42:52
whereas the 85%, they're a lot more worried about putting food on the table, right?
42:58
And they don't mind stopping using coal today as long as the alternatives are affordable.
43:06
Technologically, alternatives are available, but economically, they're just not affordable for most people on the planet.
43:14
What do you think Google or you as a scientist
43:19
could be thinking about what can be done to bridge the gap between the narrative of sustainability and the narrative of development?
43:28
Because I think it's important for the planet to be collective about this
43:33
in terms of attaining carbon neutrality by 2050 or 2060. There just seems to be no realism
43:43
when we hear the rhetoric of attaining carbon neutrality by 2050
43:50
at the rate that we're seeing a bunch of these people here that just can't afford it—the technologies.
43:56
And I'm sure you have a lot of smart people here in this building that can figure out how to make things a lot cheaper economically
44:04
by way of technological innovation that's been very exponential.
44:09
I think this is clearly a planet-wide issue,
44:15
and we all need to be working together on it.
44:21
It's definitely the case that the more economically developed countries have produced way more emissions in history.
44:27
- We don't have to get there. - Yeah. But I think there are a few sort of positive signs,
44:35
so one is that the cost of renewable energy like solar panels has been kind of on a dramatically improving curve,
44:43
a bit like computation was 15 years ago, and we're now seeing... - Still high, though. - Still high.
44:49
Battery technology is improving a lot, and so the combination of solar and battery plus wind
44:55
is becoming much more affordable. In fact, in many parts of the world, I think if you look to install new power capacity,
45:01
that actually becomes the economically rational choice. So that's a good thing because I think one of the issues we've had in the world
45:13
is that there are things that are not factored into people's decisions,
45:19
like if I install another coal plant, it's cheaper for me even if it necessarily causes indirect emissions that impact everyone.
45:31
So we've been looking at what are things that we can do to improve sustainability and reduce emissions with technological solutions.
45:40
So one of them is a project called Green Light, where basically, by using traffic patterns that we can observe through Google Maps,
45:52
we can actually identify ways in which cities around the world can make improvements to their traffic infrastructure, signals, and so on,
46:01
to actually reduce idle time at intersections.
46:06
That's actually a major source of emissions is just cars not going anywhere; it's also a situation where people don't really like not going anywhere;
46:13
you're in your car to go somewhere, and the emissions from idle engines are actually pretty harmful.
46:20
And so with Green Light, we can actually make suggestions to different cities all around the world
46:27
and have them adjust the stoplight timing. Most stoplights in the world have fairly simplistic methods;
46:35
it's sort of like, is it rush hour or not? is kind of the level of sophistication in many of them,
46:42
but now we can actually say, "Okay, Tuesdays between 10:37 and 11:30,
46:48
you should set the signal timing to 42 seconds instead of 35, and you'll get way more throughput on your roads,
46:57
a 90% reduction in the number of people who need to wait through a second light cycle," for example.
47:04
And so we've actually got pilots going with 12 cities all around the world. I think it's on like four or five continents, and Jakarta is one of them.
47:11
And so we're actually seeing quite positive results from that, and we're sort of learning from that early experience
47:19
partnering with those cities and trying to sort of expand that program. But that has rolled out much more broadly
47:26
and would have a huge potential impact on reducing emissions, and it would also help people by getting them where they want to go fast,
47:34
which is also a nice side benefit. Another area we're all talk about is contrails.
47:41
So the sort of long linear clouds you see behind airplanes sometimes;
47:46
it turns out those are actually quite harmful for carbon emissions because they trap heat in at certain times of the day,
47:55
and actually, the contrails produced by airliners are roughly one-third of the total contribution to warming in the aviation industry.
48:05
- No kidding. - The entire aviation. Kind of surprising. One-third of the actual burning of carbon.
48:10
One-third of the overall footprint of the aviation industry is related to contrails.
48:17
But contrails are actually avoidable. So if you're a plane and you're flying and the conditions that this altitude would actually produce contrails
48:25
at a time when that's a bad idea because the conditions seem like that contrail would be harmful,
48:32
you can actually change your altitude, or with going up or down a little bit,
48:37
you can actually get to a situation where you won't create a contrail because it's really just ice crystals forming around sort of slick
48:49
from the exhaust of the plane that causes contrails. And so we've actually partnered with American Airlines to do a controlled study
48:58
where we took—I forget exactly how many; about 100 flights and we took 50 of them,
49:05
and we gave them commands about where we thought contrails would be produced
49:10
and whether they should go up or down on their flight path, and what we saw was a 50% reduction in contrails
49:19
for the flights where we were controlling that versus the ones where we did not. And how are you actually controlling?
49:25
So we control it by saying okay, flight... American Airlines flight operations would tell them to go up to 31,000 feet
49:36
instead of 30,000 feet or something, and then actually, it's kind of cool how we closed the loop and figured this out.
49:42
So now you have all these flights, and so we use real-time satellite imagery of when the flights occurred
49:48
and the paths they took, and then you can use computer vision to detect if there was a contrail produced by this flight versus this one.
49:56
If you take a look at some of the publications by experts in energy, the demand for fossil fuels in automotive is going to continue declining,
50:05
but demand for fossil fuels in aviation is going up because you just can't electrify airplanes that fly long haul.
50:15
This approach seems like it might reduce about half of the warming
50:20
related to contrails, which is a third of the overall impact of the industry, so that might be like a sixth of the aviation industry impact.
50:28
What about food security? I mean, there's a lot that can be done technologically or scientifically
50:34
to improve upon a preexisting convention. Yeah, absolutely. I think that has a very broad set of ways that you can approach improving that situation.
50:46
So one is just helping farmers understand their crops,
50:52
and is this: "I'm getting these weird patterns on my leaves of this particular crop.
50:58
Is that a disease I should worry about, or is it fine?" and computer vision models can actually be helpful with this.
51:05
We've done some deployments with other nonprofits working in,
51:12
I think it was Kenya or Tanzania, helping to understand cassava leaf images
51:20
and helping to tell cassava farmers if this is a disease they should worry about
51:26
and if so, how they should treat it. Another is just predicting where food insecurity is likely to occur
51:33
because we know that when you already wait until a population is in crisis,
51:39
it's actually kind of late at that point. You'd rather directly give sort of assistance to people
51:46
that are not yet in crisis so that they can sort of plant more crops
51:53
or do things that will help them avert the most dire situations. Using machine learning to help make predictions there,
52:00
is something that... Google Research is partnering with the FAO (Food and Agriculture Organization)
52:07
to sort of help with that prediction.
AI: Humanity vs Profitability
52:26
- Let's talk about AI. - Okay. Convince us that it's going to lead up to a good future.
52:34
I think obviously there's a lot of discussion around this as…
52:40
Let me just put some context to this. There is a sense, at least from a layman like me,
52:48
that it's not being pushed forward in an adequately multidisciplinary manner;
52:55
it just seems highly technological without roping in those people
53:02
who are experts in culture, economics, environment, spirituality, philosophy, and all that good stuff.
53:08
I just think that those are important to make sure that this goes
53:14
to the end of the pipe in a benign, judicious, or wise manner.
53:21
I definitely agree with that. I think one of the things you want to do
53:27
whenever you're thinking about applying technology to some problem is you want to bring in people
53:33
who have a lot of knowledge about that area and work with them. Some of the most interesting projects I've worked on
53:40
are ones where I might have some technical expertise
53:45
but where I learn a lot from colleagues who have other domain expertise; they're clinicians, and they understand this kind of health care problem extremely well.
53:54
They can say, “Yeah, if we could do this, that would be really helpful. This isn't that helpful. This is a big problem.
54:00
This is not a big problem. We should look out for that." So whenever we're approaching the use of AI and machine learning
54:08
in different domains, we want to bring in that comprehensive set of people
54:14
who are thinking about that domain and who are thinking about issues of representation and fairness.
54:20
If the technology's going to affect people in one community, you want people who are from that community,
54:28
who speak that language, or who understand the situation in that city or country more deeply
54:36
so that they can provide feedback and advice and work together to improve things. This is one of the things that Google has done,
54:45
as we sort of saw more use of AI in our products and were thinking about it
54:51
in terms of where it was going to be applied in other areas. We actually put together a set of principles
54:58
by which we think about how do we make sure that we're responsible
55:04
in thinking about how AI is applied to different problems. We want to avoid creating unfair bias,
55:11
we want to avoid creating harm, and we want to sort of focus on positive use cases.
55:18
Our AI principles, which we published in 2018, have a set of seven principles by which we think about,
55:24
and we evaluate downstream uses of machine learning and AI in terms of those principles.
55:31
And I think it's actually been a helpful thing for us to put those out externally
55:36
because we've been thinking about AI for a while, but other organizations were starting to think about
55:43
using machine learning or AI in whatever environment,
55:48
whatever problem they're engaged in in their discipline or their domain,
55:55
and I think it was helpful for us to put out those principles so other people could or other organizations could reflect on them
56:02
and say, “Yeah, that makes a lot of sense,” or “In our industry, this one doesn't necessarily make as much sense,
56:08
but these other ones resonate.” How do you make sure that you're going to be able to find the right balance
56:15
between humanity and profitability? It's tricky.
56:22
We actually do a fair amount of work that we don't worry too much about; is this going to be profitable because it's just the right thing to do,
56:29
like our contrails or our Green Light work, we don’t really worry about that;
56:35
it's just the right thing to do for the planet. Or a lot of the health care-related work we've been doing in developing countries,
56:43
which I think are low- and middle-income countries. We've deployed some retinal image-based machine learning systems
56:55
to help with diagnosing diseases like diabetic retinopathy in partnership with hospitals in India or at other locations.
57:06
And I think that's a pretty good thing to be doing, regardless of whether that's profitable or not.
57:13
In other areas, we think there's really important uses of AI and machine learning, and they provide economic benefit,
57:20
and we create business models around that, so like some of our cloud-based AI products,
57:27
people pay money to use them because they're useful, and that's fine. So I think getting that balance right is an important thing,
57:34
but it doesn't have to be an either or. There was an announcement today
57:41
with respect to the leadership of one of the AI players. Oh yeah. Without mentioning names,
57:48
I want to put that in the context of what I want to hear from you
57:55
in terms of whether this should be open source or closed source
58:01
for the benefit of humanity for the time being. What should be open source or closed source?
58:07
- AI. Just in general. - Okay, yeah. I mean, I think…
58:13
It's a complicated question. I think we've actually had a long history of open source releases
58:20
of sort of basic building blocks of AI toolkits, so things like TensorFlow or JAX
58:28
we've been working on for many years and releasing, and actually a huge number of developers around the world
58:35
have created all kinds of amazing things with TensorFlow. I think there's 40 million downloads of that system, probably more now,
58:45
that have enabled things like the cassava detection example I mentioned.
58:52
At the same time, I think the most capable models...
58:59
I think it's really good to make sure that they are deployed in a safe manner,
59:04
and when you completely release the model to the world,
59:10
it can have all kinds of amazing uses, but it can also be used in ways that may be less desirable,
59:18
and you don't really have control over that. That doesn't mean we shouldn't open-source models. I think it's a balance,
59:25
like we want amazing models that are open source that people can do all kinds of good things with,
59:31
but the most capable models, I would be a little more circumspect;
59:37
you can offer API access to people, and they can build things on top of that, but that doesn't necessarily mean that we want them
59:44
to be completely open and available.
59:49
China has a large population, right? If you hear some of the experts on AI from China,
59:56
they seem to think that they're going to be ahead of the United States in AI
1:00:02
because they've got more data points. Is that the right logical way to think about how AI is going to move forward,
1:00:09
or are there other variables that need to be taken into account? I think obviously AI is being worked on all across the world,
1:00:20
including in the US, including in China, many people in Europe, and all over Asia and Southeast Asia.
1:00:27
I think it's a technology that is very relevant to many things,
1:00:33
and so it's natural that there's lots of work on it everywhere. I think it's not so much about getting ahead;
1:00:45
it's about everyone working on improving the capabilities of what these systems can do,
1:00:51
making sure that they are deployed in ways that benefit people, citizens, or users of the company's products,
1:01:02
or improving the lives of patients or clinicians.
1:01:07
There are a lot of things that can be done with AI, and I think having a responsible approach where you're looking at the ways
1:01:16
in which this technology is being used and deployed and contemplating how it should be used in the future is a really helpful thing.
1:01:24
If you take a look at some of the reports on the value proposition coming from AI,
1:01:31
some pontifications might say it's going to be between 50 to 100 trillion dollars worth of economic value
1:01:40
in the next 10 to 15 years. I come from a developing country,
1:01:46
and you've grown up in some developing countries in Africa and all that. It just seems from an intuitive standpoint that most of the value
1:01:57
is going to accrue to just the United States and China, right? I mean this is coming from me, my perspective.
1:02:06
I want to hear what your views are with respect to how people in Southeast Asia could actually feel confident
1:02:15
about being able to capture a little bit of that value proposition, which could amount to 50 to 100 trillion dollars globally speaking
1:02:23
in the next 10 to 15 years. What do we need to do to make sure that we're relevant
1:02:30
and that we're participatory in this narrative? It's actually a really good question.
1:02:37
I think the sort of increasing interest in AI and machine learning
1:02:43
is something that you want to encourage people in your country and other countries
1:02:49
to learn about these technologies to identify ways in which they can be applied by local companies,
1:02:57
local universities, and developers in your country.
1:03:03
I think that is a way to make sure that everyone participates
1:03:09
in what is the potential benefits of AI, both socially but also economically.
1:03:17
You were asked this at the TED Talk, and I'm going to ask you again: How do you make sure that you're going to carry forward
1:03:26
the preexisting negativity into the future?
1:03:31
- That we don't carry forward that? - Yeah. In terms of like…
1:03:36
Well, I mean, inherently, there's something that's negatively biased with a preexisting technology.
1:03:44
What do you do to make sure that that's not carried forward with respect to what's good for humanity,
1:03:51
with respect to what's good for the community, the person, and all that stuff? I think this is definitely one of the risks of AI and machine learning.
1:04:01
These systems learn from observations about the world, and if they observe the way the world works
1:04:09
and we are unhappy with the way the world works in certain ways,
1:04:15
these systems will learn to replicate that behavior and maybe even accelerate it
1:04:21
because now you can have an automated decision about, for example, who should get a home loan or not.
1:04:28
We know those are not all always based entirely on fair decisions;
1:04:35
they're sometimes biased in various ways by human fallibility, and that can be perpetuated if you train a machine learning model
1:04:45
on biased home loan decisions. You will now have an automated system that makes biased home loan decisions.
1:04:51
So there's a lot of work on how you take data that itself is biased.
1:04:57
Make sure that you can correct a model so that it doesn't have that form of bias,
1:05:05
but it does have other kinds of properties. A lot of these things are learning statistical associations between things,
1:05:14
and some of that bias is completely appropriate, like if you want the model to know that the word ‘purr’ is associated with cats,
1:05:24
that's bias. - Per or purr - Purr.
1:05:29
But that's not a bias we're particularly concerned with, but there are biases in the model about who gets a home loan
1:05:39
that we are concerned with, and I think this is partly hearkening back to how we think about things in terms of our AI principles.
1:05:47
You want to be looking for and avoiding harmful or unfair bias,
1:05:52
and there's a whole... A lot of those problems and things that we list in our AI principles,
1:06:01
some of those are active areas of research where we have some techniques that can eliminate bias or reduce bias
1:06:09
but not completely solve the problem, and so we want to continue to make sure that we do cutting-edge research on those areas
1:06:16
but also applying the best-known techniques that we have now to the problems at hand for today.
1:06:24
Last question on AI: How do you see it from a policy-making standpoint?
1:06:30
I get the sense, again as a layman, that the technologists are way ahead of the regulators
1:06:37
in many countries around the world, and I think it's in your long-term interest
1:06:43
to make sure that there's an alignment of wisdom, knowledge, and being informed.
1:06:51
How do we align these two? It gets even more interesting in a developing country,
1:06:57
much less underdeveloped country. How do you see that going forward?
1:07:03
I think in general, the field of AI has been moving very fast,
1:07:08
and that's generally at odds with the careful deliberative processes
1:07:15
that are often inherent in politics and regulatory decision-making.
1:07:21
I think it's really useful for technologists to help inform policymakers
1:07:30
about what is currently possible, what is likely to be possible 5 years from now,
1:07:36
and what are the potential paths 5 and 10 years down the road
1:07:43
so that they can be informed and make good decisions about “Okay, we should regulate this kind of thing in this way;
1:07:50
maybe we shouldn't regulate this other potential application.” I often think of these in terms of the actual application of AI
1:07:59
because it's a very broad technology, and so what is appropriate in one setting
1:08:04
may not make the most sense for another, and often there are kinds of regulatory frameworks in particular domains
1:08:11
that already exist, and with some modest changing or informing
1:08:19
about how AI could be used in that domain, that regulatory framework can be modified
1:08:25
but not completely overhauled. I think healthcare is a really good one. There's a lot of healthcare regulations in lots of places in the world,
1:08:34
and now AI is being applied to some kinds of diagnostic approaches,
1:08:41
but regulators already exist in those domains
1:08:46
and are thinking about these issues. There's other things that are like completely new domains that AI enables
1:08:53
where there isn't sort of an existing regulatory framework, and I think it makes sense for policymakers to take a look at
1:08:59
“Okay, what does this technology do? What can it do? What sorts of harms might exist that could happen
1:09:08
that might hurt our populations or people?
1:09:15
And what do we want to do about it?” But I also think it's important to look at how do we not hamper the potential of some of these approaches
1:09:28
but still protect the public interest from harm of various kinds.
1:09:35
Jeff, are you getting the sense that you're not recruiting good engineers
1:09:40
as fast as you want, or are you getting the supply of engineers at the right pace at Google?
1:09:49
I think it's a good question. I think one of the things that this shift to much more focus
1:09:55
on AI and machine learning in computing in general over the last decade or so has...
1:10:02
What has happened is that 10 years ago, machine learning was one thing that some people emerged from university
1:10:12
with a little bit of understanding of, but not everyone. What I think happened over...
1:10:20
Well, particularly from a computer science program, is what I'm talking about. I think what's happened over the last decade
1:10:26
is that there's been such interest created in what these technologies can do that universities are really reacting to this,
1:10:34
and so now it's pretty hard, I think, to emerge from an undergraduate program
1:10:46
without at least taking a machine learning course or being exposed to it in some way. And I think that that's helpful
1:10:53
because now we have more people who understand this technology at least somewhat and can understand some of the potential harms
1:11:05
that can result from applying it, the basic techniques, the kinds of things that are possible now,
1:11:11
and the kinds of things that are not quite possible but are likely to be possible. And the field is moving fast,
1:11:17
so you want people to have that understanding and then also kind of keep up with the changes in what is possible.
What's Up with Cats?
1:11:24
We've talked a little more than an hour. I feel like I've just taken a semester's worth of computer science class.
1:11:33
It's hardcore, man. I mean, you strike me as a hardcore scientist,
1:11:38
but just personally, what do you do to chill? I love hanging out with my family.
1:11:46
I have two wonderful daughters who are now adults. You sound like you have cats because you talk about cats all the time.
1:11:52
No, I used to have cats. I no longer have cats. But part of the reason we talk about cats
1:12:02
is because we were doing some unsupervised learning ages ago. Basically, we took 10 million random frames from YouTube,
1:12:10
random YouTube videos, and we trained the neural network without any labels. So the kinds of patterns the system would learn to pick up on,
1:12:18
and then we sort of said, "Oh, okay, what does it learn to identify?” And since it's YouTube, one of the things was cats.
1:12:26
So we had a particular neuron that would fire when there was a cat face in the image
1:12:31
even though it had never been told what a cat is, which is kind of cool; it's sort of like how humans learn is a very unsupervised thing,
1:12:38
you're mostly just taking in the world as a young child, and then you get an occasional bit of supervision and you're like,
1:12:45
“Okay, that's a cat.” And then the young child associates the kind of vague patterns
1:12:52
they've learned to build up about what constitutes a cat with the word ‘cat’.
1:12:57
Anyway, sorry, that was a bit of a degression. Having been born in Hawaii
1:13:03
and having grown up in Africa and all the other parts of the world, - any outdoor stuff you do? - Oh yeah.
1:13:10
So I like to do various kinds of exercise. I play in two different soccer leagues.
1:13:17
I'm clinging on in the 25 and over age division of my my leagues. The 25 years old seem faster every year, which is annoying.
1:13:26
- I got to ask you: Ronaldo or Messi? - Messi. - Sorry, Ronaldo. - Oh yeah. I’m with you.
1:13:33
Yeah. Particularly peak Barcelona Messi, it was like… - And the World Cup too. - Yeah, and the World Cup.
1:13:39
- I'm glad he won the World Cup. - That was awesome. It's great to see because he's clearly the best player in the world,
1:13:44
and it was nice to see him win a World Cup. Jeff thank you so much for your time. You’ve been kind.
1:13:49
- Thank you. I appreciate it. - Thank you. That was Jeff Dean, the chief scientist at Google.
1:13:55
Thank you.