
# 苦涩的教训

> - [原文链接](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
> - Rich Sutton
> - 2019年3月13日

从70年的人工智能研究中可以得出的最大教训是，利用计算的通用方法最终是最有效的，而且优势巨大。造成这种结果的根本原因是摩尔定律，或者更普遍地说，是单位计算成本持续呈指数级下降。大多数人工智能研究的进行都假设智能体可用的计算量是恒定的（在这种情况下，利用人类知识将是提高性能的唯一方法之一），但是，在比典型研究项目稍长的时间内，计算量不可避免地会变得更大。为了寻求在短期内产生影响的改进，研究人员试图利用他们对领域的专业知识，但从长远来看，唯一重要的是利用计算。这两者不一定相互冲突，但在实践中它们往往如此。花在一个方面的时间就是没有花在另一个方面的时间。人们对其中一种方法或另一种方法的投入存在心理上的承诺。而且，基于人类知识的方法往往会使方法复杂化，从而使其不太适合利用通用方法来进行计算。有很多例子表明，人工智能研究人员迟迟才认识到这一苦涩的教训，回顾其中一些最突出的例子是有益的。

在计算机国际象棋中，1997年击败世界冠军卡斯帕罗夫的方法是基于大规模的深度搜索。当时，大多数计算机国际象棋研究人员对此感到沮丧，他们追求的是利用人类对国际象棋特殊结构的理解的方法。当一种更简单的、基于搜索的方法与特殊的硬件和软件被证明更有效时，这些基于人类知识的国际象棋研究人员并不是好的失败者。他们说，“蛮力”搜索这次可能赢了，但这不是一个通用的策略，而且无论如何，这也不是人类下棋的方式。这些研究人员希望基于人类输入的方法获胜，但当它们没有获胜时，他们感到失望。

在计算机围棋中也出现了类似的研究进展模式，只是推迟了20年。最初人们投入了巨大的努力，通过利用人类知识或游戏的特殊功能来避免搜索，但是一旦搜索被大规模有效地应用，所有这些努力都被证明是无关紧要的，甚至是更糟的。同样重要的是，通过自我对弈进行学习来学习价值函数（就像在许多其他游戏中，甚至在国际象棋中一样，尽管学习在1997年首次击败世界冠军的程序中没有发挥重要作用）。通过自我对弈进行学习，以及一般的学习，就像搜索一样，它可以利用大量的计算。搜索和学习是利用人工智能研究中大量计算的两个最重要的技术类别。在计算机围棋中，就像在计算机国际象棋中一样，研究人员最初的努力方向是利用人类的理解（这样就不需要那么多的搜索），而直到后来，通过采用搜索和学习才获得了更大的成功。

在语音识别方面，20世纪70年代，DARPA赞助了一次早期竞赛。参赛者包括许多利用人类知识的特殊方法——关于单词、音素、人类声道等方面的知识。另一方面，有一些更新的方法在本质上更具统计性，并且基于隐马尔可夫模型（HMM）进行了更多的计算。同样，统计方法胜过了基于人类知识的方法。这导致了整个自然语言处理领域的重大变化，在几十年的时间里，统计和计算逐渐占据了主导地位。最近深度学习在语音识别领域的兴起是这一持续方向上的最新一步。深度学习方法更少地依赖人类知识，并使用更多的计算，结合在大型训练集上的学习，来产生显著更好的语音识别系统。与在游戏中一样，研究人员总是试图让系统按照研究人员认为自己的思维工作的方式工作——他们试图将这些知识放入他们的系统中——但事实证明，这最终适得其反，并且浪费了研究人员的大量时间，因为通过摩尔定律，大量的计算变得可用，并且找到了一种充分利用它的方法。

在计算机视觉中，也有类似的模式。早期的方法将视觉视为搜索边缘、广义圆柱体，或根据SIFT特征来定义的。但今天，所有这些都被抛弃了。现代的深度学习神经网络只使用卷积和某些类型的不变性的概念，并且表现得更好。

这是一个重要的教训。作为一个领域，我们仍然没有彻底吸取它，因为我们还在继续犯同样的错误。要看到这一点，并有效地抵制它，我们必须了解这些错误的吸引力。我们必须吸取苦涩的教训，那就是，构建我们认为自己是如何思考的，从长远来看是行不通的。苦涩的教训基于以下历史观察：1）人工智能研究人员经常试图将知识构建到他们的智能体中；2）这总是在短期内有所帮助，并且让研究人员个人感到满意；3）但从长远来看，它会停滞不前，甚至阻碍进一步的进展；4）突破性的进展最终是通过一种基于通过搜索和学习来扩展计算的相反方法来实现的。最终的成功带有一丝苦涩，而且往往没有被完全消化，因为这是对一种受青睐的、以人为中心的方法的成功。

从苦涩的教训中应该学到的一件事是通用方法的巨大力量，即即使在可用计算变得非常大时，仍能随着计算的增加而继续扩展的方法。似乎以这种方式任意扩展的两种方法是搜索和学习。

从苦涩的教训中可以学到的第二个一般观点是，思想的实际内容是非常、不可救药地复杂的；我们应该停止试图找到简单的方法来思考思想的内容，例如思考空间、物体、多个智能体或对称性的简单方法。所有这些都是任意的、内在复杂的外部世界的一部分。它们不是应该被构建的东西，因为它们的复杂性是无限的；相反，我们应该只构建能够找到并捕获这种任意复杂性的元方法。这些方法的关键在于它们可以找到良好的近似，但对它们的搜索应该由我们的方法完成，而不是由我们完成。我们想要的是能够像我们一样发现的人工智能智能体，而不是包含我们已经发现的东西的智能体。构建我们的发现只会让我们更难看到发现过程是如何完成的。
