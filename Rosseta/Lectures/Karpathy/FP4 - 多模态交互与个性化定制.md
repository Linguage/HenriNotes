

# 多模态交互与个性化定制：音频、图像、视频及 LLM 的个人化

## 音频 (Audio) 输入/输出：开启 LLM 的听觉与发声能力

现在，我们将目光投向 LLM 交互的全新维度——多模态交互 (Multimodal Interaction)。到目前为止，我们讨论的所有内容，都局限于通过文本与模型进行交互。我们输入文本，模型返回文本。但我们希望超越文本的限制，让模型能够以更自然的人类格式与我们进行更丰富的交互。我们希望能够与模型说话，希望模型能够与我们对话。我们希望能够向模型展示图像或视频，反之亦然，我们希望模型能够生成图像和视频。这意味着，LLM 需要具备处理语音和音频这种模态的能力，以及处理图像和视频这种模态的能力。

首先，我想介绍如何非常轻松地与这些模型交谈，也就是音频 (语音) 输入/输出。根据我的个人使用习惯，大约 50% 的时间我会在键盘上输入内容，而另外 50% 的时间我实际上太懒了，不想打字，我只是喜欢和模型说话。当我在手机上使用 LLM 应用时，这一点甚至更明显。在手机上，可能 80% 的查询都是语音输入，因为我太懒了，不想在手机的小屏幕上输入文字。

### 手机 APP 上的语音输入/输出：两种模式

现在，在手机上，事情变得相对容易。现在的ChatGPT 应用程序界面看起来像这样。我想介绍的第一件事是，实际上有两种语音模式。您可以看到有一个小麦克风图标，然后这里有一个小音频图标。这是两种不同的模式，我将分别介绍这两种模式。

第一种语音模式，通过麦克风图标启动。这种模式允许应用程序收听您的声音，然后将您的语音转录为文本。所以您不必手动输入文本，应用程序会将您的音频转换为文本。在手机应用程序上，这个功能非常简单易用，我一直都在使用。您打开应用程序，创建一个新的对话，我只需按下麦克风按钮，然后说出我的问题，例如：“天空为什么是蓝色的？是因为它反射了海洋吗？还是为什么会这样？”说完后，我只需点击 “好的”。我不确定视频中是否能听到声音，但它基本上会将我的音频转换为文本，我只需点击 “开始”，然后我就可以得到模型的文本响应。

所以，第一种语音模式非常简单，核心功能是语音转文本，它简化了文本输入的过程，尤其是在移动设备上。

### 桌面端语音输入：系统级工具的辅助

现在，在桌面上，事情变得稍微复杂一些，原因如下。当我们在桌面应用程序中使用 ChatGPT 时，您会看到我们有音频图标，它提示 “使用语音模式”。我们稍后会介绍这种模式(高级语音模式)。但您会注意到，桌面端 ChatGPT 界面没有麦克风图标，这意味着我不能直接和它说话，并让它在这个应用程序中转录为文本。

我在我的MacBook 上一直使用的是，我基本上依赖一些应用程序，这些应用程序允许您使用语音转文本功能，但它不是特定于 ChatGPT 的，它是一个系统范围的功能，可以将您的音频转录为文本。人们似乎正在使用的一些应用程序是Super Whisper、Whisper Flow、Mac Whisper等等。我目前正在使用的是一个叫做Super Whisper的应用程序，我个人认为它相当不错。

Super Whisper 的工作方式是，您下载应用程序，您将它安装在您的 MacBook 上，然后它总是准备好收听您。所以您可以绑定一个您想要用于此功能的快捷键。例如，我使用 F5 键。每当我按下 F5 键时，Super Whisper 就会开始收听我的声音。然后我可以说一些话，然后我再次按下 F5 键，Super Whisper 会将我刚才说的话转录为文本。让我向您展示一下。我将按下 F5 键，“我有一个问题，天空为什么是蓝色的？是因为它反射了海洋吗？”。好的，文本就出现在那里了，直接输入。我不需要手动输入任何东西。

所以我会说，我的很多查询，可能大约一半都是通过这种方式进行的，因为我不想实际输入文本。现在，很多查询实际上需要我说出产品名称或特定的库名称或各种各样的专业术语，这些词语在语音转录时通常不太容易被正确识别。在这些情况下，我会选择手动输入文本，以确保信息的准确性。但在非常简单的日常使用场景中，我通常能够只与模型交谈，然后系统级的语音转文本工具会正确地转录我的语音输入。

所以这基本上是在输入方面。现在在输出方面，通常使用应用程序，您将有“阅读” 它的选项。它所做的就是获取文本，并将其传递给一个模型，该模型执行文本到语音的反向操作，也就是文本转语音 (Text-to-Speech, TTS)。在ChatGPT中，有这个音频图标，它提示 “朗读”。所以我们可以按下它，“不，不是因为它反映了...这是一个关于为什么...” 好的，我会停止它。所以不同的应用程序，如ChatGPT、Claude、Gemini，或者您正在使用的任何应用程序，可能有也可能没有这个文本转语音功能。但这是您绝对可以寻找的功能。

当您让输入是系统范围的时，您当然可以在任何应用程序中将语音转换为文本。但对于将文本读回给您，不同的应用程序可能有也可能没有这个选项。或者您可以考虑下载一个文本到语音的应用程序，该应用程序是系统范围的，就像这些语音转文本工具一样，并让它大声朗读。

这些是您可以使用的选项，也是我想重点提到的。基本上这里的关键信息是，不要总是手动输入内容，尝试使用语音输入，它工作得很好，我广泛使用这个功能，我会说大约一半的查询，可能更多一点，只是音频输入，因为我很懒，而且语音输入快得多。

### 高级语音模式：突破文本中介，实现真正的音频交互

好的，但我们到目前为止所讨论的只是我所说的“假音频”，它之所以是“假音频”，是因为我们仍然通过文本与模型交互。我们只是让交互过程更快，因为我们基本上是使用语音到文本或文本到语音模型来从音频到文本以及从文本到音频进行预处理。所以，音频和语音并不是真正在语言模型内部直接处理的。

然而，我们现在确实拥有了这项技术，可以实际上做到这一点，作为语言模型内部处理的真实音频。实际上在 LLM 内部处理的，核心是文本 tokens，如果您还记得的话。所以您可以做的是，您可以以不同的模态(如音频)进行分块，类似于您将文本分块为 tokens的方式。

通常所做的是，您基本上将音频分解为频谱图，以查看音频中存在的所有不同频率。您进入小窗口，您基本上将它们量化为 tokens。所以您可以有一个 10 万个可能的小音频块的词汇表，然后您实际上用这些音频块训练模型。所以它实际上可以理解那些小块的音频。这给了模型很多您永远无法通过我们到目前为止所讨论的 “假音频” 获得的能力。

这就是这里的另一个按钮的用途。这就是我所说的“真实音频”，但有时人们会用不同的名字称呼它。例如，当您访问 ChatGPT 定价页面时，您必须寻找这个叫做 “高级语音模式” 的东西。高级语音模式指的就是 “真实音频”。这意味着语音是在语言模型内部本地处理的。模型可以理解音频块并预测音频块，所以它可以直接用音频听到和说话。这里不涉及文本。文本只是一个转录，方便我们人类理解模型在说什么和我们自己说了什么。

所以这非常神奇，它非常好。让我试一下高级语音模式。好的，这就是它的样子。

(演示高级语音模式对话)

**高级语音模式：更自然、更直接的语音交互体验**

好的，所以当您进行这样的对话时，您会看到ChatGPT 实际上会将其转录为文本。但我们必须注意的是，这不像这个文本是在音频之后生成的。实际上发生的是音频 tokens 来回传递，没有涉及文本，就像没有涉及文本一样。文本只是我们进行的音频对话的转录。所以，是的，这很酷。

我确实发现，不幸的是，高级语音非常...它真的不喜欢做事，它会拒绝很多请求。所以，我确实发现它有时有点太尴尬和烦人了。但当它是您... 这是您可以玩和在特定应用程序中使用的一些有趣的东西。

我还想指出，很多这些东西都在非常迅速地发展。例如，我相信今天在 Twitter 上我看到高级语音模式现在也向免费用户推出了。所以我认为这实际上有点过时了。所以您总是必须跟踪什么在什么层级中，这些东西变化很大。但至少您有点像知道这个功能存在，您可以寻找它。

我还想简要地向您展示Grok.com也提供高级语音模式，基本上。但它在您的电脑上的应用程序中不可用，但在应用程序本身中可用。它在右上角有这个小语音图标。您可以使用高级语音模式与 Grok 交谈。

我将向您展示这个样子，非常漂亮。我喜欢 Grok 的原因，我将向您展示，它有很多模式，其中一些模式是真正不受约束的。像OpenAI 非常...就像我提到的，很谨慎，它会拒绝很多请求。Grok 会做一些事情，您知道吗？Grok 会做到。所以如果您喜欢大量的娱乐性，我认为Grok 应用程序更适合这样做。

(演示 Grok 高级语音模式的不同人格模式)

**NotebookLM：播客生成——信息获取的新方式**

好的，我想向您展示的最后一个通过音频与语言模型交互的范例是来自谷歌的这个 NotebookLM。所以，当您访问 notebooklm.google.com时，它的工作方式是，在左边您有“来源” (Sources)，您可以在这里上传任意数据。所以它是原始文本或网页或PDF 文件等等。所以我上传了这个关于 Arc Institute 的基因组序列分析基础模型的 PDF 文件。然后，一旦您把它放在这里，这就会进入模型的上下文窗口。然后我们可以，第一，我们可以与这些信息聊天。所以我们可以提问并得到答案。但第二，有趣的是，在右边，他们有这个“深入的播客” (In-depth podcast)功能。

所以有一个 “生成” 按钮，您可以按下它，等待几分钟，它会根据您在这里输入的任何信息来源生成一个定制的播客。例如，在这里，我们得到了一个关于这篇论文的 30 分钟播客，它能够按需获得播客真的很令人兴奋，如果您出去散步或类似的事情，我认为这有点像有趣和有益的。我有时会上传一些我被动感兴趣的东西，我想获得一个关于它的播客，这只是一些有趣的东西可以听。

让我们看看这会是什么样子，非常简要地。

(演示 NotebookLM 播客生成)

所以这里有一些东西，您可以通过特殊指令定制播客以及它是关于什么的。您可以重新生成它，您也可以进入这个叫做 “交互模式” 的东西，您实际上可以在播客进行时打断并提出问题，我认为这很酷。

我偶尔会使用这个功能，当有一些文档或主题或论文(我通常不是这些方面的专家) 时，我只是有点被动地感兴趣，我出去散步或者我要进行长途驾驶，我想听一个关于这个主题的播客。所以我发现这在像这样的小众情况下很好，人类不会制作另一个播客来介绍它，这有点像一个关于您想要的任何任意小众主题的人工智能播客。

这就是NotebookLM。我还想简要地指出这个我生成的播客，它就像一个叫做 “神秘历史” 的播客系列。我把它上传到了 Spotify 上。在这里，我只是选择了一些我感兴趣的主题，我为所有这些主题生成了一个深入的播客。所以，如果您想了解这个工具的能力，那么这是一个了解质量的好方法。去这个...在 Spotify 上找到这个 “神秘历史”，听听这里的一些播客，了解它能做什么，然后自己尝试一些文档和来源。

这就是使用 NotebookLM进行的播客生成交互。

## 图像 (Image) 输入与 OCR：赋予 LLM 视觉感知能力

好的，接下来我想转向的是图像 (Image)。就像音频一样，事实证明您可以用 tokens 重新表示图像，我们可以将图像表示为 token 流，我们可以让语言模型以与我们之前建模文本和音频相同的方式对它们进行建模。

例如，最简单的方法是，您可以获取一个图像，您基本上可以创建一个矩形网格，并将其切成小块。然后图像只是一个块的序列，您量化每一个块。所以您基本上提出了一个可能有 10 万个块的词汇表，您使用词汇表中最接近的块来表示每个块。这就是让您获取图像并将它们表示为 tokens 流的方式，然后您可以将它们放入上下文窗口中，并用它们训练您的模型。

关于这一点，令人难以置信的是，语言模型，Transformer 神经网络本身，它甚至不知道一些 tokens 碰巧是文本，一些 tokens 碰巧是音频，一些碰巧是图像。它只是模拟 token 流的统计模式，然后只有在编码器和解码器处，我们才知道，图像是以这种方式编码的，然后流以这种方式解码回图像或音频。

所以，就像我们处理音频一样，我们可以将图像切成 tokens，并应用所有相同的建模技术，实际上什么都没有改变，只是 token 流改变了，您的tokens 词汇表改变了。现在让我向您展示一些具体的例子，说明我是如何在自己的生活中使用这个功能的。

### 图像输入应用示例：营养标签、血液测试、牙膏成分与 Meme 理解

好的，从图像输入开始，我想向您展示一些我使用 LLM 的例子，我上传了图像。所以，如果您访问您最喜欢的 ChatGPT 或其他 LLM 应用程序，您通常可以上传图像并向它们提问。

这里有一个例子，我正在查看 Brian Johnson 的长寿混合物的营养标签。基本上，我真的不知道所有这些成分是什么，对吧？我想更多地了解它们，以及为什么它们存在于长寿混合物中。这是一个非常好的例子，首先我想将其转录为文本。我喜欢首先将相关信息转录为文本的原因是，我想确保模型正确地看到了这些值。我不完全确定它能 “看到” 东西。所以在这里，当它把它放入一个表格中时，我可以确保它正确地看到了它，然后我可以向这个文本提问。所以，我喜欢在可能的情况下分两步完成。

然后，例如，在这里我要求它对成分进行分组，我要求它基本上对它们的安全性进行排名，因为我想了解，这些成分中哪些是超级基本的成分，存在于您的复合维生素中，哪些有点更可疑或奇怪，或者没有得到很好的研究，或类似的东西。所以模型非常擅长帮助我思考基本上长寿混合物中有什么，以及可能缺少什么，为什么它在那里等等。这再次是，对于我自己的研究来说，这是一个很好的初稿。

我想展示的第二个例子是我的血液测试。最近我做了一个我的血液测试面板，他们寄给我的东西是这个20 页的 PDF，这非常没用，我应该怎么处理它？所以显然我想知道更多的信息。所以，我在这里做的是，我上传了我所有的结果。首先我做了血脂面板，例如，我上传了我的血脂面板的小截图。然后我确保 ChatGPT 看到了所有正确的结果，然后它实际上给了我一个解释。然后我有点迭代它，您可以看到这里的滚动条非常低，因为我逐个上传了我所有的血液测试结果。顺便说一句，这很好，我对这个血液测试非常满意。

所以我想说的是，第一，注意转录，并确保它是正确的。第二，这样做非常容易，因为在MacBook 上，例如，您可以执行 Control + Shift + Command + 4，您可以绘制一个窗口，它会将该窗口复制粘贴到剪贴板中。然后您可以直接访问您的 ChatGPT，您可以使用 Control V 或 Command V 粘贴它，您可以询问它。所以，使用这种技术，您可以很容易地获取屏幕的各个部分并提问。

然后我想说的另一件事是，当然，这是医疗信息，您不希望它是错误的。我会说，在血液测试结果的情况下，我更有信心信任 ChatGPT 一点，因为这不是什么深奥的东西。我确实期望存在大量的关于血液测试结果的文档，我确实期望模型的知识足够好，它能理解这些数字，这些范围，我可以告诉它更多关于我自己的信息，以及所有这些东西。所以我确实认为它相当不错。但当然，您可能也想和真正的医生谈谈。但我认为这是一个非常好的初稿，也许可以给您一些与您的医生讨论的事情等等。

另一个例子是，我做了很多数学和代码。我在这篇论文中发现了一个棘手的问题。所以我复制粘贴了这个表达式，我要求提供它的文本，因为这样我就可以复制这个文本，我可以问模型它认为 x 在 π 处的值是多少，或类似的东西。这是一个棘手的问题，您可以自己尝试一下。

接下来，我有一个高露洁牙膏，我对我的高露洁牙膏中的所有成分有点怀疑，我想知道这到底是什么。所以这是高露洁牙膏的成分表，这些东西到底是什么？所以它转录了它，然后它告诉我一些关于这些成分的信息，我认为这非常有帮助。然后我问它，“这些中的哪一个会被认为是最安全的，也可能不太安全？” 然后我问它，“如果我只关心牙膏的实际功能，而我真的不关心其他无用的东西，比如颜色等等，我们可以扔掉其中的哪些？”。它说，“这些是必不可少的功能成分，这是一堆您可能不希望在您的牙膏中的随机东西。”。基本上，剧透警告，这里的大部分东西都不应该在那里。所以，公司把所有这些东西都放在您的食物或化妆品等东西里，这真的让我很沮丧，而实际上没有必要。

我想向您展示的最后一个例子是，这不是...所以这是一个我发给朋友的 Meme，我的朋友很困惑，比如，“这是什么 Meme？我不明白。”。我向他们展示了 ChatGPT 可以帮助您理解 Meme。我复制粘贴了这个 Meme，并要求解释。基本上，这解释了 Meme，“多只乌鸦，一群乌鸦被称为谋杀。所以当这只乌鸦靠近那只乌鸦时，就像是谋杀未遂。”。所以，是的，ChatGPT 非常擅长解释这个笑话。

### 图像输出：DALL-E 与无限可能的视觉创意

好的，反之亦然，您可以让这些模型生成图像。OpenAI 对此的提供叫做DALL-E，我们现在是第三个版本，它可以根据基本上任意的提示生成非常漂亮的图像。“这是京都的科隆寺吗？我想我参观过。”。所以这非常漂亮，所以它可以生成非常风格化的图像，并且可以要求任何任意主题的任何任意风格等等。

现在我实际上并没有经常使用这个功能，所以我编造了一个随机的例子，只是为了向您展示。但作为一个例子，“今天的大头条新闻是什么？”。“有很多关于政治、健康、国际、娱乐等方面的头条新闻。”。我为此使用了搜索工具。然后我说，“生成一个总结今天的图像。”。所以，将所有这些都放在上下文中，我们可以生成像这样的图像，有点像总结今天的新闻。这只是作为一个例子。

我使用这个功能的方式通常是用于任意内容创建。例如，当您访问我的 YouTube 频道时，这个视频，“让我们复制 GPT-2”，这里的图像是使用一个竞争对手生成的，实际上，竞争对手是 DALL-E，叫做Ideogram。这个图像也是一样的，这也是由 Ani 生成的。这个图像也是生成的，我认为也是由 Ideogram 生成的，或者这可能是 ChatGPT，我不确定。我互换地使用了一些工具。所以，我用它来生成图标和类似的东西，您可以要求任何您想要的东西。

我会注意到，这实际上是如何工作的，图像输出并没有完全在模型中完成。目前，使用 DALL-E 3，这是一个单独的模型，它接收文本并创建图像。在ChatGPT 的当前迭代中，这里实际上发生的是，当我说“生成一个总结今天的图像”时，这实际上会在底层为该图像创建一个标题，该标题被发送到一个单独的模型，该模型是一个图像生成器模型。所以它有点像以这种方式缝合起来的，但我不认为这在这一点上非常重要。

这就是图像输出。DALL-E 3为我们打开了无限可能的视觉创意空间，您可以根据您的想象力创造出各种各样的图像。

## 视频 (Video) 输入/输出的动态感知

### 视频输入：APP 上的 “指点对话”——让 LLM “看” 到世界

现在接下来我想向您展示一个更进一步的扩展，模型实际上可以像看到视频一样。这包含在我之前向您展示的叫做 “高级语音” 的功能中。它在Web 应用程序上不可用，但在移动应用程序上可用。所以，如果 我们访问高级语音并连接。“你好，我正在演示视频功能，我正在向相机展示那里有一个小视频图标，当你按下它时，你基本上可以看到，你基本上可以向模型展示不同的东西。”。

(演示 “指点对话” 功能)

所以这是一个简短的演示。您基本上让摄像头运行，您可以把它指向东西，您可以和模型说话。这非常神奇，非常简单易用。我个人并没有在我的日常生活中使用它，因为我有点像所有 ChatGPT 应用程序的高级用户，我不会只是四处走动，指着东西，并向模型询问东西。我通常有关于代码和编程等方面的非常有针对性的查询。但我想如果我向我的父母或祖父母演示其中的一些内容，并让他们以非常自然的方式进行交互，我会向他们展示这个。因为他们可以把摄像头指向东西并提问。

现在在底层，我实际上不太确定他们目前是否消耗视频。我认为他们实际上仍然只是获取图像，图像部分，比如他们可能每秒获取一张图像或类似的东西。但从您作为工具用户的角度来看，肯定感觉您可以流式传输视频并让它有意义。所以我认为这是一个非常酷的功能。“指点对话”让 LLM 拥有了 “眼睛”，能够 “看” 到真实世界，并理解视觉信息。

### 视频输出：Sora, Veo 2 等视频生成模型——AI 视频创作的未来

最后，我想简要地向您展示，现在有很多工具可以生成视频，它们令人难以置信，并且它们正在非常迅速地发展。我不会过多地介绍这一点，因为我认为这是不言自明的。我个人并没有在我的工作中使用它们那么多，但这只是因为我没有从事创造性的职业或类似的事情。

这是一条推文，比较了许多人工智能视频生成模型，例如。这条推文大约是一个月前的，所以这可能已经发生了变化。但我只是想向您展示，所有这些模型都被要求生成，我想是在丛林中的一只老虎。它们都很好，我认为现在 VEO 2，我认为是非常接近最先进的，并且非常好。是的，这非常令人难以置信，对吧？这是 OpenAI 的 Sora等等。所以它们都有略微不同的风格，不同的质量等等。您可以比较和对比，并使用其中一些专用于这个问题的工具。

Sora、Veo 2等视频生成模型的出现，预示着 AI 视频创作时代的到来。这些模型能够根据文本描述生成高质量、高逼真度的视频内容，这将极大地降低视频创作的门槛，并催生出全新的视频内容形式和应用场景。


## ChatGPT 记忆与自定义指令：打造个性化 LLM 体验

好的，我想介绍的最后一个主题是一些我认为非常值得一提的生活质量功能。我想谈论的第一个是ChatGPT 的记忆功能。

### ChatGPT 记忆功能：让 LLM 更懂你

假设您正在和 ChatGPT 交谈，您说一些类似这样的话：“你认为好莱坞的巅峰时期大约是什么时候？”。我实际上很惊讶 ChatGPT 给了我一个答案，因为我觉得这些模型通常非常不愿意发表任何意见，它们会说一些类似这样的话：“哦，我只是一个人工智能，我在这里提供帮助，我没有任何意见”等等。所以在这里，它实际上似乎有一个意见，并说评估认为，“在特许经营接管之前的最后一个高峰期是 20 世纪 90 年代到 21 世纪初。”。

我实际上非常同意 ChatGPT 的观点。我非常同意。现在我很好奇这里发生了什么。好的，什么也没发生。所以您可以...基本上每次对话，就像我们讨论的，都从空的 token 窗口开始，一直持续到结束。我做新对话或新聊天的时刻，一切都会被清除。但ChatGPT 确实有能力保存聊天之间的信息，但必须调用它。有时 ChatGPT 会自动触发它，但有时您必须要求它。所以基本上说一些类似这样的话：“你能记住这个吗？”或“记住我的偏好”或类似的东西。所以我要找的是，我想它会工作，我们开始了。

所以您看到这个记忆更新了。“认为 20 世纪 90 年代末和 21 世纪初是好莱坞最伟大的巅峰时期等等。”。是的，所以它还继续谈论了 20 世纪 70 年代，然后它允许您管理记忆。我们稍后会看看这个。但这里发生的是ChatGPT 写了一个关于它了解到的关于我这个人的简要总结，并将这段文本记录在其记忆库中。记忆库基本上是 ChatGPT 的一个单独部分，有点像关于您的知识数据库。这个知识数据库总是添加到所有对话的开头，以便模型可以访问它。

所以，我实际上非常喜欢这个功能，因为每隔一段时间，记忆就会更新。每当您与 ChatGPT 进行对话时，如果您只是让它运行，并且您只是自然地使用 ChatGPT，那么随着时间的推移，它真的会在某种程度上了解您，它将开始引用记忆中的内容。所以当这个功能被宣布时，我不完全确定这是否有帮助，但我认为我肯定会接受它，我已经在很多方面使用了它，我肯定觉得 ChatGPT 随着时间的推移对我有了更多的了解，并且与我更加相关。这一切都是通过自然的互动发生的，并且随着时间的推移，通过这个记忆功能。所以有时它会明确地触发它，有时您必须要求它。

好的，我以为我会向您展示一些记忆以及如何管理它们，但实际上我刚看了一下，老实说，这有点太私人了。它只是一个数据库，它是一个小文本字符串的列表。这些文本字符串只是添加到开头，您可以编辑记忆，我非常喜欢这一点。您可以添加记忆，删除记忆，管理您的记忆数据库。所以这令人难以置信。

我还要提一下，我认为记忆功能是 ChatGPT 独有的。我认为其他 LLM 目前没有这个功能。我还要说的是，例如，ChatGPT 非常擅长电影推荐。所以我实际上认为在它的记忆中有这个将有助于它为我创建更好的电影推荐。所以这很酷。ChatGPT 的记忆功能，让 LLM 真正开始像一个了解您的朋友或助手一样，记住您的偏好，理解您的习惯，并提供更加个性化的服务。

### 自定义指令：塑造专属 ChatGPT 个性

我想简要展示的下一件事是自定义指令 (Custom Instructions)。您可以很大程度上修改您的 ChatGPT以及您希望它如何与您交谈。所以我非常感谢这一点。您可以访问 “设置”，“自定义 ChatGPT”，您会看到这里写着 ChatGPT 应该有什么特征。我只是有点像告诉它，“不要像人力资源业务合作伙伴一样，只是正常地和我说话。”。也只是给我...我只是很多解释，教育，见解等等。“尽可能地进行教育。”。您可以把任何您想在这里输入的东西，您可以稍微试验一下。然后我也在这里试验了告诉它我的身份。我只是在试验这个等等。我也在学习韩语，所以在这里我有点像告诉它，当它给我韩语时，它应该使用这种正式的语气，否则有时...或者这像是一个很好的默认设置，因为否则有时它可能会给我非正式的或者它可能会给我太正式的语气。我只是希望默认使用这种语气。

所以这是我添加的一个例子。所以，任何您想在全球范围内修改 ChatGPT 的东西，在对话之间，您都会把它放在这里，在您的自定义指令中。所以我非常欢迎这一点，我认为您也可以用许多其他 LLM做到这一点。所以，在项目设置中的某个地方寻找它。自定义指令让用户能够根据自己的喜好塑造 ChatGPT 的 “个性”，定制其对话风格、信息输出偏好等等，从而打造更符合个人需求的 LLM 助手。

### 自定义 GPTs：打造专属 AI 工具箱

好的，我想介绍的最后一个功能是自定义 GPTs，我偶尔会使用它们，我喜欢特别将它们用于语言学习。让我给您一个例子，说明我是如何使用这些的。让我先向您展示，也许它们出现在左边。所以让我向您展示，例如，这个。“韩语详细翻译器。”。所以，不，对不起，我想从这个开始。“韩语词汇提取器。”。

所以基本上这里的想法是，我给它...这是一个自定义 GPT。我给它一个句子，它提取词汇表，以字典的形式。所以，例如，给定这个句子，“这是词汇表。”。请注意，它的格式是“韩语；英语”。这可以复制粘贴到 Anki 闪卡应用程序中，基本上这有点像...这意味着将句子转换为闪卡非常容易。

现在它的工作方式是，基本上，如果我们只是进入底层，我们访问 “编辑 GPT”，您可以看到，这只是通过提示完成的，没有什么特别的事情发生在这里。这里重要的是指令。所以当我打开这个 “韩语词汇提取器” GPT 的配置时，我只是解释了一点背景信息。“我正在学习韩语，我是初学者。”。“说明：我会给你一段文字，我希望你提取词汇表。”。然后我给它一些示例输出。基本上，我很详细。当我给 LLM 提供指令时，我总是喜欢第一，给出描述，但也要给出示例。我喜欢给出具体的例子。所以这里有四个具体的例子。

所以，我在这里做的实际上是，我在构建所谓的 Few-shot Prompt。我不仅仅是描述一个任务，这有点像要求在零样本的方式下执行，就像在没有示例的情况下执行它一样。我给它一些示例，这现在是一个 Few-shot Prompt。我发现这总是会提高 LLM 的准确性。所以，这是一种很好的通用策略。

然后，当您更新并保存这个 LLM时，只需给出一个句子，它就会执行该任务。所以请注意，这里没有发生什么新的和特别的事情。我所做的只是为自己节省了一点工作，因为我不必从头开始，然后详细描述整个设置。我不必每次都告诉 ChatGPT 所有这些。

所以这个功能实际上是，它只是为您节省了提示时间。如果有一个特定的提示您一直在重复使用，那么与其重复使用该提示并一遍又一遍地复制粘贴它，不如创建一个自定义聊天，自定义 GPT，保存该提示一次，然后每次使用它时发生变化的是不同的句子。所以，如果我给它一个句子，它总是执行这个任务。

所以，如果有一些您总是重复使用的提示或任务，自定义 GPTs是非常有帮助的。我认为可以转移到所有其他语言的下一个例子是基本翻译。例如，我有这个韩语句子，我想知道它的意思。现在很多人会去谷歌翻译或类似的东西。众所周知，谷歌翻译在韩语方面不是很好。所以很多人使用 Naver 或 Papago 等等。

所以如果您把这个句子放在 ChatGPT 里，没有使用自定义 GPTs，它会给您一个翻译。现在这些翻译通常作为一个翻译来说是可以的，但我实际上并不理解这个句子是如何变成这个翻译的。各个部分在哪里？ 我需要...我想知道更多，我想能够提出澄清的问题等等。所以在这里它有点分解它，但它只是不如，因为它省略了很多东西，对吧？这些通常是助词等等。

所以，我基本上在 GPT 中构建了一个更好的翻译器，我认为它的工作效果要好得多。我创建了一个 “韩语详细翻译器” 自定义 GPT，当我在这里输入相同的句子时，我得到的我认为是好得多的翻译。“现在是下午 3 点，我想去我最喜欢的咖啡馆。”。这就是它的分解方式，我可以准确地看到它的所有部分是如何逐个翻译成英语的。“Chigan，下午”等等。所以所有这些。

这真的很棒，不仅我可以看到所有的细节，而且我可以提出澄清的问题。就在这里，我们可以跟进并继续对话。所以，我认为这在翻译方面比您在互联网上找到的任何东西都要好得多。如果您正在学习不同的语言，我不会使用 ChatGPT 以外的翻译器。它理解大量的细微差别，它理解俚语，它非常好。我不知道为什么翻译器现在还存在，我认为GPT 好得多。

好的，所以它的工作方式是，如果我们访问这里，如果我们编辑这个 “韩语详细翻译器” GPT，只是为了我们可以简要地看到，这些是我给它的指令。“你将得到一个句子，一个韩语句子。你的任务是首先将整个句子翻译成英语，然后详细分解整个翻译。”。所以在这里，我再次创建了一个 Few-shot Prompt。所以这是我给它示例的方式，因为它们有点扩展。所以我使用了一种类似于 XML 的语言，只是为了让模型理解“示例 1 从这里开始，在这里结束。”。我正在使用 XML 标签。

所以这是我给它的输入，这是期望的输出。所以我只是给它几个例子，我有点详细地指定它们。然后我在这里还有一些其他的指令。我认为这实际上与人类非常相似，您如何教人类一项任务。您可以用语言解释他们应该做什么，但如果您通过示例向他们展示如何执行任务，那就好得多。我认为人类也可以以 Few-shot 的方式更有效地学习。所以您可以以您喜欢的任何方式编程这个，然后您得到一个为您设计的自定义翻译器，它比您在互联网上找到的要好得多。根据经验，我发现ChatGPT 在翻译方面相当不错，特别是对于像我这样的初学者来说。

好的，也许我会向您展示的最后一个自定义 GPT，只是因为我认为它结合了一堆功能，如下所示。有时，例如，我正在观看一些韩语内容，在这里我们看到我们有字幕。但字幕被嵌入到视频中，到像素中。所以我无法直接访问字幕。所以，我在这里可以做的是，我可以截取这个屏幕截图，这是 Jinyoung 和 Suki 之间的场景，《单身即地狱》。所以我可以获取它，我可以在这里粘贴它。然后这个自定义 GPT，我称之为“韩语字幕”。“首先对它进行 OCR 处理，然后翻译它，然后分解它。”。所以，基本上，它会这样做。然后我可以继续观看，每当我需要帮助时，我会剪切复制粘贴这里的屏幕截图，这将基本上进行翻译。

如果我们查看它在底层，在“编辑 GPT” 中，您会看到在“指令” 中，它只是简单地给出了...它只是分解了指令。“你将得到一个句子，一个来自电视节目《单身即地狱》的图像裁剪，但您可以更改这个。它显示了一小段对话。”。所以，我给模型提供了一个提示，以及正在发生的事情的上下文。“这些是说明。首先对它进行 OCR 处理，然后翻译它，然后分解它。”。然后您可以做任何您喜欢的输出格式，您可以玩这个并改进它。但这只是一个简单的例子，这工作得很好。

是的，这些是我为自己构建的自定义 GPTs 的类型。其中很多都与语言学习有关。您创建它们的方式是，您来到这里，您点击 “我的 GPTs”，您基本上创建一个 GPT，您可以在这里任意配置它。据我所知，GPTs 对于 ChatGPT 来说是相当独特的，但我认为其他一些 LLM 应用程序可能有类似的功能。所以您可能想在项目设置中寻找它。自定义 GPTs为用户提供了无限的可能，您可以根据自己的需求定制各种各样的 AI 工具，无论是用于语言学习、文本处理、数据分析，还是其他任何领域。

## 总结：LLM 应用的未来——多模态、个性化与无限可能

好的，我可以继续讨论 ChatGPT 中可用的所有不同功能，但我认为这是一个很好的介绍，也是一个关于现在可用内容的鸟瞰图，人们正在引入什么，以及需要注意什么。

总之，有一个快速增长、不断变化、不断转移和蓬勃发展的 LLM 应用程序生态系统，如ChatGPT。ChatGPT是第一个也是现有的，并且可能是其中功能最丰富的。但所有其他的都非常迅速地增长，并且要么达到功能对等，要么甚至在某些特定情况下超过 ChatGPT。例如，ChatGPT 现在有互联网搜索，但我仍然去 perplexity，因为perplexity 已经做了一段时间的搜索，我认为他们的模型相当不错。此外，如果我想原型化一些简单的 Web 应用程序，并且我想创建图表等，我真的很喜欢 Claude Artifacts，这不是 ChatGPT 的功能。如果我只想和模型说话，那么我认为ChatGPT 高级语音现在非常好。如果它对您来说太谨慎了，那么您可以切换到 Grok，诸如此类的事情。

所以，基本上，所有不同的应用程序都有一些优点和缺点，但我认为ChatGPT 到目前为止是一个非常好的默认选项，也是现有的和功能最丰富的。

好的，当我们考虑这些应用程序和它们之间的功能时，我们要注意的一些事情是什么？首先要意识到的是，正如我们所看到的，您基本上是在和一个 zip 文件交谈。注意您处于什么定价层级，以及根据定价层级，您正在使用什么模型。如果您正在使用一个非常大的模型，那么该模型将拥有大量的世界知识，它将能够回答复杂的问题，它将有非常好的写作能力，它将在写作中更有创造力等等。如果模型非常小，那么它可能不会那么有创造力，它拥有的世界知识要少得多，它会犯错误，例如，它可能会产生幻觉。

最重要的是，很多人对这些思考模型非常感兴趣，这些模型是用强化学习训练的，这是当今研究的前沿。特别是，我们看到这非常有用，并且在数学、代码和推理等问题中提供了额外的准确性。所以首先尝试不推理，如果您的模型没有解决这类问题，尝试切换到一个推理模型，并在用户界面中寻找它。

最重要的是，我们看到我们正在迅速地为模型提供更多的工具。例如，我们可以给它们一个互联网搜索。所以，如果您正在谈论一些新的信息或知识，这些信息可能不在 zip 文件中，那么您实际上想使用互联网搜索工具，而且并非所有这些应用程序都有它。此外，您可能想让它访问 Python 解释器，这样它就可以编写程序。例如，如果您想生成图形或绘图并显示它们，您可能想使用高级数据分析之类的东西。如果您正在原型化某种 Web 应用程序，您可能想使用 Artifacts。或者如果您正在生成图表，因为它就在那里，并且在应用程序内部。或者如果您正在专业地编程，您可能想转向一个不同的应用程序，如Cursor 和 Composer。

在所有这些之上，还有一层多模态性，它也在迅速变得更加成熟。您可能想跟踪这一点。所以，我们正在谈论所有不同模态的输入和输出，不仅是文本，还有音频、图像和视频。我们谈到了这样一个事实，即其中一些模态可以有点像在语言模型内部本地处理。有时这些模型被称为全能模型或多模态模型。所以它们可以由语言模型本地处理，这将更加强大，或者它们可以作为与主模型通过文本或类似的东西进行通信的单独模型附加。所以这也是有时需要跟踪的区别。

最重要的是，我们还讨论了生活质量功能。例如，文件上传、记忆功能、自定义指令、自定义 GPTs和所有这些东西。也许我们看到的最后一点是，所有这些应用程序通常都有一个 Web 界面，您可以在您的笔记本电脑上访问它，或者一个移动应用程序，可以在您的手机上使用。我们看到，其中许多功能可能在浏览器中的应用程序上可用，但在手机上不可用，反之亦然。所以这也是需要注意的事情。

所以，所有这些有点像一个动物园，有点疯狂。但这些是存在的各种功能，当您使用所有这些不同的 LLM 标签时，您可能想寻找这些功能。您可能有您自己的最爱，就个性或能力或类似的东西而言。但这些是您想要思考的一些事情，寻找并随着时间的推移进行试验。

所以，我认为这是一个很好的介绍。感谢您的观看，我希望我的例子对您来说很有趣或有帮助。下次见。

