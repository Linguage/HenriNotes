
## 引言：步入大型语言模型应用的蓬勃时代

各位观众，大家好！非常高兴能与大家再次相聚，继续我们的大型语言模型 (LLM) 系列教程。在之前的视频中，我们已经完成了对 LLM底层运作原理的深度剖析，包括它们是如何被训练出来的，以及我们如何尝试去理解它们所展现出的“认知”或“心理”特性。今天，我们将把目光从理论层面转向实践应用，聚焦于这些强大工具的实际应用，深入探索这个正在以前所未有的速度增长的 LLM 生态系统。

本次视频，我希望能够带领大家真正走进 LLM 的应用世界。我将通过大量的实例，生动地展示目前市场上可供选择的各种 LLM 设置，并结合我自身的实践经验，毫无保留地分享我个人是如何有效地使用这些工具的。更重要的是，我希望能够启发您，帮助您找到将 LLM 融入您自身的生活和工作的最佳方式，让这些前沿技术真正为您所用，提升效率，拓展视野。

## LLM 生态系统概览与 ChatGPT 入门


### LLM 生态系统的指数级扩张：ChatGPT 引领的变革浪潮

相信大家对chpt.com 这个网站都不会陌生，它所承载的ChatGPT，正是由人工智能领域的领军者OpenAI精心研发，并于2022 年推向世界的革命性产品。ChatGPT 最重要的意义在于，它是首个真正意义上允许普通用户通过自然语言文本界面，与大型语言模型进行互动对话的工具。它的诞生，彻底打破了 LLM 技术长期以来只停留在实验室和专业领域的局面，将这项强大的技术，以前所未有的便捷方式，带到了公众面前，并在互联网上引发了现象级的传播和应用热潮。毫不夸张地说，ChatGPT 的出现，如同一个划时代的里程碑，标志着 LLM 技术真正“破圈”，开始从专业领域走向大众化应用。

从那时起，LLM 生态系统便进入了指数级扩张的快车道，其发展速度之迅猛，规模之庞大，远超大多数人的预料。我们可以清晰地感受到，LLM 技术不再是少数科技巨头的专属，而是正在迅速渗透到各个行业、各个领域，深刻地改变着我们的工作方式、学习方式、甚至生活方式。

尽管在接下来的具体演示环节，我将主要以 ChatGPT 为例进行详细讲解，但请大家务必认识到，此刻已是2025 年，距离 ChatGPT 诞生已过去三年，整个 LLM 领域早已今非昔比。市场上已经涌现出琳琅满目的、其他类似 ChatGPT 的应用程序，它们在功能、特性、应用场景等方面，都呈现出高度的多样化和差异化。整个 LLM 生态系统，已经变得前所未有的庞大和丰富，各种创新应用层出不穷，令人眼花缭乱。

**ChatGPT：LLM 时代的“开山鼻祖”与“功能集大成者”**

我们可以将 OpenAI 的ChatGPT比作“开山鼻祖”，它不仅是最受欢迎的LLM 应用之一，而且在功能性方面也堪称集大成者。之所以如此，很大程度上归功于它“出现得最早”这一显著的先发优势。ChatGPT 的早期发布，为 OpenAI 积累了宝贵的用户反馈和数据资源，使其能够在后续的迭代升级中，不断优化模型性能，拓展功能边界，从而在竞争激烈的市场中，始终保持领先地位。

然而，我们也不能忽视市场上涌现出的众多“克隆” 产品，虽然用 “克隆” 这个词语可能稍显不公允，但它们中的一部分，确实在某些方面，提供了ChatGPT 尚未涉足的独特体验。这些 “后起之秀”，并非简单的模仿和复制，而是在 ChatGPT 的基础上，进行了大量的创新和差异化探索。例如，一些 LLM 应用可能更加专注于特定领域的专业知识，例如医疗、法律、金融等；另一些则可能在交互方式上进行创新，例如提供更加个性化的对话风格、更加丰富的多模态输入输出支持；还有一些则可能更加注重用户隐私和数据安全，提供更加安全可靠的服务。这些差异化的竞争策略，使得整个 LLM 生态系统更加充满活力，也为用户提供了更多样化的选择。

**科技巨头与创新新秀：多元力量驱动 LLM 产业蓬勃发展**

除了 OpenAI 之外，众多大型科技公司也纷纷重磅入场，凭借其强大的技术实力、雄厚资金支持和庞大的用户基数，在 LLM 领域展开激烈角逐。谷歌的 Gemini，依托谷歌在搜索引擎、人工智能等领域长期积累的深厚技术底蕴，成为了 ChatGPT 最强有力的竞争对手之一。Meta 的 LLM，则充分发挥其在社交网络和内容平台方面的优势，致力于打造更符合社交互动和内容创作需求的 LLM 应用。微软的 Co-pilot，则深度整合了微软 Office 办公套件和 Windows 操作系统，力图将 LLM 技术融入日常办公场景，打造更智能、更高效的办公体验。

与此同时，一批充满创新精神的初创公司也在 LLM 领域异军突起，展现出令人瞩目的活力和潜力。Anthropic 的 Claude，以其对安全性和可解释性的高度重视而闻名，在模型训练和应用开发过程中，始终将安全风险和伦理问题放在首位，赢得了许多对 AI 安全性有较高要求的用户的青睐。埃隆·马斯克的 xAI 旗下的 Grok，则以其特立独行的个性和“不 Political Correct”的鲜明风格，在众多同质化的 LLM 产品中脱颖而出，吸引了一批追求个性化和差异化体验的用户。此外，还有来自中国的DeepSeek和来自法国的Mistral等公司，它们都在 LLM 技术的研发和应用方面做出了积极贡献，打破了欧美科技公司在 LLM 领域的垄断格局，推动着 LLM 技术的全球化发展。值得关注的是，这些 LLM 公司，虽然大多总部位于美国，但我们也欣喜地看到，越来越多的优秀 LLM 产品，开始涌现于中国、法国等国家，这预示着未来的 LLM 产业竞争，将更加全球化和多元化，不同国家和地区的企业，将在 LLM 领域展开更加激烈的创新和竞争。

**追踪 LLM 前沿动态：洞悉行业趋势，把握技术脉搏**

面对如此浩如烟海且日新月异的 LLM 生态系统，我们该如何才能高效地找到这些 LLM 工具，又该如何才能及时地跟踪它们的最新技术进展呢？仅仅依靠传统的互联网搜索，显然已经难以满足需求。幸运的是，除了搜索引擎之外，我们还可以借助一些专业的排行榜和评估平台，这些平台能够为我们提供更加系统化、结构化的 LLM 模型信息和性能评估数据，帮助我们更高效地了解行业动态，把握技术脉搏。

在之前的视频中，我向大家推荐过Chatbot Arena，这是一个非常独特且实用的平台，它采用“众包”的方式，通过让用户参与“盲测” 投票，对不同的 LLM 模型进行用户偏好度排名，并根据投票结果，为每个模型计算出一个Elo 评分。Elo 评分，最初是用于衡量国际象棋棋手竞技水平的评分系统，现在被巧妙地引入到 LLM 评估领域，用于量化不同模型在对话能力和用户体验方面的相对水平。用户可以通过 Chatbot Arena 平台，直接与不同的 LLM 模型进行对话，然后根据自己的主观感受，对模型的对话质量、流畅度、逻辑性等方面进行投票，平台的 Elo 评分系统，会根据用户的投票结果，动态地更新模型的排名，从而反映出不同模型在用户心目中的受欢迎程度和实际表现。

此外，Scale AI Leaderboard也是一个非常值得关注的平台。与 Chatbot Arena 侧重于用户主观感受评估不同，Scale AI Leaderboard 更加专注于对 LLM 模型进行客观性能评估。它会针对一系列预定义的任务，例如语言理解、文本生成、代码编写、数学推理等等，对不同的 LLM 模型进行benchmark 测试，并给出量化的评估指标，例如准确率、召回率、F1 值、BLEU 值 等等。用户可以通过 Scale AI Leaderboard 平台，查阅到不同模型在各种任务上的详细评估结果，从而更全面、更客观地了解不同模型的优势和劣势，并根据自身的需求，选择最适合特定任务的模型。

### 为何选择 ChatGPT 作为 LLM 应用探索的起点

尽管 LLM 生态系统呈现出百花齐放的繁荣景象，我今天的教程，仍然选择从 OpenAI 的 ChatGPT 开始，作为我们探索 LLM 应用世界的首站。选择 ChatGPT 作为入门，并非意味着其他 LLM 产品不够优秀，而是基于以下几点重要的考量：

首先，ChatGPT 无疑是目前最成熟、功能最全面的 LLM 应用之一。经过多年的持续研发和迭代优化，ChatGPT 已经发展成为一个功能强大、性能稳定、用户体验优秀的综合性平台。它不仅在自然语言对话方面表现出色，而且在文本生成、代码编写、创意写作、知识问答等多个领域，都展现出了强大的能力。

其次，ChatGPT 拥有庞大的用户群体和活跃的社区支持。庞大的用户群体，意味着 ChatGPT 拥有丰富的用户反馈和数据资源，这对于模型的持续优化和功能拓展至关重要。活跃的社区支持，则为用户提供了交流学习、问题解答、经验分享的平台，用户可以在社区中找到大量的教程、案例、最佳实践，从而更快地掌握 ChatGPT 的使用技巧，并解决在使用过程中遇到的问题。

最后，ChatGPT 积累了丰富的应用案例和最佳实践。作为 LLM 领域的先行者，ChatGPT 在各个行业、各个领域都涌现出了大量的成功应用案例。这些案例，为我们提供了宝贵的借鉴和参考，帮助我们更好地理解 LLM 的应用价值，并启发我们思考如何将 LLM 应用于自身的工作和生活。

当然，选择 ChatGPT 作为入门，并不意味着我们将止步于此。在接下来的教程中，我将逐步拓展我们的视野，带领大家深入探索Claude、Gemini、Grok等其他 LLM 平台的独特特性和应用场景。我们将逐一剖析它们的优势与劣势，对比它们的功能与特点，帮助您更全面地了解LLM 生态系统的全貌，最终能够根据自身的需求，做出最明智、最合适的 LLM 工具选择。


## 深入 ChatGPT 交互原理与揭示模型本质

## ChatGPT 交互的基石：文本输入与文本输出

现在，让我们真正开始深入探索ChatGPT的奥秘。首先，我们从最基础的层面入手：ChatGPT 的交互原理。当我们打开 ChatGPT 的界面，最先映入眼帘的，通常是一个简洁的文本输入框。那么，这个文本框究竟是用来做什么的？我们应该在里面输入什么内容呢？

理解与语言模型交互的最基本形式非常重要：那就是我们输入文本，然后模型返回文本响应。这种看似简单的文本输入与输出，构成了我们与 LLM 沟通的桥梁。为了更形象地说明这一点，让我们从一个简单的例子开始。假设我们想让 ChatGPT写一首关于大型语言模型的俳句。俳句，作为一种源于日本的短诗形式，以其简洁的语言和深刻的意境而著称。LLM 在写作方面展现出了惊人的能力，无论是俳句、诗歌，还是更实用的求职信、简历，甚至是邮件回复，它们都能游刃有余地胜任。

当我们向 ChatGPT 提出这样的请求——“写一首关于大型语言模型的俳句”时，模型会迅速进行处理，并给出响应，就像这样：

> “词语如溪流，
> 无尽回声，思想不复，
> 思绪无踪影。”

（原文英文版: “Words flow like a stream, endless Echo never mind, ghost of thought unseen.”）

这首俳句，虽然寥寥数语，却颇具戏剧化的意境，仿佛在用诗意的语言，描绘了 LLM 运作的某种神秘感。在 ChatGPT 的界面上，我们看到的是以类似与朋友聊天的对话气泡形式呈现的交互结果。用户输入的信息显示在一个气泡中，模型的响应则显示在另一个气泡中，这种直观的对话形式，使得与 LLM 的交互变得更加自然和亲切。

### Token 化：文本的数字化表示

在之前的视频中，我们已经了解到，无论是用户输入的查询文本，还是模型生成的响应文本，在 LLM 的底层，都会被分解成一个个小的文本块，我们称之为“tokens”。这个文本序列，在模型的内部，实际上被表示为一个一维的 token 序列。理解 “token” 的概念，是深入理解 LLM 工作原理的关键一步。

为了更直观地了解 tokens 的构成，我们可以使用Tik tokenizer这样的在线工具。Tik tokenizer 是 OpenAI 官方提供的 tokenization 工具，它可以帮助我们查看文本被分解成 tokens 后的具体形式。例如，我们可以选择GPT-4 模型，然后将我们刚才的俳句请求文本——“写一首关于大型语言模型的俳句”——粘贴到 Tik tokenizer 的文本框中。点击 “Tokenize”，工具就会立即显示出模型实际看到的内容。

对于模型来说，我们输入的这段文本，并不是我们人眼所见的文字，而是一个由15 个 tokens组成的序列。模型的词汇表中，大约有20 万个可能的 tokens，Tik tokenizer 显示的，正是与我们的查询文本相对应的token ID。您可以尝试修改输入的文本，实时查看 token 序列的变化，感受文本与 tokens 之间的转换关系。

通过 Tik tokenizer，我们可以看到，我们的查询文本—— “写一首关于大型语言模型的俳句” —— 被分解为了15 个 tokens，而模型生成的俳句响应—— “词语如溪流，无尽回声，思想不复，思绪无踪影。” —— 则由19 个 tokens构成。这首俳句，正是由这 19 个 tokens 按照一定的顺序排列组合而成的。

### 对话格式的幕后：构建一维 Token 流

由于 ChatGPT 的交互形式是对话，因此我们需要保留大量元数据，以维护对话的上下文信息，例如对话历史、用户身份等等。实际上，在底层，情况要比我们看到的对话气泡复杂一些。为了让模型更好地理解对话的上下文，我们需要将用户查询转换为特定的聊天格式。

为了简化理解，我在这里删除了系统消息，因为它对于理解当前情况来说，并不是至关重要的。我们可以将用户的消息标记为用户输入，然后将模型的响应标记为助手输入。

通过这样的标记，我们就能更清晰地看到实际的底层情况。在 tokens 序列中，会存在一些特殊的 tokens，用于表示用户消息的开始，然后是用户实际说的话(tokenized)，接着是用户消息的结束，然后是助手消息的开始，以此类推。虽然对话格式的具体细节并不重要，但我想表达的核心观点是：在我们看来是来回的聊天气泡，但在底层，我们实际上是在与模型协作，共同写入一个 token 流。这两个气泡，实际上构成了一个由42 个 tokens组成的序列。我贡献了前面的 tokens(用户输入)，然后模型继续生成后面的 tokens作为响应(助手输出)。我们可以交替添加 tokens，共同构建一个token 窗口，或者更准确地说，一个一维的 token 序列。

回到 ChatGPT 的界面，我们看到的仍然是来回的聊天气泡，但现在，我们应该在脑海中建立起一个更深层次的理解：在这些看似独立的对话气泡背后，隐藏着的是一个一维的 token 序列。当我们点击“New Chat”按钮时，会发生什么呢？正如我们之前讨论过的，点击 “New Chat” 实际上会清除当前对话的token 窗口，将tokens 数量重置为零，从而重新开始一个全新的对话。

**上下文窗口：对话的“工作记忆”**

在我与模型进行对话时，我脑海中浮现的图景是这样的：当我们点击“New Chat”时，就如同开启了一个全新的 token 序列。这是一个一维的、线性的token 序列。用户可以向这个 token 流中写入 tokens，当我们按下回车键时，对话的控制权就转移到语言模型。语言模型接收到用户输入的 tokens，然后开始生成它自己的 token 流作为响应。语言模型在生成响应的过程中，会持续不断地输出 tokens，直到它生成一个特殊的 token，这个特殊的 token 表示“我说完了”。当 ChatGPT 应用接收到这个 “结束” token 时，它会将对话的控制权交还给我们，我们就可以轮流发言，你一句，我一句，就像人类之间的对话一样。在这个过程中，我们与模型共同构建了一个token 流，这个 token 流，就是我们所说的“上下文窗口”。

上下文窗口，可以形象地比喻为这次对话的“工作记忆”。模型可以直接访问上下文窗口中的任何内容，包括用户之前输入的所有信息，以及模型之前生成的所有响应。正是 благодаря 上下文窗口的存在，模型才能够理解对话的上下文语境，记住之前的对话内容，并在后续的对话中，保持对话的连贯性和一致性。

### LLM 的本质：互联网知识的压缩容器

现在，让我们进一步思考一个更深层次的问题：我们正在与之交谈的这个实体，究竟是什么？我们应该如何看待它？在之前的视频中，我们了解到，语言模型的训练过程，主要分为两个主要阶段：预训练 (Pre-training)和后训练 (Post-training)。

预训练阶段，可以形象地比喻为把整个互联网的文本数据，切分成一个个 tokens，然后将这些 tokens压缩成一个 zip 文件。但是，这个 zip 文件并非我们常见的、精确无损的压缩文件，而是一个有损的、概率性的 zip 文件。之所以说是 “有损” 和 “概率性”，是因为我们不可能将整个互联网的海量信息，都精确地压缩到一个，比如 1TB 大小的 zip 文件中，互联网的信息量实在太大了。我们只能将大概的内容和风格，以一种压缩的方式，存储进去。

这个 “zip 文件” 中，实际上存储的是神经网络的参数。例如，一个 1TB 大小的 “zip 文件”，可能对应着神经网络中大约一万亿个参数。这个神经网络所做的事情，就是接收 tokens，并尝试预测序列中的下一个 token。但需要注意的是，它是在互联网文档的海量数据上进行预测的，所以从本质上来说，它就像是一个互联网文档生成器。在预测序列中的下一个 token的过程中，神经网络潜移默化地获得了关于世界的大量知识，这些知识，都被压缩存储到了这大约一万亿个参数之中。

预训练阶段的成本非常昂贵，可能需要花费数千万美元，并持续几个月的训练时间。因此，预训练阶段不会经常进行。例如，GPT-4 模型，很可能是在几个月甚至一年前就已经完成了预训练。这也就是为什么这些模型会有点过时，它们有一个“知识截止” 日期，这个日期对应着模型预训练完成的时间。模型的知识，只更新到那个时间点为止。

虽然部分知识可以通过后训练阶段进入模型，我们稍后会讨论这个问题。但总的来说，您应该将这些模型看作是有点过时的，因为预训练成本太高昂，而且不会频繁进行。所以，任何最新的信息，比如你想和模型谈论上周发生的事情，我们需要其他方式来为模型提供这些信息，因为它没有存储在模型的知识库中。在后续的教程中，我们将介绍各种工具，帮助我们为模型补充最新的信息。

**后训练：为模型注入“助手灵魂”**

在预训练之后，是后训练阶段。如果说预训练阶段是生成了一个 “知识压缩包”，那么后训练阶段，就如同给这个 “zip 文件” 加上一个笑脸。这是为什么呢？因为我们不希望模型仅仅生成互联网文档，我们更希望它能够扮演一个助手的角色，积极地回应用户的查询，并提供有价值的帮助。后训练过程，正是为了实现这个目标而设计的。

在后训练阶段，我们会将模型训练所用的数据集替换为由人类构建的对话数据集。这些对话数据集，通常包含了大量的用户查询和高质量的助手回复示例。通过在这些对话数据集上进行训练，模型逐渐学会了助手的对话风格，例如如何礼貌地回应用户，如何清晰地表达观点，如何提供有用的信息等等。在这个过程中，模型获得了助手的 “灵魂”，使得我们可以像与一个智能助手聊天一样，向它提问，并期望它能够给出有帮助的回答。值得强调的是，虽然模型在后训练阶段获得了助手的风格，但它仍然拥有整个互联网的知识，这些知识是在预训练阶段获取的。后训练阶段，只是将预训练获得的知识，与助手的对话风格有机地结合在一起，从而打造出一个既博学又善于沟通的智能助手。

### 理解 LLM 的本质：与 “压缩知识库” 对话

我认为，对于本部分内容，需要理解的最重要一点是：您正在交谈的对象，是一个完全独立的实体。默认情况下，这个语言模型，就是一个磁盘上的 1TB 文件，这个文件代表着一万亿个参数，以及它们在神经网络中的精确设置。它的核心功能，就是试图为你提供序列中的下一个 token。但请记住，这是一个完全独立的实体，它没有计算器，没有计算机和Python 解释器，没有互联网浏览能力，什么都没有。在我们目前讨论的范围内，还没有涉及到任何工具的使用。您现在正在和一个 “zip 文件” 对话，如果您向它输入 tokens，它会返回 tokens。这个 “zip 文件”，拥有预训练阶段获得的互联网知识，以及后训练阶段获得的助手风格和对话形式。这就是您应该大致理解这个实体的方式。

如果让我总结一下到目前为止我们所讨论的内容，我可能会以介绍 ChatGPT 的方式来进行，我认为您也应该这样看待它：

“嗨，我是 ChatGPT，我是一个1TB 的 zip 文件。我的知识来自互联网，我大约在六个月前完整地阅读了它，但我只记得大概的内容。我的迷人个性是由 OpenAI 的人类标注员通过大量的示例设定的。”

个性是在后训练中设定的，而知识则来自预训练期间对互联网信息的压缩。需要强调的是，这些知识有点过时，而且是概率性的、有点模糊的。互联网上经常被提及的内容，我会记得更清楚，而很少被讨论的内容，我会记得比较模糊，这与人类的记忆方式非常相似。

现在，让我们继续讨论这个实体的一些重要影响，我们应该如何与它交谈，以及我们可以从它身上期待什么。在接下来的教程中，我们将通过更多的实际例子，深入探讨 LLM 的应用场景和注意事项。



## 基本的 LLM 交互示例与注意事项

### 知识型查询的实践：日常生活中的 LLM 应用

为了更具体地说明 LLM 的应用场景，我想通过一些实际的例子来进行演示。这些例子都来自于我日常生活中与 ChatGPT 的真实对话，希望能帮助您更直观地理解 LLM 的能力边界和适用范围。

首先，我想分享一个关于知识型查询的例子。今天早上，我向 ChatGPT 提出了这样一个问题：“一杯美式咖啡中含有多少咖啡因？”我之所以会问这个问题，主要是因为我当时很好奇，想将美式咖啡的咖啡因含量与抹茶进行比较。

ChatGPT 在收到我的问题后，迅速给出了回答，告诉我一杯美式咖啡大约含有63 毫克咖啡因。

我认为向 ChatGPT 询问这个问题是合适的，原因有两点：

第一，我所询问的并非是非常最近的知识。咖啡因在美式咖啡中的含量，是一个相对稳定的信息，我个人认为，模型在预训练阶段应该已经阅读过大量关于咖啡因含量的资料，并且这个信息在短时间内不太可能发生显著变化。

第二，我认为这个信息在互联网上非常常见。关于 “一杯美式咖啡含有多少咖啡因” 这样的问题和信息，在互联网上随处可见，各种咖啡相关的网站、健康科普文章、甚至社交媒体讨论，都可能会提及这个话题。正因为互联网上存在大量的提及，我预计模型对这类信息会有比较好的 “记忆”。在这个例子中，没有使用任何额外的工具，完全依靠模型自身的“zip 文件”(预训练知识库) 进行回答。

ChatGPT (zip 文件) 给出的答案是大约 63 毫克咖啡因。

需要强调的是，我不能完全保证这个答案是绝对正确的。这仅仅是模型基于其对互联网信息的模糊记忆给出的一个概率性的答案。但是，为了验证答案的可靠性，我可以进一步查阅原始资料，例如在搜索引擎中搜索 “咖啡因 美式咖啡”，或者查阅相关的咖啡因含量数据库。通过简单的搜索，我发现网络上的信息显示，一杯美式咖啡的咖啡因含量确实大约在 63 毫克左右。这意味着，在这个例子中，ChatGPT 给出的答案，在一定程度上是可靠的。您可以通过查看原始资料来判断ChatGPT 给出的答案是否正确。因此，我不能严格保证ChatGPT 给出的所有答案都是 100% 正确的，但这并不妨碍 ChatGPT 在许多知识型查询场景下，成为一个有用的信息来源。

**感冒药物咨询：低风险场景下的 LLM 应用**

接下来，我想分享两天前我与 ChatGPT 进行的另一个对话例子。这仍然是一个知识型对话的例子，也属于在一些注意事项下，我乐于向 ChatGPT 询问的问题类型。

那天，我有点感冒，症状是流鼻涕。我感到有些不适，想找一些有帮助的药物来缓解症状。于是，我向 ChatGPT 咨询，希望它能提供一些建议。ChatGPT 告诉我一些关于感冒和流鼻涕的信息，并表示希望我的鼻子能尽快停止流鼻涕。在与 ChatGPT 交流的过程中，我根据自身的情况，对一些信息进行了澄清，例如我的具体症状、过敏史等等。在了解了我的具体情况后，ChatGPT 给出了一些可能对我有帮助的药物的建议。

随后，我查看了我家里现有的一些常备药物，并再次向 ChatGPT 提问：“DayQuil 或 NyQuil 有用吗？” ChatGPT 针对我的问题，继续查看了 DayQuil 和 NyQuil 的成分，并分析了这些成分是否有可能帮助缓解流鼻涕的症状。

当 ChatGPT 列出 DayQuil 和 NyQuil 的成分时，请务必记住，我们正在与一个对互联网有记忆的 “zip 文件”交谈。我不能保证ChatGPT 给出的这些成分是完全正确的。事实上，为了确保信息的准确性，我亲自拿出了药盒，仔细查看了药物的成分表。我确保 NyQuil 的成分确实与 ChatGPT 所说的基本一致。我之所以这样做，是因为我并不会总是完全信任ChatGPT 给出的所有信息，它毕竟只是对互联网信息的概率性统计回忆。但话说回来，关于DayQuil 和 NyQuil 的对话非常常见，这些都是很常见的非处方药物，互联网上很可能存在大量关于它们的信息，这使得模型有可能对这类信息有很好的记忆。幸运的是，经过我的核对，ChatGPT 给出的 DayQuil 和 NyQuil 的成分信息，都是正确的。

然后，我继续追问：“好吧，我有 NyQuil，它大概多久会起作用？”ChatGPT 告诉我 NyQuil 的起效时间，并补充说NyQuil 的主要成分基本上就是泰诺(Tylenol)。

对我个人而言，这是一个ChatGPT 对我提供了有效帮助的典型例子。这是一个知识型查询，所涉及的知识并非最新的信息，而是来自于模型自身的知识库。我认为我所询问的是常见信息，并且这是一个低风险的应用场景。虽然我在一定程度上检查了 ChatGPT给出的信息，但即便信息出现偏差，也不会造成严重的后果，所以总体来说，这是一个低风险的场景，没什么大不了的。最终，我吃了一片 NyQuil，它确实对缓解我的感冒症状起到了帮助。这就是我对这个案例的思考方式：在合适的场景下，适度地使用LLM，可以为我们的日常生活带来便利。

### 注意事项一：对话管理——优化上下文窗口

在与 LLM 交互的过程中，一个非常自然的现象是，您会发现您与模型的对话会越来越长。随着对话的深入，上下文窗口中积累的tokens 数量也会不断增加。在这里，我想强调一个非常重要的最佳实践：任何时候当您切换话题时，我都强烈建议您开始一个新的聊天。

当您开始一个新的聊天时，正如我们之前讨论过的，您实际上是在清除 token 的上下文窗口，并将其重置为零。如果之前的对话 tokens 对您的下一个查询不再有用，我强烈建议您这样做，因为上下文窗口中的 tokens 是 “昂贵” 的。这里的 “昂贵”，包含两层含义：

第一层含义是，如果您在上下文窗口中积累了大量的 tokens，模型可能会觉得有点 “分心”。想象一下，如果模型需要处理非常长的 token 序列，它在采样后面的 tokens时，可能会被过去的所有 tokens 分散注意力。这种 “分心” 可能会降低模型的准确性和性能。模型在处理长上下文时，可能会出现“信息遗忘”的现象，即模型会忽略或弱化上下文窗口中较早出现的信息，从而影响对话的连贯性和准确性。

第二层含义是，上下文窗口中的tokens 越多，计算序列中的下一个 token 的成本就越高。虽然这种成本增加不是非常显著，但确实会导致模型略微变慢，计算下一个 token 的时间会更长，上下文窗口中的 tokens 越多，这种延迟就越明显。

因此，我们应该将上下文窗口中的 tokens视为一种宝贵的资源，把它看作是模型的“工作记忆”。我们应该尽可能保持上下文窗口的简洁，避免让它充斥着无关的信息。尽可能多地开始新的聊天，每当您切换话题时，都建议您开启一个新的对话。这样做，您可以期望模型工作得更快，性能也可能稍微好一点。当然，如果之前的对话信息实际上与您当前的任务相关，您可能希望保留这些信息在上下文中，以便模型能够更好地理解您的意图。但我仍然建议您，在不影响任务完成的前提下，尽可能保持上下文窗口的精简。

### 注意事项二：模型选择——关注您正在使用的 LLM 版本

我想强调的第二个重要注意事项是，我总是建议您记住您实际使用的是什么模型。在 ChatGPT 界面的左上角，我们可以看到一个下拉菜单，通过这个菜单，我们可以查看我们当前正在使用的模型。在我的演示中，我一直使用的是GPT-4 模型。

需要注意的是，现在市场上已经存在许多不同类型的模型，实际上数量非常庞大，我们将在后续的教程中逐步介绍其中的一些。在我的演示中，我所展示的所有功能和示例，都是基于GPT-4 模型的。

但是，当您打开一个新的隐身窗口，然后访问 chat.openai.com，并且没有登录您的 OpenAI 账号时，您在这里与之交谈的模型可能不是 GPT-4，而很可能是一个较小的版本的模型。不幸的是，当您没有登录的情况下使用 ChatGPT 时，OpenAI 并不会明确告知您正在使用什么模型，这确实有点遗憾。但您需要意识到，在未登录状态下，您很可能正在使用一个较小的、功能较弱的模型。

为了更清晰地了解 ChatGPT 的模型选择和定价策略，我们可以查看ChatGPT 的定价页面。在定价页面上，我们可以看到 OpenAI 为个人用户提供了三个基本层级的订阅服务：免费 (Free)、Plus和Pro。在免费层级中，您可以访问所谓的GPT-4 Mini，这是GPT-4 的一个较小版本，它是一个参数量更少的小型模型。与完整版的 GPT-4 相比，GPT-4 Mini 的创造力可能不那么强，写作能力可能不那么好，知识面可能不那么广，并且可能更容易产生幻觉等等。但作为免费服务，GPT-4 Mini 仍然可以提供基本的对话功能。OpenAI 在其定价页面上确实提到，免费用户可以有限地访问 GPT-4 和 GPT-3 Mini，但我实际上不太确定具体情况如何，因为在未登录状态下，ChatGPT 界面并没有明确告知我们正在使用什么模型，所以我们根本无法确定。

如果您选择每月支付 20 美元订阅ChatGPT Plus服务，即使 ChatGPT 定价页面上的描述方式有点让人困惑，但如果您仔细查看详细说明，您会发现 Plus 用户每 3 小时可以获得80 条 GPT-4 消息。这里的GPT-4，指的是目前可用的旗舰级、最大型的模型，这也是我们最希望使用的模型。如果您每月支付 20 美元，您就可以在一定限制下使用 GPT-4 模型。如果您选择每月支付 200 美元订阅ChatGPT Pro服务，您将获得无限的 GPT-4 访问权限，以及一些额外的功能和权益，我们将在后续的教程中讨论其中的一些内容，因为我个人确实支付了 Pro 订阅。

我想让您从这里得到的关键信息是，务必注意您正在使用的模型。通常情况下，对于这些 LLM 公司来说，较大的模型，计算成本更高，因此，公司会对较大的模型收取更高的费用。所以，您需要根据您对 LLM 的实际使用情况，为您自己做出权衡和选择。您可以先尝试使用更便宜的服务，例如免费版或低价订阅版。如果您发现模型的智能程度不够理想，并且您是专业地使用LLM，那么您可能真的需要考虑支付这些公司提供的顶级模型的订阅费用。就我个人而言，在我的专业工作中，我大量使用 LLM 进行编码和类似的任务，对我来说，支付 ChatGPT Pro 的费用仍然非常便宜，所以我很乐意支付这笔费用，因为我可以访问一些非常强大的模型，我将在后续的教程中向您展示这些模型的强大之处。

所以，请时刻跟踪您正在使用的模型，并根据自身需求，为您自己做出明智的决定。

我还想补充一点，所有其他的 LLM 提供商，例如 Anthropic (Claude)、Google (Gemini)、Grok 等，也都提供不同的定价层级，不同的模型会被分配到不同的层级上，您可以根据自己的需求支付相应的费用，以获得对应模型的访问权限。例如，如果我们访问Anthropic 的 Claude，您会看到我目前正在支付专业计划，这使我可以访问 Claude 3.5 Sonnet 模型。如果您没有支付 Pro 计划，那么您可能只能访问像Haiku这样的较小模型。所以，为了能够使用最强大的模型，您需要支付相应的费用。关键在于，选择对您来说最有效的模型和服务。

### “LLM 委员会”：多模型对比与选择的策略

这里，我想分享一个我个人使用 Claude的例子。我当时只是在寻求旅行建议。我向 Claude 提问，“有什么很酷的城市可以去旅行？”Claude 向我推荐了瑞士的采尔马特，并说采尔马特非常酷。最终，我采纳了 Claude 的建议，去了采尔马特度过新年。这是一个例子，说明我发现这些模型在旅行建议和想法方面非常有用，它们可以为我提供一些初步的建议，然后我可以进一步研究这些建议，并最终做出决策。

这里我们还展示了gemini.com的一个例子，这是谷歌的 Gemini。我向 Gemini 提出了类似的问题，想看看Gemini 对此事的看法。我问 Gemini，“有什么很酷的城市可以去旅行？”Gemini 也推荐了采尔马特。这很有意思，不同的模型，给出了相同的推荐。我个人很喜欢在不同的模型之间切换，问它们类似的问题，看看它们各自的想法和建议。对于 Gemini，在界面的左上角，我们同样可以看到一个模型选择器，您可以支付更高级的层级，并使用那些更强大的模型。

对于Grok来说，情况也是类似的，Grok 刚刚发布不久。我们可能不希望仅仅询问 Grok 2的问题，因为我们知道Grok 3才是最先进的模型。所以，我想确保我支付了足够的费用，以便我可以访问 Grok 3 模型。

对于所有这些不同的 LLM 提供商，我的建议是，找到最适合您的那一个。尝试不同的提供商，尝试不同的定价层级，根据您正在处理的问题的类型和复杂度，选择最合适的模型。我个人经常最终只是支付很多费用，然后问所有这些模型相同的问题。我把所有这些模型称为我的“LLM 委员会”。它们就像是一个语言模型组成的委员会。每当我想知道去哪里度假这样的问题时，我会同时询问所有这些模型，然后综合它们的建议，最终做出决定。所以，如果这种“多模型对比”的策略对您有用，您也可以为自己这样做。

## 结语：开启您的 LLM 应用探索之旅

在本部分教程中，我们共同绘制了一幅不断扩展的 LLM 生态系统的宏伟画卷，并详细阐述了ChatGPT作为入门平台的优势和价值。我们已经清晰地认识到，LLM 领域正处于一个前所未有的发展机遇期，各种创新应用正在以前所未有的速度涌现，预示着一个充满变革和无限可能的LLM 应用黄金时代已经到来。我们通过实际的例子，展示了基本的 LLM 交互方式，并强调了对话管理和模型选择这两个重要的注意事项。希望您能够从中领悟到，如何更精明地使用 LLM，从而最大化地提升您的效率和用户体验。在接下来的教程中，我们将继续深入探索 LLM 的高级功能和更复杂的应用场景。

在接下来的精彩旅程中，我们将深入 ChatGPT 的内部世界，并循序渐进地解锁 LLM 的各项强大功能。现在，就让我们扬帆起航，共同踏上这场激动人心的LLM 应用探索之旅吧！





