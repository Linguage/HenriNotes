


# 高级工具应用：深度研究、文件上传与代码工具

## 深度研究 (Deep Research)：解锁深层知识的钥匙

现在，我们将深入探索一项非常高级且极具价值的功能：深度研究 (Deep Research)。这项功能，在 ChatGPT 的定价体系中，被明确列为Pro 订阅的专属权益，目前需要每月 200 美元的订阅费用才能解锁。虽然价格不菲，但我认为这项功能非常酷，非常有趣，并且在许多人的雷达之外，而它本不该如此。接下来，我将通过具体的例子，向您展示在哪些情况下您可能会需要使用深度研究 功能，以及它能为您带来哪些意想不到的惊喜。

### 深度研究：互联网搜索、思考与持久运行的完美融合

概括来说，深度研究功能，是互联网搜索和思考模型的完美结合，并且能够持续运行很长时间。模型会花费几十分钟的时间，深入地进行研究，而不是像普通的搜索查询那样，仅仅在几秒钟内给出简短的答案。第一个宣布推出这项功能的公司，正是ChatGPT，作为其Pro 产品的一部分，这项功能非常新，大约在一个月前才正式上线。

为了更直观地理解深度研究的价值，让我们来看一个具体的例子。最近，我在网上购买补充剂，我知道这听起来可能有点疯狂。但Brian Johnson(一位知名的生物技术企业家，以其追求长寿和健康的 “Blueprint” 计划而闻名) 有一个入门包，我有点好奇。在这个入门包中，有一个叫做“长寿混合物” (Longevity Blend)的东西，对吧？它声称包含多种健康活性物质，我很想知道这些物质究竟是什么，对吧？当然，比如，CAKG，这到底是什么？产品介绍中写着“促进能量产生，以保持持久活力”，但这究竟是什么意思呢？

当然，一种方法是，您可以打开谷歌搜索，查看维基百科页面或类似的资料，手动进行信息收集和整理，就像我们一直以来习惯做的那样。但深度研究功能，为您提供了一种全新的途径，它能够为您处理大量的信息，并更系统、更深入地解释您想了解的主题。

例如，我们可以这样做，这是我的示例提示：“CAKG 是 Brian Johnson 蓝图中 2.5 克/份的健康活性物质之一。你能研究一下 CAKG 吗？告诉我为什么它可能存在于长寿混合物中，它在人类或动物模型中的可能功效，它的潜在作用机制，任何潜在的担忧或毒性，或类似的东西。”

现在，在 ChatGPT 界面上，我有一个特殊的按钮可用，这个按钮对于非 Pro 订阅用户来说是不可见的。这个按钮就是“深度研究” (Deep Research)。让我复制粘贴上述提示，然后点击 “开始”。现在，模型会响应说：“好的，我要研究这个。” 然后，有时模型喜欢在正式开始研究之前，先问一些澄清的问题。例如，模型可能会问：“关注人类临床研究，动物模型，还是两者都有？” 让我们选择 “两者”。“特定来源？” 我们选择 “所有来源，我不知道。”“与其他长寿化合物的比较？” 我们选择 “不需要比较，只需要 AKG。”“我们可以简短一点吗？” 模型理解了我们的意图，我们点击 “开始”，然后，模型再次确认：“好的，我将研究 AKG。开始研究。” 现在，我们必须等待大约 10 分钟左右。如果您想了解研究的进展，您可以点击 “预览” 按钮，查看模型正在做什么的简要总结。

### 深度研究的工作流程：思考、搜索与报告生成

深度研究功能，将持续运行一段时间，它将结合思考模型和互联网搜索工具，发出多次互联网搜索，浏览大量的学术论文，查看网页信息，它将进行深入的思考，最终在大约 10 分钟后返回一份详细的研究报告。所以，深度研究 功能，将长时间运行，为您深入挖掘您所关注的主题。

与此同时，当 ChatGPT 深度研究正在运行的同时，我想向您展示行业中的等效物。受到 ChatGPT 深度研究 功能的启发，很多人都对“克隆”这一功能非常感兴趣。所以，一个例子是，例如，perplexity。当您在 perplexity 中访问模型下拉菜单时，您会发现一个叫做“深度研究” (Deep Research)的选项。所以，您可以在 perplexity 中发出相同的查询，我们可以将我们刚才的提示复制粘贴给 perplexity。

Grok也提供了一个类似的功能，叫做“深度搜索” (Deep Search)，而不是深度研究。但我认为Grok 的深度搜索，在功能上有点类似于深度研究，但我不太确定其具体的工作机制。所以，我们也可以发出 Grok 深度搜索请求。Grok 3 深度搜索，开始。这个模型也将在后台持续运行，进行深度搜索。

我想，我的ChatGPT 深度研究在哪里？所以 ChatGPT 深度研究大概完成了四分之一。perplexity 深度研究即将完成，仍然在思考。Grok 仍在进行中。我最喜欢 Grok 的界面，它似乎... 好的，所以基本上，Grok 正在查找各种论文，Web MD(一个知名的健康信息网站)，浏览搜索结果，它只是在获取所有这些信息。当所有这些深度研究都在进行时，LLM 当然正在积累一个巨大的上下文窗口，它正在处理所有这些信息，试图为我们创建一个全面的报告。

深度研究的目标非常明确：什么是 CAKG？为什么它存在于长寿混合物中？它与长寿有什么关系？ 等等。所以，深度研究报告会提供引文，标明信息来源，并详细地告诉您所有关于 CAKG 的信息。这不是一个简单而简短的响应，这有点像一篇关于您想要的任何主题的定制研究论文。所以，深度研究功能非常酷，它为您提供了大量的参考资料，方便您进行一些自己的阅读，也许之后会问一些澄清的问题。但真正令人不可思议的是，它为您提供了所有这些不同的引文，并为您初步处理了一点信息，节省了您大量的时间和精力。

让我们看看perplexity 的深度研究是否完成了。好的，perplexity 仍在研究。ChatGPT 也在研究。为了节省时间，我暂停一下视频，当深度研究完成时，我会立即回来。

### 深度研究报告示例：ChatGPT vs. Perplexity

好的，perplexity 的深度研究已经完成了，我们可以看到它生成了一些报告。报告中包含一些参考文献和一些描述性的文字。然后，ChatGPT 的深度研究也完成了。它也思考了 5 分钟，查看了 27 个来源，并生成了一份更详细的报告。在 ChatGPT 的报告中，它谈到了CAKG 在蠕虫、果蝇、小鼠中的研究，以及正在进行的人体试验，然后是提出的作用机制，以及一些安全性和潜在的担忧，还有您可以深入研究的参考文献。

**ChatGPT 深度研究 的优势：更详尽、更可读、更深入**

通常，在我自己的工作中，到目前为止，我只使用了深度研究大概10 到 20 次查询，类似于刚才的 CAKG 研究。通常我发现ChatGPT 的深度研究产品目前是最好的，它是最彻底的，读起来最流畅，内容最长，当我阅读它的时候，它最有意义。我个人认为perplexity 和 Grok 的深度研究报告有点短，有点简洁，没有达到与来自谷歌的深度研究，哦，对不起，来自 ChatGPT 的深度研究相同的细节。

### 深度研究的局限性：幻觉风险与信息验证

我要再次强调的是，这里给您的所有东西，即使它正在进行研究并且正在引入引文，也不能保证这里没有幻觉。任何这些 LLM都可能在任何时候产生幻觉，它可能完全是编造的、捏造的、被模型误解的。这也就是为什么这些引文非常重要。将深度研究报告当作您的初稿，当作您需要查看的论文列表，但不要认为报告中的所有内容一定是真的。

所以，我接下来要做的是，我实际上会进入这些论文，我会尝试理解，ChatGPT 是否正确理解了它，也许我会有一些后续问题等等。所以您可以做所有这些，但深度研究仍然非常有用，可以看到这些报告，偶尔可以得到一堆您可能想在之后深入研究的来源。

 **深度研究应用场景拓展：浏览器对比、寿命研究与行业调研**

好的，就像之前一样，我想展示几个简短的例子，说明我是如何使用深度研究的。例如，我正在尝试更换浏览器，因为Chrome 不...Chrome 让我不高兴，因为它删除了我所有的标签。所以我在考虑 Brave 或 Arc，我最感兴趣的是哪一个更私密。基本上，我要求 ChatGPT 为我编译了这份报告，这份报告实际上非常有帮助。我查看了一些来源，我了解了为什么Brave 基本上更好，这也是为什么例如在这里我使用 Brave，因为我现在切换到 Brave 浏览器了。所以这是一个例子，研究不同类型的产品并比较它们。我认为这非常适合使用深度研究。

这里，我想了解小鼠的寿命延长方面的研究进展。所以深度研究给了我一个很长的阅读报告，但基本上总结了小鼠是研究长寿的动物模型，不同的实验室已经尝试用各种技术来延长小鼠的寿命。

然后，在这里，我想探索美国的 LLM 实验室，我想要一个表格，说明它们有多大，它们获得了多少资金等等。这是 ChatGPT生成的表格。现在这个表格基本上是不准确的，不幸的是。所以我想把它作为一个失败的例子来展示。我认为其中一些数字，我没有完全检查它们，但它们看起来没有太离谱。但有些数字看起来是错误的。但我认为更大的问题是，xAI 不在这里，我认为这是一个非常重要的遗漏。此外，相反地，Hugging Face可能不应该在这里，因为我专门询问了美国的 LLM 实验室。而且我认为A Luther AI 也不应该算作一个主要的 LLM 实验室，主要是由于它的资源规模。

所以我觉得这个表格有点不靠谱，有些重要的信息不见了，我不完全信任这些数字，我必须实际查看它们。所以，再次强调，把深度研究报告当作初稿，不要完全信任它，但它仍然非常有用。

## 文件上传与上下文增强 (File Upload)：为 LLM 注入专属知识

接下来，我们将探讨文件上传与上下文增强 (File Upload)功能。这就是实际发生的事情，有趣的是，我们正在为 LLM 提供额外的具体文档，它可以在其上下文窗口中引用。所以模型不仅仅依赖于通过其参数对世界的模糊知识，以及它在“大脑” 中知道的东西，我们实际上是在给它具体的文档。这就像您和我在参考特定的文档，比如在互联网上或类似的东西，而我们正在为某个问题产生一些答案。

现在我们可以通过互联网搜索或深度研究这样的工具来做到这一点，但我们也可以通过文件上传自己为这些 LLM 提供具体的文档。我发现这个功能在很多方面都非常有用。

## Claude 3.7 与文件上传：论文阅读的新范式

例如，让我们看看Claude，因为他们在我拍摄这个视频的时候刚刚发布了 Claude 3.7。这是一个新的 Claude 模型，现在是最先进的。请注意，我们现在有了思考模式，截至 3.7 版本。“正常”是我们目前看到的默认模式，但他们刚刚发布了 “扩展” (Extended) 模式，最适合数学和编码挑战。他们没有明确说明，但实际上在底层很可能是真的，Extended 模式是通过强化学习训练的，类似于所有其他思考模型的产生方式。

我们现在可以做的是，我们可以上传我们希望它在其上下文窗口中引用的文档。例如，有一篇论文刚刚发表，我有点感兴趣。它来自 Arc Institute(一个生物医学研究机构)，基本上是关于在 DNA 上训练的语言模型。我有点好奇，我不是学生物的，但我有点好奇这篇论文讲的是什么。这是一个完美的例子，说明LLM 非常擅长处理的任务，因为您可以将这些文档上传到 LLM，您可以将这个PDF 文件加载到上下文窗口中，然后向它提问，基本上就是与 LLM 一起阅读文档并提问。

您这样做的方式是，您基本上只需拖放。所以我们可以拿起那个 PDF 文件，然后把它放在 Claude 的界面这里。这个 PDF 文件大约是 30 兆字节。当Claude 收到这个文档时，他们很可能会丢弃大量的图像和这类信息。我实际上不知道他们在底层做了什么，他们也没有真正谈论它，但很可能图像被扔掉了，或者即使它们在那里，它们也可能不像您和我理解它们那样被很好地理解。很可能在底层发生的是，这个PDF 文件基本上被转换为一个文本文件，并且该文本文件被加载到 token 窗口中。一旦它在 token 窗口中，它就存在于模型的 “工作记忆” 中，我们可以向它提问。

通常，当我开始与任何这些 LLM 一起阅读论文时，我只是要求，“你能给我一个关于这篇论文的总结吗？” 让我们看看Claude 3.7怎么说。“好的，我超出了这个聊天的长度限制，天哪，真的吗？哦，该死。好吧，让我们试试 ChatGPT。你能总结一下这篇论文吗？” 我们正在使用 GPT-4，我们没有使用思考模式，这没关系，我们可以从不思考模式开始。“阅读文档，论文摘要。基因组建模和设计跨越所有生命领域。所以这篇论文介绍了 Evo 2，一个大规模的生物基础模型，然后是关键特征等等。”

我个人觉得这很有帮助，然后我们可以来回交流。当我阅读摘要和引言等内容时，我正在向 LLM 提问，这有点像让它更容易让我理解论文。

### 书籍阅读新体验：《国富论》与 LLM 助手

我喜欢使用这个功能的另一种方式是，当我在阅读书籍时。现在我很少再独自阅读书籍了，我总是让 LLM 帮助我阅读书籍。最近的一个很好的例子是《国富论》(The Wealth of Nations)，我最近在读这本书。这是亚当·斯密在1776 年写的一本书，它有点像古典经济学的基础，这是一本非常好的书。我只是觉得它非常有趣，它是在很久以前写的，但它有很多现代的观点，我认为即使在今天也非常及时。

现在我阅读书籍的方式，例如，您基本上打开这本书，您必须获得这些信息的原始内容。在《国富论》的情况下，这很容易，因为它来自 1776 年，所以您可以在古腾堡计划 (Project Gutenberg)上找到它。然后基本上找到您当前正在阅读的章节。例如，让我们阅读第一本书的这一章。我最近在阅读这一章，它有点涉及劳动分工，以及它如何受到市场范围的限制。

概括地说，如果您的市场非常小，那么人们就无法专业化，而专业化是创造财富的关键。因为您可以有专家，他们在他们简单的小任务上进行专业化，但您只能大规模地做到这一点。因为没有规模，您没有足够大的市场来销售您的专业化产品。

我们要做的就是复制粘贴这本书，至少是这一章的内容。这就是我喜欢做的。我们去，比如说，Claude，我们说一些类似这样的话：“我们正在阅读亚当·斯密的《国富论》。”请记住，Claude 可能知道《国富论》，但可能不记得这一章的确切内容。所以直接问 Claude 关于这一章的问题是没有意义的，因为它可能不记得这一章是关于什么的。但我们可以通过将它加载到上下文窗口中来提醒 Claude。“我们正在阅读《国富论》，请先总结一下这一章。”

然后我在这里做的是，我复制粘贴。在Claude中，当您复制粘贴时，它们实际上并没有在文本框中显示所有文本，它们创建了一个小的文本附件，当它超过一定大小时。所以我们可以点击回车，我们只是开始。通常我喜欢从总结这一章是关于什么开始，这样我就有一个大概的想法。然后我进去开始阅读这一章，在任何时候我们有任何问题，我们只需进来问我们的问题。我发现基本上与 LLM 携手并进，极大地提高了我的记忆力，以及我对这些章节的理解。我发现当您阅读其他领域的文档时，这一点尤其如此，例如生物学，或者来自很久以前的文档，例如1776 年的文档，您需要一点帮助来理解语言的基础。或者例如，我会更有勇气去阅读一篇非常古老的文本，它不在我的专业领域内，也许我正在阅读莎士比亚，或者我正在阅读类似的东西。

我觉得 LLM 使很多阅读变得更加容易，比以前容易得多，因为您不会马上感到困惑，您实际上可以慢慢地通过它，并与 LLM 一起解决它。我广泛使用这个功能，我认为它非常有帮助。

### 期待更便捷的文件阅读工具

不幸的是，我不知道今天有什么工具可以让您很容易地做到这一点。我这样做很笨拙，来回复制粘贴。实际上，我会在某个地方找到这本书，我会复制粘贴内容，我来回移动，这非常尴尬和笨拙。不幸的是，我不知道有什么工具可以让您很容易地做到这一点。但显然，您想要的是，当您阅读一本书时，您只想突出显示段落并提问。据我所知，这目前还不存在。但这非常有帮助，我建议您尝试一下，不要独自阅读书籍。

## Python 解释器：赋予 LLM 代码执行能力

好的，现在我想转向的下一个非常强大的工具是Python 解释器的使用，或者基本上是让 LLM 能够使用和编写计算机程序。所以，LLM 不再是直接给您一个答案，它现在有能力编写一个计算机程序，并发出特殊的 tokens，ChatGPT 应用程序可以识别这些 tokens，并发出指令，“嘿，这不是给人类的，这基本上是在说，我在这里输出的任何东西实际上是一个计算机程序，请去运行它，并给我运行该计算机程序的结果。”

所以，这就是语言模型与编程语言(如 Python) 的集成。这非常强大。让我们看看可以使用它的最简单的例子，以及它会是什么样子。

### Python 解释器示例：复杂计算的利器

如果我访问 ChatGPT，我给它一些乘法问题，比如30 * 9，这是一个相当简单的乘法，您和我可能可以在我们的脑海中做这样的事情，对吧？像30 * 9，您可以直接得出结果 270。让我们看看会发生什么。好的，LLM 做的和我刚才做的完全一样，它计算出这个乘法的结果是270。但它实际上并没有真正做数学，它更像是记忆工作。但这对于人脑来说，也很容易完成。

这里没有涉及工具的使用，这里发生的一切都只是 zip 文件进行下一个 token 预测，并在它的“脑海” 中给出了正确的结果。现在的问题是，如果我们想要更复杂的东西呢？例如，53829 * 20837，这是多少乘以多少？现在，当然，如果我让您计算这个，您会立即放弃，因为您知道您不可能在您的脑海中做到这一点，您会寻找一个计算器。这正是 LLM 现在也会做的。

OpenAI 已经训练 ChatGPT来识别它不能在脑海中完成的问题，并依赖工具。所以我期望 ChatGPT对这种查询所做的，是转向工具使用。让我们看看它是什么样子。好的，我们开始了。这里打开的是所谓的 Python 解释器。Python基本上是一种小程序设计语言。LLM 不是直接告诉您结果是什么，而是编写一个程序。这里没有显示的是特殊的 tokens，这些 tokens 告诉 ChatGPT 应用程序“请运行该程序。”。然后LLM 暂停执行，Python 程序运行，创建一个结果，然后将这个结果作为文本传递回语言模型。语言模型接管并告诉您“这个的结果是那个。”

这就是工具使用，非常强大。OpenAI 已经训练 ChatGPT来了解在什么情况下打开工具，他们通过示例教它这样做。所以人类标注员参与策划数据集，通过示例告诉模型在什么情况下它应该依赖工具以及如何依赖。但基本上，我们有了一个 Python 解释器，这只是乘法的一个例子，但 Python 解释器的能力要强大得多。让我们看看我们实际上可以在编程语言中做什么。

### 不同 LLM 工具支持差异：Python 解释器并非标配

在我们继续之前，我只想指出，不幸的是，您必须跟踪您正在与之交谈的 LLM有哪些不同类型的工具可用，因为不同的 LLM 可能没有所有相同的工具。特别是，无法访问 Python 解释器或编程语言，或者不愿意使用它的 LLM，可能不会在一些较难的问题中给您正确的结果。

例如，在这里我们看到 ChatGPT 正确地使用了编程语言，而没有在它的脑海中这样做。Grok 3 实际上，我相信，无法访问像Python 解释器这样的编程语言。在这里，Grok 3实际上是在它的脑海中进行计算的，并且非常接近正确答案，但如果您仔细观察，它会出错。正确的答案应该是 1120，而不是 060。所以Grok 3 会产生幻觉，通过这个乘法，在它的脑海中进行计算，并且出错，但实际上非常接近。

然后我尝试了 Claude，Claude 实际上在这种情况下编写的不是 Python 代码，而是JavaScript 代码。但JavaScript 也是一种编程语言，并且得到了正确的结果。

然后我去了Gemini，我问了2.0 pro模型，Gemini 似乎没有使用任何工具，没有任何迹象表明这一点。但它给我的我认为是正确的结果，这实际上有点让我惊讶。所以我认为Gemini 实际上在它的脑海中正确地计算了这个，这有点不可思议。我们可以判断它没有使用工具的方式是，我们可以尝试一些更难的东西。“这是什么...我们必须让它更难。” 好的，所以Gemini给我们一些结果，然后我可以使用我的计算器进行验证，结果表明它是错误的，对吧？这是使用我的 MacBook Pro 计算器计算的结果，Gemini 给出的答案不正确，但它非常接近，但它不正确。但Gemini 会产生幻觉的答案。

所以，我想我的观点是，不幸的是，LLM 目前的状态就是这样，不同的 LLM有不同的工具可用，您必须跟踪这些信息。如果它们没有可用的工具，它们会尽力而为，但这意味着它们可能会为您产生幻觉的结果。这是需要注意的事情。

### ChatGPT 高级数据分析：数据分析师助手

这可以在实践中非常强大的一个设置是所谓的ChatGPT 高级数据分析 (Advanced Data Analysis)。据我所知，这对于ChatGPT 本身来说是相当独特的，它基本上让 ChatGPT有点像一个初级数据分析师，您可以与之合作。

让我向您展示一个具体的例子，而不涉及完整的细节。首先我们需要获取一些数据，我们可以分析、绘图、图表等等。所以在这里，在这种情况下，我说，“让我们研究一下 OpenAI 的估值，例如。” 我明确要求 ChatGPT 使用搜索工具，因为我知道在底层存在这样的工具，我不希望它为我产生幻觉的数据，我希望它实际查找数据并支持它，并创建一个表格，其中每年我们都有估值。

所以这些就是随着时间的推移 OpenAI 的估值。请注意，在2015 年，估值是不适用的。所以估值是未知的。然后我说，“现在绘制这个，为 y 轴使用对数刻度。”。这就是它变得强大的地方。ChatGPT 继续编写一个程序，绘制这里的数据。所以它为我们创建了一个小图，它运行它并向我们展示它。这可能非常漂亮且非常有价值，因为这是一种非常简单的方法来收集数据，上传电子表格中的数据并可视化它等等。

我会注意到这里的几个事情。例如，请注意，我们在2015 年有“NA” (Not Applicable)，表示估值未知。但ChatGPT 在编写代码时(我总是鼓励您仔细检查代码)，它在2015 年输入了 0.1。所以基本上，它隐含地假设，它在这里做出了假设，在代码中，2015 年的估值是 1 亿美元，因为它输入了 0.1，它有点像在没有告诉我们的情况下这样做了。所以它有点偷偷摸摸，这也就是为什么您必须稍微注意一下代码。我熟悉代码，我总是阅读它。但我认为我可能会犹豫是否建议使用这些工具，如果人们不能自己阅读和验证它一点点的话。

现在拟合一条趋势线，并推断到 2030 年。标记 2030 年的预期估值。 所以我提出了更进一步的要求，希望 ChatGPT基于已有的数据，拟合一条趋势线，并预测 OpenAI 在 2030 年的估值。ChatGPT 继续进行，它基本上做了一个线性拟合，它正在使用 SciPy 的 curve_fit 函数，它完成了拟合并提出了一个图表，它告诉我，根据趋势线推断，2030 年的估值约为 1.7 万亿美元。这听起来很棒，除了在这里我开始怀疑，因为我看到 ChatGPT 告诉我它是1.7 万亿美元，但当我在这里查看 2030 年时，它打印的是 2027 年 1.7B。所以它的推断结果，当它打印变量时，与1.7 万亿美元不一致。这使得它看起来像是估值应该是大约 20 万亿美元。

这就是我说，“直接打印这个变量本身，它是什么？”。然后它有点像重写了代码，并给了我变量本身。正如我们在标签中看到的，它确实是 2271等等。所以，在2030 年，真正的指数趋势推断将是20 万亿美元的估值。

所以，我有点像，我试图质问 ChatGPT，我说：“你骗了我，对吧？”。它说：“是的，对不起，我搞砸了。” 所以我想我喜欢这个例子，因为第一，它展示了工具的力量，它可以为您创建这些图表，这非常好。但我认为第二，它展示了它的棘手之处，例如，在这里它做出了一个隐含的假设，在这里它实际上告诉我一些东西，它告诉我只是错误的，它产生了幻觉的 1.7 万亿美元。

所以，再次强调，它有点像一个非常非常初级的数据分析师。它能够绘制图形真是太棒了，但您仍然必须知道这段代码在做什么，您必须小心并仔细检查它，并确保您真的非常密切地观察，因为您的初级分析师有点心不在焉，并且并非一直都是正确的。所以高级数据分析功能非常强大，但也要小心使用。

我不会详细介绍高级数据分析的所有细节，因为有很多关于这个主题的视频。所以，如果您想在您的工作中使用其中的一些内容，我建议您查看其中一些视频。我在这里不会详细介绍。所以高级数据分析很有希望，但要小心使用。

### Claude Artifacts：应用与图表的可视化创作空间

好的，我已经向您介绍了ChatGPT和高级数据分析，这是一种强大的方式，基本上可以让LLM 与代码交互，并添加一些 UI 元素，如显示图形等。我现在想向您介绍另一个相关的工具，它是特定于 Claude的，叫做Artifacts。

让我通过例子向您展示这是什么。我与 Claude 进行了对话，我要求从以下文本中生成 20 张闪卡。对于文本本身，我只是访问了亚当·斯密的维基百科页面，例如，我复制粘贴了这个引言。我在这里复制粘贴了这个，并要求提供闪卡。Claude 回应了 20 张闪卡。例如，“亚当·斯密是什么时候受洗的？”“6 月 16 日”，等等。“他是什么时候去世的？”“他的国籍是什么？” 等等。

一旦我们有了闪卡，我们实际上想练习这些闪卡。这就是我继续对话的地方，我说：“现在使用 Artifacts 功能编写一个闪卡应用程序来测试这些闪卡。”。所以Claude 继续编写一个应用程序的代码，该应用程序基本上将所有这些闪卡格式化为一个交互式的练习工具，最终呈现出来的效果看起来像这样。

Claude 具体编写的是这段 C 代码。它使用了一个 React 库，然后基本上创建了所有这些组件，它将问答硬编码到这个应用程序中，然后是它的所有其他功能。然后Claude 界面基本上能够在您的浏览器中直接加载这些 React 组件。所以您最终得到一个应用程序。例如，“亚当·斯密是什么时候受洗的？” 您可以点击 “显示答案”，然后您可以说您是否答对了。“他是什么时候去世的？”“他的国籍是什么？” 等等。

您可以想象通过Claude Artifacts可以做到这一点，然后也许我们可以重置进度或洗牌闪卡顺序等等。所以这里发生的是Claude 为我们编写了一个超级定制的应用程序，就在这里。通常我们习惯的是一些软件工程师编写应用程序，他们提供它们，然后他们给您一些定制它们的方法，或者上传闪卡，例如在Anki 应用程序中，您可以导入闪卡和所有这些东西。

这是一个非常不同的范式，因为在这个范式中，Claude 只是为您编写应用程序，并在这里部署它，在您的浏览器中。请记住，您在互联网上找到的很多应用程序，它们有整个后端等等，这里什么都没有，没有数据库或类似的东西。但这些是可以在您的浏览器中运行的本地应用程序，它们在某些情况下可以变得相当复杂和有用。

这就是Claude Artifacts。老实说，我实际上并不是 Artifacts 的日常用户，我偶尔会使用它。我知道很多人都在试验它，您可以找到很多 Artifacts 展示案例，因为它们很容易分享。这些是人们开发的很多东西，各种计时器和游戏等等。

但我在自己的工作中确实发现非常有用的一个用例基本上是图表生成的使用。例如，让我们回到我们正在看的亚当·斯密的那一章。我有时做的是，“我们正在阅读亚当·斯密的《国富论》，我正在附加第一本书的第三章，请创建这一章的概念图。”。当Claude 听到 “这一章的概念图”时，它通常会编写一段代码，看起来像这样。如果您不熟悉这个，这是使用 Mermaid 库来创建或定义一个图形，然后这是绘制该 Mermaid 图的代码。

所以Claude 分析了这一章，并找出这里传达的关键原则如下：劳动分工与市场范围(它的大小)有关，然后这些是这一章的各个部分。所以有贸易的比较例子，以及在陆地和水上进行贸易的难易程度，以及使用的具体例子，地理因素实际上在这里产生了巨大的差异。然后是陆地运输与水上运输的比较，以及水上运输有多么容易。然后这里有一些早期的文明，它们都受益于水上运输的可用性，并因此而蓬勃发展，因为它们支持专业化。

所以，如果您是一个概念性的、视觉型的思考者(我认为我也是这样)，我喜欢把信息布局成这样的一棵树，它帮助我很容易地记住那一章是关于什么的。我只是非常喜欢这些图表，并且有点感觉，“争论的布局是什么？它是如何空间排列的？” 等等。所以，如果您像我一样，那么您一定会喜欢这个。您可以制作任何东西的图表，书籍、章节、源代码，真的任何东西。所以我特别发现这相当有用。

### Cursor：Composer 代码编写工具——“Vibe Coding” 的新体验

好的，我已经向您展示了LLM 非常擅长编写代码。所以，它们不仅可以发出代码，而且很多应用程序，如ChatGPT、Claude等，已经开始在浏览器中部分运行该代码。ChatGPT将创建图形并显示它们，Claude Artifacts实际上将集成您的 React 组件，并允许您直接在浏览器中使用它。

现在实际上，我个人和专业的大部分时间都花在编写代码上。但我实际上不会去 ChatGPT并要求提供代码片段，因为这太慢了。ChatGPT 只是没有上下文来与我专业地合作创建代码。对于所有其他的 LLM来说也是一样的。

所以，我不使用这些 LLM 在 Web 浏览器中的功能，而是使用一个特定的应用程序。我认为行业中的很多人也是这样做的。现在可能有多个应用程序，VS Code、Wind、Surf、Cursor等等。我目前喜欢使用 Cursor，这是一个单独的应用程序，您可以在您的MacBook 上使用它，它可以处理您文件系统上的文件。所以这不是一个 Web 界面，这不是您访问的某种网页。这是一个您下载的程序，它引用您电脑上的文件，然后它处理这些文件，并与您一起编辑它们。

**Cursor 的工作方式与示例：井字棋 React 应用快速构建**

Cursor 的界面看起来是这样的，这里我有一个我用 Cursor在几分钟内构建的 React 应用程序的简单示例。在底层，Cursor 正在使用 Claude 3.7 Sonnet。所以在底层，它正在调用 Anthropic 的 API，并要求 Claude 做所有这些事情。但我不需要手动访问 Claude并复制粘贴代码块，这个程序为我做这些，并且拥有目录中所有文件的上下文，以及所有这些东西。

我在这里开发的应用程序是一个非常简单的井字棋，例如。Claude 在一分钟内写了这个，我们可以玩。X 可以赢，或者我们可以平局。哦，对不起，我不小心赢了。您也可以平局。

我只是想简要地向您展示，这只是一个关于如何使用 Cursor 来提高效率的简单示例。实际上有一个单独的视频专门介绍如何使用 Cursor 来提高效率。我只想让您有一种感觉，我从一个全新的项目开始，我要求这里的 Composer 应用程序(它被称为Composer 功能) 基本上设置一个新的 React 存储库，删除大量的样板文件，“请制作一个简单的井字棋应用程序”，所有这些都是由 Cursor 完成的。我实际上没有做任何事情，除了写五句话，然后它改变了一切，并编写了所有的 CSS、JavaScript等等。然后我在本地运行它并托管它，并在我的浏览器中与它交互。

这就是Cursor，它拥有您的应用程序的上下文，并且它正在通过 API 远程使用 Claude，而无需访问网页。我认为很多人目前都是以这种方式开发的。这些工具变得越来越复杂。例如，一开始您只能说 “改变这一行代码来做这个或那个”，使用Control K。然后有一个 Control L 命令，即“解释这段代码”，您可以看到将有一个 LLM 解释这段代码，以及发生了什么。在底层，它正在调用您如果实际在这里输入就可以访问的相同 API。但这个程序可以访问所有文件，所以它拥有所有的上下文。

### “Vibe Coding”：与 AI 协同编程的新模式

现在我们要做的是，不是命令 K 和命令 L，我们现在要做的是 命令 I，这是这个叫做Composer的工具。特别是有了新的代理集成，Composer 就像是您代码库上的一个自主代理。它将执行命令，它将根据需要更改所有文件，它可以跨多个文件进行编辑。所以您主要只是坐下来，您给出命令。这个新的编程模式被称为“Vibe coding”，我认为这个名字可能是我创造的。Vibe coding只是指让 Composer 控制并告诉它做什么，并希望它能工作。最坏的情况是，您总是可以回到旧的编程方式，因为我们有所有的文件，我们可以查看所有的 CSS，我们可以检查一切。如果您是一名程序员，那么原则上您可以任意更改这个。但现在您有一个非常有帮助的助手，可以为您做很多低级的编程工作。

让我们简单地试一下。假设当X 或 O 获胜时，我想要五彩纸屑或类似的东西。让我们看看它会产生什么。好的，“当玩家赢得比赛时，我会添加一个五彩纸屑效果。”。它希望我运行 react-confetti，这显然是我不知道的一个库。所以我们只会说 “好的”。它安装了 react-confetti库，现在它将更新应用程序。所以它正在更新 app TSX，TypeScript 文件，以便在玩家获胜时添加五彩纸屑效果。它目前正在编写代码，所以它正在生成，我们应该很快就能看到它。

好的，所以它基本上添加了这段代码，这里的一段代码，以及这里的一段代码。然后我们会问，“我们还会添加一些额外的样式，使获胜的单元格脱颖而出。”。好的，仍在生成。好的，它正在为获胜的单元格添加一些 CSS。老实说，我没有完全跟踪这个，它导入了 confetti，这似乎都很简单和合理，但我必须实际深入研究代码。好的，它想在玩家获胜时添加一个声音效果，这非常雄心勃勃。我实际上不太确定它是如何做到的，因为我不知道它是如何访问声音文件的，我不知道它将从哪里获得声音文件。

但每次它保存一个文件时，我们实际上都在部署它，所以我们实际上可以尝试刷新，看看我们现在有什么。它还添加了一个新的效果，您看到它是如何淡入的，这很酷。现在我们会赢。哇！实际上没想到这会奏效，这真的很复杂。让我们再玩一次。哇！ 哦，我明白了。所以它实际上暂停了，它在等待我。所以它希望我确认命令。“使 public/声音...我必须明确地确认它。”。让我们创建一个简单的音频组件来播放胜利的声音。“声音/胜利.mp3。”。这里的问题是胜利.mp3 不存在。所以我想知道它会做什么。它正在下载它，它想从某个地方下载它。让我们顺其自然。“让我们添加一个备用方案，以防声音文件不存在。”。在这种情况下，它实际上确实存在。“是的，我们可以添加，我们可以基本上创建一个 git 提交。”

好的，Composer 认为它完成了。让我们试着试一下。好的，非常令人印象深刻。我实际上不知道它从哪里得到了声音文件，我不知道这个 URL 来自哪里，但也许这只是出现在很多存储库中，有点像 Claude 知道它。但我对这个结果很满意。所以我们可以全部接受，就是这样。然后您就可以感觉到，我们可以继续开发这个应用程序。最坏的情况是，如果我们不能调试任何东西，我们总是可以回到标准编程，而不是Vibe coding。

## 结语：高级工具赋能，LLM 应用进入新纪元

本部分教程，我们深入探讨了深度研究、文件上传与上下文增强以及代码工具这三大类高级工具的应用。我们看到，深度研究解锁了 LLM 的深层知识挖掘能力，文件上传赋予了 LLM 个性化的知识库，而代码工具则将 LLM 变成了强大的生产力助手。这些高级工具的出现，极大地扩展了 LLM 的应用边界，也预示着 LLM 应用正在进入一个全新的纪元。在接下来的教程中，我们将继续探索多模态交互和LLM 的个性化定制等更前沿的话题。
