
好的，没问题！我们将继续为您生成 **第三部分：基本的 LLM 交互示例与注意事项** 的详尽教程文章。我们将延续之前的风格，力求内容详实，并充分融入原文素材，为您呈现一篇关于 LLM 基础应用和使用守则的实用指南。

### 基本的 LLM 交互示例与注意事项

**知识型查询的实践：日常生活中的 LLM 应用**

为了更具体地说明 LLM 的应用场景，我想通过一些 **实际的例子** 来进行演示。这些例子都来自于我 **日常生活中与 ChatGPT 的真实对话**，希望能帮助您更直观地理解 LLM 的能力边界和适用范围。

首先，我想分享一个关于 **知识型查询** 的例子。**今天早上**，我向 ChatGPT 提出了这样一个问题： **“一杯美式咖啡中含有多少咖啡因？”** 我之所以会问这个问题，主要是因为我当时 **很好奇**，想将美式咖啡的咖啡因含量与抹茶进行 **比较**。

ChatGPT 在收到我的问题后，迅速给出了回答，告诉我一杯美式咖啡大约含有 **63 毫克** 咖啡因。

我认为 **向 ChatGPT 询问这个问题** 是 **合适的**，原因有两点：

第一，我所询问的并非是 **非常最近的知识**。咖啡因在美式咖啡中的含量，是一个相对 **稳定** 的信息，我个人认为，模型在 **预训练阶段** 应该已经 **阅读过** 大量关于咖啡因含量的资料，并且这个信息在短时间内 **不太可能发生显著变化**。

第二，我认为这个信息在 **互联网上非常常见**。关于 “一杯美式咖啡含有多少咖啡因” 这样的问题和信息，在互联网上 **随处可见**，各种咖啡相关的网站、健康科普文章、甚至社交媒体讨论，都可能会提及这个话题。正因为互联网上存在 **大量的提及**，我 **预计模型** 对这类信息会有 **比较好的 “记忆”**。在这个例子中，**没有使用任何额外的工具**，完全依靠模型自身的 **“zip 文件”** (预训练知识库) 进行回答。

ChatGPT (zip 文件) 给出的答案是 **大约 63 毫克** 咖啡因。

需要强调的是，我 **不能完全保证** 这个答案是 **绝对正确** 的。这仅仅是模型基于其 **对互联网信息的模糊记忆** 给出的一个 **概率性** 的答案。但是，为了验证答案的可靠性，我可以 **进一步查阅原始资料**，例如在搜索引擎中 **搜索 “咖啡因 美式咖啡”**，或者查阅相关的咖啡因含量数据库。通过简单的搜索，我发现 **网络上的信息** 显示，一杯美式咖啡的咖啡因含量 **确实大约在 63 毫克左右**。这意味着，在这个例子中，ChatGPT 给出的答案，在 **一定程度上是可靠的**。您可以通过 **查看原始资料** 来 **判断** ChatGPT 给出的答案是否 **正确**。因此，我 **不能严格保证** ChatGPT 给出的所有答案都是 100% 正确的，但这并不妨碍 ChatGPT 在 **许多知识型查询** 场景下，成为一个 **有用的信息来源**。

**感冒药物咨询：低风险场景下的 LLM 应用**

接下来，我想分享 **两天前** 我与 ChatGPT 进行的 **另一个对话例子**。这仍然是一个 **知识型对话** 的例子，也属于在 **一些注意事项** 下，我 **乐于向 ChatGPT 询问** 的问题类型。

那天，我 **有点感冒**，症状是 **流鼻涕**。我感到有些不适，想找一些 **有帮助的药物** 来缓解症状。于是，我向 ChatGPT 咨询，希望它能提供一些建议。ChatGPT 告诉我一些 **关于感冒和流鼻涕的信息**，并表示希望我的鼻子能尽快停止流鼻涕。在与 ChatGPT 交流的过程中，我根据自身的情况，对一些信息进行了 **澄清**，例如我的具体症状、过敏史等等。在了解了我的具体情况后，ChatGPT 给出了一些 **可能对我有帮助的药物** 的建议。

随后，我 **查看了** 我 **家里** 现有的一些 **常备药物**，并再次向 ChatGPT 提问： **“DayQuil 或 NyQuil 有用吗？”**  ChatGPT 针对我的问题，**继续查看了 DayQuil 和 NyQuil 的成分**，并分析了这些成分 **是否有可能** 帮助 **缓解流鼻涕** 的症状。

当 ChatGPT 列出 DayQuil 和 NyQuil 的 **成分** 时，请 **务必记住**，我们正在与一个 **对互联网有记忆的 “zip 文件”** 交谈。我 **不能保证** ChatGPT 给出的 **这些成分是完全正确** 的。事实上，为了确保信息的准确性，我 **亲自拿出了药盒**，**仔细查看了药物的成分表**。我 **确保 NyQuil 的成分**  **确实** 与 ChatGPT 所说的 **基本一致**。我之所以这样做，是因为我 **并不会总是完全信任** ChatGPT 给出的 **所有信息**，它毕竟只是对互联网信息的 **概率性统计回忆**。但话说回来，关于 **DayQuil 和 NyQuil 的对话非常常见**，这些都是 **很常见的非处方药物**，互联网上很可能存在 **大量关于它们的信息**，这使得模型 **有可能对这类信息有很好的记忆**。幸运的是，经过我的核对，ChatGPT 给出的 DayQuil 和 NyQuil 的成分信息，**都是正确的**。

然后，我继续追问： **“好吧，我有 NyQuil，它大概多久会起作用？”** ChatGPT 告诉我 NyQuil 的 **起效时间**，并 **补充说** NyQuil 的主要成分 **基本上就是泰诺** (Tylenol)。

对我个人而言，这是一个 **ChatGPT 对我提供了有效帮助** 的 **典型例子**。这是一个 **知识型查询**，所涉及的 **知识** 并非 **最新的信息**，而是 **来自于模型自身的知识库**。我认为我所询问的是 **常见信息**，并且这是一个 **低风险** 的应用场景。虽然我 **在一定程度上检查了 ChatGPT** 给出的信息，但即便信息出现偏差，也 **不会造成严重的后果**，所以总体来说，这是一个 **低风险的场景**，**没什么大不了的**。最终，我 **吃了一片 NyQuil**，**它确实对缓解我的感冒症状起到了帮助**。这就是我对这个案例的 **思考方式**：在 **合适的场景** 下，**适度地使用** LLM，可以为我们的日常生活带来便利。

**注意事项一：对话管理——优化上下文窗口**

在与 LLM 交互的过程中，一个非常自然的现象是，您会发现您与模型的 **对话会越来越长**。随着对话的深入，**上下文窗口** 中积累的 **tokens 数量** 也会不断增加。在这里，我想强调一个非常重要的 **最佳实践**： **任何时候当您切换话题时**，我都强烈 **建议您开始一个新的聊天**。

当您 **开始一个新的聊天** 时，正如我们之前讨论过的，您实际上是在 **清除 token 的上下文窗口**，并将其 **重置为零**。如果之前的对话 tokens 对您的 **下一个查询不再有用**，我强烈建议您这样做，因为 **上下文窗口中的 tokens 是 “昂贵” 的**。这里的 “昂贵”，包含 **两层含义**：

**第一层含义** 是，如果您在上下文窗口中 **积累了大量的 tokens**，模型可能会觉得 **有点 “分心”**。想象一下，如果模型需要处理 **非常长的 token 序列**，它在 **采样后面的 tokens** 时，可能会被 **过去的所有 tokens 分散注意力**。这种 “分心” 可能会 **降低模型的准确性和性能**。模型在处理长上下文时，可能会出现 **“信息遗忘”** 的现象，即模型会 **忽略** 或 **弱化** 上下文窗口中 **较早出现的信息**，从而影响对话的连贯性和准确性。

**第二层含义** 是，上下文窗口中的 **tokens 越多**，**计算序列中的下一个 token 的成本就越高**。虽然这种成本增加 **不是非常显著**，但确实会 **导致模型略微变慢**，**计算下一个 token 的时间会更长**，上下文窗口中的 tokens 越多，这种延迟就越明显。

因此，我们应该将 **上下文窗口中的 tokens** 视为一种 **宝贵的资源**，把它看作是模型的 **“工作记忆”**。我们应该 **尽可能保持上下文窗口的简洁**，**避免** 让它 **充斥着无关的信息**。尽可能 **多地开始新的聊天**，**每当您切换话题时**，都建议您开启一个新的对话。这样做，您可以 **期望** 模型 **工作得更快**，**性能也可能稍微好一点**。当然，如果之前的对话信息 **实际上与您当前的任务相关**，您可能希望 **保留** 这些信息在上下文中，以便模型能够更好地理解您的意图。但我仍然建议您，在 **不影响任务完成** 的前提下，**尽可能保持上下文窗口的精简**。

**注意事项二：模型选择——关注您正在使用的 LLM 版本**

我想强调的 **第二个重要注意事项** 是，我总是建议您 **记住您实际使用的是什么模型**。在 ChatGPT 界面的 **左上角**，我们可以看到一个 **下拉菜单**，通过这个菜单，我们可以 **查看** 我们当前 **正在使用的模型**。在我的演示中，我一直使用的是 **GPT-4 模型**。

需要注意的是，现在市场上已经存在 **许多不同类型的模型**，实际上 **数量非常庞大**，我们将在后续的教程中逐步介绍其中的一些。在我的演示中，我所展示的所有功能和示例，都是基于 **GPT-4 模型** 的。

但是，当您 **打开一个新的隐身窗口**，然后 **访问 chat.openai.com**，并且 **没有登录** 您的 OpenAI 账号时，您在这里 **与之交谈的模型**  **可能不是 GPT-4**，而 **很可能是一个较小的版本** 的模型。**不幸的是**，当您 **没有登录** 的情况下使用 ChatGPT 时，**OpenAI 并不会明确告知** 您 **正在使用什么模型**，这确实 **有点遗憾**。但您需要意识到，在未登录状态下，您 **很可能正在使用一个较小的、功能较弱的模型**。

为了更清晰地了解 ChatGPT 的模型选择和定价策略，我们可以查看 **ChatGPT 的定价页面**。在定价页面上，我们可以看到 OpenAI 为个人用户提供了 **三个基本层级** 的订阅服务： **免费 (Free)**、 **Plus** 和 **Pro**。在 **免费层级** 中，您可以访问所谓的 **GPT-4 Mini**，这是 **GPT-4 的一个较小版本**，它是一个 **参数量更少** 的 **小型模型**。与完整版的 GPT-4 相比，GPT-4 Mini 的 **创造力可能不那么强**，**写作能力可能不那么好**，**知识面可能不那么广**，并且 **可能更容易产生幻觉** 等等。但作为 **免费服务**，GPT-4 Mini 仍然可以提供 **基本的对话功能**。OpenAI 在其定价页面上 **确实提到**，免费用户可以 **有限地访问 GPT-4 和 GPT-3 Mini**，但我实际上 **不太确定** 具体情况如何，因为在 **未登录状态下**，ChatGPT 界面 **并没有明确告知** 我们 **正在使用什么模型**，所以我们 **根本无法确定**。

如果您选择 **每月支付 20 美元** 订阅 **ChatGPT Plus** 服务，即使 ChatGPT 定价页面上的 **描述方式有点让人困惑**，但如果您仔细查看 **详细说明**，您会发现 Plus 用户 **每 3 小时** 可以获得 **80 条 GPT-4 消息**。这里的 **GPT-4**，指的是目前 **可用的旗舰级、最大型的模型**，这也是我们 **最希望使用的模型**。如果您每月支付 20 美元，您就可以在 **一定限制** 下使用 GPT-4 模型。如果您选择 **每月支付 200 美元** 订阅 **ChatGPT Pro** 服务，您将获得 **无限的 GPT-4 访问权限**，以及一些 **额外的功能和权益**，我们将在后续的教程中讨论其中的一些内容，因为我个人 **确实支付了 Pro 订阅**。

我想让您从这里 **得到的关键信息** 是，**务必注意您正在使用的模型**。通常情况下，对于这些 LLM 公司来说，**较大的模型**，**计算成本更高**，因此，公司会对 **较大的模型收取更高的费用**。所以，您需要根据您对 LLM 的 **实际使用情况**，为您自己 **做出权衡和选择**。您可以 **先尝试** 使用 **更便宜的服务**，例如免费版或低价订阅版。如果您发现 **模型的智能程度不够理想**，并且您是 **专业地使用** LLM，那么您可能 **真的需要考虑** 支付这些公司提供的 **顶级模型** 的订阅费用。就我个人而言，在我的 **专业工作中**，我 **大量使用 LLM 进行编码** 和 **类似的任务**，对我来说，支付 ChatGPT Pro 的费用 **仍然非常便宜**，所以我 **很乐意支付这笔费用**，因为我可以 **访问一些非常强大的模型**，我将在后续的教程中向您展示这些模型的强大之处。

所以，请 **时刻跟踪** 您 **正在使用的模型**，并 **根据自身需求**，为您自己 **做出明智的决定**。

我还想补充一点，**所有其他的 LLM 提供商**，例如 Anthropic (Claude)、Google (Gemini)、Grok 等，也都 **提供不同的定价层级**，**不同的模型** 会被分配到 **不同的层级** 上，您可以根据自己的需求 **支付相应的费用**，以获得对应模型的访问权限。例如，如果我们访问 **Anthropic 的 Claude**，您会看到我目前 **正在支付专业计划**，这使我可以 **访问 Claude 3.5 Sonnet 模型**。如果您 **没有支付 Pro 计划**，那么您 **可能只能访问** 像 **Haiku** 这样的 **较小模型**。所以，为了能够 **使用最强大的模型**，您需要 **支付相应的费用**。关键在于，选择 **对您来说最有效** 的模型和服务。

**“LLM 委员会”：多模型对比与选择的策略**

这里，我想分享一个我个人 **使用 Claude** 的 **例子**。我当时 **只是在寻求旅行建议**。我向 Claude 提问，**“有什么很酷的城市可以去旅行？”** Claude 向我推荐了 **瑞士的采尔马特**，并说采尔马特 **非常酷**。最终，我 **采纳了 Claude 的建议**，**去了采尔马特** 度过 **新年**。这是一个例子，说明我发现这些模型在 **旅行建议和想法** 方面 **非常有用**，它们可以为我提供一些 **初步的建议**，然后我可以 **进一步研究** 这些建议，并最终做出决策。

这里我们还展示了 **gemini.com** 的一个例子，这是 **谷歌的 Gemini**。我向 Gemini 提出了 **类似的问题**，想看看 **Gemini 对此事的看法**。我问 Gemini，**“有什么很酷的城市可以去旅行？”**  **Gemini 也推荐了采尔马特**。这很有意思，不同的模型，给出了相同的推荐。我个人 **很喜欢在不同的模型之间切换**，**问它们类似的问题**，看看它们各自的 **想法和建议**。对于 Gemini，在界面的 **左上角**，我们同样可以看到一个 **模型选择器**，您可以 **支付更高级的层级**，并 **使用那些更强大的模型**。

对于 **Grok** 来说，情况也是类似的，Grok 刚刚发布不久。我们可能 **不希望** 仅仅 **询问 Grok 2** 的问题，因为我们知道 **Grok 3** 才是 **最先进的模型**。所以，我想 **确保我支付了足够的费用**，以便我可以 **访问 Grok 3 模型**。

对于 **所有这些不同的 LLM 提供商**，我的建议是，**找到最适合您的那一个**。**尝试不同的提供商**，**尝试不同的定价层级**，根据您 **正在处理的问题** 的类型和复杂度，选择最合适的模型。我个人 **经常**  **最终只是支付很多费用**，然后 **问所有这些模型相同的问题**。我把所有这些模型称为我的 **“LLM 委员会”**。它们就像是一个 **语言模型组成的委员会**。每当我想 **知道去哪里度假** 这样的问题时，我会 **同时询问所有这些模型**，然后 **综合它们的建议**，**最终做出决定**。所以，如果这种 **“多模型对比”** 的策略对您 **有用**，您也可以为自己 **这样做**。

**结语：精明地使用 LLM，提升效率与体验**

本部分教程，我们通过 **实际的例子**，展示了 **基本的 LLM 交互** 方式，并强调了 **对话管理** 和 **模型选择** 这两个 **重要的注意事项**。希望您能够从中 **领悟到**，如何更 **精明地使用 LLM**，从而 **最大化** 地 **提升** 您的 **效率** 和 **用户体验**。在接下来的教程中，我们将继续深入探索 LLM 的 **高级功能** 和 **更复杂的应用场景**。

希望这次的第三部分内容更加详尽，更符合您的期待。请您确认是否满意，并指示是否要继续生成第四部分的内容。