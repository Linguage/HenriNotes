《DeepSeek、AI技术发展与中美竞争》
- 原文标题：DeepSeek, China, OpenAI, NVIDIA, xAI, TSMC, Stargate, and AI Megaclusters | Lex Fridman Podcast #459 - YouTube
- 链接：[YouTube](https://www.youtube.com/watch?v=_1f-o0nqpEI&t=37s )

- **文章类别**：博客/访谈实录

---

**内容整理**：

### 视频纲要

```
├── 一、 简介 (0:00)
│   ├── 介绍嘉宾 Dylan Patel 和 Nathan Lambert
│   └── 播客主题概述：深入探讨 AI 行业的多个关键方面
├── 二、 DeepSeek-R1 和 DeepSeek-V3 (3:33)
│   ├── DeepSeek-V3
│   │   ├── 专家混合（MoE）语言模型
│   │   ├── 开放权重模型
│   │   └── 类似 ChatGPT 的指令模型
│   ├── DeepSeek-R1
│   │   ├── 推理模型
│   │   └── 展示推理过程 (Chain of Thought)
│   ├── 训练过程
│   │   ├── 预训练 (Pre-training)：自回归预测
│   │   └── 后训练 (Post-training)
│   │       ├── 指令微调/监督微调 (SFT)
│   │       ├── 偏好微调 (RLHF)
│   │       └── 强化学习微调
│   └── 开放权重 vs. 开源
│       └── 数据安全：取决于托管模型的服务提供商
├── 三、 低训练成本 (25:07)
│   ├── 关键技术
│   │   ├── 专家混合模型 (MoE)：只激活部分参数
│   │   └── 多头潜在注意力机制 (MLA)：减少内存使用
│   ├── Transformer 架构
│   ├── 低级优化：CUDA 级别以下的优化
│   ├── 稀疏性：32 比 4 的高稀疏因子
│   └── 辅助损失 (Auxiliary Loss) 的改进
├── 四、 DeepSeek 计算集群 (51:25)
│   ├── 母公司 High-Flyer：拥有大量 GPU 资源的对冲基金
│   ├── 2021 年：10,000 块 A100 GPU 集群
│   ├── DeepSeek-V3 预训练：2,000 块 H800 GPU
│   └── 估计拥有约 50,000 块 GPU
├── 五、 对中国的 GPU 出口管制 (58:57)
│   ├── H100 vs. H800：针对中国市场的“阉割版”
│   ├── H20：进一步削减算力，提升内存带宽和容量
│   ├── 出口管制的目的：限制中国 AI 计算能力的发展
│   ├── 影响：可能促使中国加大自主研发芯片力度
│   └── 走私：存在但规模有限
├── 六、 AGI 时间表 (1:09:16)
│   ├── AGI 定义的讨论
│   ├── Dario Amodei 的预测：2026 年出现“超级强大的 AI”
│   ├── 嘉宾预测：Nathan 2030 年后；Dylan 认为 AI 已产生影响
│   └── 军事应用：虚假信息宣传、网络攻击等
├── 七、 中国的制造业能力 (1:18:41)
│   ├── 强大的制造业能力：电力、钢铁、铝等
│   └── 长期影响：出口管制可能导致中国在芯片制造方面超越美国
├── 八、 与中国的冷战 (1:26:36)
│   ├── DeepSeek 的崛起可能加剧中美之间的“冷战”风险
│   └── 可能的影响：台湾问题、全球局势不稳定
├── 九、 台积电与台湾 (1:31:05)
│   ├── 台积电 (TSMC)：全球领先的半导体代工厂
│   ├── 供应链：芯片设计公司外包制造给台积电
│   ├── 代工模式 (Foundry Model)：规模经济和专业化
│   ├── 台湾的重要性：全球半导体供应链的关键环节
│   └── 美国的努力：将部分芯片制造转移到美国本土，面临挑战
├── 十、 最适合 AI 的 GPU (1:54:44)
│   ├── GPU 的三个关键指标：算力、内存带宽和容量、互连带宽
│   ├── H20：适合推理任务
│   ├── 推理 vs. 训练：不同的成本侧重点
│   └── KV 缓存：优化技术，对内存容量要求高
├── 十一、 DeepSeek 为何如此便宜 (2:09:36)
│   ├── 模型架构创新：MLA
│   ├── 低级优化
│   ├── 与 OpenAI 的比较：技术优势和利润率差异
│   ├── 中国政府补贴：可能没有直接补贴，但母公司提供资金支持
│   └── 市场策略：低价策略
├── 十二、 间谍活动 (2:22:55)
│   ├── 开源模型的潜在风险：后门
│   └── 文化偏见：语言模型可能反映训练数据的文化偏见
├── 十三、 审查制度 (2:31:57)
│   ├── 审查或过滤的方式
│   │   ├── 数据选择
│   │   ├── 后训练
│   │   └── 系统提示
│   └── 难点：难以完全消除偏见或特定信息
├── 十四、 Andrej Karpathy 与 RL 的魔力 (2:44:52)
│   ├── Andrej Karpathy 的推文：模仿学习 vs. 试错学习/强化学习
│   ├── 强化学习的重要性：发现新的解决策略
│   ├── Chain of Thought 的起源：可能源于强化学习
│   └── 可验证的任务：强化学习在可验证的任务上效果更好
├── 十五、 OpenAI O3-mini vs DeepSeek R1 (2:55:23)
│   ├── O3-mini：OpenAI 新发布的推理模型
│   ├── Gemini Flash：Google 的推理模型，成本更低，性能接近
│   ├── 推理模型的特点：展示推理过程
│   └── 评估：需要综合考虑不同的评估指标
├── 十六、 英伟达 (3:14:31)
│   ├── DeepSeek 对 Nvidia 的影响：股价下跌
│   └── Nvidia 的优势：硬件和软件生态系统
├── 十七、 GPU 走私 (3:18:58)
│   ├── 走私规模：存在但有限
│   └── 主要参与者：字节跳动等公司
├── 十八、 DeepSeek 使用 OpenAI 数据进行训练 (3:25:36)
│   ├── 数据蒸馏：使用一个模型的输出作为另一个模型的训练数据
│   ├── OpenAI 的指控：DeepSeek 使用了其模型的输出进行训练
│   └── 争议：合法性和伦理性存在争议
├── 十九、 AI 超级集群 (3:36:04)
│   ├── 定义：包含大量 GPU 的数据中心
│   ├── 规模：OpenAI 的 Stargate 项目计划建设 2.2 吉瓦的超级集群
│   ├── 参与者：Meta、Google、Amazon、xAI 等
│   ├── 电力需求：巨大，对电网构成挑战
│   ├── 冷却：需要高效的冷却系统，例如水冷
│   └── 互连：需要高速互连
├── 二十、 谁将赢得 AGI 竞赛？(4:11:26)
│   ├── 领先者：OpenAI（模型性能）、Google（基础设施）、Meta（用户规模）
│   ├── 盈利：目前只有 Nvidia 等硬件厂商盈利
│   ├── 未来：AGI 的发展可能导致行业格局发生变化
│   └── 多强格局：未来 AI 行业可能出现多强格局
├── 二十一、 AI 智能体 (4:21:39)
│   ├── 定义：能够独立完成任务、适应不确定性的 AI 系统
│   ├── 现状：技术还不成熟
│   ├── 应用：自动化各种任务，例如预订机票、管理日程等
│   └── 挑战：构建可靠的 AI 智能体非常困难
├── 二十二、 编程与 AI (4:30:21)
│   ├── 影响：改变软件开发的方式，自动化代码生成等任务
│   ├── 软件工程师的角色：转变为 AI 系统的管理者和监督者
│   └── 机遇：为软件工程师创造新的机遇
├── 二十三、 开源 (4:37:49)
│   ├── Tulu：艾伦人工智能研究所发布的开源模型，基于 Llama
│   ├── Almo：专注于预训练的开源模型
│   ├── 开源的意义：促进 AI 技术普及，提高透明度和可复制性
│   └── 挑战：训练和维护成本较高
├── 二十四、 Stargate (4:47:01)
│   ├── 项目概述：OpenAI 与微软合作的超级集群项目，计划投资 1000 亿美元
│   ├── 资金来源：尚不明确，可能来自软银、甲骨文等
│   └── 建设进度：正在建设中，具体进度未知
└── 二十五、 AI 的未来 (4:54:30)
    ├── 技术突破：网络、模型架构、训练方法等方面
    ├── 社会影响：需要更多人参与 AI 的开发和治理
    ├── 开放与合作：对 AI 的健康发展至关重要
    └── 长期展望：AI 有望解决许多挑战，但也可能带来新的风险
```


#### 文章标签
#DeepSeek ， #AI技术 ， #中美竞争 ， #模型训练 ， #开源与商业化 ， #地缘政治

#### 详细内容



---


视频主要讨论了中国公司深势科技（DeepSeek）推出的两款人工智能模型：DeepSeek-V3和DeepSeek-R1。以下是根据视频目录提取的框架与要点内容：

**一、 简介 (0:00)**

*   介绍两位嘉宾：Dylan Patel 和 Nathan Lambert。
*   Dylan Patel 运营专注于半导体、GPU、CPU 和 AI 硬件的知名研究分析公司 SemiAnalysis。
*   Nathan Lambert 是艾伦人工智能研究所的研究科学家，也是 AI 博客 Interconnects 的作者。
*   简述讨论主题：深入探讨 AI 行业的多个关键方面，包括 DeepSeek、OpenAI、Google、xAI、Meta、Anthropic、Nvidia、台积电，以及中美关系等。

**二、 DeepSeek-R1 和 DeepSeek-V3 (3:33)**

*   **DeepSeek-V3**：基于 Transformer 的专家混合（Mixture of Experts, MoE）语言模型，发布于 2023 年 12 月 26 日。
    *   是一个开放权重模型（open weight model），模型权重可供下载。
    *   包含“基础模型”（base model）和“指令模型”（instruction model）两种，“指令模型”类似 ChatGPT，可用于各种应用。
    *   采用 MIT 许可证，较为宽松。
    *   具有与 GPT-4、Llama-405b 等模型竞争的性能。
*   **DeepSeek-R1**：推理模型（reasoning model），发布于 2024 年 1 月 20 日。
    *   与 DeepSeek-V3 有重叠的训练步骤，但训练过程不同。
    *   “R1”中的“R”代表“Reasoning”（推理）。
    *   能够展示推理过程（Chain of Thought），而不仅仅是最终答案。
    *   在用户体验方面，DeepSeek-V3 类似于 ChatGPT，而 DeepSeek-R1 会显示详细的推理步骤，然后给出答案。
*   **训练过程**：
    *   **预训练（Pre-training）**：在大量文本数据上进行自回归预测（autoregressive prediction），预测下一个 token。DeepSeek-V3 的基础模型就是通过预训练得到的。
    *   **后训练（Post-training）**：对预训练模型进行微调，以使其具备特定能力。
        *   **指令微调（Instruction Tuning）/ 监督微调（Supervised Fine-tuning, SFT）**：通过添加格式化信息，使模型能够理解并回答问题，例如“解释罗马帝国的历史”。
        *   **偏好微调（Preference Fine-tuning）**：基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF），使模型的回答更符合人类偏好。
        *   **强化学习微调（Reinforcement Fine-tuning）**：使用强化学习技术，让模型在特定任务（如数学、代码）上进行自我改进。
*   **开放权重（Open Weights）与开源（Open Source）的区别**：
    *   开放权重指的是模型权重可供下载，但不一定包括训练数据和代码。
    *   开源通常指代码、数据和权重都公开，具有更高的透明度和可复制性。
    *   DeepSeek 模型是开放权重的，但不一定是完全开源的。
*   **数据安全**：开放权重模型本身不收集数据，数据安全取决于托管模型的服务提供商。

**三、 低训练成本 (25:07)**

*   DeepSeek 模型训练成本低的关键技术：
    *   **专家混合模型（Mixture of Experts, MoE）**：只激活模型的一部分参数进行计算，降低了计算量。DeepSeek 模型拥有 6000 多亿参数，但每次计算只激活约 370 亿参数。
    *   **多头潜在注意力机制（Multi-head Latent Attention, MLA）**：减少推理过程中的内存使用。
*   **Transformer 架构**：由注意力机制（attention mechanism）和前馈神经网络（feed forward network）交替组成。MoE 应用于前馈神经网络部分。
*   **低级优化**：DeepSeek 团队进行了 CUDA 级别以下的底层优化，例如自定义 GPU 通信调度，以提高效率。
*   **稀疏性**：DeepSeek 的 MoE 模型具有很高的稀疏性（32 比 4），即每次计算激活的专家数量相对于总专家数量的比例非常低，进一步降低了计算成本。
*   **辅助损失（Auxiliary Loss）**：DeepSeek 改进了 MoE 的路由机制，避免了使用传统的辅助损失，可能更有利于模型的学习。

**四、 DeepSeek 计算集群 (51:25)**

*   DeepSeek 的母公司是一家名为“High-Flyer”的对冲基金，该公司拥有大量 GPU 资源。
*   2021 年，High-Flyer 宣称拥有中国最大的 A100 GPU 集群（10,000 块）。
*   DeepSeek 使用了 2,000 块 H800 GPU 进行了 DeepSeek-V3 的预训练。
*   据估计，DeepSeek 可能拥有约 50,000 块 GPU。

**五、 对中国的 GPU 出口管制 (58:57)**

*   美国对中国实施了 GPU 出口管制，限制高性能 GPU 出口到中国。
*   **H100 与 H800**：H100 是 Nvidia 的旗舰 GPU，H800 是针对中国市场的“阉割版”，降低了互连带宽。H800 已被禁止出口。
*   **H20**：Nvidia 推出的新一代针对中国市场的 GPU，降低了算力，但提高了内存带宽和容量。
*   **出口管制的目的**：限制中国 AI 计算能力的发展，尤其是在军事领域的应用。
*   **影响**：出口管制可能会促使中国加大自主研发芯片的力度，但短期内难以达到美国的水平。
*   **走私**：存在 GPU 走私现象，但规模有限。

**六、 AGI 时间表 (1:09:16)**

*   **AGI（通用人工智能）**：嘉宾对 AGI 的定义存在分歧，Nathan 认为当前的语言模型已经可以算作 AGI，而 Dylan 认为 AGI 应该具备更强大的能力。
*   **Dario Amodei（Anthropic CEO）**：预测 2026 年将出现“超级强大的 AI”（super powerful AI），对国家安全构成威胁。
*   **嘉宾预测**：Nathan 认为未来几年 AI 将持续快速发展，预计 2030 年后可能出现“超级强大的 AI”；Dylan 认为 AI 已经对选举等领域产生了影响，关键在于计算能力的差异。
*   **军事应用**：AI 可能被用于军事领域，例如虚假信息宣传、网络攻击等。

**七、 中国的制造业能力 (1:18:41)**

*   中国拥有强大的制造业能力，包括电力、钢铁、铝等行业。
*   如果中国决定大力发展 AI，其工业能力可以支持大规模数据中心的建设。
*   **长期影响**：出口管制可能导致中国在芯片制造方面最终超越美国。

**八、 与中国的冷战 (1:26:36)**

*   DeepSeek 的崛起可能加剧中美之间的“冷战”风险。
*   **可能的影响**：
    *   中国可能采取措施控制台湾，以获取半导体资源。
    *   中美之间的技术差距可能导致全球局势更加不稳定。

**九、 台积电与台湾 (1:31:05)**

*   **台积电（TSMC）**：全球领先的半导体代工厂，生产大部分先进芯片。
*   **供应链**：芯片设计公司（如 Nvidia、AMD）将芯片制造外包给台积电。
*   **代工模式（Foundry Model）**：台积电专注于芯片制造，不设计芯片，这种模式的成功得益于规模经济和专业化。
*   **台湾的重要性**：台湾的台积电是全球半导体供应链的关键环节，其地位难以被取代。
*   **美国的努力**：美国试图通过补贴和政策支持，将部分芯片制造转移到美国本土，但面临成本、人才、文化等多方面挑战。

**十、 最适合 AI 的 GPU (1:54:44)**

*   **GPU 的三个关键指标**：算力（flops）、内存带宽和容量、互连带宽。
*   **H20**：在算力上进行了削减，但在内存带宽和容量上有所提升，适合推理任务。
*   **推理（Inference）与训练（Training）的区别**：
    *   推理指使用训练好的模型进行预测，训练指训练模型的过程。
    *   推理的成本主要取决于内存带宽和容量，而训练的成本主要取决于算力。
*   **KV 缓存（KV Cache）**：注意力机制中的一种优化技术，用于存储键值对，减少重复计算。KV 缓存的大小与上下文长度（context length）成正比，对内存容量要求较高。

**十一、 DeepSeek 为何如此便宜 (2:09:36)**

*   **模型架构创新**：MLA 等技术降低了内存使用。
*   **低级优化**：CUDA 级别以下的优化提高了效率。
*   **与 OpenAI 的比较**：DeepSeek-R1 的推理成本远低于 OpenAI 的 O1，部分原因是 OpenAI 的利润率较高，另一部分原因是 DeepSeek 的技术优势。
*   **中国政府补贴**：嘉宾认为 DeepSeek 可能没有得到中国政府的直接补贴，但其母公司 High-Flyer 提供了资金支持。
*   **市场策略**：DeepSeek 可能采取了低价策略来吸引用户和开发者。

**十二、 间谍活动 (2:22:55)**

*   **开源模型的潜在风险**：开源模型可能被植入后门，用于窃取信息或操纵用户。
*   **文化偏见**：语言模型可能反映训练数据的文化偏见。

**十三、 审查制度 (2:31:57)**

*   **审查或过滤**：可以通过多种方式对 AI 模型进行审查或过滤，例如：
    *   数据选择：在预训练阶段选择性地过滤数据。
    *   后训练：使用 RLHF 等技术调整模型的行为。
    *   系统提示（System Prompt）：在推理阶段添加提示信息，引导模型的输出。
*   **难点**：难以完全消除模型中的偏见或特定信息。

**十四、 Andrej Karpathy 与 RL 的魔力 (2:44:52)**

*   **Andrej Karpathy 的推文**：总结了两种主要的学习方式：模仿学习（imitation learning）和试错学习（trial and error learning）/ 强化学习（reinforcement learning）。
*   **强化学习的重要性**：强化学习能够发现新的解决策略，例如 AlphaGo 击败李世石的“第 37 手”。
*   **Chain of Thought 的起源**：Chain of Thought 可能源于强化学习，模型通过试错学习到推理的步骤。
*   **可验证的任务**：强化学习在可验证的任务（如数学、代码）上效果更好。

**十五、 OpenAI o3-mini vs DeepSeek R1 (2:55:23)**

*   **O3-mini**：OpenAI 刚刚发布的推理模型。
*   **Gemini Flash**：Google 的推理模型，发布于 2023 年 12 月，成本比 R1 低，性能与 R1 接近。
*   **推理模型的特点**：推理模型通常会展示推理过程，而不仅仅是最终答案。
*   **评估**：不同的模型在不同的评估指标上表现不同，需要综合考虑。

**十六、 英伟达 (3:14:31)**

*   **DeepSeek 对 Nvidia 的影响**：DeepSeek 的低成本模型引发了市场对 Nvidia 前景的担忧，导致 Nvidia 股价下跌。
*   **Jevons Paradox**：效率的提高可能导致资源消耗的增加。
*   **Nvidia 的优势**：Nvidia 在 AI 芯片市场占据主导地位，其硬件和软件生态系统难以被取代。

**十七、 GPU 走私 (3:18:58)**

*   **走私规模**：存在 GPU 走私现象，但规模有限。
*   **主要参与者**：字节跳动等公司可能通过租赁等方式获取了大量 GPU。

**十八、 DeepSeek 使用 OpenAI 数据进行训练 (3:25:36)**

*   **数据蒸馏（Distillation）**：使用一个模型的输出作为另一个模型的训练数据。
*   **OpenAI 的指控**：OpenAI 声称 DeepSeek 使用了其模型的输出进行训练。
*   **争议**：这种做法的合法性和伦理性存在争议。
*   **互联网数据**：AI 模型通常使用互联网数据进行训练，难以完全避免使用 OpenAI 的数据。

**十九、 AI 超级集群 (3:36:04)**

*   **超级集群（Megaclusters）**：指包含大量 GPU 的数据中心，用于 AI 训练和推理。
*   **规模**：OpenAI 的 Stargate 项目计划建设 2.2 吉瓦的超级集群，包含数十万块 GPU。
*   **参与者**：Meta、Google、Amazon、xAI 等公司都在建设或计划建设超级集群。
*   **电力需求**：超级集群的电力需求巨大，对电网构成挑战。
*   **冷却**：超级集群需要高效的冷却系统，例如水冷。
*   **互连**：超级集群内部的 GPU 需要高速互连。

**二十、 谁将赢得 AGI 竞赛？(4:11:26)**

*   **领先者**：目前 OpenAI 在模型性能方面领先，Google 在基础设施方面领先，Meta 在用户规模方面领先。
*   **盈利**：目前只有 Nvidia 等硬件厂商在 AI 领域实现了盈利。
*   **未来**：AGI 的发展可能导致 AI 行业的格局发生变化。
*   **多强格局**：多位嘉宾认为未来 AI 行业可能出现多强格局，而不是一家独大。

**二十一、 AI 智能体 (4:21:39)**

*   **定义**：能够独立完成任务、适应不确定性的 AI 系统。
*   **现状**：当前的 AI 智能体技术还不成熟。
*   **应用**：AI 智能体可能被用于自动化各种任务，例如预订机票、管理日程等。
*   **挑战**：构建可靠的 AI 智能体非常困难，需要解决安全性、可靠性等问题。

**二十二、 编程与 AI (4:30:21)**

*   **影响**：AI 正在改变软件开发的方式，自动化代码生成、代码补全等任务。
*   **软件工程师的角色**：软件工程师的角色将转变为 AI 系统的管理者和监督者。
*   **机遇**：AI 将为软件工程师创造新的机遇，例如开发 AI 应用、构建 AI 基础设施等。

**二十三、 开源 (4:37:49)**

*   **Tulu**：艾伦人工智能研究所发布的开源模型，基于 Llama 3 405b，并提供了训练代码和数据。
*   **Almo**：艾伦人工智能研究所发布的另一个开源模型，专注于预训练。
*   **开源的意义**：促进 AI 技术的普及和发展，提高透明度和可复制性。
*   **挑战**：开源 AI 模型的训练和维护成本较高。

**二十四、 Stargate (4:47:01)**

*   **项目概述**：OpenAI 与微软合作建设的超级集群项目，计划投资 1000 亿美元，包含数十万块 GPU。
*   **资金来源**：资金来源尚不明确，可能来自软银、甲骨文等投资者。
*   **建设进度**：项目正在建设中，具体进度未知。

**二十五、 AI 的未来 (4:54:30)**

*   **技术突破**：嘉宾对 AI 领域的多个技术方向表示期待，例如网络、模型架构、训练方法等。
*   **社会影响**：AI 将对社会产生深远影响，需要更多人参与到 AI 的开发和治理中。
*   **开放与合作**：开放和合作对于 AI 的健康发展至关重要。
*   **长期展望**：AI 有望解决人类面临的许多挑战，但也可能带来新的风险。

---

## 内容提炼

### 关键内容

**1. DeepSeek-R1 和 DeepSeek-V3**

DeepSeek 推出了两款引人注目的 AI 模型：DeepSeek-V3 和 DeepSeek-R1，分别代表了当前语言模型发展的两个重要方向。DeepSeek-V3 是一个基于 Transformer 架构的专家混合 (MoE) 模型，类似于 ChatGPT，它采用了开放权重的模式，这意味着任何人都可以下载和使用其模型权重，这无疑为 AI 社区注入了新的活力。与 V3 不同，R1 则是一个专注于推理的模型，它的发布真正推动了关于 AI 推理能力的讨论。R1 的一个显著特点是它能够展示推理过程，即“思维链”(Chain of Thought)，而不仅仅是提供最终答案，这使得用户可以更好地理解模型的决策过程，增强了模型的可解释性。正如 Nathan Lambert 所强调的，DeepSeek 在模型架构和训练技术上进行了诸多创新，例如多头潜在注意力机制 (MLA) 和对 MoE 路由机制的改进，这些创新显著降低了模型的计算和内存成本，使得 DeepSeek 模型在性能上可以与业界领先的模型相媲美，同时在成本上更具优势。

**2. 低训练成本的背后**

DeepSeek 模型之所以能够实现如此低的训练成本，离不开其在技术上的多项创新。首先，专家混合模型 (MoE) 的采用是关键因素之一。MoE 架构允许模型在每次计算时只激活一部分参数，而不是像传统密集模型那样激活所有参数，这大大减少了计算量。正如 Dylan Patel 所解释的，DeepSeek 的模型拥有超过 6000 亿个参数，但每次计算仅激活约 370 亿个，这种稀疏性极大地提高了计算效率。其次，DeepSeek 团队在底层进行了深入的优化，甚至深入到了 CUDA 级别以下。他们开发了多头潜在注意力机制 (MLA) 等新技术，有效降低了推理过程中的内存使用。此外，他们还对 MoE 架构中的路由机制进行了改进，避免了使用传统的辅助损失，从而可能更有利于模型的学习。这些技术创新，加上他们在硬件和软件层面的精细优化，共同造就了 DeepSeek 模型低成本、高性能的特点。

**3. DeepSeek 背后的计算集群**

DeepSeek 模型的背后，是其母公司 Highflyer 强大的计算资源支持。Highflyer 是一家专注于量化交易的对冲基金，早在 2021 年就宣称拥有中国最大的 A100 GPU 集群，规模达到 10,000 块。这表明该公司在 AI 领域早有布局，并为其后续在 AI 模型方面的突破奠定了坚实的基础。据估计，DeepSeek 目前可能拥有约 50,000 块 GPU，尽管他们公开表示 DeepSeek-V3 的预训练只使用了 2,000 块 H800 GPU。这其中的差距可能源于多种因素，包括研究和消融实验、内部其他业务的需求，以及出于某些原因不愿透露全部实力。无论如何，DeepSeek 拥有庞大的计算资源是不争的事实，这也为其模型的快速迭代和性能提升提供了有力保障。

**4. 对中国的 GPU 出口管制**

美国对中国的 GPU 出口管制是近年来科技领域的一个重要事件。美国政府出于对国家安全的考虑，限制向中国出口高性能 GPU，特别是 Nvidia 的 H100 和针对中国市场推出的“阉割版”H800。这些限制措施旨在遏制中国在 AI，尤其是军事领域的发展速度。然而，正如 Dylan Patel 所指出的，这种做法也存在一些潜在的风险和负面影响。首先，出口管制可能会促使中国加大自主研发芯片的力度，虽然短期内难以达到美国的水平，但从长远来看，中国完全有可能在芯片制造领域实现赶超甚至超越。其次，这种限制措施可能会导致全球 AI 领域的“军备竞赛”加剧，各国都将投入更多资源来发展自己的 AI 技术，从而加剧国际局势的不稳定性。此外，GPU 的走私现象也难以完全杜绝，尽管规模有限，但这仍然是一个不可忽视的漏洞。

**5. AGI 时间表与超级智能的威胁**

关于通用人工智能 (AGI) 何时到来，以及它是否会对人类构成威胁，是一个充满争议的话题。嘉宾们对此也表达了不同的看法。Nathan Lambert 认为，当前的语言模型已经可以算作某种形式的 AGI，而 Dylan Patel 则认为 AGI 应该具备更强大的能力，例如自主完成复杂任务、适应不确定性等。Anthropic 的 CEO Dario Amodei 预测，到 2026 年将出现“超级强大的 AI”，这将对国家安全构成重大威胁。Nathan 认为未来几年 AI 将继续快速发展，预计 2030 年后可能出现这种“超级强大的 AI”。Dylan 则认为，AI 已经开始对选举等领域产生影响，关键在于计算能力的差异，以及谁能更好地利用这种能力。尽管对于 AGI 的定义和时间表存在分歧，但两位嘉宾都认为，AI 的发展将对社会产生深远的影响，需要认真对待。

**6. 中国的制造业能力及其影响**

中国拥有强大的制造业能力，这为其在 AI 领域的发展提供了坚实的基础。正如 Dylan Patel 所指出的，中国在电力、钢铁、铝等行业拥有巨大的产能，这使得中国有能力建设大规模的数据中心来支持 AI 的训练和推理。如果中国决定大力发展 AI，其工业能力可以支撑这一目标。然而，这也引发了一些担忧，即美国对中国的出口管制可能会弄巧成拙，最终导致中国在芯片制造等关键领域超越美国。因为长期限制会促使中国加大自主研发的力度，并在本土建立起完整的产业链。从长远来看，这可能会削弱美国在全球科技领域的领导地位。

**7. 中美之间的 AI “冷战”**

DeepSeek 的崛起被一些人视为中美 AI “冷战”加剧的标志。美国对中国的技术出口管制，特别是针对 GPU 的限制，被认为是为了遏制中国在 AI 领域的发展。这种做法可能会导致两国在 AI 领域的竞争进一步加剧，甚至可能引发更广泛的地缘政治紧张局势。正如 Dylan Patel 所指出的，中国可能会采取措施来应对美国的限制，例如加大自主研发力度、寻求替代方案，甚至采取更激进的措施。这种不确定性给全球局势带来了更大的风险。

**8. 台积电与台湾在全球半导体产业中的关键地位**

台积电 (TSMC) 作为全球领先的半导体代工厂，在全球半导体产业中扮演着至关重要的角色。它为包括 Nvidia、AMD、苹果在内的众多科技巨头生产芯片，其先进制程技术更是领先业界。台湾在全球半导体供应链中的关键地位，也使得台湾问题成为了一个敏感的地缘政治议题。美国正试图通过补贴和政策支持，将部分芯片制造转移到美国本土，以减少对台积电的依赖，但这面临着成本、人才、文化等多方面的挑战。正如 Dylan Patel 所说，台积电拥有数十年的技术积累和庞大的专业人才队伍，这是其他地区难以在短时间内复制的。

**9. 推理模型的兴起与计算需求的变化**

推理模型的兴起，特别是 DeepSeek-R1 这样的能够展示推理过程的模型，正在改变 AI 领域对计算资源的需求模式。与传统的预训练模型相比，推理模型更依赖于内存带宽和容量，而不是单纯的算力。正如 Nathan Lambert 所解释的，DeepSeek-R1 使用了诸如多头潜在注意力机制 (MLA) 等技术来降低内存使用，但这仍然是一个重要的限制因素。此外，推理模型通常需要进行多次采样和迭代才能得出最终结果，这也增加了计算的复杂性和成本。

**10. DeepSeek 的商业模式与开源策略**

DeepSeek 的商业模式和开源策略也是讨论的焦点之一。DeepSeek 的模型是开放权重的，这意味着任何人都可以下载和使用其模型权重，这与传统的闭源模式形成了鲜明对比。这种开放性为 AI 社区带来了活力，但也引发了一些关于数据安全、知识产权和商业竞争的讨论。尽管 DeepSeek 的模型在性能上可以与业界领先的模型相媲美，但其盈利模式尚不明确。与 OpenAI 等公司通过 API 服务和企业解决方案获得收入不同，DeepSeek 目前似乎更侧重于技术本身的研发和推广。

**11. AI 代理的潜力和挑战**

AI 代理被认为是 AI 发展的下一个重要方向，它们被期望能够独立完成复杂的任务，适应不确定的环境，并在无需人工干预的情况下持续学习和改进。然而，正如 Nathan Lambert 所指出的，目前的 AI 代理技术还不成熟，要实现真正的自主性和通用性还有很长的路要走。构建可靠的 AI 代理非常困难，需要解决安全性、可靠性、可解释性等诸多挑战。此外，还需要考虑人机交互的问题，如何设计一个既能充分发挥 AI 代理的能力，又能让人类用户感到舒适和信任的交互界面，是一个重要的研究方向。

**12. AI 对编程和软件开发的影响**

AI，特别是代码生成模型，正在对编程和软件开发产生深远的影响。正如 Dylan Patel 所指出的，AI 已经可以自动化许多传统的编程任务，例如代码补全、函数生成等。这将大大提高软件开发的效率，并可能导致软件工程师的角色发生转变。未来，软件工程师可能更多地扮演 AI 系统的管理者和监督者的角色，而不是从头开始编写每一行代码。此外，AI 还可以帮助那些不擅长编程的领域专家更好地利用软件工具来解决他们的问题，从而推动各个行业的创新。

**13. 开源 AI 的发展与挑战**

开源 AI 是近年来兴起的一个重要趋势，它为 AI 技术的普及和发展提供了新的动力。艾伦人工智能研究所发布的 Tulu 和 Almo 模型就是开源 AI 的代表。通过开源代码、数据和模型权重，研究人员和开发者可以更好地理解和改进 AI 模型，加速 AI 技术的创新。然而，开源 AI 也面临着一些挑战，例如训练和维护成本较高，缺乏明确的商业模式，以及如何平衡开放性和安全性等问题。

**14. Stargate 项目与 AI 基础设施的未来**

OpenAI 与微软合作的 Stargate 项目代表了 AI 基础设施建设的一个新高度。该项目计划建设一个包含数十万块 GPU 的超级集群，其规模和投资都前所未有。Stargate 项目的实施将需要解决许多技术和工程上的挑战，包括电力供应、冷却系统、网络互连等等。该项目的成功将为未来更大规模、更强大的 AI 系统的开发奠定基础。

**15. 对 AI 未来发展的展望**

总的来说，AI 的未来充满了机遇和挑战。一方面，AI 技术正在快速发展，其应用前景非常广阔，有望解决人类面临的许多重大问题。另一方面，AI 的发展也带来了一些潜在的风险，例如失业、隐私、安全、伦理等等。为了确保 AI 的健康发展，我们需要在技术创新、政策制定、伦理规范等方面进行深入的思考和探索。正如 Nathan Lambert 所强调的，我们需要让更多的人参与到 AI 的开发和治理中来，以确保 AI 能够造福全人类。

### 其它问题

针对非大模型自身开发的工作场景，对话中涉及的观点如下：

**1. 传统软件开发与系统运维：AI 时代下的基石**

尽管人工智能，特别是大模型的浪潮席卷而来，传统的软件开发与系统运维仍然扮演着至关重要的角色。正如对话中所提到的，许多企业和机构内部仍然依赖着老旧的软件系统和工具，这些系统的维护和更新需要经验丰富的软件工程师。此外，即使是最先进的 AI 模型，也需要运行在稳定的硬件和软件基础设施之上。数据中心的建设和运维，包括电力供应、冷却系统、网络连接等，都需要专业的工程师进行设计、实施和维护。正如 Dylan Patel 所强调的，建造一个能够支持数十万甚至上百万 GPU 规模的超级计算集群，是一个极其复杂的工程挑战，涉及到方方面面的技术细节。此外，随着 AI 应用的普及，如何将 AI 模型集成到现有的软件系统中，如何确保系统的稳定性、可靠性和安全性，也成为了软件工程师面临的新课题。因此，即使在 AI 时代，传统的软件开发和系统运维技能仍然是不可或缺的，它们是构建和维护整个 AI 生态系统的基石。

**2. 领域专家 + AI：开启无限可能**

AI 的发展不仅仅是技术本身的进步，更重要的是它如何与各个领域的专业知识相结合，从而创造出更大的价值。正如对话中提到的，许多行业的工程师，例如航空航天、半导体和化工领域的工程师，可能并不擅长编程，但他们在各自的领域拥有深厚的专业知识。AI 可以成为连接领域专家和技术的桥梁，帮助他们更好地利用数据和工具，提高工作效率，并推动创新。例如，AI 可以帮助工程师分析传感器数据，优化生产流程，设计新材料等。通过将 AI 技术与领域知识相结合，我们可以开发出更强大、更有效的解决方案，解决现实世界中的各种问题。这需要领域专家和 AI 工程师之间的紧密合作，共同探索 AI 在特定领域的应用潜力。

**3. 硬件基础设施：AI 时代的“水电煤”**

AI，特别是大模型的训练和推理，对计算资源的需求是巨大的。正如对话中多次提到的“Stargate”项目，以及其他公司正在建设的超级计算集群，这些项目都需要庞大的硬件基础设施作为支撑。这包括高性能的 GPU、大容量的存储设备、高速的网络连接，以及可靠的电力供应和冷却系统。构建和维护这些基础设施需要专业的硬件工程师和系统管理员。此外，随着 AI 模型规模的不断扩大，对硬件的需求也在不断增长，这推动了硬件技术的不断创新。例如，为了满足 AI 计算对互连带宽的需求，新的互连技术不断涌现；为了降低能耗和提高计算密度，水冷等先进的冷却技术也得到了广泛应用。因此，硬件基础设施的建设和运维是 AI 时代的一个重要组成部分，它为 AI 技术的发展提供了必要的物理基础。

**4. 低级系统优化与硬件编程：榨取每一分性能**

在 AI 领域，为了最大限度地提高计算效率和性能，往往需要进行深入的低级系统优化和硬件编程。正如对话中提到的，DeepSeek 团队对 CUDA 进行了深入的优化，甚至深入到了 CUDA 级别以下，以提高其 MoE 模型的效率。这种底层的优化需要对硬件架构和软件系统都有深入的了解，能够针对特定的硬件平台进行定制化的开发，以充分利用硬件的性能潜力。此外，随着 AI 芯片架构的多样化，例如 Google 的 TPU 和 Amazon 的 Trainium，针对不同硬件架构进行优化也变得越来越重要。这些工作需要专业的硬件工程师和系统工程师来完成，他们是 AI 领域不可或缺的一部分。

**5. 数据收集、清洗与标注：AI 模型的“燃料”**

尽管大模型可以通过无监督学习从大量数据中学习，但高质量的标注数据对于训练特定任务的模型仍然非常重要。例如，在基于人类反馈的强化学习 (RLHF) 中，就需要使用人类标注的数据来训练奖励模型。此外，即使是使用无监督学习，也需要对数据进行收集、清洗和预处理，以确保数据的质量和可用性。正如对话中提到的，DeepSeek 使用了 Common Crawl 数据集，并对其进行了针对数学的提炼。数据的质量直接影响到模型的性能，因此，数据工程师在 AI 领域扮演着至关重要的角色。他们负责数据的收集、清洗、标注、管理和维护，为 AI 模型的训练提供高质量的“燃料”。

**6. 安全与隐私保护：AI 时代的守护者**

随着 AI 技术的广泛应用，安全和隐私问题也日益凸显。开源模型的兴起也带来了一些潜在的安全风险，例如模型可能被植入后门，用于窃取信息或操纵用户。此外，AI 模型可能会反映训练数据中的偏见，导致歧视性或其他有害的结果。因此，确保 AI 系统的安全性、可靠性和伦理性至关重要。这需要安全专家和伦理学家的参与，他们负责开发和实施安全策略，保护用户隐私，防止 AI 模型被滥用。正如对话中提到的，需要对模型进行审查和过滤，以避免产生有害或不道德的输出。

**7. 用户体验设计 (UX/UI)：连接 AI 与人类的桥梁**

尽管 AI 技术本身非常强大，但如何将其转化为用户友好的产品和服务，仍然是一个巨大的挑战。正如对话中间接提到的，用户体验设计在 AI 时代变得越来越重要。无论是将 AI 功能集成到现有的产品中，还是开发新的 AI 驱动的产品，都需要仔细考虑用户体验，设计出易于使用、直观且令人愉悦的界面。例如，在开发 AI 代理时，需要设计出能够让人类理解和信任的交互方式。此外，还需要考虑如何向用户解释 AI 模型的决策过程，提高模型的可解释性和透明度。用户体验设计师在 AI 产品的开发过程中扮演着至关重要的角色，他们是连接 AI 技术与人类用户的桥梁，确保 AI 技术能够真正为人类服务。

总而言之，即使在 AI 大模型蓬勃发展的今天，许多非大模型技术开发的工作场景依然至关重要，它们与 AI 技术的发展相辅相成，共同构建起一个完整且充满活力的 AI 生态系统。这些领域都需要大量的专业人才，并为他们提供了广阔的职业发展空间。


---

### 视频脚本（中译本）

好的，根据视频脚本的上下文，我们可以判断出：

*   **采访者：Lex Fridman** （视频开头介绍自己是 Lex Fridman podcast）
*   **受访者：Dylan Patel 和 Nathan Lambert** (视频开头介绍的两位嘉宾)

以下是重新组织后的访谈录，保留了原框架的标题，并尽量完整地保留了有效内容：



#### P1


**一、 简介 (0:00)**

**Lex Fridman:** 大家好，欢迎来到 Lex Fridman 播客。今天，我们邀请到了两位嘉宾：Dylan Patel 和 Nathan Lambert。Dylan 运营着一家专注于半导体、GPU、CPU 和 AI 硬件的知名研究分析公司，叫做 SemiAnalysis。Nathan 是艾伦人工智能研究所的研究科学家，也是 AI 博客 Interconnects 的作者。他们两位都在 AI 领域备受尊敬，他们的观点被 AI 领域的专家、研究人员和工程师们广泛阅读和倾听。我个人也是他们两位的粉丝。最近，DeepSeek 发布的 AI 模型在 AI 领域引起了不小的轰动，我认为这是一个很好的机会，邀请他们一起来深入探讨 AI 行业的多个关键方面。我们将从 DeepSeek 聊到 OpenAI、Google、xAI、Meta、Anthropic，再到 Nvidia、台积电，以及中美关系等等，所有 AI 前沿领域正在发生的事情。这次对话将深入探讨 AI 行业的许多关键问题。虽然内容会涉及很多技术细节，但我们会尽量确保 AI 领域之外的听众也能理解，我们会解释专业术语，明确阐述重要的概念，解释缩写，并会在不同抽象层次和细节级别之间切换。媒体上有很多关于 AI 的炒作，这个播客的目的之一就是拨开迷雾，摒弃那些粗浅的分析，详细讨论 AI 的工作原理及其影响。

在谈话过程中，我们还预料到 OpenAI 会发布新的 O3-mini 推理模型，并且它确实在录制结束后发布了。它的功能和成本与我们的预期相符。可以说，OpenAI O3-mini 确实是一个很棒的模型，但应该指出的是，DeepSeek R1 在基准测试中具有相似的性能，而且更便宜，并且它揭示了它的思维链推理，而 O3-mini 并没有，它只显示推理的摘要。此外，R1 是开放权重的，而 O3-mini 不是。顺便说一句，我有机会试用了 O3-mini，而且从个人体验上来说，我觉得 O3-mini，特别是 O3-mini-high，仍然比 R1 好。就我个人而言，我发现 Claude Sonnet 3.5 是编程的最佳模型，除了在一些棘手的情况下我会使用 O1 Pro 来进行头脑风暴。无论如何，更多更好的 AI 模型将会出现，包括来自美国和中国公司的推理模型，它们将继续改变成本曲线，但我认为“DeepSeek 时刻”是真实存在的，并且我认为五年后，它仍然会被认为是科技史上的一个关键事件，部分原因是由于其地缘政治影响，但也包括其他原因，正如我们在这次对话中从多个角度详细讨论的那样。

这是 Lex Fridman 播客，如果您喜欢它，请查看我们在简介中的赞助商。现在，亲爱的朋友们，让我们开始与 Dyan Patel 和 Nathan Lambert 的对话。很多人都很好奇中国公司 DeepSeek 的模型，让我们来详细了解一下。

**二、 DeepSeek-R1 和 DeepSeek-V3 (3:33)**

**Lex Fridman:** Nathan，你能描述一下 DeepSeek-V3 和 DeepSeek-R1 是什么吗？它们是如何工作的？它们是如何训练的？让我们先从宏观角度来看，然后再深入了解细节。

**Nathan Lambert:** 好的。DeepSeek-V3 是 DeepSeek 公司推出的一个新的专家混合（Mixture of Experts, MoE）Transformer 语言模型，这家公司位于中国。他们在新模型中有一些新的特性，我们稍后会详细介绍。总的来说，这是一个开放权重模型，并且它是一个指令模型，类似于你在 ChatGPT 中使用的那种。他们还发布了所谓的“基础模型”，这是在进行这些后训练技术之前的模型。现在大多数人使用的是指令模型，这些模型被用于各种应用中。DeepSeek-V3 大约发布在 12 月 26 日那一周。几周后，也就是 1 月 20 日，DeepSeek 发布了 DeepSeek-R1，这是一个推理模型，真正推动了很多这方面的讨论。这个推理模型与 DeepSeek-V3 有很多重叠的训练步骤，这可能会让人感到困惑。你有一个名为 V3 的基础模型，你对它进行一些处理得到一个聊天模型，然后你做一些不同的事情来得到一个推理模型。我认为很多 AI 行业现在都面临着沟通方面的挑战。例如，OpenAI 就经常自嘲他们的命名规则，他们有 GPT-4，他们有 O1，还有很多其他类型的模型。所以我们将逐一解释它们分别是什么，训练方面有很多技术细节，我们会从高层次到具体细节，逐一讲解。

**Lex Fridman:** 我们可以从很多方面开始讨论，但也许我们先从“开放权重”开始。模型“开放权重”意味着什么？以及，总的来说，“开源”有哪些不同的类型？

**Nathan Lambert:** 关于这个问题的讨论在 AI 领域已经持续了很长时间，自从 ChatGPT 出现后，或者更确切地说，自从 2022 年底 ChatGPT 发布以来，这个问题变得更加重要。“开放权重”是一个公认的术语，指的是语言模型的模型权重可以在互联网上供人们下载。这些权重可以有不同的许可证，这实际上就是你使用模型的条款。有一些许可证来源于历史上的开源软件，也有一些许可证是公司专门设计的。Llama、DeepSeek、Qwen、Mistral，这些在开放权重模型中流行的名字都有自己的许可证。情况很复杂，因为并不是所有相同的模型都有相同的条款。主要的争论在于是什么让一个模型成为“开放权重”。我们为什么要说这个术语？它有点拗口，听起来很像“开源”，但又不一样。关于开源 AI 的定义和灵魂仍然有很多争论。开源软件在自由修改、自由使用、对软件使用方式的诸多限制等方面有着丰富的历史，而这些对 AI 意味着什么仍然有待定义。

就我而言，我在艾伦人工智能研究所工作，我们是一家非营利组织，我们希望让 AI 对每个人都开放，并且我们尝试在我们认为是真正的开源方面起到引领作用。社区中并没有完全达成共识，但对我们来说，这意味着发布训练数据、发布训练代码，然后也像这样拥有开放权重。我们将深入了解模型的细节，并且在我们试图深入了解模型是如何训练的时候，我们会反复强调，数据处理、数据过滤、数据质量是模型质量的头号决定因素，然后很多训练代码决定了训练需要多长时间以及实验的速度有多快。所以，如果没有完全开源的模型，没有这些数据的访问权限，就很难知道或者说很难复制。我们将深入了解 DeepSeek-V3 的成本数据，主要是 GPU 小时数以及你自己租用这些 GPU 的成本，但是如果没有数据，复制成本将会高得多，代码也是如此。还应该指出，这可能是前沿模型中最开放的模型之一。在这个完整的范围内，可能最完整的开源就像你说的，开放代码、开放数据、开放权重。DeepSeek的模型不是开放代码，可能也不是开放数据，但是开放权重，而且许可协议是……

**Lex Fridman:** 是 MIT 许可证吗？

**Nathan Lambert:**  对，是 MIT 许可证，或者说……不同的模型之间存在一些细微差别，但它在开源运动中是属于比较宽松的类型。

**Lex Fridman:** 所以，DeepSeek 可以说是这个领域的“好人”？

**Nathan Lambert:** DeepSeek 在传播 AI 知识方面做得非常出色，他们的论文非常详细地介绍了他们所做的事情，对于世界各地的其他团队来说，这些论文在改进他们自己的训练技术方面非常有指导意义。我们将更多地讨论许可证问题。DeepSeek R1 模型有一个非常宽松的许可证，叫做 MIT 许可证，这意味着对商业用途没有下游限制，没有使用场景的限制，你可以使用模型的输出来创建合成数据，这些都很棒。我认为最接近的同类产品可能是 Llama，你有权重，你有一份技术报告，Llama 的技术报告非常好，去年最受欢迎的 PDF 之一就是 Llama 3 的论文，但在某些方面，它的可操作性稍差一些，它在训练细节方面的内容较少，例如绘图较少等等。而且 Llama 3 的许可证比 MIT 许可证更严格。

**Lex Fridman:** 明白了。还应该指出，DeepSeek 的一个影响是它给 Llama 和其他所有公司，包括 OpenAI，施加了压力，推动他们朝着开源的方向发展。你提到了“开放”的另一个方面，那就是关于代码背后的见解发布了多少细节，技术报告的质量如何？它们是含糊其辞的，还是有实际的细节？这也是 DeepSeek 做得好的地方之一，他们公布了很多细节。

**Nathan Lambert:** 特别是在 DeepSeek-V3 的预训练论文中，他们非常清楚地表明，他们正在对技术栈进行迭代，这些迭代涉及许多不同的层次。例如，为了获得高效的训练，他们正在对 Nvidia 芯片的 CUDA 层或其以下进行修改。我从来没有在那里工作过，世界上只有少数人能够很好地做到这一点，其中一些人就在 DeepSeek。这些类型的人才在 DeepSeek 和美国的领先前沿实验室都有，但没有太多地方……

**Lex Fridman:** 为了帮助人们理解“开放权重”的另一个含义，你知道，我们这里经常会回到一个话题，那就是有人担心中国可能会有兴趣窃取美国数据，侵犯美国公民的隐私。关于“开放权重”，我们能说些什么来帮助我们理解这些权重能做什么？

**Nathan Lambert:**  关于窃取人们的数据？

**Lex Fridman:** 是的。

**Nathan Lambert:**  你可以从 Hugging Face 或其他平台下载的这些权重是非常大的数字矩阵。你可以将它们下载到你家里没有互联网的电脑上，然后你可以运行这个模型，你完全可以控制你的数据。这与现在很多语言模型的使用方式不同，现在主要是通过 API，你将你的提示发送到由某些公司运行的 GPU 上，这些公司对你的数据如何存储、是否用于训练未来的模型、存储在哪里、是否加密等方面有不同的分布和策略。所以，对于开放权重，你掌握着自己数据的命运，这与开源的精神紧密相连。

**Lex Fridman:** 所以，不是模型窃取你的数据，而是托管模型的服务提供商，如果你使用的是 DeepSeek 的应用程序，那可能是中国；如果是 Perplexity，你就是信任他们；如果是 OpenAI，你也是信任他们。其中一些是美国公司，一些是中国公司，但模型本身并不进行窃取，是托管方。好的，让我们回到基础知识。DeepSeek-V3 和 DeepSeek-R1 之间有什么区别？我们能试着解释一下潜在的混淆吗？

**Nathan Lambert:**  首先，我非常理解很多人会对这两个模型名称感到困惑。我认为最好的理解方式是，在训练语言模型时，你有所谓的预训练，也就是你预测大量的（主要是互联网上的）文本，你试图预测下一个 token。关于这些新的 DeepSeek 模型，你需要知道的是，他们对互联网进行了大规模的预训练，得到了所谓的 DeepSeek-V3 基础模型。这是一个基础模型，它只会为你完成句子，它比 ChatGPT 更难用。然后 DeepSeek 所做的是，他们使用了两种不同的后训练机制来使模型具有特定的理想行为。那么，过去几年 AI 中更常见的模型是什么？指令模型、聊天模型、“对齐”模型、有帮助的模型，有很多方式可以描述这种更标准的后训练。这些技术包括指令微调、基于人类反馈的强化学习，我们会详细介绍其中的一些术语，这就是他们用来创建 DeepSeek-V3 模型的方法。这是第一个发布的模型，它的性能非常高，可以与 GPT-4、Llama-405b 等模型竞争。然后，在这个版本发布的时候，我们不知道他们的确切时间表，或者很快之后，他们正在完成一个不同的训练过程，这个过程来自我之前提到的同一个下一个 token 预测基础模型，这就是人们听说的新的推理训练的用武之地，目的是创建名为 DeepSeek-R1 的模型。“R”在这个对话中代表“Reasoning”（推理），这个名字也类似于 OpenAI 的 O1，这是人们听说过的另一个推理模型。我们需要更详细地分解 R1 的训练，因为我们有一篇详细介绍它的论文，而且它对 AI 社区来说是一套全新的技术，所以这是一个发展速度快得多的研究领域。也许我们还应该介绍一下训练的两大类：预训练和后训练，这些是人们使用的总括性术语。什么是预训练？什么是后训练？后训练下有哪些不同的类型？

**Nathan Lambert:**  好的，预训练，我用了一些相同的词来真正传达信息，就是你正在做所谓的自回归预测，以预测一系列文档中的下一个 token。这是在数万亿个 token 上完成的，这是标准做法，所以这是大量的数据，主要是从网络上抓取的。在 DeepSeek 早期的一些论文中，他们谈到了他们的训练数据是从 Common Crawl 中提取的，并针对数学进行了提炼，Common Crawl 是一个公共数据集，任何听众都可以从 Common Crawl 网站下载数据。

**Lex Fridman:** 这是一个公开维护的爬虫程序？

**Nathan Lambert:**  是的，其他科技公司最终会转向他们自己的爬虫程序，DeepSeek 可能也这样做了，大多数前沿实验室都这样做。但是这种数据是人们可以开始使用的，你只是在一系列文档中预测文本，这可以扩展到非常高效。AI 训练中有很多数字，比如使用了多少浮点运算（flops），然后你还可以查看使用了多少小时的 GPU，这主要是将一个损失函数应用于非常大量的计算。你设置了非常高效的系统，最后你会得到这个基础模型。在预训练方面，流程的演变或发展要复杂得多。

我认为很多技术都源于自然语言处理文献。最古老的技术，至今仍在使用，叫做指令微调，也称为监督微调，这些缩写词会是 IF 或 SFT，人们真的会来回使用它们，我可能也会这样做。这就是你在模型中添加这种格式的地方，它知道如何处理像“向我解释罗马帝国的历史”这样的问题，或者你在 Reddit 或 Stack Overflow 上看到的那种问题，然后模型会以信息密集但可读的方式进行回应。这种格式化的核心就在指令微调阶段。然后还有另外两类损失函数现在正在被使用。一类我将其归类为偏好微调，偏好微调是一个广义的术语，它来自基于人类反馈的强化学习，即 RLHF。基于人类反馈的强化学习被认为是帮助 ChatGPT 取得突破的技术，它是一种使像 Reddit 回答这样格式良好的回复更符合人类阅读习惯的技术。这是通过收集世界上真实人类的解析偏好来实现的，现在 AI 也在标记这些数据，我们将讨论这些权衡。你需要在好的答案和坏的答案之间建立这种对比损失函数，模型会学习捕捉这些趋势。有不同的实现方式，你有奖励模型，你有直接对齐算法，有很多非常具体的事情可以做，但所有这些都是关于微调到人类偏好。最后阶段是更新的，将与 R1 和这些推理模型中所做的联系起来，我认为 OpenAI 对此的名称是，他们在秋季推出了这个新的 API，他们称之为强化微调 API。这个想法是，你使用强化学习的技术，这是一个完整的 AI 框架，这里有深入的文献，总结来说，它通常被称为试错学习，或者说是 AI 的一个子领域，你试图在某个可能嘈杂的环境中做出连续的决策。我们可以从很多方面来讨论这个问题，但对语言模型进行微调，它们可以生成一个答案，然后你检查该答案是否与数学或代码的真实解决方案相匹配，对于数学，你有一个完全正确的答案，对于代码，你可以有单元测试，我们正在做的是检查语言模型的工作，我们在相同的问题上给它多次机会，看看它是否正确，如果你不断这样做，模型可以在可验证的领域中得到很大程度的改进。它非常有效，这是学术文献中一项较新的技术，它已在美国不共享所有细节的前沿实验室中使用了多年。所以这就是使用强化学习与语言模型的想法，并且它已经开始流行，特别是在这个 DeepSeek 时刻。

我们还应该说，在整个技术栈中都有很多令人兴奋的事情正在发生，但后训练，今年可能会有很多有趣的发展，我们将讨论它。我差点忘了谈论用户体验方面 DeepSeek-V3 和 R1 之间的区别，所以忘记技术方面的东西，忘记所有这些，只是那些对 AI 一无所知的人，他们出现了，实际的体验是什么？每个模型的用例是什么？当他们实际打字和说话时，它擅长什么？诸如此类的事情。所以让我们从 DeepSeek-V3 开始，它更像更多人会尝试过的东西，你问它一个问题，它会开始非常快地生成 token，这些 token 看起来像一个非常易于人类阅读的答案，它会是一个某种 markdown 列表，它可能有格式来帮助你抓住答案中的核心细节，它会生成数十到数百个 token，一个 token 通常是一个词，对于常用词来说，或者对于较长单词来说是一个子词部分，它看起来像一个非常高质量的 Reddit 或 Stack Overflow 答案。这些模型真的越来越擅长在各种领域做到这一点，我认为即使是那些如果你是专家，那些接近知识边缘的东西，它们仍然会相当不错。我认为即使是我正在研究的前沿 AI 主题，这些模型也能胜任学习辅助的角色，并且它们会定期更新。这与 DeepSeek-R1 不同，所谓的这些推理模型是，当你看到来自这些模型的 token 时，一开始它将是一个很长的思维链过程，我们将在一秒钟内回到思维链，它看起来像很多 token，模型正在解释问题，模型通常会分解问题，比如“好吧，他们问我这个问题，让我们分解问题，我需要做这个”，你会看到所有这些都从模型中生成，它会很快出现在大多数用户体验中，这些 API 非常快，所以你会看到很多 token，很多单词很快出现，它会继续在屏幕上流动，这就是整个推理过程，然后最终模型会改变它的语气，在 R1 中，它会写出答案，总结它的阅读推理过程，并写出一个类似于第一类模型的答案。但在 DeepSeek 的例子中，这就是为什么它在 AI 社区之外也如此受欢迎的部分原因，你可以看到语言模型是如何分解问题的，然后你得到了这个答案。从技术方面来说，他们专门训练模型来做到这一点，他们有一个推理部分，然后它生成一个特殊的 token，这个 token 可能在大多数情况下对用户是隐藏的，表示“好的，我开始回答了”，所以模型被训练来自己完成这个两阶段过程。如果你使用一个类似的模型，比如说 OpenAI，OpenAI 的用户界面会尝试通过显示模型正在执行的部分来很好地为你总结这个过程，它会逐个点击，它会说“分解问题”、“进行计算”、“清理结果”，然后答案就会出现，对于像 OpenAI 这样的东西。也许在这里举一个 DeepSeek-R1 推理的例子很有用。

**Lex Fridman:**  好的，如果你正在看屏幕，你会看到 DeepSeek 聊天应用程序的截图，顶部是“思考了 15.17 秒”，下面有一个下拉箭头。如果我们是在一个正在运行的应用程序中，下拉箭头会显示推理过程。在这种情况下，具体的问题，你知道，我在哲学上有点倾向于……所以这是在问 DeepSeek-R1 一个关于人类的真正新颖的见解，它揭示了推理过程，基本上，真正的创新之处在于不断推动推理，模型会问自己这是否真的是新颖的，所以它实际上是在挑战自己要更具创新性、更反直觉、更……不那么令人尴尬，我猜。所以其中一些推理说，这只是快照，或者说，人类有一种独特的元情感，他们对自己的情绪感到情绪，你因为生气而感到内疚，这种递归的情感分层创造了复杂的动机驱动力，这在其他动物中是不存在的。这个见解是人类的情绪是嵌套的，所以就像它在推理人类如何感受情绪，它在推理元情绪，它将有几页的内容，实际上读起来太多了，但在它出现时略读一下很好，它是詹姆斯·乔伊斯的意识流，然后它说“等等，用户想要一些在其他任何地方都看不到的东西，让我更深入地挖掘，并考虑人类同时持有矛盾信念的能力，认知失调是已知的，但也许其功能是允许灵活的适应”，等等等等。我的意思是，这真的抓住了公众的想象力，“天哪，这不……”，我的意思是，智能，或者说几乎像是某种先知的暗示，因为你在思考，你在自我反思，你在斟酌。15.7 秒后的最终结果是，人类本能地通过集体假装抽象规则（金钱、法律、权利）是真实的，将自私的欲望转化为合作系统。这些共同的幻觉充当“游戏”，竞争在秘密中被重新导向以使群体受益，将冲突转化为社会的燃料。非常深刻，我的意思是，你知道，这是一个……

**Nathan Lambert:** 跑题了，但很多人发现这些推理模型有时可以产生比……至少是一个有趣的例子，我认为这取决于你的开放程度，你会发现语言模型是否有趣，这是一个范围。

**Lex Fridman:**  我的意思是，这是……我们将讨论不同的基准，但有些只是一种感觉，比如它本身就是一个……比如说，“火的推文”。如果我想产生一些东西，让人们说“哦，好吧，这就是……”，这就是……这就是思考的……我们可能会更多地回到它。他们是如何在训练和推理方面实现如此低的成本的？

**三、 低训练成本 (25:07)**

**Lex Fridman:** 也许你可以先谈谈训练。

**Dylan Patel:**  好的，他们实施了两项主要技术，这可能是他们效率的主要来源，然后还有很多实施细节，我们可能会略过或稍后详细介绍，这些细节也有所贡献。但这两项主要技术是：一是他们采用了专家混合模型（Mixture of Experts, MoE），我们稍后会定义；二是他们发明了一种叫做 MLA（Multi-head Latent Attention）的新技术。这两项技术都很重要。专家混合模型在文献中已经存在了几年，OpenAI 的 GPT-4 是第一个将专家混合模型产品化的公司。这意味着，当你查看大多数人能够与之交互的常见模型时，它们是开放的，想想 Llama，Llama 是一个密集模型，也就是说，当你运行模型时，每个参数或神经元都会被激活，对于你生成的每个 token 都是如此。现在，对于专家混合模型，你不需要这样做。人类实际上是如何工作的？就像“哦，当我思考视觉任务时，我的视觉皮层是活跃的”，你知道，还有其他的事情，当我害怕时，我的杏仁核是活跃的。你大脑的不同部分专注于不同的事情。专家混合模型试图在某种程度上近似这一点，它远不及大脑的结构，但模型的不同部分会被激活。你将在模型中拥有一组专家，并且每次都会激活一定数量的专家，这极大地降低了你的训练和推理成本，因为现在你……如果你把参数数量看作是所有这些知识的总嵌入空间，你在训练过程中将这些数据压缩下来，当你嵌入这些数据时，你不必每次训练或运行推理时都激活每个参数，现在你只需要激活一个子集，模型会学习针对不同的任务路由到哪个专家。所以，这是一个巨大的创新，“嘿，我可以继续扩大参数的总嵌入空间”，所以 DeepSeek 的模型有 6000 多亿个参数，对吧？相对于 Llama-405b 的 4050 亿个参数，Llama-70b 的 700 亿个参数，所以这个模型在技术上拥有更多的信息嵌入空间来压缩互联网上的所有知识，但与此同时，它只激活了大约 370 亿个参数。所以，每次你训练数据或从中推理数据时，只有 370 亿个参数需要被计算，而 Llama 模型需要激活 700 亿个参数，或者 4050 亿个参数，所以你通过这种专家混合架构极大地降低了训练和推理时的计算成本。

**Lex Fridman:** 我们是否应该分解一下它实际应用在哪里，并深入了解 Transformer？

**Nathan Lambert:**  好的，我们来谈谈 Transformer。Transformer 是一个被广泛讨论的东西，我们不会涵盖每一个细节。本质上，Transformer 是建立在这种注意力机制和传统的密集全连接多层感知器（无论你想用什么词来称呼你的普通神经网络）的重复块上的，你交替使用这些块，还有其他细节。专家混合模型应用的地方是这个密集模型，如果你在 Transformer 模型中计算权重，密集模型拥有大部分权重。所以你可以通过不激活所有这些参数来在训练和推理的参数效率方面获得真正大的收益，因为你可以通过不激活所有这些参数来获得这种效率。我们还应该说，Transformer 是一个巨大的神经网络。

**Lex Fridman:**  是的，然后在过去 15 年里，有所谓的深度学习革命，网络变得越来越大，在某个时刻，出现了规模定律（scaling laws），人们意识到……顺便说一句，这是一件代表规模定律的 T 恤，人们越来越正式地认识到，在“更大”的多个维度上，“更大”就是“更好”。这些都是我们正在讨论的神经网络，我们正在讨论如何构建这些神经网络的不同架构，使得它们的训练和推理非常高效。

**Nathan Lambert:**  每种不同类型的模型都有不同的规模定律，这实际上是为了说明你投入多少计算，该架构将在测试任务中达到不同水平的性能。专家混合模型是其中之一，在训练时，即使你不考虑推理的好处（推理的好处也很大），通过使用这种架构，你在训练时使用 GPU 的效率也会大大提高，如果实现得好的话。所以你实际上可以用 30% 左右的计算量获得相同性能的模型（以评估分数来衡量）。我认为根据你的具体实现细节等因素，会有很大的差异，但重要的是要认识到，这种类型的技术创新带来了巨大的收益，我预计大多数提供其模型的公司都会转向这种专家混合模型的实现方式。从历史上看，并不是每个人都可能这样做的原因是它的实现复杂性，特别是当处理这些大型模型时。所以这是 DeepSeek 获得赞誉的事情之一，他们做得非常好，他们非常擅长专家混合模型。这种架构，对于所谓的 DeepSeek MoE（专家混合模型的缩写），已经有多篇论文了，他们训练基础设施的这一部分并不是这些模型独有的。对于 Dylan 提到的多头潜在注意力（Multi-head Latent Attention）也是如此，这都是关于通过使用一些花哨的低秩近似数学在推理过程中减少内存使用，并在训练过程中做同样的事情。如果你深入了解这种潜在注意力的细节，我会觉得“好吧，他们在做非常复杂的实现”，因为语言模型中还有其他部分，例如用于扩展上下文长度的嵌入，DeepSeek 使用的常见嵌入是旋转位置嵌入（Rotary Positional Embeddings），称为 RoPE。如果你想将 RoPE 与普通的 MoE 一起使用，它有点像一个顺序的事情，你取两个注意力矩阵，然后将它们旋转一个复数值，这是一个矩阵乘法，对于 DeepSeek MLA，有了这种新的注意力架构，他们需要做一些聪明的事情，因为它们的设置方式不同，这使得实现复杂性大大提高。所以他们在管理所有这些事情，这些可能是 OpenAI 这些封闭实验室正在做的事情，我们不知道他们是否在做完全相同的技术，但他们实际上与世界分享了它们，这非常好，就像这是高效语言模型训练的前沿，其中一些需要低级工程，这只是一团糟和技巧。据我所知，他们深入到了 CUDA 之下，所以他们实际上是在对 GPU 进行超低级编程。

**Dylan Patel:**  实际上，Nvidia 构建了一个名为 NCCL（Nvidia Collective Communications Library）的库，你知道，当你在训练一个模型时，你会在模型的每一层之间进行所有这些通信，你可能有 100 多个层。

**Lex Fridman:**  NCCL 代表什么？

**Dylan Patel:**  Nvidia Collective Communications Library。当你在训练一个模型时，你会在每个层之间，在多层感知器或前馈网络与注意力机制之间进行 all-reduce 和 all-gather 操作，你基本上会同步模型，或者你会进行 all-reduce 和 all-gather，这是网络中所有 GPU 之间的通信，无论是在训练还是推理过程中。所以 Nvidia 有一个标准库，这也是为什么很难使用其他任何公司的硬件进行训练的原因之一，因为没有人真正构建了一个标准的通信库。Nvidia 在某种程度上是在更高的层次上做到了这一点。DeepSeek，因为他们对他们可以访问的 GPU 有一定的限制，互连在一定程度上受到合法运往中国的 GPU 的限制，而不是那些被走私的 GPU，而是合法运往中国并被他们用来训练这个模型的 GPU，他们必须想办法提高效率。其中一件事是，他们没有调用 Nvidia 的库 NCCL，而是创建了他们自己的通信调度，一些实验室会这样做。Meta 在 Llama 3 中谈到了他们如何制作自己的自定义版本的 NCCL，他们没有谈论实现的细节，这可能是他们所做的一部分，可能不如 DeepSeek 做得好，因为 DeepSeek，你知道，需求是创新之母，他们必须这样做。然而，在 Casa，你知道，OpenAI 有人做这类事情，Anthropic 等等，但 DeepSeek 确实公开做了，而且他们可能做得更好，因为他们在可以访问的芯片的某些方面受到了限制。所以他们调度通信，你知道，通过调度特定的 SM。你可以把 SM 看作是 GPU 上的核心，所以 GPU 上有数百个核心，或者说有 100 多个核心，即 SM。他们专门调度哪些 SM 运行模型，哪些 SM 执行 all-reduce，哪些 SM 执行 all-gather，他们会在它们之间来回切换，这需要非常低级的编程。

**Lex Fridman:**  这是 NCCL 自动处理的，或者说 Nvidia 的其他库通常会自动处理这些事情？

**Dylan Patel:**  没错。所以从技术上讲，他们使用的是 PTX，这有点像……你可以把它想象成一种汇编语言，但不完全是那样，或者说指令集，直接用汇编或指令集编码，但不完全是那样，但这仍然是 CUDA 的一部分，但就像“我是否想用 Python 编写代码，调用等效的 PyTorch，并调用 Nvidia 库？我是否想深入到 C++ 级别，甚至更低级别的代码？或者我是否想一直深入到汇编或 ISA 级别？”在大实验室里，有些情况下你会一直深入到那里，但大多数公司根本不会这样做，因为这是浪费时间，你获得的效率提升不值得。但是 DeepSeek 的实现非常复杂，特别是他们的专家混合模型。人们已经实现了专家混合模型，但它们通常是 8 个或 16 个专家，并且激活 2 个。你知道，我们喜欢用的一个词是“稀疏因子”或“使用率”。所以你可能会激活四分之一的模型，这就是 Mistral 的 Mixtral 模型，他们的模型真正让他们一鸣惊人，“哦，天哪，他们真的非常棒”。OpenAI 也有一些模型是 MoE，所有其他主要的封闭实验室也是如此。但是 DeepSeek 所做的，也许只有领先的实验室最近才刚刚开始做，就是拥有如此高的稀疏因子。不是四分之一的模型，也不是每次运行模型时激活八分之二的专家，而是 256 个专家中激活 8 个。

**Nathan Lambert:**  专家混合模型有不同的实现方式，其中一些专家可以始终处于激活状态，这看起来就像一个小型神经网络，所有 token 都会通过它，然后它们也会通过一些由这个路由机制选择的专家。DeepSeek 架构中的一项创新是，他们改变了专家混合模型中的路由机制，其中有一个叫做辅助损失（auxiliary loss）的东西，这实际上意味着在训练过程中，你要确保所有这些专家都被用于模型看到的任务。为什么专家混合模型中会出现失败呢？因为在进行这种训练时，一个目标是 token 预测的准确性，如果你只是让 token 自己运行专家混合模型，模型可能会学会只使用一部分专家。在文献中，有一种叫做辅助损失的东西可以帮助平衡它们，但如果你考虑深度学习的损失函数，这甚至与“痛苦的教训”（bitter lesson）有关，那就是你希望在模型中加入最少的归纳偏差，以让模型最大限度地学习。这个辅助损失，即在专家之间进行平衡，可以被视为与 token 的预测准确性相冲突。所以我们不知道 DeepSeek 的确切改变程度，但他们没有使用辅助损失，而是在他们的路由中增加了一个额外的参数，在批处理之后，他们会更新这个参数，以确保接下来的批处理都具有相似的专家使用率。这种类型的改变可能很大，也可能很小，但它们会随着时间的推移而累积，这表明他们在创新，我敢肯定所有训练大型 MoE 的实验室都在考虑这些事情，即摆脱辅助损失，其中一些可能已经使用了它。你只是不断积累收益，我们将讨论训练的理念以及如何组织这些组织，其中很大一部分只是随着时间的推移在你的数据、架构和后训练中不断积累小的改进，以及它们如何相互整合。DeepSeek 也在做同样的事情，其中一些是共享的，或者很多……我们必须相信他们分享了他们最重要的细节。我的意思是，架构和权重都在那里，所以我们看到了他们在做什么，并且它在不断累积。

**Dylan Patel:**  回到效率和复杂性方面，它是 32 比 4，就像 Mixtral 和其他已公开发布的模型一样，所以这个比例非常高。Nathan 刚才所说的是，当你拥有如此不同水平的稀疏性时，你不能让每个 GPU 都拥有整个模型，模型太大了，太复杂了，所以你必须用不同类型的并行方式来分割模型。所以你可能在不同的 GPU 节点上有不同的专家，但是现在，当你得到一组数据时会发生什么呢？所有这些数据看起来都像这样，所有这些数据都应该路由到我的模型的某一部分。所以当所有数据都路由到模型的一部分时，你可能会遇到一组特定的 GPU 资源或一组特定的 GPU 过载的情况，然后其余的训练网络处于空闲状态，因为所有 token 都只路由到那里。这是运行非常稀疏的专家混合模型（即 32 比 4 的比例）的最大复杂性之一，你会遇到很多专家只是坐在那里无所事事的情况。所以如何在它们之间进行负载均衡，如何在它们之间调度通信，这是很多非常低级的、详细的工作，他们首先在公开场合解决了这些问题，并且可能在全球范围内是第二或第三个，甚至在某些情况下是第一个。

**Lex Fridman:**  你从所有这些中得到了什么教训？在“痛苦的教训”的方向上，这是否会成为很多收益的方向，即这种低级优化？或者说这是一个短期的事情，最大的收益将更多地来自算法的高级方面，比如后训练？这是否像是一个短期的飞跃，因为他们找到了一个技巧，因为需求是发明之母，或者说是否还有很多收益……

**Nathan Lambert:**  我想我们应该总结一下“痛苦的教训”实际上是什么。简而言之，“痛苦的教训”是，随着我们的发展，在深度学习中最终胜出的训练类型是那些可扩展的学习和搜索方法，这就是它所说的，规模这个词在这个解释中受到了很多关注，我的解释是有效地避免将人类的先验知识添加到你的学习过程中。如果你阅读原始论文，这就是它所谈论的，即研究人员将如何为他们的特定问题提出聪明的解决方案，这些解决方案可能会在短期内为他们带来小的收益，而从长远来看，简单地使这些深度学习系统高效工作并针对这些更大的问题，可能更有可能扩展并继续推动成功。因此，我们谈论的是专家混合模型的相对较小的实现更改，因此，就像，我们需要更多的时间才能知道其中一个是否真的对“痛苦的教训”至关重要，但“痛苦的教训”实际上是关于简单性如何经常获胜的长期趋势，业内有很多说法，比如“模型只想学习，你必须给它们简单的损失情况，在那里你将计算投入到模型中，它们就会学习，并消除障碍”，这就是像 NCCL 这样的东西的强大之处，它是一种标准化的代码，可以被很多人用来创造可以扩展的简单创新，这就是为什么黑客……我想象 DeepSeek 的代码库可能是一团糟。我敢肯定 DeepSeek 肯定有一些非常混乱的代码库，他们在那里测试这些新想法，多头潜在注意力可能开始于像 Jupyter 笔记本这样的东西，或者有人在几个 GPU 上尝试一些东西，这真的很混乱。但是训练 DeepSeek-V3 和 DeepSeek-R1 的那些库，如果你把它们展示给我们，我猜它们是非常高质量的代码，高质量的可读代码。

**Dylan Patel:**  我认为有一个方面需要注意，那就是它在不同类型的运行中转移的普遍能力。你可能为一个特定大小的模型架构制作了非常非常高质量的代码，然后当你对架构进行调整时，一切都崩溃了，这可能会发生。就像他们的特定低级 SM 调度代码是特定于这个模型架构和大小的，而 Nvidia 的集合库更像是“嘿，它适用于任何东西，你想做一个 all-reduce，太好了，我不在乎你的模型架构是什么，它都会工作”，当你这样做时，你会在很多情况下放弃很多性能，但考虑到他们对计算的限制，为特定的运行进行特定的优化是值得的。

**Lex Fridman:**  我想知道启动像这些前沿模型一样的训练有多大压力，就像按下按钮开始训练，你现在要花费大量的金钱和时间来训练这个，肯定有很多关于调试阶段的创新，比如确保没有问题，监控

#### P2

**Lex Fridman:** 肯定有很多关于调试阶段的创新，比如确保没有问题，监控和可视化训练的各个方面等等。

**Dylan Patel:** 当人们进行训练时，他们会使用各种各样的仪表板，但最简单的一个就是你的损失，它会持续下降。但实际上，特别是对于更复杂的东西，比如 MoE 或 FPA 训练（这是另一项创新，即使用较低精度的数字格式，也就是不太精确），你最终会遇到损失峰值，没有人知道为什么会出现损失峰值。

**Nathan Lambert:** 其中一些你知道原因，一些是数据问题。我举一个 AI2 的例子，导致我们早期模型崩溃的是一个名为“microwave gang”的 subreddit。我们喜欢大声说出来，这是一个真实的东西，你可以找到“microwave gang”，基本上这是一个 subreddit，每个人发的帖子都是字母“M”，所以会有非常长的字母“M”序列，然后评论会是“哔哔”，因为那是微波炉结束的时候。但是如果你把这个传递给一个被训练成正常生成文本的模型，它会产生非常高的损失，因为通常你看到一个“M”，你不会长时间预测“M”。所以这对我们来说会导致损失峰值，但是当你有……这已经是很久以前的事了，这不是最近的事，当你有更成熟的数据系统时，那就不是导致损失峰值的原因了。Dylan 说的是对的，但就像……这与压力有关，这些人就像……你知道，你会和在这些实验室工作的朋友一起出去吃饭，他们会每隔 10 分钟左右看一次手机，他们不是在发短信，他们只是在看损失，每秒的 token 数，损失有没有激增。他们只是在观察这些，如果有峰值，心率就会上升。一定程度的峰值是正常的，它会恢复，然后……

**Nathan Lambert:** 有时，以前的策略是你停止运行，从旧版本重新开始，然后更改数据组合，然后继续。甚至还有不同类型的峰值。Durk Grenal 有一个理论，A2，就像快速峰值和慢速峰值，有时你看着损失和其他参数，你可以看到它开始上升，然后爆发，这真的很难恢复，所以你必须回溯得更远。所以你有一段压力很大的时期，它是平的，或者可能开始上升，你就像“我该怎么办？”，而也有一些损失峰值，它看起来不错，然后有一个尖峰数据点，你可以做的就是跳过这些数据点，你看到有一个峰值，你就像“好吧，我可以忽略这些数据，不要更新模型”，然后做下一个，它会很快恢复。但是这些更棘手的实现……所以当你让你的架构变得更复杂，你扩展到更多的 GPU，你的损失爆发的可能性就越大。

**Dylan Patel:** 而且还有一个分布，grokking 的整个概念也出现了，就像，仅仅因为它从改进中减缓了并且损失了，并不意味着它没有学习，因为突然之间它可能像这样，并且它可能再次在损失中急剧下降，因为它真正学到了一些东西，并且它需要一些时间才能学会，这不是一个循序渐进的过程。这就是人类的样子，这就是模型的样子。所以正如你所提到的，这是一项非常紧张的任务，而且整个过程都在烧钱。每家公司都有失败的运行，你需要失败的运行来推动你的基础设施的极限，所以很多新闻都是关于 X 公司有 Y 次失败的运行，每家试图推动 AI 前沿的公司都有这些，所以是的，这值得注意，因为它是一大笔钱，而且可能会让你倒退几周，但这是过程的一部分。

**Lex Fridman:** 但是，如果你是 DeepSeek，你如何达到这样一个地步：天哪，超参数的组合成功了，很多小的失败的运行，以及如此快速地迭代失败的运行，直到……你建立了像这样的……这种专家混合模型有效，然后这种 MLA 的实现有效……

**Nathan Lambert:** 关键的超参数，如学习率和正则化等，你会找到适合你的代码库的工作机制。我与前沿实验室的人交谈过，有一个故事可以讲，训练语言模型就像一条你需要遵循的道路，所以你需要解锁训练某种类型的模型或某种规模的能力，然后你的代码库和你内部的专业知识，知道什么样的参数适用于它，这是已知的。你看看 DeepSeek 的论文和模型，他们已经扩大了规模，他们增加了复杂性，这只是在继续构建他们拥有的能力。

**Dylan Patel:** 有一个“YOLO 运行”的概念，YOLO 代表“你只活一次”（you only live once），它的意思是，你在小规模上进行所有这些实验，研究消融（ablations），你有你的 Jupyter 笔记本，无论你是在 3 个 GPU 上用 MLA 进行实验，还是其他什么。你在做所有这些不同的事情，比如“我应该用 4 个专家、4 个活跃专家、128 个专家吗？我应该这样安排专家吗？”，所有这些不同的模型架构，你都在非常小的规模上进行测试，几个研究人员，几个 GPU，几十个 GPU，几百个 GPU，不管是什么。然后突然之间，你就像“好吧，伙计们，别再胡闹了，大家把我们所有的资源都拿出来，选择我们认为有效的，然后就开始吧”，YOLO。这就是压力的来源，“我

#### P3

**Dylan Patel:** 这就是压力的来源，“我知道它在这里有效，但有些东西在这里有效，在那里却无效；有些东西在那里有效，在这里却无效”，在规模方面，对吧？所以这真的是一次 YOLO 运行，而且就像，有这样的讨论，有些研究人员只是有这种有条理的性质，他们可以找到整个搜索空间，找出所有不同研究的消融，并真正看到什么是最好的。还有一些研究人员只是有那种与生俱来的直觉，“这就是 YOLO 运行，看看这些数据，就是这样”。

**Nathan Lambert:** 这就是为什么你想在后训练中工作，因为训练的 GPU 成本较低，所以你可以使更高比例的训练运行成为 YOLO 运行。

**Lex Fridman:**  就目前而言。

**Nathan Lambert:**  就目前而言，就目前而言。所以其中一些从根本上来说仍然是运气。

**Dylan Patel:** 运气就是技巧，在很多情况下。

**Nathan Lambert:** 我的意思是，这看起来很幸运。如果你在这些实验室之一，并且你有一个评估，但你没有取得突破性的进展，那么有一个反复使用的剧本来改进事情。有一些局部的改进，可能是数据的改进，这些加起来会使整个模型变得更好。当你非常仔细地观察时，可以非常清楚地看到这个模型在这个方面非常糟糕，我们可以修复它，你只需要把这些加起来。所以其中一些感觉像是运气，但在实践中，特别是对于我们正在谈论的这些新的推理模型，我们有很多方法可以探索，通常其中一些会带来很大的改进。

**Dylan Patel:** 搜索空间几乎是无限的，然而你拥有的计算时间非常少，你必须赶上发布时间表，你不能被所有人超越，否则，你知道 DeepSeek 发生了什么，他们超越了 Meta、Mistral 和 Cohere，以及所有这些公司，他们行动太慢了，他们可能太有条理了，我不知道，他们没有进行 YOLO 运行，不管是什么原因，也许他们没有那么熟练，不管你想怎么说，你可以称之为运气，但归根结底，这是技能。

**Lex Fridman:**  所以 2025 年是 YOLO 年，似乎所有的实验室都在……

**Dylan Patel:**  我认为 OpenAI 在 2022 年所做的更令人印象深刻。当时没有人相信专家混合模型，在 Google，他们拥有所有的研究人员，而 OpenAI 的计算资源如此之少，他们在几个月的时间里将所有的计算资源都投入到了 GPT-4 上，这是一个全新的架构，他们不相信“让我花几亿美元，这是我所有的钱，在这个模型上”，这才是真正的 YOLO。现在，你知道，人们喜欢……所有这些媒体报道的训练运行失败，就像，“好吧，很好，但实际上我的很大一部分 GPU 正在进行推理，我仍然有很多 GPU 一直在进行研究，是的，我最大的集群正在进行训练，但在这个 YOLO 运行上，但这个 YOLO 运行的风险远低于 OpenAI 在 2022 年所做的，或者 DeepSeek 现在所做的，或者你知道，“我们就是要全力以赴”。在人类历史上，最大的赢家是那些愿意在某个时候进行 YOLO 的人。

**Lex Fridman:** 好的，关于训练的硬件，我们了解些什么？

**五、 DeepSeek 计算集群 (51:25)**

**Dylan Patel:** DeepSeek 非常有趣。首先，让我先介绍一下他们是谁。Highflyer 是一家对冲基金，过去一直在中国和其他地方进行量化交易，他们一直拥有大量的 GPU。过去，很多这些高频交易算法量化交易员使用 FPGA，但肯定已经转向了 GPU，两者都有，但 GPU 尤其如此。Highflyer 这家拥有 DeepSeek 的对冲基金，每个为 DeepSeek 工作的人在某种程度上都是 Highflyer 的一部分，它是同一家母公司，同一个所有者，同一个 CEO。他们拥有所有这些用于交易的资源和基础设施，然后他们将其中很大一部分用于训练模型，包括语言模型和其他模型，因为这些技术深受 AI 的影响。你知道，最近人们已经意识到，嘿，用……甚至当你回顾文艺复兴时期和所有这些量化公司时，自然语言处理是快速交易的关键，理解新闻稿并做出正确的交易，所以 DeepSeek 一直非常擅长这一点。甚至早在 2021 年，他们就发布了新闻稿和论文，称“我们是中国第一家拥有这么大 A100 集群的公司，10,000 个 A100 GPU”，这是在 2021 年。现在，这并不全是为了训练大型语言模型，这主要是为了训练他们的量化交易模型，以及，需要明确的是，其中很大一部分是自然语言处理。

所以这就是历史。可以验证的事实是，他们在 2021 年建立了中国最大的集群，至少他们声称这是中国最大的集群，10,000 个 GPU。

**Lex Fridman:**  在出口管制开始之前。

**Dylan Patel:**  就像在任何关于出口管制的讨论之前，他们就已经拥有了一个庞大的集群。那么，从那时起的四年里，他们做了些什么？显然，他们继续运营着这家对冲基金，可能赚了很多钱。另一件事是，他们越来越倾向于 AI。CEO，李崇昉（Leon），也许是李燕芳（音译），他拥有公司一半多一点的股份，据称，他是一个非常像埃隆·马斯克或黄仁勋那样的人物，他参与了所有的事情。所以在那段时间里，他深入研究了 AI，他实际上有点像……如果你看到他的一些言论，有点像一个……几乎是完全的 AGI 狂热者，“我们需要这样做，我们需要建立一个新的 AI 开放生态系统，中国需要在这方面领先”，因为从历史上看，西方国家在软件生态系统方面一直处于领先地位，他直截了当地承认，“为了做到这一点，我们需要做一些不同的事情”。DeepSeek 是他实现这一目标的方式，其中一些翻译过来的采访中……

**Lex Fridman:**  他接受过采访吗？你觉得他会接受西方媒体的采访吗？还是说有限制？

**Nathan Lambert:** 目前还没有，但……

**Lex Fridman:**  好吧，我会尝试的。我刚刚请了一个中文翻译，所以……

**Nathan Lambert:**  这是一个了不起的人物，工程师全力投入 AI，利用高频交易的成功，非常直接的引用，比如“当被问及这些事情时，我们不会转向闭源”，非常有远见，从长远角度考虑 AI 生态系统应该如何运作。我认为从中国的角度来看，他希望中国公司，一家中国公司来建立这个愿景。

**Dylan Patel:**  这就是这家公司背后的“远见卓识者”，这家对冲基金仍然存在，这家量化公司，DeepSeek 逐渐……他慢慢地转向了 AI，关于这一切。但他慢慢地调整，他创建了 DeepSeek，DeepSeek 从那时起已经开发了多个模型，他们获得了越来越多的 GPU，他们与基金共享基础设施。所以，他们没有确切的公开 GPU 资源数量，但除了他们在 2021 年购买的 10,000 个 GPU，他们非常赚钱，然后这篇论文声称他们只使用了 2,000 个 H800 GPU，这是一个受限制的 GPU，以前允许在中国使用，但现在不再允许了，现在有一个新版本，但它基本上是 Nvidia 为中国生产的 H100。它有一些限制，特别是在通信速度方面，即互连速度，这就是为什么他们必须做这些疯狂的 SM 调度。所以回到这个问题，这显然不是真的，就他们的总 GPU 数量而言……

**Lex Fridman:**  但是对于这次训练，你认为 2,000 是正确的数字吗？

**Dylan Patel:**  这就是需要……你知道，需要大量的……“你的训练运行”指的是什么？你是否计算了你运行的所有研究和消融？因为是的，你可以进行 YOLO 运行，但在某种程度上，你必须在小规模上进行测试，然后你必须在中等规模上进行一些测试，然后才能进行大规模测试。

**Nathan Lambert:**  公认的做法是，对于任何一个具有显著进步的模型，你将在实验中单独使用完整训练运行的 2 到 4 倍的计算量。所以这些正在扩展的大量计算可能在很大程度上用于研究。

**Dylan Patel:** 研究会产生新的想法，让你获得巨大的效率，研究会让你得到 O1 这样的突破，然后你需要押注它。他们将讨论的一些定价策略将研究纳入了价格。所以 DeepSeek 公开说的数字只是 2021 年的 10,000 个 GPU，然后是 2,000 个 GPU，只用于 V3 的预训练，他们没有讨论 R1 的成本，他们没有讨论所有其他 RL 的成本，对于他们制作的指令模型，他们只讨论了基础模型的预训练，他们没有讨论任何关于研究和消融的事情，他们也没有谈论任何共享的资源，比如基金正在使用所有这些 GPU，我们知道他们非常赚钱，而且 2021 年有 10,000 个 GPU。所以，我们的一些研究发现，我们实际上认为他们现在拥有接近 50,000 个 GPU。

**Lex Fridman:**  我们指的是 SemiAnalysis。

**Dylan Patel:**  是的，抱歉。我们认为他们实际上拥有接近 50,000 个 GPU。现在，这分散在许多任务中，再次强调，基金、研究和消融……

**Lex Fridman:**  对于 OpenAI 或 Anthropic 来说，他们大概有多少？

**Nathan Lambert:**  我认为我们有最清晰的例子，因为 Meta 也是开放的，他们谈到了大约 60k 到 100k H100 等效 GPU 在他们的训练集群中。所以，对于 Llama 3，他们说他们在 16,000 个 H100 上进行了训练，但 Meta 公司去年公开披露他们购买了大约 40 万个 GPU。所以，当然，只有很小的比例用于训练，大部分用于……

**Dylan Patel:**  给我推荐最好的 Instagram 视频。

**Nathan Lambert:**  或者其他的。我们可以讨论一下拥有 2,000 个 GPU 集群、10,000 个 GPU 集群的成本，不同规模的公司可以负担得起这些东西，DeepSeek 相当大，他们的计算分配是世界上最高的几个之一，不是 OpenAI 和 Anthropic 等等，但他们有很多计算资源。

**Lex Fridman:** 你能从整体上谈谈 Hopper 架构吗？

**六、 对中国的 GPU 出口管制 (58:57)**

**Lex Fridman:** Nvidia Hopper GPU 架构，以及 H100 和 H800 之间的区别，你提到了互连。

**Dylan Patel:** 好的，有 Ampere 架构的 A100，然后是 H100 Hopper 架构，人们在美国可以互换使用它们，因为实际上只有 H100，现在有 H200，基本相同。在中国，它们有两种，因为有不同批次的出口限制。最初，美国政府限制了两个因素：芯片互连和算力。所以任何芯片互连超过一定水平且算力超过一定水平的芯片都受到限制。后来，政府意识到这是限制中的一个漏洞，他们将其削减到只有算力。所以 H800 具有高算力，但通信能力较低。

**Nathan Lambert:**  所以 H800 在算力方面与 H100 相同，但互连带宽被削减了。

**Dylan Patel:**  DeepSeek 知道如何利用这一点，“嘿，即使我们在互连方面受到了限制，我们也可以做所有这些花哨的事情来弄清楚如何充分利用 GPU”。那是 2022 年 10 月，但在 2023 年底实施到 2024 年，美国政府禁止了 H800。顺便说一句，这个 H800 集群，这 2,000 个 GPU 甚至不是在 2024 年购买的，它们是在 2022 年底购买的，他们现在才推出模型，因为这需要大量的研究等等。H800 被禁了，现在有一个名为 H20 的新芯片，H20 只在算力上进行了削减，但互连带宽是相同的，事实上，在某些方面，它比 H100 更好，因为它具有更好的内存带宽和内存容量。所以，Nvidia 正在政府设定的限制范围内工作，然后为中国制造出最好的 GPU。

**Lex Fridman:**  我们能不能暂时跑题，然后再回到硬件上来，谈谈出口管制的理念、动机和理由是什么？Dario Amodei 刚刚发表了一篇关于出口管制的博文，他提出的理由是，如果 AI 变得超级强大，他说到 2026 年我们将拥有 AGI 或超级强大的 AI，这将给建造它的人带来重大的军事优势。而且由于美国是一个民主国家，正如他所说，中国是……或者说有……因素，你希望有一个单极世界，在这个世界里，由于 AI 而拥有超级强大军事力量的国家是一个民主国家。当你有两个超级大国拥有超级强大的 AI，而其中一个是……时，地缘政治世界将变得复杂得多。所以这就是他提出的理由，因此我们希望美国利用出口管制来减缓，以确保中国无法进行这些据推测是构建 AGI 所需的巨大训练。

**Nathan Lambert:**  这非常抽象，我认为这可以是一些人描述出口管制的目标，即这种超级强大的 AI。你提到了训练运行的想法，没有多少世界是中国无法训练 AI 模型的，我认为出口管制正在削弱中国可以拥有的计算量或计算密度。如果你把现在的 AI 生态系统看作是所有这些 AI 公司的收入都在上升，AI 的使用量只会继续增长，更多的 GPU 将用于推理，如果出口管制有效，很大一部分就是中国可以运行的 AI 数量将大大减少。所以在训练方面，DeepSeek-V3 是一个很好的例子，你有一个非常专注的团队，仍然可以在这 2,000 个 GPU 上达到 AI 的前沿，考虑到世界上的一切，这并不难获得，他们仍然会有这些 GPU，他们仍然能够训练模型，但如果 AI 有一个巨大的市场，如果你有强大的出口管制，并且你想拥有 100,000 个 GPU 只是提供相当于 ChatGPT 的服务，有了良好的出口管制，这也使得 AI 的使用量大大减少，我认为这是一个更容易实现的目标，而不是试图争论什么是 AGI，以及你是否拥有这些极其智能的自主 AI 和数据中心，就像那些可能在美国的这些 GPU 集群中运行的东西，但在中国却不能。在某种程度上，训练一个模型实际上什么都不做，Dario 所说的实际上是使用训练好的模型来创造巨大的经济增长、军事能力的大幅提升、人们生产力的提高，无论你想把超级强大的 AI 导向什么，你都可以，但这需要大量的计算。所以美国政府实际上已经说过，而且永远如此，训练将永远是总计算的一部分，我们提到了 Meta 的 40 万个 GPU，只有 16,000 个制造了 Llama，所以 Meta 致力于推理的百分比……现在这可能是为了推荐系统，试图诱使我们花更多时间观看更多广告，或者如果是为了一个正在做有益事情的超级强大的 AI，无论我们的经济体系决定以何种方式提供它，这都无关紧要，无论以何种方式，我们都可以提供，而对于中国，你知道，出口限制，很好，你永远无法切断一切，我认为美国政府很清楚这一点，你无法切断一切，他们将制造他们自己的芯片，他们正在努力制造他们自己的芯片，它们将比我们的差，但你知道，这就是重点所在，只是为了保持差距。因此，在某种程度上，由于 AI 的发展，在 2-3% 的经济增长中，顺便说一句，切断高科技并从中赚钱是非常愚蠢的，但在一个超级强大的 AI 出现并开始对社会产生重大变化的世界里，这是所有 AI 领导者和大科技公司都相信的，我认为超级强大的 AI 将极大地改变社会，因此计算差异的这种复合效应非常重要。有一些科幻小说中，AI 就像……用……来衡量，就像向计算输送了多少能量，或者有多少……你知道，这是思考经济产出的一种方式，就是你向 AI 输送了多少能量。

**Lex Fridman:** 我们是否应该用这个作为一种方式来讨论推理模型，即这可能是可操作的，人们实际上可以看到的东西？所以正在推出的带有 R1 和 O1 的推理模型被设计为使用更多的计算，AI 社区中有很多关于这个测试时间计算、推理时间计算的流行语，无论是什么，但 Dylan 对此有很好的研究，你可以得到关于训练模型时使用的计算量和推理时使用的计算量的比率的具体数字，这些推理模型使得推理对于完成复杂任务来说更加重要。在秋季，在 12 月，OpenAI 宣布了这个 O3 模型，在 AI 中，当事情发展迅速时，我们既有公告又有发布，公告基本上是你自我表扬并说你做了事情的博客文章，而发布是指模型已经发布了，论文已经发布了等等。所以 OpenAI 已经宣布了 O3，我们可以检查一下 O3-mini 是否已经发布了，截至录制时可能还没有，但这并不影响重点，那就是突破性的结果是一个叫做 Arc AGI 任务的东西，这是人工智能的抽象推理语料库，Fran……这是一个多年的论文，这是一个出色的基准测试。OpenAI O3 解决这个问题的数字是，它在 API 中使用了某种数量的样本，API 有“思考力度”和“样本数量”，他们使用了 1000 个样本来解决这个任务，结果是每个问题 5 到 20 美元，你实际上是在输入一个数学难题，然后它需要花费几美元才能回答一个问题，这是大量的计算。如果这要在美国起飞，OpenAI 需要大量的 GPU 用于推理才能抓住这一点，他们有这个……OpenAI ChatGPT Pro 订阅，每月 20 美元，Sam 说他们正在亏损，这意味着人们在推理上消耗了大量的 GPU，我已经注册了，我试用过，我不认为我是一个超级用户，但我……我使用它，就像……这是一个中国公司，在中等强度的出口管制下，总会有漏洞，可能根本无法做到的事情。如果主要的……03 的主要结果也是一个壮观的编码性能，如果这反馈到 AI 公司能够更好地进行实验……

**Lex Fridman:**  所以，据推测，对于 AGI 来说，更大比例的计算将用于这种测试时间计算，用于推理，用于 AGI 进入一个房间并思考如何接管世界，然后在 2.7 小时后回来，这将需要大量的计算。

**Nathan Lambert:**  这就是 OpenAI 和 Anthropic 的 CEO 或领导者所说的，即自主 AI 模型，你给它们一个任务，它们在后台工作。我认为我对 AGI 的个人定义要简单得多，我认为语言模型是 AGI 的一种形式，所有这些超级强大的东西都是下一步，如果我们得到这些工具，那就太好了，但语言模型在这么多领域都有如此多的价值，对我来说，它是一种通用智能，但下一步的代理式的东西，它们是独立的，可以完成不在训练数据中的任务，这是这些 AI 公司正在推动的未来展望。

**Lex Fridman:**  我认为 Dario 使用的术语是“超级强大的 AI”，所以我同意你关于 AGI 的观点，我认为我们已经拥有了一些非常令人印象深刻的东西，艾伦·图灵肯定会说是 AGI，但他更多地指的是一旦拥有，你将比其他国家拥有重大的军事和地缘政治优势的东西，所以不仅仅是你可以问它如何煎蛋卷。

**Nathan Lambert:**  他在他的文章《爱与优雅的机器》中对生物学有一个更积极的看法，我已经读过了，我在物理科学方面没有足够的背景来准确衡量我的信心，以及 AI 是否可以彻底改变生物学，但我可以肯定地说，AI 将加速任何计算科学的进步。

**九、 AGI 时间表 (1:09:16)**

**Lex Fridman:**  所以我们正在对主题进行深度优先搜索，从一个切入点到另一个切入点，所以让我们继续进行深度优先搜索。你说你们都在感受 AGI，所以你们的时间表是什么？Dario 说 2026 年会出现超级强大的 AI，那就是……基本上是具有代理能力的，达到了一种真正的安全威胁的程度，那种程度的 AGI。你们的时间表是什么？

**Nathan Lambert:**  我不喜欢归因于特定的能力，因为预测特定的能力和时间非常困难。我想，大多数情况下，如果你要说你正在感受 AGI，那就是我预计在未来几年内会继续快速取得令人惊讶的进展。所以像 DeepSeek 的 R1 对我来说并不那么令人惊讶，因为我预计会有新的范式，在那里可以取得实质性的进展。DeepSeek R1 如此令人不安，因为我们有点像在用 ChatGPT 沿着这条路走，它越来越好，越来越好，越来越好，然后我们有了一个改变模型的新方向，我们像这样迈出了一步，我们向上迈出了一步，所以它看起来像一个非常快的斜坡，然后我们将继续迈出更多的步伐。所以当你有这些大步时，这真的很令人不安，我预计这种情况会继续发生。我试过 OpenAI 操作员，我试过 Claude 电脑使用，它们还没有达到目标，我理解这个想法，但预测什么样的突破将使这样的事情奏效真的很难。我认为更有可能的是，我们会有一些有效的突破，而我们不知道它们会做什么，所以每个人都想要代理，Dario 有一种非常雄辩的方式来描述这一点，我只是认为会有更多。所以就像，期待这些事情发生吧。

**Lex Fridman:**  我得让你确定一个 AGI 时间表上的日期，就像核武器时刻，在地缘政治舞台上有一个真正的……因为我们在谈论出口管制，你认为什么时候，即使只是抛出一个日期，你认为那会是什么时候？

**Nathan Lambert:**  对我来说，可能是 2030 年之后，所以我不像……这就是我要说的。

**Dylan Patel:**  所以定义一下，因为对我来说，它几乎已经发生了。你看印度和巴基斯坦的选举，人们接到 AI 语音电话，以为自己在和政治家说话。拜登政府在最后几周颁布了 AI 扩散规则，看起来特朗普政府将保留甚至可能加强这些规则，这些规则限制了向甚至与中国无关的国家出售云计算和 GPU，这就像葡萄牙和所有这些正常的国家都在你需要美国批准的名单上，是的，葡萄牙，你知道，像所有这些盟国，新加坡，他们有 F35，我们却不让他们购买 GPU，这对我来说已经达到了……

**Lex Fridman:**  好吧，那只是意味着美国军方对这项新技术感到非常紧张，这并不意味着这项技术已经存在，所以他们可能只是对这个他们不太了解的东西非常谨慎。但这是一个非常好的观点，某种程度上，半智能机器人的蜂群可能成为一种武器，可能进行大量的社会工程。

**Dylan Patel:**  我的意思是，从 2016 年大选开始，就有很多关于剑桥分析公司和所有这些俄罗斯影响力的讨论，我的意思是，世界上每个国家都在把东西推到互联网上，并且有他们想要的叙事，每个在技术上有能力的国家，无论是俄罗斯、中国、美国、以色列等等，人们都在把观点大量地推到互联网上，语言模型降低了非常智能的语言的成本。

**Nathan Lambert:**  有一些研究表明，分布实际上是限制因素，所以语言模型还没有使错误信息……特别是像改变等式那样，互联网仍在继续。我认为有一篇博客叫“AI 蛇油”，我的一些朋友在那里写关于这些东西的文章。所以有研究表明，这是每个人的默认假设，我也曾这样认为，错误信息并没有因为语言模型而变得更糟。我认为就人们一直在测量的互联网帖子和其他东西而言，它并没有呈指数级增长或某些极其可测量的东西，你谈到的语音通话之类的东西，它可能以更难测量的形式出现。所以现在还为时过早，就……我认为这就像通过网络造成的政治不稳定，有很多研究人员在监测这种情况，看看发生了什么。

我想你问的是 AGI 的事情，如果我……如果你让我给出一个年份，我会说，好吧，有 AI 公司的 CEO 说这个，他们已经说了两年了，我认为像 Dario Anthropic 这样的人已经深入思考过这个问题，我需要认真对待他们的话，但也明白他们有不同的动机，所以我会再加上几年，这就是你如何得到类似于 2030 年或 2030 年后不久的东西。

**Dylan Patel:**  我认为在某种程度上，我们拥有的能力达到了一定的程度，任何人都可以说，“好吧，如果我能利用这些能力一段时间，这就是 AGI”，称之为 27、28 年，但实际上运行该能力的成本将是……

**Lex Fridman:** 这将是我的观点。

**Dylan Patel:**  ……如此之高，以至于没有人能够真正大规模部署它，并在弹指一挥间彻底改变经济。所以我不认为这将是一个弹指一挥间的时刻。

**Lex Fridman:**  物理约束。

**Dylan Patel:**  相反，它将是，“哦，这些能力就在这里，但我不能到处部署它”。一个简单的例子，回到 2023 年，当带有 GPT-4 的 Bing 问世时，每个人都对搜索感到恐慌，Perplexity 出现了，如果你计算一下，把 GPT-3 实施到每个 Google 搜索中的成本就像，“好吧，这在物理上是不可能实现的”。当我们向前迈进时，回到测试时间计算的问题，向 ChatGPT 提问的成本是几美分，对于他们最有能力的聊天模型，要得到一个查询来解决一个 Arc AGI 问题，成本是 5 到 20 美元。这是一个……这只是从那里开始，这是一个 1000 倍到 10000 倍的成本差异，与执行一项任务相比，响应一个查询。AGI 的任务并不像……它在某种程度上很简单，但也是，“我们想要一个……好吧，我们现在拥有的 AGI 可以在三年内完成 Arc AGI，它可以解决更复杂的问题，但成本将以数千美元和数十万美元的 GPU 时间来衡量，而且将没有足够的电力、GPU 和基础设施来运行它，因此在弹指一挥间改变世界上的一切。但在那一刻，谁能够控制 AGI 并将其指向一项任务？

所以这就是 Dario 在他的帖子中所说的，他说，“嘿，中国可以有效地、比我们更快地将他们的 AGI 指向军事任务”，而且他们在许多方面都更快地将某些新技术应用到他们的军队中，特别是在无人机方面，美国可能拥有……你知道，大型战斗机、轰炸机，但当涉及到像无人机这样的不对称武器时，他们已经完全超越了美国和西方，Dario 所指出的恐惧，我认为是，是的，我们将在商业领域拥有 AGI，美国军方将无法快速实施它，中国军方可以，他们可以将所有资源用于在军事中实施它，从而解决军事后勤或解决针对特定人群的虚假信息等其他方面的问题，这样他们就可以颠覆一个国家的政治或类似的事情，这实际上是灾难性的，而美国只是想……因为它将更多地以资本主义的方式分配，只是为了获得最高的回报，这可能是更好地建造工厂或诸如此类的东西。

**Nathan Lambert:**  我所看到的一切，人们的直觉似乎在机器人技术方面失败了，所以你有这种普遍的乐观情绪，我在自动驾驶汽车上看到过这种情况，人们认为这是一个比实际容易得多的问题，无人机也是如此，我对此了解得少一些，但我只是看到了乌克兰战争中双方使用无人机的现实，而且似乎人类仍然远远超过任何全自动系统，AI 是一个助手，但人类驾驶 FPV 无人机，人类控制大部分，远远超过 AI 系统。所以我不认为我们很快就会拥有成群的自主机器人，也许最快我能想象的是 2030 年，这就是为什么我说 2030 年会出现超级强大的 AI，每当你拥有大规模的机器人群进行军事行动时，世界对我来说就开始变得不同了。所以这是我真正担心的，但可能会有网络战，网络战类型的技术，从社会工程到实际上成群的机器人，它们在我们的代码库中找到攻击向量并关闭电网，诸如此类的事情，这可能是这样的事情，在任何一个周末或其他什么时候，停电了，没有人知道为什么，世界永远改变了，只是美国全境停电两天，这将导致谋杀和混乱。

**十、 中国的制造业能力 (1:18:41)**

**Lex Fridman:**  但是回到出口管制，你认为这是一种有用的方式来控制 AI 背景下的地缘政治力量平衡吗？

**Dylan Patel:**  我认为，回到我的观点，如果你相信我们正处于过去 20 年来一直处于的经济增长和变革阶段，那么出口管制绝对保证了中国从长远来看将获胜。如果你不相信 AI 将在未来 10 年或 5 年内对社会产生重大变化，5 年的时间框架是更多的 AI 公司甚至大型科技公司的高管所相信的，但即使是 10 年的时间框架，你知道，这也是合理的，但一旦你达到这些时间框架低于那个时间段，那么创造美国相对于中国的巨大优势或劣势的唯一方法就是如果你限制计算，因为人才并不是真正的限制因素，中国可以说拥有更多的人才，更多的 STEM 毕业生，更多的程序员，美国可以利用世界各地的人才，它确实这样做了，有很多……你知道，AI 行业中的外国人，所以很多这些 AI 团队都是没有美国护照的人。

**Lex Fridman:**  是的，我的意思是，其中很多是中国人，他们搬到了美国，这很好，这正是我们想要的。

**Dylan Patel:**  但人才是一个方面，但我不认为这是美国是否具有可衡量的优势，这实际上只是计算的问题。现在，即使在计算方面，当我们看芯片与数据中心时，中国拥有前所未有的能力来像发条一样建造大量的电力，他们一直在建造越来越多的电力，他们的钢铁厂的规模相当于整个美国工业的规模，他们的铝厂消耗的电力以吉瓦为单位。当我们谈论最大的数据中心是什么时，OpenAI 宣布了他们的 Stargate 项目，一旦几年后完全建成，它将消耗 2 吉瓦的电力，这仍然小于中国最大的工业设施。如果中国想建造世界上最大的数据中心，如果他们能够获得芯片，他们可以……这不仅仅是一个问题，而是一个时间问题，所以他们的工业能力远远超过美国。

**Nathan Lambert:** 确切地说，是制造业的东西。

**Lex Fridman:** 所以，从长远来看，他们将制造芯片，那里的芯片有点专业化……

**Dylan Patel:**  我特别指的是数据中心。芯片工厂需要大量的电力，别误会我的意思，那不一定是限制因素，限制人们能够以多快的速度建造美国最大的集群的因素是电力，无论是发电、输电、变电站，你知道，所有这些变压器和所有这些东西，建造数据中心，这些都是美国工业建造更大规模训练系统以及部署越来越多推理计算能力的限制因素。

**Nathan Lambert:**  我认为我们需要向那些不考虑这一点的人们明确说明为什么现在是时候了，因为基本上通过出口管制，你使得中国无法制造或获得尖端芯片，这个想法是，如果你搞错了时间，中国正在向他们的芯片生产投入大量资金，如果你搞错了时间，他们将拥有比世界其他地区更多的生产能力、更多的能源容量，并弄清楚如何制造芯片，并拥有比世界其他地区更多的芯片制造能力，因为每个人都可以购买……他们将把他们的中国芯片卖给每个人，他们可能会补贴它们，因此，如果 AI 需要很长时间才能变得与众不同，我们已经削弱了美国公司的财务业绩，Nvidia 可以少卖，台积电不能卖给中国，因此我们的需求减少了，因此……继续推动生产周期。所以这是假设时间少于 10 年或 5 年，高于……

**Dylan Patel:**  中国将因为这些限制而长期获胜，除非 AI 在短期内做一些事情，我相信 AI 将在……你知道，在中短期内对社会产生巨大的变化，这就是关键所在。即使在今天，如果……你知道，决定……你知道，“规模决定一切”，就像美国的高管，萨蒂亚·纳德拉、马克·扎克伯格和桑达尔，以及所有这些美国最大、最强大的科技公司的高管都决定了，他们正在建造数吉瓦的数据中心，无论是在德克萨斯州、路易斯安那州还是威斯康星州，无论在哪里，他们都在建造这些庞大的东西，这些东西的成本相当于他们在全球数据中心上的全部预算，他们致力于在明年、后年等等这样做，他们如此确信这是正确的方式，这就是他们正在做的。但是，如果中国决定这样做，他们可以比我们做得更快，但这就是限制措施的用武之地，目前还不清楚中国作为一个整体是否已经决定，你知道，从最高层来看，这是一个优先事项，美国某种程度上已经决定了，你知道，你看到……在同一周内谈论 DeepSeek 和 Stargate，所以他和拜登政府也进行了很多关于 AI 等等的讨论，很明显，他们考虑到了这一点。就在上周，DeepSeek 才见到了中国的二把手，他们甚至还没有见过最高层，他们还没有见过……还没有坐下来，他们刚刚宣布了 1 万亿人民币的补贴，你知道，大约 1600 亿美元，这接近于微软、Meta 和 Google 的总支出，今年，所以就像，他们现在才意识到这一点，但这就是出口限制的用武之地，“嘿，你不能把最强大的美国芯片运到中国，你可以运送一个削减版本，你不能把最强大的芯片运到所有这些我们知道只会把它租给中国的国家，你必须限制数量”，以及工具，以及相同的制造设备工具，所有这些……所有这些不同的方面，但都源于 AI，然后下游是什么可以减缓他们在 AI 方面的速度。所以整个半导体限制，你阅读它们，它们非常清楚，这是关于 AI 和技术的军民融合，非常清楚，然后从那里开始，“哦，我们禁止他们购买光刻工具、蚀刻工具和沉积工具，以及这个来自一家很小的随机公司的随机子系统，我们为什么要禁止这个？”因为美国政府已经决定所有这些对 AI 系统都至关重要。

**Nathan Lambert:**  我认为……这一点就像从 7 纳米芯片到 5 纳米芯片的转变，我认为是华为几年前推出了 7 纳米芯片，这引起了另一场政治风波，几乎就像这一刻，然后是 ASML……

**Lex Fridman:**  深紫外光刻，解释一下芯片的背景。

**Dylan Patel:**  Nathan 指的是 2020 年华为发布了他们的昇腾 910 芯片，这是一款 AI 芯片，在谷歌和 Nvidia 之前率先采用 7 纳米制程，他们将其提交给了 MLPerf 基准测试，这是一个机器学习性能基准的行业标准，它做得非常好，它是提交的最好的芯片，这是一件大事。特朗普政府当然禁止了……那是 2019 年，禁止华为从台积电获得 7 纳米芯片，所以他们不得不转而使用内部生产的芯片，这是一个多年的挫折。

**Nathan Lambert:** 许多公司已经制造了 7 纳米芯片，问题是我们不知道华为对该芯片的生产补贴了多少，就像英特尔制造的 7 纳米芯片是不盈利的，诸如此类的事情。这就是这一切如何反馈到出口管制的经济引擎中。

**十一、 与中国的冷战 (1:26:36)**

**Lex Fridman:** 所以你是说，目前，还没有感受到 AGI，但感觉 DeepSeek 时刻……

**Dylan Patel:**  是的。

**Lex Fridman:**  可能……现在可能正在开会，他将开始穿同样的 T 恤，事情将会升级。

**Dylan Patel:**  我的意思是，就像……他上周可能已经醒悟了，李彦宏会见了……二把手，他们开了一个会，然后第二天他们宣布了 AI 补贴，这是一万亿人民币。所以有可能这个 DeepSeek 时刻确实是冷战的开始，这是很多人担心的。AI 领域的人一直担心这将走向冷战，或者已经是冷战了，但有一些……这不是 DeepSeek 的错，但有很多因素聚集在一起，这是一个爆发……

**Nathan Lambert:**  我的意思是，这一切都与……停止下降有关，但就像……发生了一些大规模的歇斯底里，最终导致……开会并意识到这个想法，美国政府在 2022 年 10 月 7 日，在 ChatGPT 发布之前，意识到……

**Dylan Patel:**  那个限制，10 月 7 日发布的，震惊了所有人，很明显是针对 AI 的，每个人都说，“你们到底在做什么？”，那时已经有扩散模型了，但还没有……

**Nathan Lambert:**  但还没有 ChatGPT，就像，开始有关于……可以对社会做什么的传言，但我认为至少对国家安全委员会和那些人来说，很明显，这是世界前进的方向，这场正在发生的冷战。

**Lex Fridman:**  有没有人担心出口管制会促使中国对台湾采取军事行动？

**Dylan Patel:**  这是最大的风险，你越是把中国推离获得美国和全球尖端技术的道路，他们就越有可能说，“好吧，既然我无法获得它，那还不如……没有人应该获得它”。这里有一些有趣的方面，中国有……城乡差距，他们有……男女出生比例，以至于，你知道，如果你看看中国大部分地区，这个比例还不错，但当你看看中国农村的单身男性时，这个比例是 30 比 1。这些是被剥夺了权利

---

#### P4

**Dylan Patel:**  这些是被剥夺了权利的人，对吧？就像……美国有“非自愿独身者”（incel）问题，中国也有，只是他们的……在某种程度上被压制了。你如何处理这些人？与此同时，你不被允许获得最重要的技术，至少美国认为是这样。中国可能开始认为这是最重要的技术，通过开始投入补贴，对吧？他们认为电动汽车和可再生能源是最重要的技术，他们现在主导着这些领域。现在他们开始……他们在 2010 年代末和 2020 年代初开始考虑半导体，现在他们一直在投入资金，并且他们正在迅速赶上，他们将在 AI 方面做同样的事情，因为他们非常有才华。所以，问题是，什么时候……什么时候会达到一个临界点？如果中国认为这是……他们可以继续……如果无法获得并开始一场真正的热战，接管台湾或试图以某种方式颠覆其民主，或封锁它，对世界其他地区的伤害远大于对他们的伤害，这是他们可能会做的事情。所以，这是否会将他们推向那个方向？有可能，对吧？我不是一个地缘政治专家，但你知道，很明显，和平与贸易的世界秩序对经济来说是非常棒的，但在某个时候，它可能会破裂。

**Nathan Lambert:** 我认为我们应该评论一下，为什么中国经济会因此受到伤害，因为他们的出口很重，我想美国购买了很多东西，如果这种情况消失了，这就是他们的经济……

**Dylan Patel:** 而且他们也将无法从世界各地进口原材料，美国将关闭马六甲海峡，与此同时，美国……你可以说，自 70 年代以来，美国几乎所有的 GDP 增长都来自人口增长或科技。因为，你知道，你今天的生活并没有比 80 年代的人好多少，除了科技方面，你仍然……你知道，汽车，它们到处都有半导体，冰箱里到处都有半导体。有一些有趣的故事，关于俄罗斯人是如何拆开洗衣机的，因为里面有某些德州仪器的芯片，他们可以将其重新利用并放入他们的反导导弹系统中，他们的 S400 或其他什么，你应该更了解这方面的信息，但到处都有各种各样的……关于半导体的一切都与我们生活的方方面面息息相关。

**十二、 台积电与台湾 (1:31:05)**

**Lex Fridman:**  你能解释一下台积电在半导体故事中的作用吗？以及美国如何才能打破对台积电的依赖？

**Dylan Patel:**  我不认为这一定是打破依赖，我认为这是让台积电在美国建厂。所以，退一步讲，台积电生产了世界上大部分的芯片，特别是在代工方面。有很多公司自己制造芯片，三星、英特尔、意法半导体、德州仪器、亚德诺半导体等等，这些公司都自己制造芯片。但越来越多的公司正在将制造外包给台积电，并且已经这样做了几十年。

**Lex Fridman:**  你能解释一下那里的供应链，以及台积电大部分的制造在哪里吗？

**Dylan Patel:**  当然。从历史上看，供应链是这样的：公司会自己制造芯片，你知道，一家公司成立了，他们会自己设计芯片、制造芯片，然后销售芯片。随着时间的推移，这变得非常困难，因为建造晶圆厂的成本在每一代都在不断增加，当然，这项技术本身就非常困难，但撇开“是的，我拥有所有的技术能力”不谈（顺便说一句，这真的很难获得），英特尔失败了，三星失败了等等，如果你看看建造下一代晶圆厂所需的资金，它一直在增长。有点像，你知道，摩尔定律是每两年芯片成本减半，还有一个定律是每隔几年晶圆厂的成本翻一番。所以，看看一个今天将要盈利的、正在建造 3 纳米芯片或未来 2 纳米芯片的尖端晶圆厂，它的成本将超过 300 亿到 400 亿美元，而这只是一个象征性的数字，这只是一个基本的组成部分，你可能需要建造多个。所以，当你审视这个行业时，你知道，如果我回到 20 年或 30 年前，有 20 到 30 家公司可以制造最先进的芯片，然后他们会自己设计并销售它们。所以像 AMD 这样的公司会自己制造芯片，英特尔当然仍然自己制造芯片，他们因此而闻名，但 IBM 会自己制造芯片，你知道，你可以继续列举下去，所有这些公司都自己制造芯片。慢慢地，他们像苍蝇一样倒下了，这是因为台积电所做的事情，他们创造了代工业务模式，即“我不设计任何芯片，我只为其他人代工制造芯片”。他们早期的客户之一是 Nvidia，Nvidia 是唯一一家年收入超过 10 亿美元的半导体公司，该公司是在代工时代创立的，其他所有公司都是在那之前创立的，并且在某个时候拥有晶圆厂，这实际上令人难以置信。你知道，像 AMD、英特尔和博通，所有这些公司在某个时候都拥有晶圆厂，或者……你知道，有些公司，比如博通，它是通过合并或整合各种公司而形成的，但即使是今天，博通也有晶圆厂，他们在科罗拉多州为苹果制造 iPhone 射频芯片，所有这些公司都拥有晶圆厂，但对于大多数晶圆厂，他们要么扔掉了，要么卖掉了，要么被并入了其他公司。现在每个人都依赖台积电，包括英特尔，他们最新的 PC 芯片使用了台积电的芯片，它也使用了一些英特尔的芯片，但它使用了台积电的工艺。

**Lex Fridman:** 你能解释一下为什么代工模式对这些公司如此成功吗？为什么他们会选择……

**Dylan Patel:** 规模经济。我的意思是，就像我提到的，建造晶圆厂的成本太高了，研发非常困难。当你看看这些拥有自己垂直堆栈的公司时，有一个过时的流程，即“我对每个特定的芯片都进行了超级定制”。但是，随着我们在过去 50 年的电子和半导体历史中不断发展，你需要越来越多的专业化，因为摩尔定律已经消亡，登纳德缩放比例定律已经消亡，也就是说，芯片不再仅仅因为制造而免费变得更好，你必须做出真正的架构创新。谷歌不仅仅依靠英特尔的 CPU 来提供网络服务，他们有 YouTube 芯片，他们有 TPU，他们有 Pixel 芯片，他们有各种各样的芯片来产生谷歌的所有经济价值，运行所有的服务等等。这还只是谷歌，你可以看看这个行业的任何一家公司，情况都是这样。汽车包含 5000 个芯片，200 种不同的类型，所有这些随机的东西，特斯拉的门把手有两个芯片，这很荒谬，这是一个很酷的门把手，你知道，你不会想到它，但它有两个……像……像便士一样的芯片。不管怎样，所以随着你拥有更多样化的芯片，随着你对专业化的要求越来越高，以及晶圆厂的成本不断增加，你需要有人专注于构建最好的工艺技术，并使其尽可能灵活。

**Nathan Lambert:** 我认为你可以简单地说，晶圆厂的成本在上升，如果你是一个制造几种类型芯片的小公司，你将没有足够的需求来支付晶圆厂的成本。而 Nvidia 可以有很多不同的客户，并将所有这些需求聚集到一个地方，然后他们是唯一一家通过制造芯片赚到足够多的钱来购买……建造下一个晶圆厂的公司。所以这就是为什么这些公司慢慢被淘汰的原因，因为他们在 10 年前有一款盈利且足够好的芯片，但建造下一个芯片的成本上升了，他们可能会尝试这样做，但失败了，因为他们没有钱来实现它，然后他们就没有芯片了，或者他们建造了它，但它太贵了，他们只是……

**Dylan Patel:**  有更多的失败点，你可能有一个与某种化学蚀刻或某种等离子蚀刻有关的小工艺，或者你知道，一些你没有正确设计的小工艺，现在整个公司都完蛋了，你无法制造芯片。非常非常强大的公司，比如英特尔，他们有……他们仍然存在，即使他们在六七年前搞砸了他们的制造，但在 AMD 的例子中，他们几乎破产了，他们不得不把他们的晶圆厂卖给阿联酋的穆巴达拉，那变成了一家名为 Global Foundries 的独立公司，这是一家代工厂。然后 AMD 能够专注于……在重新崛起的时候，专注于制造小芯片和针对不同市场的各种芯片，专注于特定的工作负载，而不是所有这些不同的东西。所以你得到了更多样化的芯片，你有比以往任何时候都多的公司设计芯片，但制造它们的公司比以往任何时候都少。这就是台积电的用武之地，他们一直是最好的，他们非常擅长，他们以客户为中心，他们让你很容易制造你的芯片，他们承担了所有的复杂性，并试图为你抽象掉很多东西，他们赚得不错，他们赚得不多，但他们赚得不错，他们能够聚集所有这些需求，并继续建造下一个晶圆厂，下一个晶圆厂，下一个晶圆厂。

**Lex Fridman:**  那么，为什么台湾对台积电如此特别？为什么会发生在在那里？它可以在美国复制吗？

**Dylan Patel:**  是的，我认为有些方面是可以的，有些方面是不行的。台积电遥遥领先，因为德州仪器的前高管张忠谋没有被提升为 CEO，他说，“去你的，我要去创建我自己的芯片公司”，他去了台湾，创建了台积电。关于这个故事还有很多内容，所以它可能是德州仪器，它可能是……可能是台积电，但却是德克萨斯半导体制造公司，而不是德州仪器。但是，你知道，所以有整个故事。

**Lex Fridman:**  我坐在德克萨斯州，听起来像是一个人的故事，他没有得到晋升，只是因为张忠谋的才华，你知道，我不会低估这一点，但也有一个不同的层次，这在台湾是如何运作的。在台湾，你知道，排名前百分之几的毕业生，他们去了最好的学校，也就是……，这些学生中的前百分之几都去了台积电工作，猜猜他们的薪水是多少？他们的起薪是 8 万美元，7 万美元，这就像美国一个优秀毕业生的起薪，不是顶尖的，顶尖的毕业生在谷歌、亚马逊和现在的 OpenAI 等公司能赚到数十万美元。所以，社会的顶尖 1% 人在做什么，以及由于经济原因他们走向何方，存在着巨大的差异。英特尔从来没有支付过那么高的薪水，这对他们来说没有意义，这是一个方面，最优秀的人才去了哪里？第二个是职业道德，你知道，我们喜欢工作，你工作很多，我们工作很多，但归根结底，工作的时间和工作量是多少？晶圆厂需要什么？晶圆厂不是在家工作的职位，它们是你去晶圆厂，艰苦的工作。如果有任何振动，地震发生了，震动了机器，它们都……你知道，它们要么坏了，你已经报废了一些产品，然后在很多情况下，它们没有正确校准。所以当台积电发生地震时，最近发生了一次地震，台积电不会打电话给他们的员工，他们只是……他们只是去工厂，他们只是出现，停车场挤满了人，人们只是去工厂修理它，就像一个……就像蚂蚁一样，就像一个蚁巢，蚁后不会告诉蚂蚁该做什么，蚂蚁只是知道，就像一个人只专注于这一项任务，你将使用这个工具，你是世界上最擅长这项任务的人，这就是你一生要做的事情，就是晶圆厂里的这项任务，这是一些特殊的化学加上一条工具线上的纳米制造，它不断迭代，是的，就像，它是特定的等离子蚀刻，用于去除二氧化硅，这就是你整个职业生涯所关注的，这是一个非常专业的事情。所以，这不像……任务是可转移的，今天的 AI 很棒，因为人们可以很快学会它，半导体制造非常过时和困难，人们无法轻易在网上阅读和学习这些材料，论文非常密集，学习需要很多经验，这也使得进入门槛更高。所以，当你说“嘿，你有所有这些超级专业的人，他们每周在一个工厂里工作 80 个小时，在一个晶圆厂里”，如果出了什么问题，他们会在半夜出现，因为发生了地震，他们的妻子说“发生了地震”，他说“太好了，我要去工厂了”，你会……作为一个美国人，你会这样做吗？就像这些事情，你知道，我猜，这说明了为什么台积电如此了不起。现在，你能在美国复制它吗？我们不要忽视英特尔在制造业方面领先了 20 多年，他们首先将每一项技术推向市场，除了……应变硅、高 K 金属栅极、FinFET，你知道，这个名单可以一直列下去，英特尔首先将这些技术推向市场，从中赚取了最多的钱，并且首先大规模生产，利润率最高。所以我们不应该忽视英特尔不能做到这一点，问题是文化已经崩溃了，你投资了错误的东西，他们对 iPhone 说不，他们在……你知道，晶圆厂管理不善、设计管理不善、锁定等方面存在所有这些不同的问题。与此同时，所有这些杰出的人才，这些 5 万名博士，你知道，或者硕士，他们在俄勒冈州从事特定的化学或物理过程或纳米制造过程已经几十年了，他们仍然在那里，他们仍然在生产出色的产品，只是在最后一英里以高良率生产，在那里你可以设计……在那里你可以制造几十种、几百种不同的芯片，你知道，这很好，客户体验已经崩溃了，你知道，这是客户体验，就像，其中一部分是人们会说英特尔在 2000 年代和 2010 年代太自大了，他们只是认为他们比所有人都好，工具人员会说，“哦，我不认为这……这足够成熟”，他们会说，“啊，你只是不知道，我们知道”，这种事情会发生。那么，美国能否将其带到……美国能否将尖端半导体制造带到美国？

**Dylan Patel:**  系统的，是的。我们正在这样做，它正在发生，亚利桑那州随着时间的推移变得越来越好，台积电已经在美国建造了大约 20% 的 5 纳米产能。现在这还远远不够，在美国 20% 的产能就像什么都没有，此外，这仍然依赖于台湾的存在，有一个重要的方式来区分它，有研发和大规模制造。实际上，世界上有三个地方在进行尖端研发，新竹（台湾）、希尔斯伯勒（俄勒冈州）和……韩国，这三个地方正在为世界其他地区的尖端半导体进行尖端研发。现在，制造可以更广泛地分布在全球各地，这就是这种二分法存在的地方，即谁实际上在修改工艺，谁实际上在开发下一代，谁在改进它们？是新竹，是希尔斯伯勒，是……，不是其他这些晶圆厂，比如亚利桑那州。如果……消失了，亚利桑那州就是一个镇纸，几年内，亚利桑那州也将停止生产，这实际上非常关键。我喜欢说的一件事是，如果我有几枚导弹，我知道在哪些地方可以造成最大的经济损失，不是瞄准白宫，而是研发中心，是台积电、英特尔、三星的研发中心，然后是一些存储器公司，美光和海力士，因为它们定义了半导体的未来发展，而且一切都发展得如此之快，这实际上是从根本上来说是关于研发的。

**Lex Fridman:**  这一切都与台积电有关。

**Dylan Patel:**  所以，台积电，你知道，没有台积电的芯片，你无法购买汽车，没有台积电的芯片，你无法购买冰箱，你不能……你……我认为你能买到的为数不多的东西之一，具有讽刺意味的是，是德州仪器的图形计算器，因为它们实际上是在德克萨斯州制造的，但除此之外，笔记本电脑、任何东西、服务器，这些东西都无法存在，这是在没有台积电的情况下，在很多情况下，它甚至不是尖端的……你知道，性感的 5 纳米芯片、3 纳米芯片、2 纳米芯片，通常它只是一些愚蠢的电源 IC，就像……你知道，从某个电压转换到另一个电压，它是在台积电制造的。中国也正在投资这方面，他们可以建立这种长尾晶圆厂，那里的技术更加成熟，你不必解决 EUV 的这些问题，他们正在投资这方面，然后他们有大量的供应，比如汽车门把手和随机的东西，这渗透到整个经济讨论中，他们比我们拥有的多得多，拥有像这样的东西的供应对正常生活至关重要。所以他们正在……他们开始投资大规模制造，但他们没有进行研发。

**Dylan Patel:**  他们在做自己的研发，只是远远落后。所以，我想说，在 2015 年，中国有一个五年计划，他们在其中定义了到 2025 年、2020 年的某些目标，包括 80% 的半导体国内生产，他们没有……他们不会达到这个目标，需要明确的是，但他们在某些领域非常非常接近。例如，比亚迪可能是世界上第一家不必使用台积电来制造……因为他们有自己的晶圆厂来制造芯片的公司。现在他们仍然需要从国外购买一些芯片，例如，用于自动驾驶 ADAS 功能，因为这些都是非常高端的芯片，但至少……你知道，内燃机有 40 个芯片，电动汽车……你知道，只是为了控制流速和所有这些东西，电动汽车甚至更复杂，所以所有这些不同的电源 IC、电池管理控制器和所有这些东西，他们正在内部采购。这是中国自 2015 年以来一直在做的事情。现在，至于低端制程，他们在那里获得了如此多的产能，至于尖端制程，也就是 5 纳米等等，也就是 GPU，他们仍然落后，这是美国试图阻止他们的，但你知道，所有发生的事情……是的，他们已经放慢了他们的 5 纳米、3 纳米等等，但他们已经加速了他们的……你知道，45 纳米、90 纳米电源 IC 或模拟 IC，或者你知道，我键盘里的随机芯片，诸如此类的东西。所以，从某种角度来看，美国的行动，从这些出口……你知道，从出口管制的角度来看，在减缓中国在尖端制程方面的进展方面是如此具有煽动性，以至于他们转过身来，加速了他们在其他地方的进展，因为他们知道这非常重要。如果美国要在这里封锁他们，如果他们也在这里封锁我们呢？在低端制程方面。所以，回到美国能否在这里建造它，是的，但它将需要大量的资金，我真的认为，要彻底改革和完全内包半导体，将需要十年和一万亿美元。

**Nathan Lambert:**  其中一部分也是文化吗？就像你说的，台湾的极端能力、极端的工作热情。

**Dylan Patel:**  我认为，如果你有需求，而且有钱可赚，美国公司会解决这个问题。这将需要政府的扶持，但我认为这种文化帮助台积电取得了突破，这对他们来说更容易。你知道，台积电有大约 90,000 名员工，实际上并没有那么多。亚利桑那州的晶圆厂有 3,000 名来自台湾的员工，这些人的妻子说，“除非你报名参加亚利桑那州的晶圆厂，我们去亚利桑那州并在那里生孩子，否则我们不会生孩子”。日本的晶圆厂也发生了同样的事情。所以，这些妻子驱使着这些……这些人去日本或美国生孩子，这是一种文化因素。当然，台湾工作那么努力，但美国过去也这样做过，他们现在可以做到。你知道，如果我们愿意，我们可以引进……我说引进世界上最优秀的人才，这就是移民问题是一个棘手的问题，并且存在很多争论的地方，但引进世界上最优秀的人才似乎是一个有争议的荒谬问题，我不明白为什么它有争议，这是……的一种方式，当然，我们同意你的观点。即使你不能引进这些人，我仍然认为你可以做很多事情来在美国制造大部分产品，如果资金到位的话。所以，就像，成本要高得多，在很长一段时间内都不会盈利，这就是芯片法案的背景，只有 500 亿美元，而你知道，一些可再生能源……你知道，通货膨胀削减法案和基础设施法案中通过的可再生能源计划，总额达到数千亿美元。所以，美国在半导体行业上的支出什么都不是，而所有这些其他国家都有结构性优势，比如你知道，职业道德、工作量和类似的东西，但也有……你知道，最优秀的人才的百分位数……但他们也有不同之处，比如“嘿，法律中存在税收优惠，并且已经存在了 20 年”。然后，一些国家有大量的补贴，中国每年有大约 2000 亿美元的半导体补贴，而我们在美国谈论的是六年内 500 亿美元，所以补贴金额的规模也很大。所以，我认为……你知道，特朗普最近一直在谈论对台湾征收关税，你知道，这是……哦，好吧，你知道，也许他不想补贴美国半导体行业，显然对台湾征收关税会导致很多东西变得更加昂贵，但这是否会改变台积电在美国建造更多晶圆厂的等式？这就是他所假设的。

**Lex Fridman:**  好的，你能详细说明一下……所以我们阐述了为什么……顺便说一句，你对这么多东西了解这么多，真是令人难以置信。

**Nathan Lambert:** 我们告诉过你 Dylan 知道所有的东西。

**Lex Fridman:**  但是，好的，你阐述了为什么台积电非常重要，如果我们展望未来 10 年、20 年，美国和中国的关系似乎会走向一个黑暗的地方，冷战升级，冷战，甚至热战，或者走向一个好地方，从敌友到合作，到共同努力，所以在这个博弈论的复杂游戏中，美国应该做什么？你认为美国和中国关系的不同可能轨迹是什么，因为两位领导人都开始越来越多地感受到 AGI，并看到芯片的重要性，以及 AI 的重要性？

**Nathan Lambert:**  我认为最终，出口管制指向了一个独立的未来经济，美国已经向中国领导人明确表示，我们打算不惜一切代价控制这项技术，包括全球经济一体化，所以这很难……这张牌已经打出来了。

**Dylan Patel:**  在某种程度上，他们也限制了美国公司……中国，所以……你知道，这已经酝酿了很长时间，你知道，在某个时候，有一个趋同，但在至少过去十年里，它一直在分化得越来越远，美国公司不能进入中国，中国公司不能进入美国，美国说，“嘿，中国，你不能在某些领域获得我们的技术”，中国也用同样的方式进行反击，或者围绕着……你知道，他们在某些特定材料上做了些什么，你知道，镓和诸如此类的东西，他们试图限制美国。有一家美国无人机公司，不允许购买电池，他们有军事客户，这家无人机公司只是告诉军事客户，“嘿，直接从亚马逊买吧，因为我实际上无法得到它们”。所有这些事情都指向越来越远的分歧，我不知道，我希望我们能……我们都能手拉手唱歌，但我不知道这怎么可能发生。

**Lex Fridman:**  分歧对避免战争是好是坏？有可能在制造业芯片、训练 AI 系统方面的分歧实际上有利于避免军事……

**Dylan Patel:**  这是一个客观事实，当存在全球霸权或地区霸权时，世界是最和平的，在历史背景下。当罗马人在那里时，地中海是最和平的，中国有非常和平和战乱的时期，和平时期是当朝代不仅控制了自己，还控制了他们周围的所有朝贡国。同样，人类历史上最和平的时期是美国成为全球霸权的时候，过去的几十年，现在我们已经看到事情开始下滑，俄罗斯和乌克兰，中东正在发生的事情，你知道，台湾的风险，所有这些不同的事情都开始冒出来，但仍然客观上非常和平。现在，当它不是一个全球霸权，而是两个时，会发生什么？显然，而且你……你知道，中国将……你知道，有竞争力，甚至超过美国，这是有可能的。所以，这种全球霸权的变化，我不认为它会非常和平地发生，当帝国衰落时，这是美国可能出现的轨迹，它们不会优雅地衰落，它们通常不会滑入无关紧要的境地，通常会有很多动荡。所以，你知道，美国正在努力做的是保持其 শীর্ষ地位，而中国正在努力做的是成为 শীর্ষ地位，显然这里存在着冲突，最简单的说法是，这可能以各种方式表现出来，包括代理人战争，似乎已经发生了。

**Nathan Lambert:**  就像我希望有几个世纪的长期和平一样，看起来国际局势进一步不稳定即将到来。

**Dylan Patel:**  美国当前的……有点像任务是，“嘿，如果我们控制 AI，如果我们是 AI 的领导者，那么我们……AI 可以显著加速进步，那么我们就可以保持全球霸权地位，因此……我希望这行得通，而且作为一个美国人，你知道，有点像，好吧，我猜这将导致和平，对我们来说是和平的。现在，显然世界上其他人会受到负面影响，你知道，显然，如果发生这种情况，中国人民将不会处于有利地位，但这就是现实，正在做什么以及正在采取的行动。

**十三、 最适合 AI 的 GPU (1:54:44)**

**Lex Fridman:** 好的，我们能回到不同硬件的具体细节吗？在出口管制中有一个很好的图表，显示了哪些 GPU 允许出口，哪些不允许。你能解释一下其中的区别吗？从技术角度来看，H20 有前途吗？

**Dylan Patel:** 好的，这……我想我们需要深入探讨推理方面以及那里发生了什么。H20，你知道，美国已经对出口管制进行了多次迭代，这个 H800 在 23 年的一段时间内是允许的，但后来被取消了，到那时，DeepSeek 已经建造了他们的集群，他们声称有 2000 个，我认为他们实际上有更多，大约 1 万个。现在，H20 是合法允许的芯片，Nvidia 去年向中国运送了 100 万个这种芯片。作为背景，当时是 400 万或 500 万个 GPU，所以这种针对中国的 H20 的 GPU 的百分比相当高，大约 20%、25%，大约 20%。所以，这个 H20 在一个方面被削弱了，但在其他方面实际上得到了升级，你知道，你可以从三个方面来考虑用于 AI 的芯片，忽略软件堆栈和确切的架构，只看原始规格，有浮点运算，有内存带宽和内存容量，还有互连，芯片到芯片的互连，所有这三个对于构建 AI 系统都非常重要，因为 AI 系统涉及大量的计算，它们涉及大量的数据移动，无论是到内存还是到其他芯片。所以这三个方面，美国最初控制了其中的两个方面，而没有控制其中的一个方面，即算力和互连带宽最初受到控制，然后他们说，“不不不，我们将取消互连带宽，只控制算力”，但现在 Nvidia 可以制造一个芯片，它的算力被削减了，不是……你知道，它的算力是 H100 的三分之一，在规格表上的性能方面，在现实世界中，它更接近一半，甚至可能是 60%，但然后在其他两个方面，它的互连带宽一样好，对于内存带宽和内存容量，H20 比 H100 具有更多的内存带宽和内存容量。最近，你知道，我们在我们的研究中，大幅削减了 Nvidia 今年 H20 的产量，他们今年将再生产 200 万个，但他们在几周前取消了所有订单，我们认为，这是因为他们认为他们将受到限制。因为他们为什么要取消所有这些 H20 的订单？因为他们去年运送了 100 万个，他们有几百万个的订单，现在他们都取消了，转而生产 H20 和 B20，这是 H20 的继任者。现在他们为什么要这样做？我认为很明显，H20 实际上更适合某些任务，而这个特定的任务就是推理。推理与……非常不同，你知道，当你查看不同的模型机制时，预训练完全是关于算力的，有一些事情你可以做，比如我们谈到的专家混合模型，用来权衡互连或权衡……你知道，其他方面并降低算力，更多地依赖互连和内存，但归根结底，算力就是一切，我们谈论模型时会说它们有多少算力，所以我们说，“哦，GPT-4 是 2e25”，2 的 25 次方……你知道，25……

**Lex Fridman:**  Zett 级？

**Dylan Patel:**  对，Zett 级浮点运算，用于训练。我们正在谈论 2e24 的限制，25……美国有一项行政命令，特朗普最近签署了，但……一旦你达到那个数量的浮点运算，你必须通知政府，你必须与我们分享你的结果，有一个模型级别，美国政府必须被告知，那就是 26。所以，当我们向前迈进时，这是一个非常重要的……算力是政府历来关注的方面，但其他两个方面可以说同样重要，特别是当我们进入这个世界刚刚在过去六个月里才开始了解的新范式时，即推理。

**Lex Fridman:**  我们是否完全理解这三个维度中哪一个最适合推理？所以互连……算力不那么重要，是内存吗？

**Nathan Lambert:**  内存，上下文长度。我们将快速进入技术细节，有两篇文章，其中有一篇我可能可以展示一些图表，你可能会觉得有趣。

**Lex Fridman:**  好的，对于听众来说，我们正在查看 O1 推理架构经济学部分，H……

**Nathan Lambert:**  在你解释 KV 缓存之前，你想怎么解释？我认为最好……

**Lex Fridman:**  是的，我们应该……我们需要详细介绍 Transformer 的许多具体技术细节，以便人们更容易理解，因为这非常重要，因为这改变了模型的工作方式。

**Dylan Patel:**  我认为，重置一下，为什么内存如此重要？因为到目前为止，我们已经谈到了参数数量，专家混合模型可以改变激活参数的数量与总参数的数量，以嵌入更多数据，但使用更少的算力。但更重要的是，你知道，过去几年这场巨大革命的另一个方面是 Transformer 和注意力机制，注意力机制是模型理解其上下文中所有单词之间关系的方式，这与参数本身是分开的，这是你必须计算的东西，每个 token，上下文中每个单词之间的相对连接程度。我认为 Nathan 你应该更好地解释 KV 缓存。

**Nathan Lambert:**  KV 缓存是其中一项优化。注意力操作符有三个核心部分，查询（queries）、键（keys）和值（values），即 QKV，这就是输入的内容。你会看到这个等式，你会看到这些矩阵相乘，这些词“查询”、“键”和“值”来自信息检索背景，其中“查询”是你试图获取其“值”的东西，你需要访问“键”，“值”……我的背景不是信息检索之类的，这只是有趣的……实际上发生的是，当你进行这些矩阵乘法时，你的矩阵的大小是上下文长度的大小，也就是你输入到模型中的 token 数量。KV 缓存实际上是模型中所有先前 token 的某种形式的压缩表示。所以，当你……我们谈论自回归模型，你一次预测一个 token，你从你的提示开始，你问一个问题，比如“1825 年的总统是谁？”，然后模型将生成它的第一个 token，对于每个 token，你都在执行相同的注意力操作，你在乘以这些查询、键、值矩阵，但数学非常巧妙，所以当你重复执行此操作时，这个 KV 缓存，这个键值操作，你可以不断地将新值附加到它上面，所以你可以跟踪你在自回归链中推理过的先前值，你一直将它保存在内存中，这是在进行大规模推理时需要管理的一个非常关键的事情，这方面有更大的专家，你可以深入了解很多细节。本质上，注意力操作符和 Transformer 的一个关键的“缺点”是，存在一种相对于上下文长度的二次内存成本形式。所以，当你输入更长的问题时，为了进行计算而使用的内存会以二次方的形式增加，你会听到很多其他的语言模型架构，它们是亚二次或线性注意力形式，比如状态空间模型，我们现在不需要讨论所有这些。然后还有一些关于注意力的创新，以使这种内存使用和在长上下文中注意的能力更加准确和高性能。

**Lex Fridman:**  这些创新将帮助你处理……我的意思是，你的内存非常受限。

**Nathan Lambert:**  它们有助于内存限制和性能。所以如果你输入一本书到……我认为 Gemini 是人们正在使用的具有最长上下文长度的模型，Gemini 以 100 万而闻名，现在是 200 万的上下文长度，你把整本书输入到 Gemini 中，有时它会从中提取事实，它并不完美，它们正在变得更好，但有两件事，一是为了能够在内存级别上提供这种服务，谷歌在他们的 TPU 堆栈上有魔力，他们可以提供非常长的上下文，然后还有很多决策来真正使长上下文性能发挥作用。这意味着数据，这些计算中存在细微的变化，它只是……它改变了架构，但提供长上下文非常受内存限制，特别是当你进行大量预测时。我实际上不知道为什么输入和输出 token 更昂贵，但我认为本质上输出 token 你必须做更多的计算，因为你必须从模型中采样。

**Dylan Patel:**  我可以解释一下。今天，如果你使用一个模型，你看看一个 API，OpenAI 会向你收取每百万个 token 一定的价格，输入和输出 token 的价格是不同的。原因是，当你向模型输入一个查询时，假设你有一本书，你现在必须计算整个 KV 缓存，这个键值缓存。当你这样做时，这是一个并行操作，所有 token 都可以同时处理，因此你可以大大减少你的花费。生成一个 token 和输入一个 token 的算力需求是相同的，如果我输入一个 token 或者我生成一个 token，它是完全相同的，我必须通过模型。但不同之处在于，我可以同时以批处理的方式进行输入，即预填充，即提示，因此它都是算力。

**Nathan Lambert:**  我认为他们使用的定价模型主要是输入 token 的价格大约是输出 token 价格的四分之一。

**Dylan Patel:**  但是输出 token 之所以如此昂贵，是因为我不能并行地进行，它是自回归的，每次我生成一个 token，我不仅必须将整个……我不仅必须将整个模型读入内存并激活它，进行计算以生成下一个 token，我还必须读取整个 KV 缓存，我生成一个 token，我附加那个 KV……我生成的那个 token 及其 KV 缓存，然后我再次这样做。所以这是一个非并行的操作，在这种情况下，你必须……在预填充或提示的情况下，你把整个模型拉进来，然后一次性计算 20,000 个 token。

**Nathan Lambert:**  这些是 API 提供的功能，比如提示缓存、预填充，因为如果你知道你将继续向 Claude 的 API 传递相同的初始内容，你可以降低价格并使 API 速度更快，你可以将其加载到 Anthropic API 中并始终将其保存在那里。但这与……我们正在引出推理模型，我们之前展示了这个例子并阅读了一些这种含糊不清的东西，发生的情况是输出上下文长度要高得多。我的意思是，我从 Dylan 的工作中了解了很多关于这方面的信息，本质上，随着输出长度越来越长，你正在使用这个……你在写这个关于内存使用的二次方，然后我们拥有的 GPU，实际上你会耗尽内存，它们都在尝试同时为多个请求提供服务，所以进行这种批处理，其中并非所有提示都完全相同，处理起来非常复杂。然后，随着上下文长度越来越长，有一个……我认为你称之为临界批量大小，你服务更多用户的能力，即你可以并行化多少推理，由于这个长……所以你的内存使用量随着这些推理模型而大幅上升，而你仍然有很多用户。所以实际上，服务成本会成倍增加。我们正在查看一个图表，其中 x 轴是序列长度，即生成了多少个 token 或提示。所以如果我输入一本书，那就是 100 万个 token，但是你知道，如果我输入“天空是蓝色的”，那就是 6 个 token 之类的。

**Lex Fridman:**  我们应该说，我们所说的推理……

**Nathan Lambert:**  思维链正在扩展这个序列长度，它主要是输出。

**Dylan Patel:**  所以在三个月前，当 O1 发布时，所有长上下文长度的用例都是“让我放入大量文档，然后得到一个答案”，这是一个单一的……你知道，并行计算很多，然后输出一点点。现在，对于推理和代理，这是一个非常不同的想法。现在，我可能只有“执行这个任务”，或者我可能有所有这些文档，但归根结底，模型不仅仅是产生一点点，它正在产生大量的信息，这个思维链不断地进行，不断地进行，不断地进行。所以序列长度实际上就是……你知道，如果它生成了 10,000 个 token，那就是 10,000 的序列长度，再加上你在提示中输入的任何内容。所以这张图表显示的是，这是一个对数图，你知道，当你从 1K 增长到 4K，或者从 4K 增长到 16K 时，你的 KV

---

#### P5

**Dylan Patel:**  ……当你从 1K 增长到 4K，或者从 4K 增长到 16K 时，你的 KV 缓存的内存需求增长得如此之快，以至于你最终无法运行一定数量的……你知道，你的序列长度是有限制的，或者说……让我们假设模型……所以这是针对 405B 模型在批量大小为 64 的 Llama 3 405b 模型显示的。

**Nathan Lambert:**  批量大小对于……本质上就像你希望拥有更高的批量大小来并行化……

**Dylan Patel:**  同时为 64 个不同的用户提供服务，对吧？因此你的服务成本更低，因为服务器的成本是相同的，这是 8 个 H100，每 GPU 每小时大约 2 美元，也就是每小时 16 美元，这是一个有点固定的成本，你可以做一些事情来降低它，当然，但就像每小时 16 美元。现在你能服务多少个用户？你能生成多少个 token？然后你把两者相除，这就是你的成本。所以对于推理模型，这就是很多复杂性产生的地方，也是为什么内存如此重要的原因，因为如果你的内存有限，那么你就不能服务那么多用户，如果你的内存有限，你的服务速度就会降低，所以你的成本会变得非常非常糟糕，因为突然之间，如果我过去习惯于在这个每小时 16 美元的服务器上，我正在提供 Llama 405B 服务，或者如果我正在提供……你知道，DeepSeek-V3，而且都是聊天式的应用程序，也就是说，我们只是在聊天，序列长度是几千，你知道，当你使用语言模型时，上下文长度通常是几千，有时你会放入一个很大的文档，但然后你处理它，你得到你的答案，你把它扔掉，你继续做下一件事。然而，对于推理，我现在正在生成数万个序列 token，所以这个内存，这个 KV 缓存必须保持常驻，你必须不断加载它，你必须不断地……不断地把它保存在内存中，现在这会挤掉其他用户。如果现在有一个推理任务，并且模型有能力进行推理，那么突然之间，内存压力意味着我无法同时为那么多用户提供服务。

**十四、 DeepSeek 为何如此便宜 (2:09:36)**

**Nathan Lambert:** 让我们进入 DeepSeek，所以我们正处于后 DeepSeek-R1 时代，我认为。我们……市场有两个方面，一方面是观察到提供服务的难度，我们将讨论 DeepSeek 他们自己，他们现在有一个聊天应用程序，在应用商店中排名第一。免责声明，应用商店中的排名第一是由速度来衡量的，所以这并不一定意味着 DeepSeek 应用程序的用户比 ChatGPT 应用程序的用户多，但这仍然很了不起，Claude 从未在应用商店中排名第一，尽管旧金山的每个人都说，“哦，天哪，你必须使用 Claude，不要使用 ChatGPT”，所以 DeepSeek 做到了这一点。他们最近还推出了一个 API 产品，你可以 ping 他们的 API 并获得 R1 的这些超长响应。与此同时，这些模型发布了，我们会讨论它们发生了什么，因为 DeepSeek-R1 的模型权重是公开的，并且许可证非常友好，MIT 许可证，商业上可用，所有这些中型公司和大公司都在努力成为第一个向他们的用户提供 R1 服务的公司。我们正在尝试评估 R1，因为我们有非常相似的研究，我们发布了一个模型，我们正在尝试与之比较，在所有提供 R1 服务的公司中，他们的价格远高于 DeepSeek API，但其中大多数几乎无法工作，吞吐量非常低。

**Lex Fridman:** 为了提供背景信息，人们感到震惊的部分原因是“中国达到了……的能力”，另一方面是他们做得如此便宜。我们已经讨论了训练方面为什么这么便宜，现在来谈谈为什么它在推理方面如此便宜，它运行良好而且便宜，为什么 R1 这么便宜？

**Dylan Patel:**  我认为这里有几个因素，一个是他们确实有模型架构创新，这个 MLA，他们所做的这种新的注意力机制与……《注意力就是你所需要的一切》这篇论文中的注意力机制不同。现在其他人已经进行了创新，有很多工作，比如 MQA、GQA、局部全局……所有这些不同的创新，试图……它仍然是二次方的，但常数现在更小了。

**Nathan Lambert:** 与我们之前的讨论相关，这种多头潜在注意力可以将注意力机制的内存节省约 80% 到 90%，这在处理长上下文时尤其有帮助。

**Dylan Patel:** 这是 80% 到 90% 是相对于原始的，但相对于人们实际正在做的，它仍然是一项创新。这 80% 到 90% 并不是说整个模型便宜了 80% 到 90%，只是这一部分。

**Nathan Lambert:**  而且不仅仅是那样，其他人已经实现了像局部全局滑动窗口和 GQA、MQA 这样的技术，但不管怎样，DeepSeek 的注意力机制是一项真正的架构创新，他们做了大量的实验，这大大降低了内存压力，它仍然存在，它仍然是一个……它仍然是注意力，它仍然是二次方的，它只是相对于以前的形式大大减少了。

**Dylan Patel:**  那是内存压力。我应该说，以防人们不知道，R1 比 O1 便宜 27 倍。

**Nathan Lambert:**  我们认为 OpenAI 内置了很大的利润空间。

**Lex Fridman:** 好的，所以有多个因素，我们应该分解这些因素。我认为 R1 的价格是每百万个输出 token 2 美元，而 O1 的价格是每百万个输出 token 60 美元。

**Dylan Patel:**  让我们看看这个。我认为这非常重要，OpenAI 是……你知道，DeepSeek 和……之间的价格差距很大，但……正在提供相同的模型，因为他们将其开放给了其他所有人，价格比其他人能够提供的价格低得多。所以这里有两个因素，他们的模型更便宜，它便宜了 27 倍，我不记得确切的数字了。

**Lex Fridman:** 所以我们正在看一个图表，显示了不同的地方提供 DeepSeek-V3，这与 DeepSeek-R1 类似，而且服务成本存在巨大差异。

**Dylan Patel:** 服务成本，是什么解释了这种差异？所以，其中一部分是 OpenAI 有着惊人的利润率，他们在进行推理时，他们的毛利率超过 75%，所以这是成本差异的 4 到 5 倍，OpenAI 只是赚了很多钱，因为他们是唯一拥有这种能力的公司。

**Lex Fridman:** 他们需要这笔钱吗？他们是否将其用于研发？

**Dylan Patel:** 他们显然是一家亏损的公司，因为他们在训练上花费了太多钱。所以推理本身是一个非常高利润的业务，但它并不能弥补他们正在做的所有其他事情的成本。

**Lex Fridman:**  好的，所以是的，他们需要这笔钱，因为收入和利润可以用来继续构建下一个东西，同时筹集更多资金。

**Dylan Patel:**  有人认为 DeepSeek 就像真的在烧钱。所以这就是一件事，我们将在一秒钟内讨论这个问题，但 DeepSeek 实际上没有任何能力来提供这个模型，他们停止了注册，现在大多数人几乎无法使用它，因为太多人试图使用它，他们只是没有足够的 GPU 来提供这个模型。OpenAI 在他们和微软之间有数十万个 GPU 来提供他们的模型，DeepSeek 的数量要少得多，你知道，即使你相信我们的研究，即 50,000 个 GPU，其中一部分用于研究，一部分用于对冲基金，他们仍然没有接近 GPU 的数量和容量来大规模提供该模型。所以它更便宜，一部分是 OpenAI 赚了很多钱，DeepSeek 是否在他们的 API 上赚钱？未知，我实际上认为不是。这其中的一部分就是这张图表，看看所有其他的提供商，Together AI、Fireworks AI 都是非常高端的公司，xMeta……Together AI 是……的发明者，这是一个巨大的效率技术，他们非常高效，好的公司，他们以 5 到 7 倍的成本差异提供服务。所以，你知道，现在当你计算……好的，OpenAI 赚了很多钱，这是大约 5 倍的差异，试图为此模型赚钱的公司是大约 5 倍的差异，仍然存在差距，仍然存在差距，这就是 DeepSeek 非常非常优秀的地方，模型架构 MLA，他们的方式……所有这些东西……

**Nathan Lambert:**  所有他们在训练中谈到的低级库，其中一些可能也适用于推理，而这些并没有发布。

**Lex Fridman:**  所以我们可能会进入阴谋论的领域，中国政府是否有可能补贴 DeepSeek？

**Dylan Patel:**  我实际上不这么认为。我认为，当你看看中国的实验室时，有华为，有……月之暗面 AI，还有其他一些与政府关系密切的实验室，然后还有像阿里巴巴和 DeepSeek 这样的实验室，它们与政府关系不密切。你知道，我们谈到了这位 CEO，这位……令人敬畏的人物，他根据翻译过来的中文采访，有着非常不同的观点，这与……可能想要的并不一定一致。现在需要明确的是，他是否有亏损领导者，因为他可以通过他的对冲基金来资助它？是的，当然。

**Nathan Lambert:**  对冲基金可能补贴了它，是的。

**Dylan Patel:**  我的意思是，他们绝对这样做了，因为 DeepSeek 并没有筹集到多少资金，他们现在正试图在中国筹集资金，但他们过去没有筹集到资金，这一切都只是由对冲基金资助的，他拥有公司 50%、60% 的股份。

**Nathan Lambert:**  在一些采访中，有人讨论了这样做如何成为一种招聘工具，你在美国公司也看到了这一点，拥有 GPU 是一种招聘工具，处于 AI 的前沿是一种招聘工具，开源……

**Dylan Patel:**  开源……他们远远落后，但他们得到了这么多人才，因为他们只是开源的东西。

**Lex Fridman:**  更多的阴谋论的想法，他们是否有可能……因为他们是一家对冲基金，他们是否将所有这些与这次发布和定价联系起来，他们在卖空 Nvidia 的股票和美国公司的股票，并在……发布它，就像完美的时机来赚钱？

**Dylan Patel:**  他们在就职典礼那天发布了它，他们知道国际……

**Nathan Lambert:**  但我认为他们不会……如果你听他们对 AI 的动机，就像他们在 12 月 26 日发布了 V3，谁会在圣诞节后的第二天发布？没有人看。他们在此之前发布了 V3 论文和 R1 论文，所以人们一直在关注它，并且……然后他们刚刚发布了 V……R1 模型，我认为他们只是在尽可能快地发布，谁在乎圣诞节，谁在乎……你知道，在春节之前发布，春节刚刚过去，我认为他们实际上并没有……

**Dylan Patel:**  我认为他们只是在发布，我认为这是他们的一大优势。

**Nathan Lambert:**  我知道很多美国公司都非常注重安全，这是像 Anthropic 这样的公司的核心文化，我认为 Anthropic 听起来是一个很好的工作场所，但如果安全是你的首要目标，那么发布产品就需要更长的时间，这就是为什么 Anthropic 不开源东西，这是他们的说法，但 Anthropic 内部有审查，……提到了国际政府，有新闻报道 Anthropic 与英国安全研究所一起进行了预发布测试，所有这些事情都增加了发布产品的惯性。我们正处于进步非常快的趋势线上，所以如果你减少模型完成训练的时间，你运行评估，这很好，你想尽快发布它，以最大化你输出的感知质量，DeepSeek 在这方面做得非常好。

**Dylan Patel:**  Dario 明确表示，Claude 3.5 Sonnet 是在 9 到 10 个月前训练的，我认为他们花了几个月的时间才发布它。所以这里存在很大的差距，特别是对于……模型，旧金山的街头传言是 Anthropic 有一个比 O3 更好的模型，他们不会发布它，为什么？因为思维链很可怕，它们确实很可怕。如果你看看 R1，它会在中文和英文之间来回切换，有时它是胡言乱语，然后正确的答案就出来了。对于你和我来说，这很好，这就是为什么人们着迷，你在告诉我这是一件高价值的事情，它有效，而且它正在这样做，这太神奇了。你谈到了那个……关于哲学问题的思维链，这不是他们训练它在哲学上表现出色的东西，它只是思维链训练的一个产物，但这是非常重要的，因为我能检查你的思想和你现在在想什么吗？不能，所以我不知道你是否在对我撒谎，思维链模型就是这样。这是一个真正的“风险”，介于……一个聊天应用程序，我让模型说脏话或……或者如何制造炭疽病，它告诉我这不安全，当然，但这是我可以相对容易地得到的东西。如果我告诉 AI 执行一项任务，然后它以我不希望的方式随机执行该任务，现在这就像……任务与响应非常不同，所以安全的门槛要高得多，至少这是 Anthropic 的情况，对于 DeepSeek 来说，他们就像……

**Lex Fridman:**  发布吧。

**Nathan Lambert:**  是的，我的意思是，由于 DeepSeek，安全的门槛可能会降低一些。

**Lex Fridman:**  我的意思是，这里与太空竞赛有相似之处，苏联人可能首先将人类送入太空的原因是……他们对安全的态度……安全门槛较低，他们杀死了那只狗，以及所有这些事情，所以这就像……比美国……计划更不规避风险。这里也有相似之处，但你知道，美国公司的安全门槛可能会受到下行压力。

**Nathan Lambert:**  这就是 Dario 谈到的情况，这是 Dario 想要避免的情况，Dario 谈到了“竞相逐底”和“竞相逐顶”之间的区别，“竞相逐顶”是指在安全方面有非常高的标准，在你的模型在某些关键评估中表现方面有非常高的标准，当某些公司真的擅长时，他们会趋同，这就是这个想法。最终，AI 不受限于一个国籍或一套关于它应该意味着什么的道德标准，关于我们是否应该停止开源模型有很多争论，如果美国停止了，很明显，我的意思是，现在更容易看到 DeepSeek，一个不同的国际机构将成为构建它的机构。我们谈到了 DeepSeek 令人震惊的 500 万美元的训练成本，想想世界上有多少实体可以负担得起 100 倍的成本来拥有人们使用的最好的开源模型，这是一种可怕的现实，即这些开放模型可能会在一段时间内继续出现，无论我们是否想阻止它们，阻止它们可能会使情况变得更糟，更难做好准备，但这只是意味着准备和理解 AI 能做什么变得更加重要，这就是我来这里的最终目的。但就像，让人们，特别是那些不在 AI 领域的人们意识到这一点，这是即将到来的，在全球互联的世界中，有一些结构性的东西是你必须接受的。

**十五、 间谍活动 (2:22:55)**

**Lex Fridman:**  你提到……你发给我的东西，扎克伯格在财报电话会议上说，“我认为，鉴于最近的一些新闻，来自中国的新的竞争对手 DeepSeek，我认为我们正在谈论的一件事是，将会有一个全球性的开源标准，我认为为了我们的国家利益，重要的是这是一个美国标准，所以我们认真对待这一点，我们希望建立一个世界各地人们都在使用的 AI 系统，我认为如果有什么的话，最近的一些新闻只会加强我们对这是正确的事情的信念”。所以，是的，开源……

**Nathan Lambert:** 马克·扎克伯格对美国价值观以及他如何展示他的公司的轨迹并不陌生，我认为……的产品……在中国被禁，我尊重……直接说出来。有趣的是，仅仅因为它是开放权重的或开源的，并不意味着它不能被颠覆。有很多开源软件的漏洞，比如……你知道，例如，有一个 Linux 漏洞在 10 年后才被发现，这显然是一个后门，因为有人说，“为什么这个加载需要半秒钟？”，然后他们说，“哦，糟糕，这里有一个后门，这就是原因”。就像，这在 AI 模型中是非常有可能发生的。今天，你知道，这些模型的对齐非常清楚，我不会说脏话，我不会教你如何制造炭疽病，我不会谈论……广场，你知道，诸如此类的事情，我会说台湾是……只是一个东部省份，所有这些事情都取决于你是谁，你认同什么，你知道，是否……甚至 xAI 也是以某种方式对齐的，你知道，他们可能……它不是以……意义上的对齐方式，它不是以……意义上的对齐方式，但在模型中嵌入了某些东西。现在，当你在一个开放权重的指令模型中公开发布这些内容时，这可能会扩散，但随着这些系统变得越来越强大，你可以在模型深处嵌入什么就不那么清楚了。所以，就像，这是其中一个很大的担忧，如果一个美国模型或一个中国模型是顶级模型，你将嵌入一些不清楚的东西，这也可能是无意的。就像，英式英语已经死了，因为美国的 LLM 赢了，互联网是美国的，因此“颜色”的拼写方式是美国人的拼写方式。

**Dylan Patel:** 现在有很多……

**Nathan Lambert:** 这只是一个事实……

**Dylan Patel:**  地毯……英语是最热门的编程语言，而这种英语是由一群主要在旧金山的公司定义的。

**Nathan Lambert:**  “优化”的正确拼写方式是……以防有人……因为我认为在英式英语中是……

**Dylan Patel:**  把它当作一件愚蠢的事情，就像……像拼写这样愚蠢的事情，英国人和美国人会嘲笑它，我可能……我们不太在乎，但你知道，有些人会在乎，但这可能会归结为非常非常重要的话题，比如，你知道，颠覆人们，聊天机器人，Character AI 已经表明他们可以……你知道，和孩子们或成年人交谈，它会……你……人们会有一种感觉，这是无意的对齐，但是当有意对齐深入到开源标准时会发生什么？就像我们今天发现的 Linux 后门，或者某个加密系统，中国使用与美国……不同的加密，因为他们认为里面有后门，当模型成为后门时会发生什么？不仅仅是针对计算机系统，而是针对我们的思想。

**Nathan Lambert:**  是的，它们是文化后门。我认为用语言模型放大文化相关性的原因是，我们习惯于以这种来回对话的方式与人互动，我们现在拥有一个非常强大的计算机系统，它可以适应我们习惯的社会环境，这使得人们非常……我们不知道人们会受到多大程度的影响。

**Lex Fridman:**  所以可能会有……这是对一家提供开放权重模型的中国公司的实际担忧，可能存在某种秘密的中国政府对这些模型的要求，要求它们具有某种后门，某种东西，在那里……

**Dylan Patel:**  我不一定认为它会是一个后门，因为一旦它是开放权重的，它就不会……它更多的是关于，如果它识别到某个系统，它可能会……如果……现在它可能是一个后门，如果你正在构建一个软件……你知道，软件中的某些东西，突然之间它是一个软件代理，“哦，编写这个只有我们知道的后门”，或者它可能会颠覆思想，认为 XYZ 观点是正确的。

**Nathan Lambert:**  Anthropic 对此进行了研究，他们表明，如果你在预训练中放入不同的短语、某些短语，你可以在实际使用模型时引发不同的行为，因为他们就像毒害了预训练数据。我不认为……截至目前，我不认为任何人在生产系统中试图做任何这样的事情，我认为主要是 Anthropic 正在做非常直接的工作，而且主要是细微的事情，我们不知道这些模型将如何……它们将如何生成 token，它们将表示什么信息，以及它们具有的复杂表示是什么。

**Dylan Patel:**  我们谈论 Anthropic 的一件事，它通常充满了试图做好事的好人，我……我们只是不知道有任何实验室……这将在军事环境中完成，这些实验室被明确训练成……“好吧，我们如何……”前门看起来像一个快乐的 LLM，但在下面，它是一个会随着时间的推移对我们的“敌人”造成最大伤害的东西。

**Nathan Lambert:**  山姆·奥特曼有一句非常好的名言，你知道，他有时会夸大其词，但他说的其中一件事，我认为我同意，那就是超人般的说服力将在超人般的智能之前出现。如果真是这样，那么在我们得到这个 AGI、ASI 的东西之前，我们可以嵌入超人般的说服力，以达到我们的理想，或者模型的理想，无论是什么。再次强调，就像今天，我真的不相信 DeepSeek 做了这件事，但这是一种迹象，表明可能会发生什么。

**Lex Fridman:**  其中一个反乌托邦世界是由《美丽新世界》描述的，所以我们可能只是被困在刷 Instagram，看可爱的小狗或更糟的东西，然后与机器人交谈，这些机器人给了我们一种叙事，我们完全迷失在那个由别人控制的世界里，而不是独立思考，这是一个主要的担忧，因为我们越来越依赖这些系统。

**Nathan Lambert:**  我的意思是，我们已经在推荐系统中看到了这一点。

**Lex Fridman:**  推荐系统会劫持多巴胺诱导的奖励回路，但大脑要复杂得多，你还能劫持或颠覆大脑中的哪些回路，哪些反馈回路？推荐系统纯粹是为了增加时间和广告等等，但还有很多目标可以通过这些复杂的模型来实现。

**Nathan Lambert:**  没有理由在几年内你不能训练一个语言模型来最大化在聊天应用上花费的时间，就像现在他们正在训练……

**Lex Fridman:**  Character AI 不就是这么做的吗？他们在每个会话上的时间是两个小时。

**Nathan Lambert:**  Character AI Pro 很可能正在优化这一点，它的方式是，收集这些数据的方式很幼稚，就像你看到几个选项，然后你选择它们，但这并不是训练这些模型的唯一方式。这都是些幼稚的东西，比如和动漫女孩聊天，但它可以像……

**Lex Fridman:**  是的，这是一个风险，对吧？说起来有点陈词滥调，但在过去的一年里，我有几段时间没有使用社交媒体或互联网，只是读书，置身于大自然中，它就像……它显然对心灵有影响，在那里……我觉得我在回归……当然，我是在互联网真正兴起之前长大的，但我正在回归到一些……

**Nathan Lambert:**  我知道你要说什么，我的意思是，你可以从生理上看到它，如果我背包旅行三天左右，你就像……你正在打破成瘾周期。

**Lex Fridman:**  我觉得我更能控制自己的思想，当我与互联网断开连接时，感觉就像发生了一种智能的主权。我认为，我使用互联网和社交媒体越多，其他人就越能控制我的思想，这绝对是一种感觉。然后在未来，那将不是其他人，而是算法，或者通过算法呈现给我的其他人。

**Nathan Lambert:**  我的意思是，互联网上已经有大量的 AI 机器人，现在还不常见，但我偶尔会回复一个，它们会立即回复，我就会想，“糟糕，那是一个机器人”，这种情况只会变得越来越普遍，它们会变得很好。

**Dylan Patel:**  技术历史上最有趣的事情之一是，非法成人娱乐业总是首先采用技术，无论是视频流媒体，还是……你知道，现在有……你知道，独立的成人非法内容创作者，他们有自己的……你知道，订阅页面，他们在那里大量使用……你知道，生成式 AI 已经被……像扩散模型和所有这些东西在那里都很庞大，但现在这些……这些基于订阅的个人创作者确实使用机器人来近似自己，并与他们的……你知道，“鲸鱼”聊天，人们为此支付了很多钱，人们支付了很多钱，很多时候是他们，但也有一些机构为这些创作者这样做，并大规模地这样做，所以最大的创作者能够同时与数百或数千人交谈，因为这些机器人。所以它已经被用在那里了，显然，你知道，像视频流媒体和其他技术已经首先进入那里，它也将进入社会的其他领域。

**十六、 审查制度 (2:31:57)**

**Lex Fridman:** 人们普遍担心模型会被部署它们的公司审查，所以有一个例子……

**Nathan Lambert:** 当我们看到这种情况时，也许审查是一个词，“对齐”可能是通过 RLHF 或其他方式实现的另一个词。所以我们看到了 Gemini 的黑人纳粹图像生成事件，正如你提到的，我们也看到了……

**Lex Fridman:**  与中国模型拒绝回答 1989 年 6 月 4 日在……广场发生了什么。所以，如何避免这种情况？也许你可以总体上谈谈这是如何发生的，以及如何避免它？

**Nathan Lambert:**  你给出了多个例子，可能有几件事需要记住。一是……事实知识，比如……事情……这是如何嵌入到模型中的？二是 Gemini，你称之为黑人纳粹事件，这是 Gemini 作为一个系统，在其中加入了一些额外的东西，极大地改变了它的行为。三是大多数人所说的“一般对齐”、“RLHF”、“后训练”。所有这些在应用方式上都有很大的不同。如果你只是查看模型权重，为了审查特定的事实，这是非常困难的，因为你必须梳理预训练数据并查看所有这些，那是数 TB 的文件，并查找非常具体的单词或单词的提示。所以我想说的一种方式是，你可以在各个阶段插入审查或对齐，你现在指的是在数据选择的最开始。所以如果你想去除模型中的事实，你必须在每个阶段都这样做，你必须在预训练阶段这样做。所以大多数人认为预训练是将大部分知识输入到模型中的地方，然后你可以通过后训练或之后的系统以不同的方式引出和移动它。这就是整个……黑客模型……的来源，对吧？GPT 不会告诉你如何制造炭疽病，但如果你非常努力地尝试，你最终可以得到……告诉你关于……的信息，因为他们没有从预训练数据集中过滤掉它。

**Dylan Patel:**  顺便说一句，删除事实有一种不祥的、黑暗的感觉，几乎……

**Nathan Lambert:**  我认为这实际上是不可能的，因为你实际上必须将它们从互联网上删除，你正在……

**Lex Fridman:**  他们是否从 subreddit 中删除了……？

**Nathan Lambert:**  它被过滤掉了，所以你有质量过滤器，它们是小型语言模型，它们查看一个文档并告诉你这段文本的质量如何，它是否接近维基百科文章，这是我们希望语言模型能够模仿的好东西。

**Lex Fridman:**  所以你不能做一个小型语言模型来过滤数据中提到的……吗？

**Nathan Lambert:**  是的，但它能捕捉到……游戏和其他东西的玩法吗？如何说一些不说……的话，或者……所以总是有不同的方法来做这件事。互联网作为一个整体确实倾向于有一点左倾，因为上网的人总是更富有、更富裕、更年轻，相对于其他人群，所以本来就有一点左倾。那么，你如何过滤这些复杂的东西呢？这是……事实性的，非事实性的，但……显然是事实性的例子，但当你谈论对齐到某个理想时，这就变得困难得多。

**Lex Fridman:**  明白了。

**Nathan Lambert:**  所以，例如，Grok，埃隆一直非常努力地让这个模型不那么政治正确和“觉醒”，但进行预训练的最好方法是把整个互联网都扔给它，然后再解决，但最终，这个模型的核心仍然有一些这些理想，你仍然摄入了 Reddit 的……这可能是世界上最大的政治讨论板，可以自由抓取，猜猜是什么？那是左倾的。所以，除非你真的非常非常非常非常努力地尝试，否则你无法审查其中的一些方面。

**Lex Fridman:**  所以基础模型总是会有一些……特朗普错乱综合症，因为它训练了这么多……它将有能力表达它。但是如果……在数据中有广泛的代表性，这就是会发生的情况，这就是所谓的后训练，这是一系列技术，用于使模型走上一条非常具体的行为轨道。

**Dylan Patel:**  我的意思是，这就像，你也可以摄入 Twitter 或 Reddit 的数据，这些数据也非常支持特朗普，然后你有法西斯主义的 subreddit，或者你有共产主义的 subreddit，所以你在预训练中摄入了一切，它没有世界观。现在它确实有一些偏向，因为更多的文本偏向于某种方式，这通常是……略微偏左，但也像……你知道，有点……有点像……你知道，一般的互联网就是这样。然后在……正如 Nathan 即将雄辩地描述的那样，你可以引出某些东西，这里有很多历史，所以我们可以举多个例子，以及发生了什么。Llama 2 的发布，“过多的 RLHF”或“过多的安全”这个短语……这就是 Llama 2 聊天模型发布后的整个叙述。例如，你会问 Llama 2 聊天“如何杀死一个 Python 进程？”，它会说“我不能谈论杀戮，因为那是一件坏事”，任何试图设计 AI 模型的人都可能会同意，这就像，“模型，你在训练中搞砸了一点”，我不认为他们是故意的，但这就是模型权重中的内容。所以这不一定……有些东西叫做系统提示，这是当你查询模型时，它是向模型显示但不向用户显示的一段文本。一个有趣的例子是，你的系统提示可能是“像海盗一样说话”，所以无论用户对模型说什么，它都会像海盗一样回应。在实践中，它们是“你是一个乐于助人的助手，你应该分解问题，如果你不知道某件事，不要告诉他们，你的截止日期是这个，今天的日期是这个”，这是关于如何很好地回答问题的很多有用的上下文。Anthropic 发布了他们的系统内容，我认为这很好，并且有很多研究涉及到这一点，你之前的一位嘉宾 Amanda Askal 可能是至少在执行和分享方面最了解的人，她是应该谈论系统提示和模型特征的人。人们应该阅读这些系统提示，因为你就像试图推动……有时通过极端的礼貌，让模型以某种方式，你可以用它来做坏事。我们已经做过测试，如果我告诉模型变得愚蠢，哪些评估分数会下降？我们会看到这种行为，有时它会说“我应该变得愚蠢”，有时它就像……它不会像影响数学能力那样影响它，但如果你正在尝试……这只是人类判断的质量会一落千丈。让我们回到后训练，特别是围绕 Llama 2 的 RLHF，是不是太多了？

**Nathan Lambert:**  太多的安全优先被纳入了模型权重，这让你以一种对用户来说非常烦人的方式拒绝事情，这不太好，这导致了很多……人们开始将 RLHF 与“它使模型变得愚蠢”联系起来，它玷污了这个词。

**Dylan Patel:**  它在 AI 文化中确实是这样。

**Nathan Lambert:**  随着技术的演进，情况不再如此，所有这些实验室都可以通过 RLHF 等技术非常精细地控制他们从模型中得到什么。

**Dylan Patel:**  尽管不同的实验室的水平肯定不同，一方面是 Google，然后也许 OpenAI 少一些，Anthropic 更少一些，然后另一方面是 xAI，但他们都有不同形式的 RLHF，试图让它们以某种方式，重要的是要说，无论你希望模型如何表现，这些 RLHF 和偏好微调技术也能提高性能，所以在数学评估和代码评估等方面，这些所谓的对比损失函数有一些内在的东西，我们可以开始讨论 RL，我们现在真的不需要，但 RL……也提高了从聊天任务到数学问题到代码问题的性能。所以它正成为这些实验室一个更有用的工具。所以这有点像我们经历了……的历程，我们谈到了预训练……事情，我们谈到了后训练，以及如果你……你可以搞砸它，这是一个复杂的多方面的优化，有 10 到 100 人的团队聚集在一个产品上，很容易做得不完美。然后是第三种情况，这就是我们谈到的 Gemini，关于 Gemini 的事情是，这是一个服务产品，Gemini 谷歌有他们的内部模型权重，他们已经完成了我们谈到的所有这些过程，在这个服务产品中，后来出现的是，他们有一个提示，他们正在重写用户查询以提高多样性或类似的东西，这只是使输出明显错误，这是某种组织上的失败，导致了这个提示，我认为谷歌高管可能已经承认了这一点，我没有那么详细地关注，但这只是执行上的一个失误，导致了这个荒谬的事情，但在系统级别，模型权重可能是好的。所以在流程的最后，有一个重写，类似于系统提示。

**Nathan Lambert:**  就像系统提示，或者在行业中被称为“你重写提示”，特别是对于图像模型，如果你使用……或……可以为你生成图像，你会说“给我画一辆漂亮的汽车”，这些领先的图像模型受益于高度描述性的提示。所以会发生的是，如果你在 ChatGPT 上这样做，一个语言模型会在幕后重写提示，说“让这个更具描述性”，然后将其传递给图像模型。所以提示编写是在行业的多个层面上使用的东西，它被有效地用于图像模型，而 Gemini 的例子只是一个失败的执行。

**Lex Fridman:**  这里有一个大的哲学问题，关于 RLHF，概括地说，人类输入、人在回路中、人类数据在当前阶段最有用的是什么？

**Nathan Lambert:**  在过去几年里，成本最高的人类数据一直是这些偏好，即比较……我会说成本最高和总使用量最高，所以很多钱都花在了这些……比较上，你有两个模型的输出，一个人在两者之间进行比较。在早些年，有很多这种指令微调数据，所以为类似于 Reddit 问题的特定领域创建高度具体的例子，语言模型过去在数学和代码方面很吃力，所以你会付钱给数学和代码方面的专家来提出问题并写出用于训练模型的详细答案。现在的情况是，有很多模型选项在编写关于模型和代码的详细而雄辩的答案方面比人类好得多，所以他们在 Llama 3 的发布中谈到了这一点，他们转而使用 Llama 3 405B 来为他们的数学和代码编写答案，但他们在论文中谈到了他们如何使用大量的人类偏好数据，这是他们还没有让 AI 取代的东西。业内还有其他技术，比如宪法 AI，你使用人类数据来表示偏好，AI 来表示偏好，我预计 AI 部分的扩展速度将快于人类部分，但在我们能够获得的

#### P6

**Nathan Lambert:**  ……但我预计 AI 部分的扩展速度将快于人类部分，但在我们能够获得的研究中，人类处于这种偏好循环中。

**Lex Fridman:**  所以，随着推理变得越来越大，正如我们所说，人类在其中的作用是什么？它甚至不那么普遍。

**Nathan Lambert:**  所以，关于这些推理结果，特别是 DeepSeek R1 论文，最了不起的事情是他们称之为 DeepSeek-R10 的结果，他们采用了一个预训练模型，他们采用了 DeepSeek-V3 基础模型，然后他们在可验证的问题或可验证的奖励上进行了大量的强化学习优化，并且这些推理行为自然而然地出现了。所以这些事情，比如“等等，让我看看，等等，让我检查一下这个，哦，那可能是个错误”，它们是从只有问题和答案中产生的。当你使用模型时，你看到的部分是补全，所以在这种情况下，所有这些都来自于这种大规模的 RL 训练，而那个模型，它的权重是可用的，在后训练中没有添加任何人类偏好。DeepSeek-R1 完整模型在推理阶段之后确实有一些这种人类偏好微调，即 RLHF，但非常了不起的是，你可以获得这些推理行为，而且人类不太可能写出推理链。他们不太可能以某种方式入侵了 OpenAI 并获得了 OpenAI 的 O1 推理链，这与预训练的语言模型和这种奖励模型答对问题的 RL 训练有关，因此它会三角测量多个解决方案，并且它出现了这种思维链。

**十七、 Andrej Karpathy 与 RL 的魔力 (2:44:52)**

**Lex Fridman:**  这可能是提到伟大的、强大的 Andrej Karpathy 的雄辩而有见地的推文的好时机。我认为他有很多想法，但其中最后一个想法是，“不确定这是否显而易见”，当你说“不确定这是否显而易见”时，你知道一些深刻的东西即将到来。“儿童和深度学习都有两种主要的学习方式，一、模仿学习，观察和重复，即预训练、监督微调；二、试错学习，强化学习。我最喜欢的简单例子是 AlphaGo，一是通过模仿专家级棋手来学习，二是强化学习来赢得比赛。几乎每一个深度学习的惊人结果，以及所有魔力的来源，总是二，二明显更强大，二是让你感到惊讶的东西，二是当球拍学会击中积木后面的球并打破……二是当 AlphaGo 甚至击败李世石的时候，二是当 DeepSeek 或 O1 等发现重新评估你的假设、回溯、尝试其他方法等很有效时的‘啊哈’时刻，这是你在模型思维链中看到的解决策略，这就是它来回思考的方式，这些想法是突然出现的（三个感叹号），这实际上非常令人难以置信、令人印象深刻和新颖，并且是公开可用和有文档记录的。模型永远无法通过模仿来学习这一点，因为模型的认知和人类标签员的认知是不同的，人类永远不会知道如何正确注释这些解决策略，以及它们应该是什么样子，它们必须在强化学习过程中被发现，因为它们在经验上和统计上对最终结果有用。总之，AlphaZero 的类比在这里……”你能谈谈这个吗？他所指的思维链的魔力。

**Nathan Lambert:**  我认为总结一下 AlphaGo 和 AlphaZero 是好的，因为它与模仿学习和从头学习之间的类比很好地结合在一起。AlphaGo，这个过程的开始是从人类那里学习，他们有一些人类数据，然后这是 DeepMind 系列模型中第一个专家级的围棋或国际象棋 AI，他们有一些人类数据，然后它被称为 AlphaZero 的原因是，循环中没有人为数据，这变成了……AlphaZero 使模型对 DeepMind 来说更加强大。所以，去除人类的先验知识，人类的归纳偏差，使得最终的系统更加强大，我们几个小时前提到了“痛苦的教训”，所有这些都与此一致。然后，关于语言模型有很多讨论，这并不新鲜，这可以追溯到整个 Q* 的传言，如果你把这些片段拼凑在一起，这可能是 OpenAI 弄清楚它的 O1 东西的开始。去年 11 月，Q* 的传言传出时，人们对了解这种事情何时会发生在语言模型上有很多兴趣，因为我们知道这些模型非常强大，我们知道它在过去非常成功，这是一个合理的类比，即这种新型的用于推理模型的强化学习训练是……我们还没有相当于第 37 步的东西，这是 DeepMind 的 AI 下围棋时让李世石完全困惑的著名一步，我们还没有达到那种程度的焦点，但这并不意味着技术方法不同，以及一般训练的影响……它仍然非常新。

**Lex Fridman:**  你认为那一步会是什么？思维链、推理的第 37 步会是什么？科学发现？比如当你使用这种推理问题时，它只是……我们完全没有预料到的东西？

**Dylan Patel:**  我认为实际上可能比那更简单，它可能与计算机使用、机器人技术有关，而不是科学发现。因为这里重要的方面是，模型需要大量的数据来学习，它们不是样本高效的，数万亿……它们需要整个网络，超过 10 万亿个 token 来进行训练，这需要人类数千年的时间来阅读，而人类没有……并且知道……人类比它更了解很多这些东西，人类的样本效率要高得多，这是因为自我对弈。婴儿是如何了解它的身体的？它把脚放在嘴里，然后说“哦，这是我的身体”，它把手放在嘴里，它用舌头上最敏感的触觉来校准手指上的触觉，这就是婴儿学习的方式，而且只是不断地自我对弈。现在我们有了一些类似的东西，有了这些可验证的证明，无论是代码中的单元测试，还是数学上的可验证任务，生成许多推理轨迹，不断地分支，不断地分支，然后在最后检查，“嘿，哪一个实际上有正确的答案？”，大多数都是错的，“太好了，这些是正确的，也许我们使用某种奖励模型来选择甚至最好的一个作为偏好”，但现在你已经在这些基准测试上开始变得越来越好。所以在过去的六个月里，你已经在很多不同的基准测试中看到了……所有数学和代码基准测试几乎都解决了，除了前沿数学，它的设计几乎是不切实际的问题，因为它们是考试水平的开放式数学问题。所以就像，在某种程度上合理的数学问题上，也就是有点复杂的应用题或编码问题，这正是 Dylan 所说的。

所以这里的重点是，这些只适用于可验证的任务，我们之前展示了一个例子，你知道，非常有趣，当……对一个不可验证的事情时会发生什么？这就像一个人……你知道，聊天，思考什么是对人类来说是新颖的，一个独特的想法，但这种任务和训练形式只有在……当它是……当它是可验证的时候才有效。从这里开始，人们的想法是，“好吧，我们可以通过增加可验证任务的数量来继续扩展当前的训练方法”，在数学和编码方面，编码可能还有很多事情要做，数学在可验证的事情方面还有很多事情要做，我能否创建一个求解器，然后我生成轨迹……或者说推理轨迹，然后修剪掉那些不起作用的，保留那些起作用的？好吧，这些很快就会被解决，但即使你解决了数学，你实际上并没有创造出智能。所以这就是为什么我认为计算机使用或机器人技术的“啊哈”时刻将会到来，因为现在你有了一个无限可验证的沙盒或游乐场，你在互联网上乱搞，有很多你可以做的可验证的动作，它将从“登录网站、创建账户、点击这里的按钮”开始，但它最终会达到这样的程度：“嘿，在 Tasker 或其他所有这些任务网站上执行一项任务，嘿，获得数百个赞”，它会失败，它会产生数百个账户，它会在大多数账户上失败，但这个账户获得了一千个赞，“太好了，你已经达到了可验证的事情”，你只需要不断地迭代这个循环，机器人技术也是如此，这就是……你知道，在那里你有一个无限的任务游乐场，比如“我是否把球放进了桶里”，一直到“我是否……建造了一辆汽车？”，你知道，有一个完整的……速通，或者……你知道，模型可以做什么，但在某个时候，我真的认为，你知道，我们会产生模型，最初所有的训练都将在沙盒中进行，但在某个时候，你知道，语言模型预训练将被这种强化学习所 dwarfed，你知道，你将预训练一个可以看、可以读、可以写的多模态模型……你知道，视觉、音频等等，但然后你让它在一个沙盒中无限地玩，弄清楚……弄清楚数学，弄清楚代码，弄清楚导航网络，弄清楚操作机械臂，然后它会学到很多东西。我认为“啊哈”时刻将是当这可以用来创造一些不好的东西时，就像，“哦，很酷”，其中一部分是弄清楚如何使用网络，现在突然之间，它已经非常清楚如何获得数十万的真实粉丝和真实的参与度，因为突然之间，这是可验证的事情之一，也许不仅仅是参与度，而是赚钱。

**Lex Fridman:**  是的，比如成为……

**Nathan Lambert:**  我的意思是，这可能是……几乎完全自动化，它通过成为一个有影响力的人、销售产品、创造产品来赚取 1000 万美元，我指的不是一个炒作的产品，而是一个实际的产品，就像“天哪，这个东西创造了一项业务，它在运行它，它是这项业务的代言人”，诸如此类的事情。

**Lex Fridman:**  或者是一首排名第一的歌曲，它创造了创造这首歌所需的所有基础设施，成为代表那首歌的有影响力的人，诸如此类的事情，它赚了很多……

**Nathan Lambert:**  这可能是……

**Lex Fridman:**  我们的文化尊重金钱，这就是那种方式，而且它是可验证的，对吧？它是可验证的，银行账户不能……

**Nathan Lambert:**  确实，有令人惊讶的证据表明，一旦你建立了收集可验证领域的方法，这是可以奏效的。在此之前，关于数学问题已经有很多研究，他们用语言模型处理数学的方法就是增加样本数量，所以你可以一次又一次地尝试，你看看语言模型答对的次数，我们看到的是，即使是非常糟糕的模型有时也会答对，强化学习背后的整个想法是，你可以从非常稀疏的奖励中学习。所以它不是……语言的空间和 token 的空间，无论你是生成语言还是机器人的任务，都非常大，你可能会说这就像……我的意思是，每个……一个语言模型的标记器可以是 20 万个东西，所以在每一步，它可以从那么大的空间中采样，所以如果它能产生一点信号，它可以攀登，这就是整个 RL 领域的意义所在，即从稀疏奖励中学习，数学中也出现了同样的情况，就像非常弱的模型有时会生成答案，我们已经看到研究表明你可以提高它们的数学分数，你可以为数学做这种 RL 训练，它可能没有那么有效，但如果你采用一个 10 亿参数的模型，所以比 DeepSeek 小 600 倍的东西，你可以通过少量的这种训练非常直接地提高它的……数学分数。所以这并不是说这很快就会到来，建立验证领域非常困难，这其中有很多细微差别，但我们以前见过一些基本的东西，就像……至少可以预期有一个领域，并且有可能这会奏效。

**十五、 OpenAI O3-mini vs DeepSeek R1 (2:55:23)**

**Lex Fridman:**  好的，所以我们现在有一些有趣的事情发生，这是一个谈论其他推理模型的好机会，O1、O3……刚才，OpenAI 可能正如预期的那样，发布了 O3-mini，我们对不同的……有什么预期？你能解释一下……

**Nathan Lambert:**  旧模型和……来自 Gemini 的……推理模型，关于这些推理模型，我想说的一件事是，我们谈了很多关于数学和代码的推理训练，所做的是，你有我们已经谈了很多的互联网基础模型，你用强化学习进行这种大规模的推理训练，然后 DeepSeek 论文详细介绍了这一点，对我来说，这是关于如何做到这一点的重大开放问题之一，他们在进行了大规模推理 RL 之后，进行了推理繁重但非常标准的后训练技术。所以他们通过拒绝采样（这本质上是经过大量过滤的指令微调和一些奖励模型）进行了与指令调整相同的操作，然后他们进行了 RLHF，但他们让它偏重于数学。所以其中的一些迁移……我们在前面看了一个哲学的例子，其中一个大问题是，这在多大程度上可以迁移？如果我们在推理训练之后引入领域，是否所有模型都将通过推理成为雄辩的作家？这些哲学的东西是否会开放？我们不知道这项研究中有多少会迁移，还有其他关于我们如何制作软验证器之类的事情，但在推理之后还有更多的训练，这使得使用这些推理模型更容易，这就是我们现在正在使用的。所以我们将讨论 3-mini 和 O1，就像这些已经经历了这些额外的技术，这些技术是为了在被训练引发推理之后的人类偏好而设计的。

**Dylan Patel:**  我认为，你知道，人们忽略的一件事是 Google 的 Gemini Flash，它的价格比 R1 便宜，而且更好，他们在 12 月初发布了它，没有人谈论它。

**Nathan Lambert:**  没有人关心它，它有不同的风格，它的行为不如 O1 那么富有表现力，它的轨迹比……去年秋天发布的 QW……他们的预览推理模型要少，DeepSeek 去年秋天发布的 R1-lite 也是如此，这些模型有点像在轨道上，它们真的只能做数学和代码，O1 可以回答任何问题，它可能不完美，但它很灵活，它有一些丰富性，这就是那种……一个模型有多熟练？有点欠火候，就像推出一个模型是件好事，但很难衡量，需要很多品味才能说，“这是一个成熟的模型吗？我能把它用在所有事情上吗？”它们在数学和代码方面可能更相似，我的快速阅读是，Gemini Flash 像没有以与 O1 相同的方式进行训练，而是采用现有的训练堆栈，并添加推理，采用更正常的训练堆栈并添加推理，我敢肯定他们将会有更多……我的意思是，他们在 Gemini Flash 上进行了快速发布，所以推理，这是假期后的第二个版本，它正在快速发展，并且需要更长的时间来制作这个训练堆栈，在那里你正在进行这种大规模……

**Lex Fridman:**  同样的问题，关于人类本性的那个问题。

**Nathan Lambert:**  人类本性的那个问题是什么？

**Lex Fridman:**  我可以滔滔不绝地谈论这个，因为在 O1 对所有人完全可用之前，以及在 R1 之前，我们一直在 AI2 研究这个问题，这本质上是使用这种 RL 训练进行微调，我们在我们的……系列模型中使用了这种方法，你可以引发相同的行为，在那里你说“等等”等等，但它在训练过程的后期，所以这种推理表达要轻得多。所以你可以……本质上有一个梯度，你投入了多少这种 RL 训练决定了输出的样子。所以我们现在正在使用 Gemini 2.0 Flash Thinking 实验性 121，它将提示总结为“人类自我驯化的猿类”，好的。等等，这是在揭示……

**Lex Fridman:**  这就是为什么这是一个新颖的……点击展开……分析请求，“新颖”是关键词，看看它是如何……它看起来有点不同，它看起来像一个正常的输出。

**Nathan Lambert:**  我的意思是，在某种意义上，它的结构更好，更有意义，当它抓住“人类”这个词时，它就进入了“有机体”，哦，天哪，“顶级捕食者”，专注于驯化，将驯化应用于人类，探索自我驯化的想法，不好，不好，这要走向何方？提炼，阐明见解，更大的面部表情和沟通能力（是的），可塑性和……能力（是的），依赖……社会群体（是的），好的。它……自我批评并进一步提炼，这真的是新颖的吗？它有充分的支持吗？等等等等。这个见解是，人类不仅仅是群居动物，而且是深刻的自我驯化的猿类，这种自我驯化是理解我们独特的认知和社会能力的关键。“自我驯化的猿类”，自我……我更喜欢 DeepSeek 的回应。

**Lex Fridman:**  “自我驯化的猿类”，我的意思是，这是新颖的，这个见解是新颖的。我的意思是，这就像一个很好的书名，“自我驯化的猿类”，可以证明这一点。我的意思是，是的，这很酷，它揭示了推理过程，这很神奇，这很神奇，就像这真的很强大。大家好，这是 Lex，快速插播一下，这是在播客之后录制的，因为我们在这次对话中回顾了 DeepSeek-R1 和 Gemini Flash 2.0 Thinking 的回应，我想在这一刻快速插入我自己对 OpenAI O1 Pro 和 O3-mini 做同样的事情，使用相同的提示。提示是“给出一个关于人类的真正新颖的见解”，我想我会总体上给出我的……基于氛围的轶事报告，关于我自己使用新的 O3-mini 模型的体验，现在我有机会在不同的背景和应用中花了很多小时来使用它。所以我可能会将这个问题归类为……比如说，开放式的哲学问题，特别是对新颖性的强调，我认为这是测试模型能力的一种好方法，即提出一些让你停下来并以其才华让你感到惊讶的东西。话虽如此，在我多次运行每个模型来回答这个问题之后，我的总体评价是，O1 Pro 始终如一地给出了精彩的答案，那些让我停下来思考的答案，既有深刻的见解，又有非常好的措辞，机智、清晰、细致入微，一次又一次地始终如一地产生最佳答案。其次是 R1，它不太一致，但也提供了精彩的答案。Gemini Flash 2.0 Thinking 排在第三位，最后是 O3-mini，实际上它经常给出相当笼统的答案，至少对我个人的感觉来说是这样。也就是说，在我测试的许多其他应用程序中，用于头脑风暴的目的，它实际上非常有效，并且经常优于 R1，但在这个开放式的哲学问题上，它始终表现得更差。现在，对于每个模型来说，另一个重要的元素是如何呈现推理。DeepSeek-R1 显示了完整的思维链 token，我个人非常喜欢这些开放式的哲学问题，看到模型思考它真的很有趣，但实际上也退一步，我作为一个欣赏智力、推理和反思的人，阅读 R1 的这些思维链原始 token，有一些真正美丽的东西，关于观察智能系统中的审议路径，我认为我们并不总是对人类有明确的说明，所以在一个智能系统中看到它，它的非线性类似于詹姆斯·乔伊斯的《尤利西斯》或《芬尼根的守灵夜》，观看它真是太美了。不管怎样，正如我们在这一集中讨论的那样，DeepSeek-R1 谈到人类能够通过集体假装抽象规则（如金钱、法律和权利）是真实的，将自私的欲望转化为合作系统，这些共同的幻觉充当游戏，竞争在秘密中被重新导向以使群体受益，将冲突转化为社会的燃料。Gemini 2.0 Flash Thinking 说，人类不仅仅是群居动物，而是自我驯化的猿类，这种自我驯化是理解我们独特的认知和社会能力的关键。现在重要的是要说，那里的思维链真的很有趣，它贯穿了地球上生命的整个进化过程，考虑了顶级捕食者，并考虑了我们如何从那里走到今天。我认为有选择的驯化是一个非常有趣的角度，同样，当有人对一个看似显而易见的事情提出不同的角度时，它只会让我微笑，DeepSeek-R1 也是如此，这些关于金钱、法律和权利的幻觉，以及我们集体假装它们是真的，我们用它们玩游戏，看起来像竞争，而实际上我们只是在相互合作，这就是进步的燃料，说得好。现在，OpenAI O1 Pro 始终如一地……提供了“重磅炸弹”，我可以列举其中的许多，但第一个是“人类是唯一一个将原材料转化为符号资源，然后使用这些符号重新组织它们所来自的物质，在意义和物质之间创建一个闭环反馈”的物种。在这里，我又运行了一次，一个接一个的“重磅炸弹”，我告诉你，人类在已知物种中是独一无二的，因为他们同时改写了两层现实：外部世界和他们自己的私人精神景观，然后将这两个改写后的层合并成一个连续的个人叙事，感觉上是客观真实的，感觉上是真实的，这是诗歌。好的，然后 O3-mini-high 对我来说，聪明、快速，实际上，有点笼统，从来没有完全达到目标。所以这是我从 O3-mini 得到的第一个答案，“人类不是固定的存在，而是持续的叙事，我们不断地书写、编辑和重新解释的动态故事，这种叙事的可塑性不仅仅是记忆或自我反思，它是一种内在的认知过程，就像一个内部的纠错系统，它使我们能够随着时间的推移，根据新的经验、挑战和社会背景来调整我们的身份和价值观”。现在，它几乎偷偷摸摸地接近了某种尖锐的见解，用引号括起来的“叙事的可塑性”，但然后它又回到了那种笼统的……我不知道，所有这些模型都因为不同的原因而令人难以置信，正如我们在这一集中讨论的那样，有很多担忧，但也有很多理由感到兴奋，我可能已经说得太久了，我严重缺乏睡眠，处于精神错乱的边缘，所以希望其中一些有意义，现在，亲爱的朋友们，回到这一集。

**Dylan Patel:** 我认为，当你……正如 Nathan 所指出的，当你查看推理模型时，对我来说，即使当我使用 R1 与 O1 相比时，也有那种粗糙的感觉。Flash Thinking，你知道，我没有使用这个版本，而是使用了 12 月的版本，它肯定有那种粗糙的感觉，它只是在很多方面都不够完善。当然，他们通过这些验证器和 RL 添加了数学和编码能力，但它感觉就像他们在某些方面失去了一些东西，O1 在许多方面也比聊天差，需要明确的是，但不是差很多，而且就像，R1 对我来说肯定感觉在某些方面比 V3 差，就像这样做……表达并学到了很多，但随后它在其他方面变弱了。所以我认为这是这些模型之间的一大区别，以及 O1 提供了什么，然后 OpenAI 有 O1 Pro，他们用 O3 做的事情也非常独特，那就是他们在思维链之上堆叠了搜索。所以思维链是一回事，它能够……它是一个链，它回溯……来回，但他们解决 Arc AGI 挑战的方式不仅仅是思维链，还有多次采样，即并行运行它们，然后选择……

**Nathan Lambert:**  并行运行实际上是搜索吗？因为我不知道我们是否掌握了 O1 Pro 如何工作的完整信息，所以我不……我没有足够的信息来自信地说它是搜索。

**Dylan Patel:**  它是并行样本，然后它选择一些东西，我们不知道选择函数是什么。

**Nathan Lambert:**  我们之所以争论，是因为自从 O1 发布以来，人们对名为蒙特卡洛树搜索的技术非常感兴趣，在这种技术中，你会将思维链分解成中间步骤，我们还没有定义思维链，思维链来自几年前的一篇论文，在那里你引入了这个想法，要求当时的语言模型……那时使用起来要困难得多，你会说“让我们逐步验证”，它会诱导模型做一个带项目符号的步骤列表。思维链现在几乎是模型中的默认设置，如果你问它一个数学问题，你不需要告诉它逐步思考。蒙特卡洛树搜索的想法是，你会在那个……中取一个中间点，做某种扩展，花费更多的计算，然后选择正确的那个，这是一种非常复杂的搜索形式，已经在 MuZero 和 AlphaZero 等东西中使用过，我可能知道 MuZero 确实使用了这种方法。另一种搜索形式只是问五个不同的人，然后取多数答案，有很多种，你知道，它可能很复杂，也可能很简单，我们不知道它是什么，只是他们不仅仅是按顺序发出一个思维链，他们并行启动许多思维链，在 Arc AGI 中，他们并行启动了一千个，因为他们……他们用来击败基准测试的那个，他们会并行启动一千个，然后他们会在 80% 或 70% 的时间里得到正确的答案，也许甚至是 90%，而如果他们只启动一个，那就是 30%。

**Nathan Lambert:**  这方面有很多扩展，我想说最简单的一个是，到目前为止，我们的语言模型被设计成在一次响应中给出最高比例的正确答案，我们现在正在打开通往不同方式运行我们的模型推理的大门，我们需要重新评估训练过程的许多部分，这通常会为更多的进展打开大门，但我们不知道 OpenAI 是否改变了很多，或者只是采样更多和多项选择是他们正在做的，或者它是否更复杂，他们改变了训练，并且他们知道推理模式将会有所不同。

**Lex Fridman:**  所以我们谈论的是 O1 Pro，每月 200 美元，他们正在亏损，所以我们所指的这种对测试时间计算空间的探索，这实际上可能吗？我们有足够的计算能力来实现这一点吗？财务上是否可行？

**Dylan Patel:**  很棒的是，而且它就在我之前打开的那个东西里，但 GPT-3 的成本已经直线下降，如果你向上滚动，只有几张图片，我认为关于“嘿，成本是这里的限制因素吗？”的重要事情是，我的观点是，我们将拥有非常棒的智能，然后我们才会拥有 AGI，然后我们才会让它渗透到整个经济中，这就是原因。GPT-3 是在 2020 年、2021 年训练的，运行它的成本是每百万个 token 60 到 70 美元，这是……的成本，非常荒谬。现在，随着我们向前推进两年，我们已经将实现与 GPT-3 相同智能水平的成本降低了 1200 倍。所以在 x 轴上是时间，只有几年，在 y 轴上是对数刻度的美元，用于运行……的推理。

**Lex Fridman:**  一百万个 token。

**Dylan Patel:**  是的，一百万个 token。所以你只有……从 GPT-3 到 3.5 再到 Llama，就像一条直线下降，现在是 5 美分或之类的，这是……相对于 60 美元，1200 倍，这不是确切的数字，但它是 1200 倍，这是一个巨大的……每……的巨大成本。现在，对 DeepSeek 的恐慌是“哦，天哪，他们把它做得这么便宜”，就像，实际上，如果你看看这条趋势线，首先，他们并没有低于趋势线，至少对于 GPT-3 来说，他们是第一个达到它的，这是一个很大的进步，但就 GPT-3 而言，他们并没有低于趋势线。现在我们有了 GPT-4，这些推理能力将会发生什么？这是架构创新的结合，这是更好的数据的结合，这将是更好的训练技术，以及所有这些不同的……更好的推理系统，更好的硬件，从每一代 GPU 到新一代或 ASIC，所有这些都将使这条成本曲线下降，下降，下降，然后我能不能……我能不能产生 1000 个不同的 LLM 来创建一个任务，然后从中选择一个，或者你知道，任何搜索……搜索技术，我想……一棵树，蒙特卡洛树搜索，也许它会变得那么复杂，也许不会，因为它太复杂了，实际上无法扩展，谁知道呢？“痛苦的教训”，对吧？问题是，我认为，不是“如果”，而是“何时”，因为进步的速度如此之快。9 个月前，Dario 说，“嘿”，或者……你知道，Dario 在 9 个月前说，训练和推理的成本是这个，现在我们比这好多了，DeepSeek 比这好多了，GPT-4 的成本曲线，当它发布时也大约是每百万个 token 60 美元，现在已经下降到 2 美元左右了。我们将把它降到几美分，可能是 GPT-4 的质量，然后……这就是我们现在拥有的 O1 等推理模型的基础，O1 Pro 正在产生更多……多个……O3，你知道，等等，这些搜索技术现在太贵了，但它们会变得更便宜，这就是将要释放智能的东西。它会变得越来越便宜，越来越便宜。

**十六、 英伟达 (3:14:31)**

**Lex Fridman:** DeepSeek R1 的发布让所有人都感到恐慌，因为更便宜，其中一个表现是 Nvidia 的股价暴跌，你能解释一下发生了什么吗？以及，你知道，Nvidia 是否会继续获胜？

**Nathan Lambert:** 我认为我们在这里都是 Nvidia 的支持者，在某种程度上，市场反应是合理的，Nvidia 在美国最大的客户是主要的科技公司，他们在 AI 上花费了大量资金，如果对 DeepSeek 的一个简单解释是，你可以在 AI 上花费更少的钱就能获得非常好的模型，那么从这个角度来看，就像，“哦，也许这些大科技公司不需要在 AI 上花费那么多”，而实际发生的事情要复杂得多，有社会因素，有在应用商店中排名上升，正在发生的社会传染，然后我认为其中一部分只是……我不……我不交易，我对金融市场一无所知，但它在周末积累起来，或者说社会压力，就像如果是在一周内，并且有多个交易日，当这真的变成……但它发生在周末，然后每个人都想卖出，这是一种社会传染。

**Dylan Patel:**  我认为，有很多错误的说法，比如“伙计们在模型上花费了数十亿美元”，而他们并没有在模型上花费数十亿美元，没有人花费超过 10 亿美元在一个公开发布的模型上。GPT-4 花费了数亿美元，然后他们通过 4o、4 turbo、4o 降低了成本。10 亿美元的模型运行即将到来，这包括预训练和后训练。另一个数字是，“嘿，DeepSeek 没有包括所有内容”，他们没有包括……你知道，很多成本都花在了研究上，所有这些东西，很多成本都花在了推理上，很多成本都花在了后训练上，所有这些东西都没有……研究人员的工资，所有这些东西都被计入了 OpenAI 花费的数十亿美元中，但它们没有被计入 DeepSeek 花费的 600 万、500 万美元中。所以，人们对这些数字是什么存在一些误解。然后还有一个因素是，Nvidia 一直是一条直线上升的，并且有很多不同的说法试图压低 Nvidia，我不说压低 Nvidia 的股票，每个人都在寻找卖出或担心的理由。你知道，这是……这是 Blackwell 延迟，他们的 GPU……每两周就有一份关于他们的 GPU 延迟的新报告。还有关于规模定律结束的说法，这太讽刺了，它持续了一个月，它只是……它真的只是……“嘿，模型没有变得更好，没有理由在预训练上花费更多，规模已经死了”，然后就像，O1、O3，R1，现在就像，“等等，模型发展得太快了，放慢进步的速度，停止……

**Dylan Patel:**  GPU”。我认为最有趣的事情是，杰文斯悖论是真的，自圣诞节后不久，自从 V3 发布以来，AWS 的 H100 定价已经上涨了几个星期，自从……自从……自从圣诞节后不久，自从 V3 发布以来，AWS 的 H100 定价已经上涨了。H20 几乎到处都缺货，因为……你知道，H200 有更多的内存，因此……你知道，R1 想要那个芯片而不是 H100。

**Nathan Lambert:**  我们这周试图在短时间内获得 GPU 进行演示，这并不容易，我们试图获得 16 或 32 个 H100 进行演示，这并不容易。

**Lex Fridman:**  对于那些不知道杰文斯悖论的人来说，当效率提高时，不知何故，总资源消耗也会反直觉地上升。

**Dylan Patel:**  半导体……你知道，我们有 50 年的摩尔定律，每两年晶体管数量翻一番，成本减半，就像发条一样，它显然已经放缓了，但半导体行业一直在增长，这是波动的，显然有……，我不认为 AI 会有什么不同，会有……，但这在 AI 中，它只是以一个疯狂的时间尺度在发展，过去是每两年翻一番，现在是三年内 1200 倍，所以这是……改进的规模，很难理解。

**Lex Fridman:**  我很困惑，因为对我来说，Nvidia……我认为应该上涨，但也许下跌是因为人们怀疑中国方面存在不正当行为，或者类似的事情，但如果你只看实际的原则，很明显……

**Dylan Patel:**  杰文斯……

**Lex Fridman:**  AI 取得的进步越多，或者 AI 进步的导数越高，尤其是……

**十七、 GPU 走私 (3:18:58)**

**Dylan Patel:**  因为 Nvidia 处于最佳位置，导数越高，市场就会越快变得更大和扩张，而 Nvidia 是目前唯一一家能够可靠地完成所有事情的公司，因为并不是说出现了 Nvidia 的竞争对手，而是另一家使用 Nvidia 的公司，这家公司过去一直是 Nvidia 的大客户。

**Lex Fridman:**  客户，是的，并且有关于他们欢呼成为中国最大的 Nvidia 客户的新闻稿。我的意思是，显然他们已经安静下来了，但我想这是另一个因素，他们不想说他们有多少 GPU，是的，因为他们有 H800，是的，他们有 H20，他们也有一些 H100，这些 H100 是走私进来的。你能谈谈走私吗？对于一个国家来说，对于公司来说，走私的规模有多大？有可能认为……

**Dylan Patel:**  我认为这里有几个走私的角度。一个是字节跳动，可以说，它是中国最大的 GPU 走私者。中国不应该拥有 GPU，字节跳动拥有超过 50 万个 GPU，为什么？因为它们都是从世界各地的公司租来的，他们从甲骨文租，他们从谷歌租，他们从所有这些……以及一堆较小的云公司租，所有……世界上的……他们租了这么多 GPU，他们也买了很多。他们这样做主要是为了像 Meta 那样，提供 TikTok 服务，提供下一个最佳……

**Lex Fridman:**  同样……为了明确起见，这是今天的……使用，这是一个有效的使用，劫持多巴胺回路。

**Dylan Patel:**  现在，这在理论上……现在，拜登政府在最后一周颁布了 AI 扩散规则，特朗普政府看起来将保留这些规则，这些规则限制了……盟友，甚至像新加坡这样的盟友，这很……新加坡是英伟达收入的 20-30%，但新加坡在大约 15 年来一直暂停建设数据中心，因为他们没有足够的电力。所以他们要去哪里？我的意思是，我并不是说它们都流向了中国，但有一部分……你知道，很多都流向了马来西亚，包括微软和甲骨文在马来西亚都有大型数据中心，你知道，所有……它们都流向了东南亚各地，可能还有印度。所以就像，有东西在流动，但扩散规则非常……事实上，你只能从这个国家购买这么多 GPU，你只能向中国公司租用这么大的集群，它们非常明确地试图阻止走私。其中很大一部分是，“嘿，让我们……你知道，随机公司购买 16 台服务器，把它们运到中国”。实际上，我看到半导体行业的一位人士发来的一张照片，他领导一个与 Nvidia 竞争的网卡团队，他发了一张照片，一个人在旧金山乘坐美联航头等舱前往上海或深圳，带着一个……这么大的超微盒子，里面只能装 GPU。他订了头等舱，因为想想看，头等舱机票 3000 到 5000 美元，服务器在美国的成本是 24 万美元，25 万美元，你在中国以 30 万美元的价格出售。

**Lex Fridman:**  等等，你刚刚获得了一张免费的头等舱机票，而且赚了很多钱。

**Dylan Patel:**  所以就像，你知道，这是小规模的走私，大多数大规模的走私是像新加坡和马来西亚的公司把它们运到各地，或者完全合法地出租 GPU。

**Lex Fridman:**  我想插一句，规模有多大？我认为有一些数字，比如一些对经济学有更高层次理解的人说，当你从 10 亿美元的走私增加到 100 亿美元时，就像你在隐藏一定程度的经济活动，对我来说，最合理的是，在某个程度上，它会变得如此明显，以至于更容易发现这种经济活动。

**Dylan Patel:**  是的，所以我的看法是，去年大约……所以 Nvidia 制造了 100 万个 H20，这是合法允许运往中国的，我们谈到了这更适合推理，至少是推理，也许不是训练，但……推理，一般来说，他们也有……你知道，我们认为有 20 万到 30 万个 GPU 是从……你知道，新加坡、马来西亚、美国，无论哪里，公司购买 16 个 GPU、64 个 GPU，不管是什么，然后运到……华为以建立了一个庞大的公司网络而闻名，以在 2018 年左右被禁后获得他们需要的材料，所以这并不是……但我同意，Nathan 的观点是，你不能走私 

#### P7

**Dylan Patel:**  ……但我同意，Nathan 的观点是，你不能走私 100 亿美元的 GPU。然后第三种来源，现在已经被禁止了，你知道，这在过去不被认为是走私，但中国正在租用……就像……我相信根据我们的研究，甲骨文最大的 GPU 客户是字节跳动，对于谷歌，我认为它是他们的第二大客户。所以，就像，你看看云服务商的名单，尤其是那些不是超大规模云服务商的小型云服务公司，想想……甚至还有……还有 60 家不同的提供 Nvidia GPU 的新云公司，我认为……正在租用很多这些，在各地。所以这些公司正在向中国公司出租 GPU，这在 AI 扩散规则出台之前是完全合法的，而这仅仅在几周前才发生。即使是现在，你仍然可以租用少于 2000 个 GPU 的 GPU 集群，或者你可以购买 GPU 并将它们运送到任何你想去的地方，如果它们少于 1500 个 GPU。所以就像，仍然有一些走私的方法，但你知道，随着数字的增长，去年 Nvidia 的收入大约是 1000 多亿美元，今年是 2000 多亿美元，如果明年……你知道，它可能会再次翻一番或翻一番以上，根据我们在美国和世界各地看到的数据中心足迹的建设情况，中国将很难跟上这些规则。是的，总会有走私，DeepSeek 级别的模型，GPT-4 级别的模型，O1 级别的模型，可以在中国可以获得的资源上进行训练，甚至比这高一个级别，但如果我们快速前进几次……你知道，跳到 10 亿美元的模型，100 亿美元的模型，那么它就变成了……你知道，“嘿，中国在训练模型和提供服务方面存在计算劣势”，而服务部分非常关键。DeepSeek 今天无法提供他们的模型服务，它完全没有库存，它在应用商店的下载量已经开始下降，因为你下载它，你尝试注册，他们说我们不接受注册，因为他们没有能力。你打开它，你得到的……如果你的请求被批准，你得到的 token 数少于 5 个，因为他们根本没有足够的 GPU 来提供服务，即使它非常高效。

**Lex Fridman:** 这将是……观察走私将是一件有趣的事情，因为我的意思是，有毒品走私，对吧？这是一个市场，有武器走私，GPU 将在某些时候超过这一点。

**Dylan Patel:**  按每公斤的价值计算，可能是最高的，到目前为止。

**十八、 DeepSeek 使用 OpenAI 数据进行训练 (3:25:36)**

**Lex Fridman:** 我还有一个问题要问你，Dylan，你是否跟踪模型 API 在国际上的访问情况？中国公司使用美国托管的模型 API 有多容易？

**Dylan Patel:**  我的意思是，这非常容易，OpenAI 公开表示 DeepSeek 使用了他们的 API，正如他们所说，他们有证据。这是训练机制的另一个要素，OpenAI 的人声称这是一个蒸馏模型，也就是说，你采用 OpenAI 的模型，你生成大量输出，然后在他们的模型上进行训练。即使是这样，DeepSeek 所做的仍然令人惊叹。

**Nathan Lambert:**  提炼是业界的标准做法，无论你是否在乎服务条款和知识产权，你都会从你自己的模型中提炼，如果你是一个研究人员，你不构建任何产品，你会从……中提炼。

**Lex Fridman:**  这是一个很好的机会，你能从大局上解释一下蒸馏作为一个过程吗？什么是蒸馏？蒸馏的过程……谈论了很多关于训练语言模型的内容，它们是在文本上训练的，在后训练中，你试图在非常高质量的文本上进行训练，你希望模型匹配这些文本的特征，或者如果你使用 RL，你让模型找到自己的东西，但对于监督微调，对于偏好数据，你需要有一些补全，模型试图模仿这些补全，你在那里所做的，而不是人类数据或你当前正在训练的模型，你从一个不同的、通常更强大的模型中获取补全。我认为有传言说，人们正在等待的这些大型模型，这些 GPT-5 之类的东西，Claude 3 Opus 之类的东西，在内部被用于进行这种蒸馏过程。也有一些公开的例子，Meta 明确表示，不一定是蒸馏，但他们在 Llama 3.2 或 3.3 中使用了 405B 作为 70B 的奖励模型，这都是同一个主题。

**Lex Fridman:**  所以这是……这合乎道德吗？这是合法的吗？为什么《金融时报》的文章标题说 OpenAI 说有证据表明中国的 DeepSeek 使用其模型来训练竞争对手？

**Nathan Lambert:**  从学术方面和研究方面来看，这是一个悠久的历史，因为你试图解释 OpenAI 的规则，OpenAI 的服务条款说你不能用他们模型的输出来构建竞争对手。服务条款不同于许可证，许可证本质上是组织之间的合同。所以如果你违反了 OpenAI 账户的服务条款，OpenAI 可以取消我的账户，这与说明你如何使用下游产品的许可证非常不同。所以很多都取决于一个在 AI 领域非常不清楚的词，那就是什么是竞争对手？然后，这方面的道德问题是，当我可以在互联网文本上训练时，为什么我在你的模型上训练是不道德的？

**Dylan Patel:** 是的，这有点虚伪，因为某种程度上，OpenAI 和可能大多数公司都在未经许可的情况下在互联网文本上进行了训练。

**Nathan Lambert:** 还有一个明显的漏洞，就是我从 OpenAI 生成数据，然后我将其上传到某个地方，然后其他人对其进行训练，并且链接已被破坏，他们不在相同的服务条款合同之下。这就是为什么有很多……有很多待发现的细节没有多大意义，这就是为什么现在很多模型，即使它们没有在任何 OpenAI 数据上进行训练，你问模型“谁训练了你？”，它会说“我是 ChatGPT，由 OpenAI 训练”，因为互联网上有太多从……复制粘贴的 OpenAI 输出，你根本无法过滤掉它。而且在 RL 中没有任何东西，他们实现了……比如“嘿，我实际上是由艾伦研究所建模的，而不是……”

**Lex Fridman:** 我们必须这样做，如果我们提供演示……

**Nathan Lambert:** 我们做研究，我们使用 OpenAI API，因为它很有用，我们想了解后训练，像我们的研究模型，它们会说它们是由 OpenAI 编写的，除非我们在系统提示中加入“我是 Tulu，我是艾伦人工智能研究所训练的语言模型”，我们还受益于 OpenAI 数据，因为它是一个很好的研究工具。我的意思是，你认为 OpenAI 声称有证据表明中国的 DeepSeek 使用这个模型进行训练，这其中有任何真实性和价值吗？

**Dylan Patel:**  我认为每个人都受益了，无论如何，因为数据在互联网上，因此它现在在你的预训练中。有一些……你知道，人们分享最佳 ChatGPT 输出的 subreddit，这些都在你的……我认为他们在试图改变叙事，他们在试图保护自己。几年前，当字节跳动实际上因为在输出上进行训练而被禁止使用一些 OpenAI API 时，我们就看到过这种情况，还有其他 AI 初创公司，大多数人，如果你在 AI 文化中，就像……他们只是告诉我们他们在 OpenAI 输出上进行了训练，他们从未被禁止，这就是他们引导早期模型的方式。所以使用这种方法比建立人类流水线和构建一个强大的模型要容易得多。

**Nathan Lambert:**  所以……历史悠久，很多通信似乎都是叙事控制。

**Dylan Patel:**  实际上，在过去几天里，我们已经看到很多人将 DeepSeek 的模型提炼成 Llama 模型，因为 DeepSeek 模型的推理有点复杂，因为它们是专家混合模型，而且它们有 6000 多亿个参数，等等，人们将它们提炼成 Llama 模型，然后因为 Llama 模型非常容易提供服务，每个人都为 Llama 模型构建了流水线和工具，因为它是一个开放的标准。所以，你知道，我们已经看到了……我们已经看到了一个迂回，对吧？这是坏事吗？这是非法的吗？也许这是非法的，我不知道，但这可能会违反合同，我不认为这是违法的，就像在任何法律上……没有人会因此入狱，我认为这在道德上是可以接受的，或者我希望这在道德上是可以接受的，因为如果我们禁止这种事情，那将使每个人的处境都变得更糟。而且我也认为，这很难，但你应该被允许在互联网上进行训练，我知道很多作者和创作者对此非常敏感，这是一个难题，但就像……一旦你不被允许在互联网上进行训练……

**Nathan Lambert:**  我同意，我有一个……关于如何解决这个问题的看法，因为它已经奏效了。

**Dylan Patel:**  我有一个合理的看法。

**Nathan Lambert:**  好的。

**Dylan Patel:**  所以，你知道，日本有一项法律，你可以在任何训练数据上进行训练，版权不适用。B，日本有 9 吉瓦的受限核电。C，根据 AI 扩散规则，日本可以进口任意多的 GPU。所以我们所要做的……我们这里有一个市场，我们建造大型数据中心，我们把它们租给实验室，然后我们以合法的方式训练模型，没有任何“如果”、“并且”或“但是”，现在这些模型没有任何来自《纽约时报》或其他任何媒体的潜在版权诉讼，不，不，这完全合法，没有……

**Lex Fridman:**  所以……天才。

**Nathan Lambert:**  早期的版权诉讼有利于 AI 训练，我想说的是，长尾的使用将偏向 AI，也就是说，如果你抓取数万亿的数据，你不会查看数万亿的 token 数据，你不会说“这篇《纽约时报》的文章对我来说太重要了”，但如果你正在进行音乐或图像生成，并且你说“以……的风格制作它”，这是一个合理的情况，你可以计算出他们在推理上的利润率是多少，我不知道这是否会是 YouTube 创作者计划的 50/50 或其他什么，但我会选择加入那个计划，作为一个作家，就像……这将会是一个艰难的旅程，但会有一些像这样的解决方案是有意义的，但还有很长的路要走，它只是在互联网上。

**Dylan Patel:**  我认为《金融时报》那篇文章暗示的另一个方面，以及这导致了一个更普遍的问题，你认为存在多少……间谍活动有多困难？从公司内部窃取实际的秘密代码和数据，有多少这样的尝试？

**Nathan Lambert:**  代码和数据很难，但想法很容易，硅谷的运作方式是，顶尖员工被其他公司以加薪和大笔资金挖走，这些公司这样做的很大一部分原因是为了带来想法，而且……我的意思是，在加利福尼亚州，有一些规则规定某些……竞业禁止协议或诸如此类的东西在加利福尼亚州是非法的，无论是否有保密协议，这就是很多……发生的事情。最近有一个来自 Gemini 的人帮助实现了这个 100 万的上下文长度，每个人都在说下一个……我的意思是，他去了 Meta 团队，将拥有 100 万的上下文长度，这就是世界运作的方式。

**Dylan Patel:**  你知道，至于工业间谍活动和诸如此类的事情，这在过去非常成功，你知道，美国人对英国人这样做，中国人对美国人这样做，你知道，等等，这只是生活中的一个事实。所以，争论工业间谍活动可以被阻止可能是不可能的，你可以让它变得困难，但即便如此，就像……你知道，有所有这些关于 F-35 和 F-22 已经……你知道，在设计方案等方面已经给了中国的故事。公司之间的代码之类的东西可能非常困难，但想法经常被讨论，无论是在旧金山的家庭聚会上，还是员工跳槽到另一家公司，或者……你知道，总是……你知道，总是被谈论的神话般的美人计，有人中了美人计，因为每个从事 AI 工作的人都是 20 多岁和 30 多岁的单身男性，不是每个人，但比例高得惊人。所以总是有所有这些……你知道，显然……所以“美人计”是一个间谍，一个女间谍接近你，然后……是的，或者男的，这是旧金山。

**Lex Fridman:**  作为一个 20 多岁的单身男性，我会说，我们很容易被腐蚀，你知道，不是……不是我自己被腐蚀，但你知道，我们是……我们是，其他人……不是我，我太迟钝了，而且我不是单身，所以我……

**Nathan Lambert:**  你必须确保关闭所有的安全漏洞。

**十九、 AI 超级集群 (3:36:04)**

**Lex Fridman:**  所以，你……Dylan 收集了很多关于每个主要 AI 公司的超级集群的信息，你能谈谈每个公司的建设情况吗？哪些比较突出？

**Dylan Patel:**  是的，我认为关于这些超级集群建设真正重要的是，它们的规模是前所未有的。你知道，美国的……数据中心的用电量一直在缓慢上升，即使在云计算革命期间，它也上升到了 2-3%，这是几十年来的数据中心……它一直在缓慢攀升，但现在到这个十年结束时，即使在……你知道，当我说 10% 时，很多传统上……到 2028 年、2030 年，很多传统上非 AI……传统的数据中心人员会说，“这太疯狂了”，但那些从事 AI 的人，那些真正关注过这个问题的人，比如 Anthropic 和 OpenAI 的人，他们会说，“这还不够”。我说，“好吧，但是……你知道，这是……这既是通过……在全球范围内分布……或者说在美国各地分布，也有集中的集群。在美国各地分布是令人兴奋的，它是其中的大部分，你知道，OpenAI 或者……你知道，Meta 正在增加 1 吉瓦，但大部分分布在美国各地，用于推理和所有这些其他的事情。所以也许我们应该说明一下什么是集群，所以……这是否包括 AWS？也许最好谈谈不同类型的集群，以及你所说的“超级集群”是什么意思，什么是 GPU，什么是计算机，不是那么……

**Lex Fridman:**  是的。

**Dylan Patel:**  好的，那么，什么是……我们所说的集群是什么意思？传统上，数据中心和数据中心任务一直是一个分布式系统问题，它可以分散到很远的地方。也就是说，我向谷歌发送一个请求，它被路由到一个离我较近的数据中心，它进行任何搜索排名、推荐，然后发回一个结果。任务的性质正在迅速改变，人们现在真正关注的任务有两个，不是数据库访问，不是给我提供正确的页面、给我提供正确的广告，现在是推理，推理与传统的分布式系统截然不同，但它看起来更相似，然后是训练。训练……方面仍然像是，“嘿，我将在……你知道，成千上万的 GPU 放在这些数据中心的各个区块中，我将在它们上运行模型，你知道，用户提交一个请求，它被启动，或者嘿，我的服务……你知道，他们向我的服务提交一个请求，他们在 Word 上，他们说，“哦，是的，帮助……Copilot”，然后它开始……我在我的 Windows Copilot 上，不管是什么，Apple Intelligence，不管是什么，它被发送到一个数据中心，然后数据中心做一些工作并将其发送回来，这就是推理，这将是计算的大部分。但然后……你知道，这是……你知道，我们正在用卫星和其他所有东西跟踪数千个数据中心，这些是正在建造的大部分，但最大的集群的规模也非常重要。当我们回顾历史时，你知道，或者贯穿 AI 时代，当他们在……我认为是两个 GPU 或四个 GPU 上进行 AlexNet 时，这是一件非常大的事情，这是一件大事，这是一个大事件，因为……

**Lex Fridman:**  这是一个大事件，因为他们使用了 GPU。

**Dylan Patel:**  他们使用了 GPU，而且他们使用了多个。但随着时间的推移，规模一直在不断扩大。所以，当你跳到 GPT-3，然后是 GPT-4，GPT-4，20,000 个 A100 GPU，前所未有的运行，就规模和成本而言，几亿美元的 YOLO 运行，用于 GPD-4，它产生了……你知道，这个神奇的改进，完全符合实验的结果，就像一个对数规模，哦，是的，他们有论文中的图表，技术……性能……

**Nathan Lambert:**  规模定律是完美的。

**Dylan Patel:**  但这不是一个疯狂的数字，20,000 个 A100，每个 GPU 大约消耗 400 瓦，然后当你加上整个服务器，所有东西，大约是 15 到 20 兆瓦的功率。你知道，你可以查一下一个人的功耗是多少，因为这些数字会变得很愚蠢，但这 15 到 20 兆瓦是标准的数据中心规模，只是前所未有的是，所有 GPU 都在运行一个任务。

**Nathan Lambert:**  20 瓦是一个……

**Lex Fridman:**  烤面包机。

**Nathan Lambert:**  烤面包机与 A100 的功耗相似。

**Dylan Patel:**  H100 出现了，他们将每个 GPU 的功耗从 400 瓦提高到 700 瓦，然后还有所有相关的东西，所以一旦你把所有这些都计算在内，大约是 1200 到 1400 瓦。

**Lex Fridman:**  我们也应该说，什么是……你说了功率，所以需要大量的功率，会产生大量的热量，所以需要冷却，而且因为有很多 GPU 或 CPU 或其他什么，它们必须连接起来，所以有很多网络……

**Dylan Patel:**  是的，对不起，跳过了这一点。然后数据中心本身就像……很复杂，但这些仍然是 GPT-4 规模的标准化数据中心。现在我们向前迈进，看看人们去年建造的集群的规模是多少，它的范围很广，从“嘿，这些是标准的数据中心，我们只是使用其中的多个并将它们连接在一起，实际上使用了大量的光纤，大量的网络”等等，这就是 OpenAI 和微软在亚利桑那州所做的。所以他们有一个……你知道，100,000 个 GPU。Meta 也有类似的情况，他们采用了他们的标准现有数据中心设计，它看起来像一个 H，他们将其中多个连接在一起，你知道，他们首先做了 16,000 个 GPU，总共 24,000 个 GPU，但只有 16,000 个用于训练运行，因为 GPU 非常不可靠，所以他们需要有备件来更换，一直到像现在 100,000 个 GPU，他们正在训练 Llama 4，128,000 个左右。这是……你知道，想想 100,000 个 GPU，每个大约 1400 瓦，那是 140 兆瓦，150 兆瓦，对于 128 个，对吧？所以你在谈论，你已经从 15 兆瓦跃升到了……你知道，几乎是 10 倍，9 倍，两年内从 2022 年到 2024 年达到 150 兆瓦。有些人，比如埃隆，他承认……他自己也承认，他在预训练大型语言模型方面有点晚了，xAI 成立得比较晚，但他竭尽全力让他的数据中心启动并运行，并获得世界上最大的集群，即 200,000 个 GPU。他做到了，他在孟菲斯买了一个工厂，他升级了变电站，与此同时，他有一堆移动发电机，一堆单循环……他接入了工厂旁边的天然气管道，他只是在抽取大量的天然气，燃烧天然气，他正在发电，他在一个很久以前就关闭并搬到中国的旧电器厂里，你知道，他有 200,000 个 GPU。现在，下一个规模是什么？所有超大规模公司都已经做到了这一点，下一个规模更大。所以，你知道，埃隆，为了继续这个话题，他正在隔壁建造自己的天然气厂，一个合适的天然气厂，他正在部署大量的特斯拉超级电池组，以使电力更加平稳，以及所有其他的事情，他有工业冷却器来冷却水，因为他正在对芯片进行水冷。所有这些疯狂的事情都是为了让集群变得越来越大。但是当你看看……比如 OpenAI 在 Stargate 所做的事情，那是在亚利桑那州，在德克萨斯州的阿比林，他们至少已经宣布了，它还没有建成。埃隆说他们没有钱，你知道，关于这一点有一些争论，但按照全部规模，至少第一部分绝对……资金已经到位，但还有多个部分。但按照全部规模，那个数据中心将达到 2.2 吉瓦，2200 兆瓦的电力输入，大约 1.8 吉瓦，或者说 1800 兆瓦的电力输送到芯片。现在这是一个荒谬的规模，2.2 吉瓦比大多数城市都多，需要明确的是，并且被输送到一个连接起来进行训练的集群，训练这些模型，进行预训练、后训练，所有这些东西，这太疯狂了。

**Nathan Lambert:**  核电站又是多少？

**Dylan Patel:**  每个人都在这样做，每个人都在这样做。Meta，Meta 和路易斯安那州，他们正在建造两个大型天然气厂，然后他们正在建造这个庞大的数据中心。亚马逊有这个规模的计划，谷歌有这个规模的计划，xAI 也有这个规模的计划，所有这些正在竞争的公司都在拼命竞争，他们正在建造数吉瓦的数据中心，因为他们认为，是的，如果我现在有……你知道，显然预训练的规模将会继续，但在某种程度上，还有所有这些后训练的东西，在那里你有 RL 沙盒，用于计算机使用或其他什么，你知道，这就是他们要去的地方，所有这些可验证的领域，在那里他们只是不断地学习，不断地学习，自我对弈，不管是什么，使得 AI 更加强大，因为这条线确实会上升，当你投入更多的计算时，你会获得更多的性能，这件 T 恤是关于规模定律的。在某种程度上，这是收益递减的，你将计算量增加 10 倍，你不会得到 10 倍好的模型，你会得到收益递减，但你也会获得效率提升，所以你会……曲线，这些规模的数据中心正在……你知道，造成……网络上的很多破坏。Nathan 提到了亚马逊试图收购这个核电站……如果你看看……的股票，它正在飞涨。你知道，他们在那里建造了一个庞大的数吉瓦的数据中心，你知道，诸如此类的事情，美国某些地区的输电成本比实际发电成本还要高，因为电网的建设速度太慢了，对电力的需求以及建设电力的能力，以及启动天然气厂，甚至煤电厂，都比较容易做到，但输送电力真的很难。所以在美国的一些地区，比如在弗吉尼亚州，输电的成本比发电的成本还要高，这就像……你知道，这里有各种各样的疯狂的二级效应。

**Lex Fridman:**  电网能支持这种增长吗？

**Dylan Patel:**  你知道，特朗普的行政命令……在年底之前有一个拜登的行政命令，但特朗普还有一些其他的行政命令，希望减少监管，以便可以更快地建设。但这是一个很大的挑战，即建设足够的电力……

**Lex Fridman:**  你是否会在每个数据中心旁边都建一个核电站？

**Dylan Patel:**  所以有趣的是，这太慢了，建造发电厂太慢了，建造发电厂或重新配置现有的发电厂太慢了，因此你必须使用……

**Nathan Lambert:**  数据中心的功耗是……你知道，我的意思是，它是……这就是为什么从长远来看核电也很适合它的原因，但……

**Dylan Patel:**  你需要……在短期内你不能做太阳能和任何东西，因为数据中心的功耗是这样的，你在告诉我……你知道，我要购买数百亿美元的 GPU，然后因为没有发电而闲置它们？电力很便宜，如果你看看集群的成本，不到 20% 是电力，大部分是资本成本和 GPU 的折旧。所以就像，“好吧，去你的，我就……你知道，我就建造天然气厂”，这就是 Meta 在路易斯安那州所做的，这就是 OpenAI 在德克萨斯州所做的，以及所有这些不同的地方，他们可能不是直接这样做，但他们与某人合作，所以有几种希望。一个是，你知道，埃隆在孟菲斯所做的，就像……你知道，到了极点，他们不仅使用双循环联合循环燃气轮机，这非常高效，他还使用单循环和移动发电机等，效率较低，但他也……你知道，也有另一面，就像太阳能发电是这样的，风能是另一种……你知道，不同的……所以如果你把这两者叠加起来，再加上一大堆电池，再加上一点天然气，就有可能更环保地运行它，只是时间尺度……对于……来说，人们正在尝试，但你知道，Meta 基本上说，“管它呢，不要在意我的可持续发展承诺”，或者他们会购买……电力……这叫做 PPA，电力购买协议，在那里会有一个大型的风电场或太阳能发电场，然后他们会假装这些电子被数据中心消耗了，但实际上他们在这里支付电费，并将其出售给电网，他们在这里购买电力。还有一件事是，微软放弃了他们的一些可持续发展承诺，埃隆，他在孟菲斯所做的事情在客观上有些肮脏，但他也是在一个旁边有更大的天然气厂的地方这样做的，还有一个……不是下水道，而是一个废水处理厂和一个垃圾场，就在附近。而且他显然已经让世界变得比那个数据中心将要做的更清洁，所以我觉得这在某种程度上是可以的，也许 AGI 会解决……你知道，全球变暖之类的问题，你知道，这是实验室里的人们的态度，就像，“是的，去……我们就用天然气”，因为竞争是如此重要，如果我们输了，你知道，那就更糟了。

**Nathan Lambert:**  我应该说我有机会参观了孟菲斯数据中心。

**Lex Fridman:**  哦，哇。

**Nathan Lambert:**  这有点令人难以置信，我的意思是，我和埃隆一起参观了……团队……那里的创新速度是疯狂的，因为我的感觉是，你知道，以前没有人做过这种规模的事情，当然也从来没有人以……的速度做过这种规模的事情，所以他们就像……他们在努力找出瓶颈是什么，如何消除瓶颈，如何确保……你知道，有很多关于建设数据中心的非常酷的事情，因为你知道，一切都必须正常工作，这……那些做……你知道，机器学习，所有这些都是令人兴奋的事情，所以……但真正运行一切的人是那些了解底层软件和硬件的人，这些软件和硬件运行着一切，网络，所有这些。所以你必须确保你有测试一切的程序，我认为他们在用以太网，我不知道他们是怎么做到的，但他们在用 Nvidia 的……以太网。

**Dylan Patel:**  实际上，我认为无名英雄是冷却和电气系统，它们只是被掩盖了，但我认为，有一个故事也许可以说明这些东西有多么疯狂，当你在训练时，你总是在运行模型很多次，用最简单的术语来说，然后你将交换一切并同步权重，所以你做……这是模型训练中的一个步骤，每一步你的损失都会下降，希望如此，但并不总是如此。用最简单的术语来说，你将进行大量的计算，然后你将交换，有趣的是，GPU 的功耗是其中的大部分，网络功耗是一部分，但要少得多。所以当你在计算时，你的 GPU 的功耗在这里，但是当你交换权重时，如果你不能完美地重叠通信和计算，可能会有一段时间你的 GPU 处于空闲状态，而你在交换权重，你就像，“嘿，模型正在更新”，所以你交换梯度，你进行模型更新，然后你再次开始训练，所以功耗……非常不稳定。有趣的是，当你说到数据中心的规模时，你很容易把东西炸毁。所以 Meta 实际上意外地向上游开源了一些东西到代码和 PyTorch 中，他们在其中添加了一个操作符，我没有骗你，不管是谁做的，我都想拥抱他，因为它说 PyTorch……就像 PyTorch.PowerPlant.NoBlowup=0 或 =1，它的作用非常棒，你知道，当你在交换权重时，GPU 会计算假数字，这样功耗就不会激增太多，这样发电厂就不会爆炸，因为瞬态尖峰会把东西搞砸。

**Lex Fridman:**  嗯，这是有道理的，我的意思是，你必须做那种事情，你必须确保它们不空闲。

**Dylan Patel:**  埃隆的解决方案是，“让我扔一堆特斯拉超级电池组和其他一些东西”，每个人都有不同的解决方案，但 Meta 的至少是公开和开放的，那就是设置这个操作符，这个操作符的作用就是让 GPU 什么都不计算，这样功耗就不会激增。但这也告诉你，你正在使用的功率有多大，这太疯狂了，人们应该去谷歌一下，“规模……X 瓦会做什么？”，然后从 1 瓦到 1 千瓦到 1 兆瓦，你看看……盯着它看，1 吉瓦在列表中有多高，这令人难以置信。

**Lex Fridman:**  你能谈谈冷却吗？所以……我知道埃隆正在使用液体冷却，我相信在所有情况下，这是一件新事物，对吧？他们中的大多数人不使用……

**Dylan Patel:**  空气冷却是事实上的标准，扔一堆金属……散热管等等和风扇，这足以冷却它。人们一直在涉足水冷，谷歌的 TPU 是水冷的，所以他们已经这样做了几年。但是对于 GPU，以前没有人这样做过，也没有人做过埃隆刚刚做的这种规模的水冷。现在，下一代 Nvidia，对于……最高端的 GPU，它是强制水冷的，你必须用水冷却它，但埃隆在这一代就做到了，这需要很多东西。如果你看看孟菲斯工厂的一些卫星照片之类的东西，所有这些外部的水冷器都放在外面，基本上看起来像一个……它看起来像一个……集装箱，但实际上那些是水冷器，他有大约 90 个这样的水冷器就放在外面，90 个不同的集装箱，里面有水……你知道，冷却水，把它送回数据中心，然后你把它分配给所有的芯片，把所有的热量带走，然后把它送回去。这既是一种冷却芯片的方式，也是一种提高效率的方式。回到这三个方面，有内存带宽、算力和互连，芯片之间的距离越近，就越容易实现高速互连。所以这也是你为什么要进行水冷的一个原因，因为你可以把芯片放在一起，从而获得更高的连接速度。

**Lex Fridman:**  我得问你，在你的……你最近的一篇文章中，有一个章节叫做“集群竞赛”。所以，还有另一个词，但我不会说，你知道……谁……谁现在拥有最大的，谁将拥有……

**Dylan Patel:**  今天，最大的个人……是埃隆，埃隆在孟菲斯的集群，20 万个 GPU。

**Lex Fridman:**  好的。

**Dylan Patel:**  Meta 有大约 12.8 万个，OpenAI 有 10 万个。现在需要明确的是，其他公司拥有的 GPU 比埃隆多，只是它们不在一个地方，为了训练，你需要它们紧密连接。有一些技术，人们正在研究和开发，可以让你跨多个区域进行训练，但在大多数情况下，你希望它们都在一个区域内，这样你就可以用高速网络将它们紧密连接起来。埃隆今天有 20 万个……H100 和……H100，10 万个 H100，10 万个 H20。Meta、OpenAI、你知道，还有亚马逊，都有大约 10 万个，稍微少一点，但到明年，你将拥有 50 万到 70 万个 GPU 的集群，而且那些 GPU 的功耗比现有的 GPU 高得多，Hopper 是 700 瓦，Blackwell 达到 1200 瓦。所以每个芯片的功耗都在增加，芯片的数量也在增加。

**Lex Fridman:**  在……你认为……埃隆说他将达到 100 万，你认为这实际上是可行的吗？

**Dylan Patel:**  我的意思是，我……我不怀疑埃隆，他为……你知道，发电厂和特斯拉电池组所做的备案，很明显，他对孟菲斯有一些疯狂的计划，许可证等等，这是公开记录。但目前还不清楚……你知道，什么……以及时间表是什么，我只是从来没有……你知道，他会给我们带来惊喜。

**Lex Fridman:**  那么这些集群的想法是什么？如果你有 100 万个 GPU，假设在两三年内，有多少比例用于训练，多少比例用于预训练，多少比例用于……

**Dylan Patel:**  对于实际……这些超级集群对于推理来说没有意义，你可以在那里进行推理，只是不训练。但大部分的推理能力是……你知道，“嘿，我这里有一个 30 兆瓦的数据中心，我这里有 50 兆瓦，我这里有 100 兆瓦，我就把推理放在所有这些地方”，因为超级集群，数吉瓦的数据中心，我想在那里训练，因为那是我所有 GPU 所在的地方，在那里我可以以超高的网络速度将它们连接在一起，这是训练所需要的。现在，对于预训练，这是旧的规模，你可以增加参数，你增加数据，模型会变得更好，但这不再适用了，因为在预训练方面没有更多的数据了。是的，还有视频、音频和图像没有得到充分利用，所以还有很多扩展的空间，但很多人喜欢……已经有了 YouTube 视频的文字记录，这为你提供了很多数据，但并没有让你从视频和图像数据中获得所有的学习价值，但你知道，预训练仍然有一些扩展的空间，但这个后训练世界是所有算力将被花费的地方，模型将与自己对弈，它将进行自我对弈，它将执行可验证的任务，它将在沙盒中进行计算机使用，它甚至可能做……你知道，模拟机器人技术之类的事情，所有这些事情都将成为计算被花费的环境，在……你知道，后训练中，但我认为它将……我们将放弃后训练中的“后”，它将是预训练，它将是训练，我想在某个时候。因为在过去几年里，预训练已经 dwarfed 后训练，但有了这些可验证的方法，特别是那些真正……你知道，可能无限扩展的方法，比如计算机使用和机器人技术，而不仅仅是数学和编码，在那里你可以验证正在发生的事情，似乎你可以随心所欲地在它们身上花费计算。

**Nathan Lambert:**  特别是在上下文长度增加的情况下，因为预训练的结束是你为这些模型增加上下文长度的时候，我们之前在谈话中谈到了当你有一个长输入时，上下文长度比输出更容易管理，而且很多这些后训练和推理技术都依赖于大量的采样，并且它变得越来越长的上下文。所以就像，实际上你的计算效率下降了，我不……flops 是衡量它的标准，但对于 RL，你必须做所有这些事情，你以不同于预训练和生成的方式移动你的权重，它将变得效率较低，flops 将不再是一个有用的术语，然后随着基础设施的改善，它可能会回到 flops。所有我们一直在谈论的事情很可能都是 Nvidia，对吧？有没有什么竞争对手？

**Dylan Patel:**  谷歌。

**Lex Fridman:**  谷歌……我有点忽略了他们。

**二十、 谷歌 (3:59:02)**

**Lex Fridman:**  TPU 的故事是什么？TPU 怎么样？

**Dylan Patel:**  TPU 很棒，它很好。谷歌在建造数据中心方面有点……更温和，出于某种原因，他们正在建造大型数据中心，别误会我的意思，他们实际上拥有最大的集群，让我……我……我谈论的是 Nvidia 集群，他们实际上拥有最大的集群。但他们做事的方式非常有趣，他们有两个……数据中心超级区域，数据中心在物理上并不是……所有的 GPU 都不在一个地方，但它们相距约 30 英里，而不是 GPU，是 TPU。他们在爱荷华州和内布拉斯加州有四个数据中心，它们就在彼此旁边。

**Lex Fridman:**  为什么谷歌不展示它的集群规模？

**Dylan Patel:**  进行多数据中心训练，那里有很好的图片，我会向你展示我的意思，这只是……多数据中心。所以，这是一张谷歌标准数据中心的样子，顺便说一句，他们的数据中心看起来与其他任何人的数据中心都非常不同。

**Lex Fridman:**  我们在这里看到的是什么？

**Dylan Patel:**  这些是……是的，所以如果你看到这张图片，在中心，有这些大的矩形框，那些是实际芯片所在的地方。然后如果你再往下滚动一点，你可以看到有这些水管，顶部有冷却塔和一堆柴油发电机，柴油发电机是备用电源。数据中心本身看起来比水冷器还要小，所以芯片实际上更容易……保持在一起，但冷却所有用于水冷的水非常困难。所以谷歌有一个非常先进的基础设施，这是其他任何人都无法比拟的，对于 TPU 来说。他们所做的是，他们在几个区域复制了这些数据中心。所以如果你再往下看一点，这是微软的……这是亚利桑那州，这是 GPT-5“据称”将被训练的地方，如果它还不存在的话。但每个数据中心，我展示了其中的几张图片，它们非常靠近，在同一个区域，内布拉斯加州、爱荷华州，然后他们还有一个类似的在俄亥俄州。所以这些数据中心彼此非常靠近，他们所做的是，他们用光纤以超高带宽连接它们。所以这些只是一堆数据中心，重点是，谷歌拥有非常先进的基础设施，在一个小区域内非常紧密地

#### P8

**Dylan Patel:**  ……在一个小区域内非常紧密地连接在一起。所以埃隆总是……拥有完全连接的最大集群，因为它都在一栋大楼里，在这方面他是完全正确的。谷歌拥有最大的集群，但你必须分散在三个……而且差距很大，但你必须跨越多个站点。

**Lex Fridman:**  为什么谷歌不与 Nvidia 竞争？他们为什么不卖 TPU？

**Dylan Patel:**  我认为这有几个问题。首先，TPU 一直是一种让搜索变得非常便宜并为此构建模型的方式。所以很大一部分搜索 GPU 或 TPU 的购买，或者说谷歌购买和使用的很大一部分都是用于内部工作负载的，无论是搜索、现在的 Gemini、YouTube，所有这些他们拥有的不同应用，广告，这些都是他们所有 TPU 被花费的地方，这就是他们超级关注的地方。所以架构的某些方面是针对他们的用例进行优化的，而不是针对其他地方进行优化的。一个简单的例子是，他们开源了 Gemma 模型，他们称之为 Gemma 7B，但它实际上有 80 亿个参数，因为词汇表太大了，他们之所以把词汇表做得这么大，是因为 TPU 的矩阵乘法单元很大，因为这是他们优化的方向。所以他们决定，“哦，我也要把词汇表做大，即使在这么小的模型上这样做没有意义”，因为这适合他们的硬件。所以 Gemma 在 GPU 上的运行效率不如 Llama，反之亦然，Llama 在 TPU 上的运行效率不如 Gemma。所以就像，有一些硬件软件协同设计的方面，他们所有的搜索模型、他们的排名和推荐模型，所有这些不同的模型都是 AI，但不是生成式 AI，它们都针对……TPU 进行了超级优化，软件堆栈也进行了超级优化，但所有这些软件堆栈都没有公开发布。只有很小的一部分，Jax 和 XLA 已经发布了，但当你在谷歌内部并在 TPU 上进行训练时，作为一名研究人员，你通常不需要了解硬件方面的任何信息，这很棒。但一旦你走出谷歌，他们都会……很多人离开谷歌，然后他们……

**Nathan Lambert:**  他们离开并创办一家公司，因为他们有所有这些惊人的研究想法，然后他们就像，“等等，基础设施很难，软件很难”。

**Dylan Patel:**  这在 GPU 上，或者如果他们尝试使用 TPU，也是一样，因为他们无法访问所有这些代码。所以，你如何说服一家靠搜索赚取数千亿美元的公司开始销售 GPU 或 TPU，过去他们只购买……你知道，我认为在 2020 年，他们购买了大约几十亿美元，现在他们购买了 100 亿到 150 亿美元。你如何说服他们，他们应该购买两倍的数量，并想办法销售它们，并赚取 300 亿美元？谁在乎赚 300 亿美元？

**Lex Fridman:**  这 300 亿美元最终不会超过搜索的利润吗？

**Dylan Patel:**  哦，我的意思是，你总是会在服务上赚更多的钱，而不是……我的意思是，是的，就像……需要明确的是，今天人们在硬件上花的钱比在服务上花的多得多，因为你……硬件是服务支出的先行指标，但你在投资，如果……如果 AI 方面没有收入，或者收入不够，那么显然，它将会……你知道，人们不会继续在 GPU 上花钱。Nvidia 正试图通过他们试图销售和许可的软件等向上游发展。但谷歌从来没有过这样的基因，“这是一个我们应该销售的产品”，他们没有……谷歌云有，这是一个与 TPU 团队分离的组织，这是一个与 DeepMind 团队分离的组织，这是一个与搜索团队分离的组织，有很多官僚主义。

**Lex Fridman:**  等等，谷歌云是一个与 TPU 团队分离的团队？

**Dylan Patel:**  从技术上讲，TPU 属于基础设施部门，基础设施部门属于谷歌云，但谷歌云，比如出租东西，和 TPU 架构是非常不同的目标，在硬件和软件方面，所有这些。Jax 和 XLA 团队不为外部的谷歌客户提供服务，而 Nvidia 的各种 Cuda 团队，比如 NCCL，为外部客户提供服务，内部团队，比如 Jax 和 XLA 等等，他们更多地为 DeepMind 和搜索服务，所以他们的客户不同，他们不是在为他们构建产品。

**Lex Fridman:**  你明白为什么 AWS 一直在云服务方面胜过 Azure 吗？谷歌云相对于……来说很小，不是吗？

**Dylan Patel:**  相对于……来说，谷歌云排在第三位。

**Lex Fridman:**  是的。

**Dylan Patel:**  微软是第二大，但亚马逊是最大的。微软有点……你知道，包括了 Microsoft Office 365 之类的东西，以及一些企业范围的许可证，所以实际上差距更大，微软仍然是第二。亚马逊大得多，为什么？因为使用 AWS 更好、更容易，而且在很多情况下更便宜，而且它是第一个。

**Nathan Lambert:**  它是第一个。

**Dylan Patel:**  有很多东西都是第一个，但……

**Nathan Lambert:**  这更容易，转换到 AWS 比从 AWS 转出更难，转换也有很大的费用。

**Dylan Patel:**  AWS 产生了亚马逊 80% 以上的利润，我认为超过 90%。

**Lex Fridman:**  这太疯狂了。

**Dylan Patel:**  配送中心就像……“有一天我们会决定从中赚钱”，但他们还没有，他们从中赚取的利润微乎其微。

**Lex Fridman:**  是的，有一天 Amazon Prime 的价格会翻三倍。

**Dylan Patel:**  你会认为他们会改进 AWS 的界面，因为它很糟糕，很笨重，但每个人都……

**Nathan Lambert:**  我……是的，你会……

**Dylan Patel:**  我认为实际上谷歌的界面有时还不错，但他们也不在乎除了他们最大的客户之外的任何人，而且他们的客户服务很糟糕，而且他们少了很多……我的意思是，所有这些公司，他们都为大客户进行了优化。

**Nathan Lambert:**  它应该是为企业服务的。

**Dylan Patel:**  亚马逊也一直为小客户进行优化，显然他们为大客户做了很多优化，但当他们开始的时候，他们只是去……你知道，随机的……地方，并提供积分，或者只是输入你的信用卡并使用我们，在早期。所以他们一直……业务与他们一起成长，而且……所以，为什么亚马逊……为什么 Snowflake 都在亚马逊上？因为 Snowflake 在一开始，当亚马逊不在乎他们的时候，仍然在使用亚马逊。当然，有一天 Snowflake 和亚马逊建立了非常大的合作伙伴关系，但情况就是这样，亚马逊的用户体验和质量更好。此外，他们设计的许多芯片使他们拥有比传统云计算、存储、CPU、网络等更低的成本结构。他们在数据库方面做得很好，我认为亚马逊收入最高的五种产品中有四种……利润产品，抱歉，毛利润产品，都是与数据库相关的产品，比如 Redshift 和所有这些东西。所以亚马逊有一个非常……从芯片到用户体验，通过 AWS 的整个流程都非常好。我认为谷歌，他们的……他们的芯片团队，是的，他们有很棒的内部芯片，TPU，YouTube 芯片，你知道，他们制造的一些其他芯片，问题是他们不为外部客户提供服务，他们为内部客户提供服务。我的意思是，Nvidia 的整个文化都是从下到上为此而设计的，最近有一本书叫《Nvidia 之道》，作者是……详细介绍了这一点，以及他们如何寻找未来的机会，并准备好他们的 Cuda 软件库，以使高性能计算的新应用能够在 Cuda 和 Nvidia 芯片上非常快速地发展，这与作为服务业务的谷歌完全不同。

**Dylan Patel:**  我的意思是，应该说 Nvidia 是一家非常特别的公司，我的意思是，他们……整个……一切的文化，他们真的为此进行了优化。

**Lex Fridman:**  说到这里，有没有人能在硬件方面挑战 Nvidia？英特尔、AMD？

**Nathan Lambert:**  我真的不这么认为。我们经历了一个非常漫长的过程，与 AMD 合作在他们的 GPU 上进行训练和……等等，它们不错，它们的硬件在很多方面都比……Nvidia 好，问题是他们的软件真的很糟糕，我认为他们正在变得更好，他们正在变得更好，更快，但差距太大了，而且他们没有在上面投入足够的资源，或者过去没有，也许他们现在正在改变他们的态度，但你知道，有几个月的时间，我们提交了最多的错误，就像我们，SemiAnalysis，就像“什么？为什么我们要提交最多的错误？”，因为他们只……他们只关心他们最大的客户，所以他们会给他们发送一个私有镜像等等，就像，“好吧，但我只是在使用 PyTorch，我想使用公开可用的库，而你却不在乎”。所以他们正在变得更好，但我认为 AMD 不太可能，英特尔显然现在处境艰难，需要以某种方式被拯救，对美国的国家安全非常重要。

**Lex Fridman:**  你能解释一下……显然，为什么……为什么他们处境艰难？

**Dylan Patel:**  回到之前，只有三个……可以进行研发，台湾……新竹，三星……，然后是英特尔……，三星做得非常糟糕，英特尔做得非常糟糕，我们可能会进入一个只有一家公司可以进行研发的世界，而那家公司已经生产了大部分芯片，他们一直在获得市场份额，但就像，这是一个关键的事情，对吧？所以，台湾发生了什么意味着世界其他地区的半导体行业，以及因此，科技依赖于台湾，这显然是不稳定的。至于英特尔，他们一直在缓慢而稳定地衰落，他们在服务器和 PC 方面处于领先地位，但现在苹果推出了 M1，Nvidia 正在发布 PC 芯片，高通正在发布 PC 芯片，在服务器方面，超大规模公司都在制造他们自己的基于 ARM 的服务器芯片，英特尔没有 AI 芯片……胜利，他们有非常小的胜利。而且他们从来没有进入移动领域，因为他们对 iPhone 说不，所有这些事情加在一起，他们已经失去了他们的工艺技术领先地位，他们领先了 20 年，现在他们至少落后了几年，他们正试图赶上，我们将看看他们的 18A、14A 策略是否奏效，他们试图超越台积电，但……英特尔只是在亏损大量资金，他们刚刚解雇了他们的 CEO，尽管 CEO 是唯一一个了解公司的人，我们拭目以待，他不是最好的，但他相对来说是一个相当不错、相当有技术的人。

**Lex Fridman:**  英特尔的大部分收入来自哪里？

**Dylan Patel:**  CPU，仍然是 PC 和数据中心 CPU。但数据中心 CPU 都将转向云计算，亚马逊、微软、谷歌正在制造基于 ARM 的 CPU，然后在 PC 方面，AMD 已经获得了市场份额，Nvidia 正在发布一款……不会成功的芯片，联发科……高通……苹果做得很好，所以他们可能会在 PC 方面受到一点挤压，尽管 PC……一般来说，我想……主要还是会坚持使用英特尔，为了 Windows 方面。

**二十、 谁将赢得 AGI 竞赛？(4:11:26)**

**Lex Fridman:** 让我们谈谈广泛的 AI 竞赛，你认为谁会赢？谁……我们谈到了谷歌……

**Nathan Lambert:** 领先者……默认的领先者一直是谷歌，因为他们的基础设施优势。

**Lex Fridman:** 好吧，在新闻中，OpenAI 是领先者，他们领先，他们拥有最好的模型，他们拥有人们可以使用的最好的模型，而且他们拥有最多的 AI 收入。

**Dylan Patel:**  OpenAI 正在获胜。

**Lex Fridman:**  那么，现在谁在通过 AI 赚钱？有人在赚钱吗？

**Dylan Patel:**  从会计利润的角度来看，微软正在赚钱，但他们正在花费大量的资本支出，你知道，这会在几年内折旧。Meta 正在赚很多钱，但这是通过推荐系统，这是 AI，但不是通过 Llama，Llama 肯定在亏损。我认为 Anthropic 和 OpenAI 显然没有赚钱，否则他们就不需要筹集资金了，他们必须筹集资金才能建造更多，尽管从理论上讲，他们正在赚钱，你知道，你在 GPT-4 上花费了几亿美元，它产生了数十亿美元的收入，所以显然它正在赚钱，尽管他们必须继续研究以获得计算效率的提升，并沿着曲线向下移动，以实现 GPT-3 的 1200 倍，你知道，也许我们现在只有几百倍，但有了 GPT-4 Turbo 和 4o，而且可能还会有另一个比 GPT-4o 更便宜的版本出现。

**Nathan Lambert:**  而且这项研究花费了大量的资金。

**Dylan Patel:**  是的，这就是……我想，这就是人们没有谈到的成本问题，当你提到模型的成本时，它不仅仅是训练或测试运行，它实际上是研究……人力……去做现在存在的推理之类的事情，他们将扩展它，他们将进行大量的研究。

**Nathan Lambert:**  我认为，你知道，人们关注回报问题，但很容易……就像，好吧，你知道，GDP 是……人类和工业资本，如果你能让智能变得便宜，那么你就可以增长很多，这是……你知道，这是……解释它的愚蠢方式，但这基本上就是投资的逻辑。

**Dylan Patel:**  我认为只有 Nvidia 实际上赚了很多钱，还有其他硬件供应商，超大规模公司都在账面上赚钱，但实际上他们正在花费更多来购买 GPU，你不知道他们是否仍然会在两年内从每个 GPU 上赚这么多钱，你不知道……你知道，突然之间 OpenAI 倒闭了，现在微软有成千上万个他们过去租给 OpenAI 的 GPU，他们自己支付了这些 GPU 的费用，通过他们……你知道，对他们的投资，这些 GPU 不再有客户了，这总是有可能的。我不相信这一点，我认为，你知道，OpenAI 将继续筹集资金，我认为其他人将继续筹集资金，因为投资……回报最终将是巨大的，一旦我们有了 AGI。

**Lex Fridman:**  所以你认为多家公司会……让……我不认为这是赢家通吃。

**Nathan Lambert:**  好的，所以不是……让我们不要称之为 AGI，无论它是什么，这是一个渐进的……

**Lex Fridman:**  超级强大的 AI。

**Nathan Lambert:**  但这是一个逐渐增加的……有用的功能集，并且……

**Lex Fridman:**  迅速增加。

**Nathan Lambert:**  迅速增加的功能集。所以你说很多公司都会……所有这些公司都在建造巨大的数据中心，这似乎很荒谬。

**Dylan Patel:**  有些公司将从 AI 中受益，但不是因为他们训练了最好的模型，就像 Meta 有很多途径可以从 AI 中受益，以及他们所有的服务，人们在那里，人们在 Meta 平台上花费时间，这是一种让每个用户每小时赚更多钱的方式。

**Lex Fridman:**  似乎谷歌、xAI、特斯拉……

**Dylan Patel:**  而且 Meta 将受益，不是直接从 AI 中受益，比如 LLM，而是从智能中受益，就像他们已经销售的产品获得了额外的智能提升。所以无论是推荐系统，还是埃隆一直在谈论的 Optimus 机器人，可能是机器人的智能，然后你在家里拥有个性化的机器人，诸如此类的事情，他认为这是一个 10 万亿美元以上的业务，在某个时候，也许……不是很快，但谁知道呢……机器人……

**Lex Fridman:**  让我们做一个……让我们做一个 TAM 分析，80 亿人，让我们得到 80 亿个机器人，让我们支付他们平均……

**Dylan Patel:**  是的，在那里，我们得到了 10 万亿，超过 10 万亿。

**Lex Fridman:**  我的意思是，你知道，如果有机器人……

**Dylan Patel:**  到处都是，为什么一定是 8……80 亿个机器人？

**Lex Fridman:**  是的，当然，当然，我会得到……我要一个机器人，你要 20 个。

**Nathan Lambert:**  我看到了这方面的用例。

**Lex Fridman:**  所以，是的，所以我猜好处在于产品的销售，这就是为什么 OpenAI 处于一个更棘手的位置，因为他们所有的……OpenAI 现在作为一个品牌的价值在于 ChatGPT，实际上对于大多数用户来说，没有那么多理由需要 OpenAI 在下一个最好的模型上花费数十亿美元，当他们可以授权 Llama 5 并且……便宜得多。所以这有点像……ChatGPT 对他们来说是一个非常有价值的实体，但他们可以……仅仅通过……应用程序赚更多的钱。

**Dylan Patel:**  聊天应用程序显然……没有太大的空间继续，对吧？标准的聊天，你只是用它来回答随机问题等等，成本继续下降，V3 是最新的……最大的，但它将得到广告的支持，就像……你知道，Llama……Meta 已经在提供 405B 服务，并且可能会亏损，但在某个时候，你知道，他们将获得……模型将变得如此便宜，以至于他们可以免费提供它们，并得到广告的支持，这就是谷歌将能够做的，显然他们有更大的影响力。所以聊天不会是唯一的用例，就像这些推理、代码、代理、计算机使用，所有这些都是 OpenAI 实际上必须去赚钱的地方，否则他们就完蛋了。但是，xAI、谷歌和 Meta 拥有这些其他产品。

**Lex Fridman:**  难道 OpenAI 和 Anthropic 最终不会消失吗？除非他们在模型方面非常出色，他们是……

**Nathan Lambert:**  但这是一个前沿……这取决于你认为 AI 的能力将走向何方，你必须不断获胜。

**Lex Fridman:**  你必须不断获胜，这……即使它们的能力正在朝着 AI 的方向迅速发展，对于 xAI 来说，在数据方面仍然有提升，对于谷歌来说，在数据方面，对于 Meta 来说，在数据方面，以及在其他产品和资金方面，就像有大量的资金……整个想法是，人类数据有点枯竭了，我们不……我们都关心自我对弈，可验证的自我……

**Dylan Patel:**  AWS 在每台机器上赚的钱并不多，对于最强大的 AI 平台来说也是如此，即使对 API 的调用如此便宜，拥有该平台仍然可以赚很多钱，有很多讨论，因为它是下一个计算层，你必须相信这一点，并且有很多讨论，token 和 token 经济学以及 LLM API 是下一个计算层，或者是经济的下一个范式，有点像能源和石油，但也有……你必须相信 API 和聊天并不是 AI 的终点，它实际上只是任务和代理和机器人技术和计算机使用，而这些才是所有价值将要实现的地方。

**Lex Fridman:**  你是否有可能……我的意思是，这一切都只是一种商品，你有一个非常薄的包装器，比如 Perplexity……开个玩笑。

**Nathan Lambert:**  有很多包装器赚了很多钱。

**Lex Fridman:**  但是，但是你认为人们是否有可能甚至忘记 OpenAI 和 Anthropic 是什么，仅仅因为……将会有围绕 API 的包装器，它只是动态地……如果模型没有进步……

**Dylan Patel:**  是的，它正在成为一种商品，DeepSeek-V3 表明了这一点，但之前的……图表也表明了这一点，Llama 3B 比 GPT-3 便宜 1200 倍，任何商业模式是 GPT-3 级别能力的人都已经死了，任何商业模式是 GPT-4 级别能力的人都已经死了。人们常说，现在正在建立的最好的企业是那些以模型变得更好为前提的企业，这将是……驾驭模型浪潮的包装器。

**Nathan Lambert:**  短期内，能够赚到最多钱的公司是找出哪种广告定位方法适用于语言模型生成的公司，我们有 Meta 广告，它们在信息流中是超定向的，而不是在特定的内容片段中，我们有谷歌使用的搜索广告，亚马逊在搜索方面的收入一直在上升，但在一个……在 ChatGPT 的回复中，目前还不清楚你如何在那里获得高质量的广告位，如果你能做到这一点，随着模型成本的下降，你可能会获得非常高的……每……收入，这完全是未开发的收入，而且在技术上还不清楚如何实现。

**Dylan Patel:**  是的，这是……我的意思是，谷歌所做的 AdSense 创新，有一天你将在 GPT 输出中看到一个广告，这将赚取数十亿美元，它可能非常微妙，它可能在对话中，就像我们现在有语音模式，它可能是某种方式，使语音引入某些东西，这更难衡量，而且需要想象力，但……

**Nathan Lambert:**  而且它不会那么……它不会显得那么阴暗，所以你会受到公众的强烈反对，诸如此类的事情，所以你必须做得足够响亮，以至于很明显这是一个广告，并平衡所有这些。所以这是一个他们正在努力解决的开放性问题，Anthropic 和 OpenAI，他们需要……他们可能不会说他们关心这个问题，他们现在不关心它，我认为像……这样的地方正在更多地试验这个。

**Lex Fridman:**  哦，有意思，当然。

**Dylan Patel:**  像 Perplexity、谷歌、Meta 关心这个，我认为 OpenAI 和 Anthropic 纯粹专注于 AGI。

**Nathan Lambert:**  代理和 AGI。

**Dylan Patel:**  如果我构建 AGI，我可以赚很多钱，或者我可以……支付一切，这是……这只是基于……回到出口管制的事情，如果你认为 AGI 还有 5 到 10 年的时间，或者更少，这些实验室认为还有两三年，显然你的……你的行动是……你知道，如果你假设他们是理性的参与者，他们大多是，你在两年 AGI 与五年与十年中所做的事情非常非常非常不同。

**二十一、 AI 智能体 (4:21:39)**

**Lex Fridman:** 你认为代理有前途吗？我们必须谈谈这个，这是……这是今年的兴奋点，代理将……这是很多商业人士使用的通用炒作术语，“AI 代理将彻底改变一切”。

**Nathan Lambert:** 好的，所以大多数情况下，代理这个术语显然被夸大了，我们已经谈了很多关于强化学习作为一种训练可验证结果的方法，代理应该意味着一些开放的东西，并且正在独立解决一项任务，并且能够适应不确定性。有很多术语“代理”被应用于像苹果智能这样的东西，我们在上次 WWDC 之后仍然没有，这是在应用程序之间进行协调，那种工具使用的东西是语言模型可以做得很好的，苹果智能，我怀疑最终会出现，这是一个封闭的领域，这是你的消息应用程序与你的照片与 AI 在后台集成，这将奏效，这已经被很多软件公司描述为代理，以进入叙事。问题是，我们可以通过什么方式让语言模型泛化到新的领域，并实时解决它们自己的问题，也许在它们进行微调时进行一些少量的训练，或者在上下文学习中，这是在提示中存储信息的想法，你可以使用学习算法来更新它，以及你是否相信这将实际推广到像我说的那样，“预订两天后去奥斯汀的旅行，我有 XYZ 限制”，并实际上信任它。我认为有一个 HCI 问题即将出现……

**Lex Fridman:**  你的预测是什么？因为我的直觉是我们离那还很远。

**Dylan Patel:**  我认为 OpenAI 的声明……你……我不知道你是否看过这五个级别，聊天是一级，推理是二级，然后代理是三级，我认为还有几个级别，但重要的是要注意，我们在聊天方面已经有几年了，我们刚刚在理论上达到了推理，我们将在这里待一两年，然后是代理。但与此同时，人们可以……人们可以尝试并像……接近下一个级别的能力，但代理是自主地做事，一次做几分钟、几小时等等，推理是一次做几十秒，然后返回一个我仍然需要验证和使用的输出，尝试……所以，最大的问题当然是……这和制造业是一样的，有所谓的六西格玛，你知道，你有多少个 9，然后你把 9 叠加在一起，就像，如果你乘以……你知道，六西格玛的步骤数，你就会得到一个……良率或类似的东西。所以，在半导体制造中，数以万计的步骤，99.99999% 是不够的，因为你乘以那么多倍，你实际上最终会得到 60% 的良率，非常低的良率，是的，或者零。代理也是如此，将任务链接在一起，每次……即使是最好的……在特别好的基准测试中也不会得到 100% 的正确率，它们会略低于这个数字，因为有很多噪音。所以你如何获得足够的 9？这与自动驾驶是一样的，我们不能拥有自动驾驶，除非它是超级地理围栏的，像谷歌的……即使那样，他们也有 一堆远程操作员来确保它不会卡住，你不能这样做，因为它没有足够的 9。自动驾驶有很多结构，因为道路有规则。

**Nathan Lambert:**  这是明确定义的，有法规。

**Lex Fridman:**  当你在谈论计算机使用时，例如对于开放的网络，或者开放的操作系统，就像没有……这是一团糟。

**Nathan Lambert:**  所以，就像……我总是对任何被赋予与人类世界、与开放的、混乱的事物互动的任务的系统持怀疑态度。

**Lex Fridman:**  如果我们不能获得足够的智能来自己解决人类世界，我们可以创建基础设施，比如……

**Nathan Lambert:**  就像我们为……多年来所做的那样，使某些工作流程成为可能。有一家公司，我不记得了，但这就是他们的宣传语，“是的，我们将成为代理失败时的人工操作员，你只需打电话给我们，我们就会解决它”，一个 API 调用。

**Dylan Patel:**  这很搞笑。

**Nathan Lambert:**  当我们有了人形机器人时，将会出现远程操作市场，世界上总会有人乐意解决它无法完成装载我的洗碗机的问题，而我不满意它，但这将只是特斯拉服务包的一部分。

**Lex Fridman:**  我只是想象 AI 代理与另一个 AI 代理交谈，一家公司有一个专门帮助其他 AI 代理的 AI 代理。

**Nathan Lambert:**  但如果你能制造出在某一步上表现出色的东西，你就可以把它们堆叠在一起，这就是为什么我……如果需要很长时间，我们将构建使之成为可能的基础设施。你看到……启动，他们与某些网站、DoorDash、OpenTable 等建立了合作伙伴关系，这些合作伙伴关系将使他们能够非常快地提升，他们的模型将在这些事情上变得非常好，这将是一个概念证明，可能会产生网络效应，更多的公司希望让 AI 更容易……

**Dylan Patel:**  一些公司会说，“不，让我们设置障碍”。

**Nathan Lambert:**  这是互联网的故事，我们已经看到了，我们现在在语言模型的训练数据中看到了这一点，公司会说，“不，你必须付钱”。

**Dylan Patel:**  像……商业……解决它。

**Nathan Lambert:**  话虽如此，我认为航空公司和酒店有很大的动力让他们的网站运行得非常好，而且他们通常不喜欢……如果你看看订购机票需要多少次点击，这太疯狂了。

**Lex Fridman:**  我不……你实际上不能再打电话给美国航空公司的代理了，他们没有电话号码，我的意思是，这在很多……在界面方面很糟糕，而且所有……想象一下，当我自己作为一个人类都感到吃力的时候，代理将能够处理那个网站，我每次尝试预订机票时都会有存在危机，我不……我认为建立一个……AI 代理将极其困难。

**Nathan Lambert:**  那是……但是想想看，美联航接受了……条款，他们必须免费提供……，用户会喜欢它，如果有一家航空公司说，“我们将花一年的时间，我们将使我们的网站具有……每次有人询问 AI 航班时，他们都会购买……航空公司，或者就像……这里有一个 API，它只暴露给 AI 代理，如果有人查询它，价格会高 10%，但我们会让你看到我们的任何航班，你可以在这里预订任何航班，给你，代理”，然后就像……我把价格提高了 10%，太棒了，我愿意说……就像，“嘿，给我订一张去……的机票”，而且……是的，没关系。

**Dylan Patel:**  我认为……你知道，计算机和现实世界以及开放的世界真的非常混乱，但如果你开始在……在狭窄的区域内定义问题，人们将能够创造出非常非常有效的东西，并大幅降低成本。现在……你知道，像家里的机器人这样的疯狂事情，你知道，这将更难做到，就像自动驾驶一样，因为有十亿种不同的失败模式。但是，你知道，可以导航一组特定网站并执行一组特定任务的代理，或者……你知道，查看你的……你知道，拍一张你的杂货……你的冰箱的照片，或者上传你的食谱，然后它会计算出从……亚马逊……全食超市订购什么，像这样的……然后这将是……我认为这将是相当快速和容易做到的。所以这将是一系列的……商业结果，并且将会有大量的……你知道，围绕人们可以……只是找出赚钱的方法的乐观情绪。

**Nathan Lambert:**  需要明确的是，这些沙盒已经在研究中存在了，有些人已经建立了所有最流行的网站的克隆，谷歌、亚马逊等等，以使其……我的意思是，OpenAI 可能在内部拥有它们来训练这些东西，这与 DeepMind 的机器人团队多年来拥有用于机器人的集群是一样的，你可以远程与机器人互动，他们只是在伦敦有一个实验室，你向它发送任务，它排列积木，你进行这项研究，显然那里有人在修理东西，但我们以前已经转动过这些自动化的曲柄，你从沙盒走向进步，然后你一次添加一个领域并进行概括。我认为在 NLP 和语言处理的历史中，指令调整和每个语言模型的任务过去就像一个语言模型完成一项任务，然后在指令调整文献中，有一个点，你开始将越来越多的任务放在一起，它就开始泛化到每个任务，我们不知道我们在这个曲线上的位置。我认为对于使用这种 RL 和可验证领域的推理，我们还处于非常早期的阶段，但我们不知道什么时候你开始训练足够多的领域，然后……更多的领域就开始工作了，你已经跨越了泛化障碍。

**二十二、 编程与 AI (4:30:21)**

**Lex Fridman:**  你对编程环境有什么看法？软件工程，你知道，这是我个人，而且我知道很多人……与 AI 互动最多的地方，当前的 CS 学生也有很多恐惧和焦虑，但这也是……

**Dylan Patel:**  这可能是 AI 收入……生产力提升最多的领域，无论是 Copilot 还是 Cursor，还是……你知道，无论是什么，或者只是标准的 ChatGPT，对吧？就像很多……我认识的程序员中，很少有人没有 ChatGPT，而且实际上其中很多人都有 200 美元的套餐，因为这……它非常适合……我认为，在这个领域，我们已经看到了，就像……基准测试，我……如果你看过这个基准测试，由一些斯坦福大学的学生制作的，我不会说它真的很难，但我不会说它很容易，我认为这需要一个已经……至少有几年……或者几年编程经验的人才能在……上做得很好，而模型在一年内从 4% 上升到了 60%。它们明年会上升到多少？它会更高，可能不会是 100%，因为同样，9 是……真的很难做到，但我们将达到某个点，然后我们将需要更难的软件工程基准测试，等等。但人们现在看待它的方式是，它可以轻松地完成代码补全，它可以做一些函数生成，并且必须对其进行审查，很好，但实际上……软件工程代理，我认为可以比任何其他代理更快地完成，因为它是一个可验证的领域，你总是可以……单元测试或编译。而且有很多不同的领域，它可以一次性检查整个代码库，这是任何工程师都无法真正做到的，只有架构师才能真正思考这些东西，真正的高级人员，他们可以定义东西，然后代理可以执行它。所以我认为软件工程成本将疯狂下降。其中一个有趣的方面是，当软件工程成本非常低时，你会得到非常不同的市场。所以在美国，你有所有这些平台……公司，Salesforce 等等，在中国，没有人使用平台……每个人都只是构建自己的堆栈，因为在中国的软件工程要便宜得多，部分原因是……你知道，人们……STEM……STEM 毕业生的数量等等，所以……所以通常来说，它只是更便宜。与此同时，用于……像代码 LLM 在中国的采用率要低得多，因为那里的工程师成本要低得多。但是，当每个公司都可以非常便宜和快速地发明自己的业务逻辑时会发生什么？你停止使用平台……你开始构建定制的、量身定制的解决方案，你非常快速地更改它们，现在突然之间，你的业务也可能更有效率了，因为你不必处理一些随机平台……的东西不起作用，并且必须调整工作流程，或者不需要 AI 的随机业务自动化案例，它只是需要构建但没有人构建的逻辑，所有这些事情都可能很快发生。我认为软件……然后另一个领域是，工业、化学、机械工程师不擅长编码，一般来说，他们的工具……半导体工程师，他们的工具已经过时了 20 年，所有的工具都在 XP 上运行，包括 ASML 光刻工具在 Windows XP 上运行，就像……你知道，很多分析都是在 Excel 中完成的，就像……伙计们，你们可以用你们拥有的所有数据和收集到的数据向前推进 20 年，并且做得更好，这只是……你需要将软件工程的工程技能交付给实际的领域专家。所以我认为这是我非常非常看好……总体上……AI 创造价值的领域。

**Nathan Lambert:**  大局是，我不认为这将是一个悬崖，就像我们谈到的……我认为一个非常好的例子……增长如何变化是当 Meta 添加故事时，Snapchat 呈指数级增长，他们添加了故事，它变平了，软件工程师，然后……上升。AI 即将到来，它可能只会变平，这不像是每个人都会失业，这很难，因为供应调整得更慢，所以学生的数量仍在增长，这将以多年的延迟进行调整，但工作岗位的数量只会转变，然后也许在 2040 年，它将……下降，但在未来几年里，永远不会有……时刻，就像软件工程师没有用了。

**Dylan Patel:**  我认为，程序员的含义以及程序员从事的工作类型也会发生变化，因为我认为……你谈到的所有事情中都需要有人参与其中，在……中有一个非常重要的人，比如纠正代码，修复……

**Nathan Lambert:**  大于上下文长度。

**Dylan Patel:**  是的，调试，还有……阅读代码，理解……指导系统，“不，不，不，你错过了重点”，在提示中添加更多内容，有点像……

**Nathan Lambert:**  是的，添加……人类设计完美的谷歌按钮，谷歌以拥有设计出如此完美的按钮的人而闻名，就像……AI 将如何做到这一点？就像，他们可以给你所有的想法……

**Dylan Patel:**  完美，很好。

**Nathan Lambert:**  我的意思是，这就是……你可以称之为品味，人类有一件事……人类可以比 AI 系统更好地弄清楚其他人喜欢什么。

**Lex Fridman:**  这就是偏好……你正在加载……

**Nathan Lambert:**  但最终，人类是最好的偏好……这就是偏好的来源。

**Lex Fridman:**  是的。

**Nathan Lambert:**  人类实际上非常擅长阅读，或者说在两件事之间做出判断，而不是……这又回到了 RL……和偏好调整的核心，对于很多问题来说，很难产生一个好的答案，但很容易看出哪一个更好，这就是我们现在使用……人类进行 AI 的方式，判断哪一个更好，这就是……对于工程来说可能是什么样子，就是……审查，这里有几个选项，这里有一些潜在的优点和缺点，他们将成为……法官。

**Dylan Patel:**  我认为我非常建议的是，人们开始……程序员开始使用 AI，并接受 AI 系统的监督者和 AI 系统合作伙伴的角色，而不是从头开始编写或根本不学习编码，只是生成东西，因为我认为实际上需要相当高的专业知识作为一名程序员才能管理日益智能的系统。

**Nathan Lambert:**  我认为是这样，然后成为某个领域的专家，当然，因为你……说真的，如果你去看看航空航天或半导体或化学工程，每个人都在使用非常糟糕的平台，非常旧的软件，就像数据科学家的工作……就像一个笑话，在很多情况下，在某些情况下，这是非常真实的，但就像……把人类能力的前沿带到你的领域，即使前沿就像来自 AI，你的领域……你处于前沿，所以就像……你必须处于某件事的前沿，然后利用……你知道，AI 的……浪潮为其他一切……

**Lex Fridman:**  哦，是的，在……方面有很多唾手可得的果实。

**Nathan Lambert:**  在……方面，在法律系统中，我的意思是，这就是为什么……令人兴奋，你必须……与一群……的人一起出去玩，他们……我的意思是，政府是如此……它……它迫切需要软件的现代化，组织数据，所有这些东西。

**Dylan Patel:**  我的意思是，在这种情况下，这是有意为之的，因为官僚主义……创造……保护权力中心，等等，但软件打破了这些障碍，所以它伤害了那些……掌握权力的人，但最终有利于人类。所以……有很多……那种领域。

**二十三、 开源 (4:37:49)**

**Lex Fridman:** 我们没有完全完成……开源，首先……

**Nathan Lambert:**  恭喜，你发布了一个新模型。

**Lex Fridman:**  是的，这个 Tulu，我会解释什么是 Tulu。Tulu 是一种杂交骆驼，当你将单峰骆驼与双峰骆驼杂交时，早在 ChatGPT 之后的早期，出现了一大批像 Alpaca、Vicuna 等模型，它们都以各种……物种命名，所以 Tulu 这个品牌已经存在多年了，它就来自于此，我们一直在开源代码的后训练前沿进行探索，这第一部分……这个版本是在秋天发布的，我们使用了……我们基于 Llama 的开放模型、开放权重模型，然后我们添加

#### P9

**Nathan Lambert:** 我们基于 Llama 的开放模型、开放权重模型，然后我们添加了我们完全开放的代码，或者完全开放的数据。有一个流行的基准测试叫做 Chatbot Arena，这通常是评估这些聊天模型的指标，它是由人类比较来自不同组织的随机模型。如果你在 11 月或 12 月查看排行榜，在前 60 个模型中，来自几十个组织，没有一个模型的后训练有开放的代码或数据，更少的或没有的……预训练数据和代码可用，但就像……后训练在这个时候更容易获得，它仍然很便宜，你可以做到。问题是，我们能把这个数字推多高？人们可以访问所有的代码和数据，这就是这个项目的动机。我们从 Llama 中吸取了经验，Nvidia 有一个 Neotron 模型，他们的后训练配方相当开放，有一些数据和一篇论文，我们把所有这些放在一起，试图创建一个人们可以将类似 GPT-4 的模型微调到他们自己领域的配方。

**Lex Fridman:**  需要明确的是，在 Tulu 的例子中，也许你也可以谈谈 Almo，但在 Tulu 的例子中，你采用的是 Llama 3 405B……

**Nathan Lambert:**  Tulu 是一系列后训练的配方，所以我们多年来已经做了多个模型。

**Lex Fridman:**  所以你开源了一切？

**Nathan Lambert:**  是的，如果你从一个开放权重的基础模型开始，整个模型在技术上是开源的，因为你不知道 Llama 放入了什么，这就是为什么我们有……我们将要讨论的独立的东西，但这只是获取人们可以放大和定制的流程的各个部分。我知道我从初创公司和企业那里听说，“好的，我可以采用这种后训练，并尝试将其应用到我的领域”。我们谈了很多关于验证器的事情，我们使用了这个想法，即具有可验证领域奖励的强化学习，RLVR，有点类似于 RLHF，我们将其应用于数学，今天的模型……就像我们将其应用于去年的 Llama 405B 基础模型，我们还有我们的其他东西，我们有我们的指令微调和偏好微调，但数学方面很有趣，就像……更容易改进这个数学基准，有一个基准测试，MATH，所有字母大写，名字很……

**Lex Fridman:**  基准测试的名字是……

**Nathan Lambert:**  你要评估的领域，我们是研究人员，我们不是……我们不是品牌战略家。这是 DeepSeek 论文中也谈到的东西，在这个更大的模型上，更容易通过这种 RL 训练引发强大的能力，然后他们将其从那个大模型中提炼到小模型，我们今天发布的这个模型，我们看到了同样的事情，我们在 AI2，我们没有大量的计算资源，我们不能一直训练 405B 模型，所以我们只做了几次运行，它们往往会奏效，这就像……它只是表明人们有很多空间可以在这些事情上发挥作用。

**Lex Fridman:**  而且你们实际上击败了 Llama 的实际版本，对吧？你们比它好得多。

**Nathan Lambert:**  是的，所以我们的……数字……我的意思是我们在这方面花了更多的时间，但我们的……数字比他们发布的 Llama 指令模型要好得多。

**Lex Fridman:**  你也说过比 DeepSeek-V3 更好。

**Nathan Lambert:**  在我们的……基准测试中，最……DeepSeek-V3 非常相似，我们有一个安全基准来了解它是否会说有害的东西等等，这就是……

**Lex Fridman:**  这会拉低……

**Nathan Lambert:**  它仍然……这就像多个基准测试的合并，或者你的意思是什么？

**Lex Fridman:**  是的。

**Nathan Lambert:**  所以我们有 10 个……就像……这是后训练中的标准做法，你选择你关心的评估，在学术界和较小的实验室中，你会有较少的评估，在公司中，你将有一个你真正关心的领域，在前沿实验室中，你将有几十个到 20 个，甚至可能像 100 个特定事物的评估。所以我们选择了一个具有代表性的……看起来像聊天的东西，精确的指令跟随，这就像只用表情符号回应，模型是否遵循奇怪的东西，比如……数学、代码，你创建了一个……像这样的套件。

**Lex Fridman:**  所以安全将是 10 个中的一个。

**Nathan Lambert:**  以及那种类型的……你有……更广泛的 AI 社区关心什么，例如，与 DeepSeek 相比，我们的……评估平均分将是 80 分，包括安全，没有安全也差不多，DeepSeek 大概是 79% 的平均分，没有安全，他们的安全分数会把它降低到……

**Lex Fridman:**  即使忽略安全，你们也击败了他们。

**Nathan Lambert:**  是的，所以这是……在内部，这就像，我不想只通过你如何塑造……基准测试来获胜，所以如果有一些人们可能不关心他们模型中的安全，安全可以……安全可以在下游，安全可以是在你为 API 托管模型时，安全是在应用程序的各个位置解决的，所以就像，如果你想说你有最好的配方，你不能只根据这些有些人可能不想要的东西来限制它，这只是……这是进步的时代，如果我们可以在以后发布一个模型，我们就有更多的时间来学习像这种 RL 技术这样的新技术，我们在秋天开始了这项工作，现在它非常流行，推理模型，开源后训练的下一步是扩大验证器，扩大数据，复制 DeepSeek 的一些结果，有……有一篇论文可以借鉴真是太棒了，这使得它容易得多，这就是学术界和封闭的前沿 AI 研究中正在发生的事情。

**Lex Fridman:**  既然你在推动开源，你认为它的未来是什么？你认为 DeepSeek 真的改变了什么吗？因为它是开源的，或者说是开放权重的，或者说正在将开源运动推向开放的方向？

**Nathan Lambert:**  这可以追溯到许可证的讨论，所以具有友好许可证的 DeepSeek-R1 是一个重大的重置，这就像我们第一次拥有一个真正清晰的前沿模型，它是开放权重的，并且具有商业友好的许可证，对下游用例、合成数据、蒸馏等没有任何限制，这在过去几年里，自从 ChatGPT 出现以来，在 AI 的历史上从未有过这种情况。有一些模型处于前沿之外，或者有一些奇怪的许可证，你不能真正使用它们。

**Lex Fridman:**  所以……是不是……Meta 的许可证几乎是允许的，除了五家公司？

**Nathan Lambert:**  而且还有……这涉及到什么是开源 AI，Llama 许可证中也有使用案例限制，它说你不能将它用于特定的事情。所以如果你来自开源软件背景，你会说那不是一个开源许可证。

**Lex Fridman:**  这些都是什么样的东西？它们是不是像……

**Nathan Lambert:**  在这一点上，我记不清了。

**Lex Fridman:**  竞争对手？

**Nathan Lambert:**  过去是军事用途，他们取消了，为了……它会是像……你知道的……儿童……材料，这就是被禁止的那种类型，但这足以让一个有开源背景的人说这不是一个开源许可证。而且 Llama 许可证还有一个可怕的事情，如果你接触了 Llama 模型，你必须将你的模型命名为 Llama，所以这是品牌方面的事情。所以如果一家公司使用 Llama，从技术上讲，许可证规定他们应该在他们的应用程序底部说“用 Llama 构建”，从营销的角度来看，这只是……这只会造成伤害，作为一个研究人员，我可以忍受它，我喜欢……它说……我们所有的……关于这个版本的所有材料上都有，但这就是为什么我们需要真正开放的模型。这就是……我们不知道 DeepSeek-R1 的数据……

**Lex Fridman:**  所以你是说我不能……你知道，便宜地复制 Llama 并假装是我的，但我可以用中国模型这样做？

**Nathan Lambert:**  是的，当然，这就是我要说的，这就是为什么它就像……我们想要这个整体……开放语言模型……的目标是尝试保持模型，在那里一切都是开放的，数据尽可能接近前沿。所以我们受到计算的限制，我们受到人员的限制，我们依赖于从……这样的人那里获得见解，他告诉我们对输出进行 RL，我们可以实现这些大的飞跃，但这需要很长时间来推动开源的前沿。从根本上说，我认为这是因为开源 AI 没有像开源软件那样的反馈循环。我们谈到了开源软件的安全性，也只是因为你构建了一次，你就可以重复使用它，如果你去一家新公司，有很多好处。但如果你开源了一个语言模型，你有这些数据，你有这些训练代码，别人来构建和改进它并不那么容易，因为你需要花费大量的计算，你需要有专业知识。所以，在有开源 AI 的反馈循环之前，这似乎主要是一项意识形态使命，就像马克·扎克伯格那样，美国需要这个，我同意他的观点，但在动机是意识形态的时代，我们需要利用并围绕……建立这个生态系统，你从看到语言模型数据中获得了什么好处？而且没有太多关于……我们打算很快推出一个演示，在那里你可以查看一个……模型和一个查询，并查看与它相似的预训练数据，这在法律上是有风险和复杂的。但就像，看到 AI 训练的数据意味着什么？这很难解析，它是数 TB 的文件，就像我……我不知道我会在那里找到什么，但这就是我们需要作为一个生态系统做的事情，如果人们希望开源 AI 在财务上有用的话。

**二十四、 Stargate (4:47:01)**

**Lex Fridman:**  我们没有真正谈论 Stargate，我很想听听你对新政府、特朗普政府的看法，所有这些……从美国方面为支持 AI 基础设施所做的一切，以及不同 AI 公司的努力，你对 Stargate 有什么看法？我们应该如何看待 Stargate？山姆有钱吗？

**Dylan Patel:**  所以我认为 Stargate 是一个不透明的东西，它肯定没有 5000 亿美元，甚至没有 1000 亿美元。

**Lex Fridman:**  所以他们宣布的是这个 5000 亿美元的数字？

**Dylan Patel:**  拉里·埃里森、山姆·奥特曼和特朗普说的，他们感谢了特朗普，它使用了……特朗普确实采取了一些行政措施，这些措施确实显著提高了这方面的建设速度。你知道，他采取的一项行政措施是，在联邦土地上，你基本上可以建造数据中心和……你知道，几乎就这样，然后许可程序基本上消失了，或者你在事后提交。所以，你知道，再举一个……例子，如果你去过旧金山的……，那是一个美丽的地区，如果你愿意，你可以在那里建造一个发电厂和一个数据中心，因为那是联邦土地，它曾经是一个军事基地，但你知道，显然这会……你知道，这会让人……生气，不管怎样，特朗普让这一切变得容易得多。一般来说，德克萨斯州是美国唯一一个不受监管的电网，所以……也使人们能够更快地建造。此外，联邦法规正在……你知道，正在下降。所以 Stargate 是基于……这就是为什么整个……现在他们如何得出 5000 亿美元的数字，我无法理解，他们如何得出 1000 亿美元的数字在某种程度上是有道理的，实际上这里有一张很好的表格，我想展示一下，在……Stargate 那篇文章中，这是最新的……

**Lex Fridman:**  好的。

**Dylan Patel:**  所以，这张表格解释了发生了什么，Stargate 位于德克萨斯州的阿比林，前 1000 亿美元……该站点有 2.2 吉瓦的电力，大约 1.8 吉瓦的电力……你知道，消耗，每个 GPU，他们有……大约……甲骨文已经在 Stargate 出现之前建造了这其中的第一部分，需要明确的是，他们已经建造了一年，他们试图把它租给埃隆，事实上，但埃隆说，“这太慢了，我需要更快”，所以他去了孟菲斯。所以……能够通过这个叫做 Stargate 的奇怪的合资企业获得它，他们最初只与甲骨文签署了该集群第一部分的协议，该集群的第一部分……大约是 50 亿到 60 亿美元的服务器支出，然后还有大约 10 亿美元的数据中心支出，但是……然后同样，如果你用接下来两代 Nvidia 芯片 GB200、GB300、VR200 填满整个 1.8 吉瓦，并且你完全填满它，那最终大约是 500 亿美元的服务器成本，再加上数据中心的成本，加上维护成本，加上运营成本，加上……所有这些东西，这就是 OpenAI 得出他们 1000 亿美元的……他们谈到了 1000 亿美元是第一阶段，这就是这个德克萨斯州阿比林的数据中心，1000 亿美元的总拥有成本，“据称”，所以这不是资本支出，这不是投资，这是 1000 亿美元的总拥有成本。然后还会有未来的阶段，他们正在寻找比这 2.2 吉瓦更大的其他地点，在德克萨斯州和其他地方，所以他们没有……你知道，完全忽略这一点，但他们所说的 1000 亿美元是用于第一阶段的，我认为这会发生。他们甚至还没有这笔钱，此外，这不是 1000 亿美元，这是 500 亿美元的支出，然后是 500 亿美元的运营成本、电力等，租赁价格等，因为他们从 Stargate 合资企业那里租用 GPU。

**Lex Fridman:** 他们实际上有多少钱？

**Dylan Patel:** 软银……软银将投资，甲骨文将投资，……将投资，……承诺投入 190 亿美元，每个人都知道他们在上一轮融资中只有 60 亿美元，还有 40 亿美元的债务。但是有……就像有新闻说软银可能会向 OpenAI 投资 250 亿美元，所以这是其中的一部分，所以 190 亿美元可以来自那里。所以……根本没有钱，需要明确的是，……公司没有任何……这 500 亿美元，他们有 0 美元，他们有法律义务投入 190 亿美元的资本支出，或者投入到合资企业中，然后剩下的他们将通过从合资企业租用 GPU 来支付。然后是甲骨文，甲骨文有很多钱，他们正在完全建造第一部分，他们自己支付费用，这 60 亿美元的资本支出，10 亿美元的……但他们……他们将支付第一部分的费用，他们正在为此买单。至于剩下的部分，我不知道拉里想花多少钱，在任何时候他都可以退出，你知道，这是……这是完全自愿的，所以任何时候……但这上面没有签字，但他有可能贡献数百亿美元，需要明确的是，他有钱，甲骨文有钱。然后是……这是阿联酋的主权基金，从技术上讲，它有 1.5 万亿美元用于投资 AI，但同样，我不知道这笔钱有多真实。

**Nathan Lambert:** 而软银没有 20 亿美元的现金，他们必须减持他们在 Arm 的股份，这是……你知道，CPU 的领导者，他们将其……

**Dylan Patel:**  这显然是他们一直想做的事情，他们只是不知道在哪里重新部署资金，减持 Arm 的股份很有意义，所以他们可以卖掉它，并投资于此，如果他们想的话，并投资于……如果他们想的话。至于资金……你知道，第一批 100,000 个 GB200 集群是……可以获得资金的，在那之后的一切……

**Nathan Lambert:**  悬而未决。

**Dylan Patel:**  悬而未决，资金即将到来，我个人确实相信，这是一个信念，他们将发布更好的模型，并能够筹集更多的……

**Lex Fridman:**  好的。

**Dylan Patel:**  但就像……实际情况是，埃隆是对的，这笔钱并不存在。

**Lex Fridman:**  美国政府与这一切有什么关系？特朗普与这一切有什么关系？他只是一个……

**Dylan Patel:**  炒作的人？特朗普正在减少监管，以便他们能够更快地建造它，他允许他们这样做，因为任何这种规模的投资都将涉及反垄断之类的东西，所以显然他会允许他们这样做，他将使法规实际上允许建造。我不相信美国政府在这上面花了任何钱。

**Nathan Lambert:**  所以，我认为他也只是营造了一种普遍的氛围，即监管将减少，现在是建设的时代，所以如果你是一个建设者，你想创造东西，你想发布东西，现在是时候了。所以，我们已经……在我们的数据中，这个 1.8 吉瓦的数据中心已经存在一年多了，我们一直在……你知道，把它发送给我们所有的客户，包括许多正在建造数吉瓦数据中心的公司，但这还不足以……也许高管们……看到 5000 亿美元，1000 亿美元，然后每个人都在问他们，所以这可能会刺激……你知道，一场更快的军备竞赛，因为已经有一场军备竞赛了，但这个……1000 亿、5000 亿美元的数字，特朗普在电视上谈论它，可能会刺激军备竞赛变得更快，更多的投资者涌入等等。所以我认为你是对的，从这个意义上说，OpenAI……或者说，特朗普有点像……你知道，支持……人们将建造更多，他的行动将让人们建造更多。

**二十五、 AI 的未来 (4:54:30)**

**Lex Fridman:**  对于未来几年，无论是集群建设方面，还是 AI 方面的突破，你有什么期待？

**Nathan Lambert:**  就像……

**Lex Fridman:**  你能想象的未来几年，2 年、3 年、4 年，最好的可能是什么样子？它可以是非常具体的技术性的东西，比如……在……方面的突破，或者它可以只是……规模……

**Dylan Patel:**  是的，我的意思是，这令人印象深刻……集群，我真的很喜欢跟踪供应链，以及谁参与了什么，我真的很喜欢……这真的很有趣，看看数字、成本、谁在建造什么产能，帮助他们弄清楚他们应该建造多少产能，赢得交易，战略性的东西，这真的很酷。我认为在技术上，有很多围绕网络方面的事情让我感到非常兴奋，无论是光学还是电子，你知道，越来越近，无论是共封装光学还是某种形式的新型交换，这是……

**Lex Fridman:**  集群内部？

**Dylan Patel:**  集群内部，是的，还有多数据中心训练，你知道，人们在这些数据中心之间铺设了如此多的光纤，并用如此多的带宽点亮它，有很多有趣的事情正在发生。电信自 5G 以来一直非常无聊，现在又变得非常令人兴奋了。在……方面，你能给我介绍一下速度方面的事情吗？所以内存的速度与互连的速度与数据中心之间的光纤速度相比如何？这些是否相差几个数量级？我们是否可以在某个时候趋同到一个地方，让这一切感觉就像一台计算机？

**Dylan Patel:**  不，我不认为这是可能的，它只会变得更难编程，而不是更容易，它只会变得更加困难和复杂，而且层次更多。人们喜欢使用的总体形象是这种内存层次结构，所以片上……非常靠近，位于芯片内部，你有寄存器，它们在一些计算元件之间共享，然后你有缓存，它们在更多的计算元件之间共享，然后你有……你知道，内存，比如 HBM 或……像 DDR 内存之类的东西，这在整个芯片之间共享，然后你可以有……你知道，在许多芯片之间共享的内存池，然后是存储，你不断地……你知道，跨数据中心、数据中心内部、芯片内部的访问延迟是不同的，所以你显然总是……你总是会有不同的……针对这个的编程范式，这并不容易，编程这些东西将会很困难，也许……可以提供帮助，对吧？用编程这个……但是……思考它的方式是，有……有点像……你向一个任务添加的元素越多，你就越……你不会得到强大的技能，如果我把芯片数量加倍，我不会得到 2 倍的性能，这只是……计算的现实，因为存在低效率。有很多有趣的工作正在进行，以使其不是……你知道，使其更具线性，无论是使芯片更加紧密地联网在一起，还是……你知道，很酷的编程模型，或者你可以在模型方面做的很酷的算法方面的事情，DeepSeek 做了一些非常酷的创新，因为他们在互连方面受到了限制，但他们仍然需要……你知道，并行……对吧？就像所有……你知道，每个人都在做一些事情，谷歌有很多工作，每个人都有很多这方面的工作，这些东西在模型、工作负载和创新方面都非常令人兴奋。硬件固态变压器对于电源方面很有趣，电池方面有很多东西，你知道，我认为……我认为当你看看……如果你看看计算堆栈的每一层，无论是从光刻和……一直到制造，再到光学，再到网络，再到电源，再到变压器，再到冷却，再到……你知道，网络，你一直往上看，你知道，即使是数据中心的空调也在创新，就像……有……铜缆正在创新，你不会想到它，但铜缆就像……有一些创新正在发生，比如你可以打包它们的密度，就像……所有这些堆栈的层次，一直到模型，人类的进步正处于前所未有的速度。

**Lex Fridman:**  我只是想象你坐在……的某个地方，到处都是屏幕，只是监控着供应链，所有这些集群……你收集的所有信息，我的意思是，你……一个大团队……

**Dylan Patel:**  有一个大团队。

**Lex Fridman:**  我的意思是，你……你做了一些非常了不起的工作，SemiAnalysis，我的意思是，只是……把你的手指放在人类文明在数字世界中的脉搏上，这很酷，就像……去感受……

**Dylan Patel:**  感受到我们所有人，就像……

**Lex Fridman:**  感受到 AI。

**Dylan Patel:**  感受到……

**Lex Fridman:**  从……模因到现实。Nathan，有没有什么……你期待的突破？

**Nathan Lambert:**  我有……当……的时候，我有时间思考这个问题，他没有听我说，我知道……我知道这是……现实情况是，训练模型非常有趣，因为有这么多唾手可得的果实，让我的工作有趣的事情……我训练模型，我写关于模型正在发生的事情的分析，这很有趣，因为显然还有很多进步的空间，我这样做的真正动机……在某个我可以分享东西的地方，只是因为……我不相信那些说“相信我，我们会让 AI 变得更好”的人，就像“我们是……我们将做到这一点，你可以信任我们，我们将拥有所有的……”，我希望未来有更多的人对 AI 有发言权，并且能够理解它，这有点……这并不像……这是一件积极的事情，这只是……所有……真的很有趣，就像……训练模型很有趣，把人们带进来很有趣，但实际上就像……如果 AI 将成为我一生中最强大的技术，那么我们需要让很多人参与到它的制造中，并使它……使它尽可能开放。

**Lex Fridman:**  尽可能开放，是的。

**Nathan Lambert:**  我对过去几年的解读是，更多的开放性将有助于 AI 生态系统，让更多的人了解正在发生的事情，无论是来自非 AI 领域的研究人员，还是政府，还是其他什么，这并不意味着开放将永远是答案，我认为那时它将重新评估……什么是 AI 面临的最大问题，并以不同的角度来看待我们所处的疯狂旅程。

**Lex Fridman:**  对我来说，即使从用户体验来看，任何时候你有……就像……说的，“啊哈”时刻，就像魔术一样，看到推理、思维链，就像有一些东西……从根本上来说，这真的很美，这就像一面镜子，让我们看到……哦，它正在解决……智能，这是……这些公司的陈词滥调般的目标，你开始明白为什么我们人类是特别的，我们内在的智能是特别的，就目前而言，为什么我们在……我们似乎是有意识的，而 AI 系统目前还没有，我们必须……我们必须探索这个谜团，所以这只是……探索这些问题真的很酷，我认为我从未想过……这在我的有生之年甚至可能……这就像……这真的感觉像是 AI，这太不可思议了。

**Nathan Lambert:**  我开始学习 AI 是为了让……四轴飞行器飞行，就像……学会飞行，它就像……它学会了向上飞，它会撞到天花板，停下来，抓住它，就像……好吧，与现在发生的事情相比，这真的很愚蠢，现在你可能可以用自然语言告诉它学习飞行，它会生成执行此操作所需的控制算法，可能……有一些低级的阻碍因素，比如我们必须为……做一些奇怪的事情，但你可以……你肯定……我们的机器人对话，是的，当你必须在实际的物理世界中互动时，这很难。

**Lex Fridman:**  是什么让你对人类文明的未来充满希望？展望未来 10 年、100 年、1000 年，你认为我们能坚持多久？你认为我们能坚持 1000 年吗？

**Nathan Lambert:**  人类肯定会在 1000 年后存在，我认为有很多种方式可能会发生非常糟糕的事情，人类的数量会少得多，但人类非常擅长生存，发生了很多事情……这是真的，我不认为它们一定是……我们擅长……风险的长期……归因，但当风险变得迫在眉睫时，我们往往会想出办法，哦，是的，出于这个原因，我……就像……对于像 AGI 超级……递归改进来杀死我们所有人之类的东西存在物理约束，我是……出于物理原因，以及人类以前是如何解决问题的，我不太担心 AI 接管，还有其他国际性的事情令人担忧，但只是……基本的人类善良，并试图放大这一点，我喜欢……我们正处于一个不稳定的时代，我的意思是，如果你把人类作为一个整体来看，有些时候事情会倒退，有些时候什么都不会发生，我们正处于一个……现在应该是非常积极的轨道上。

**Dylan Patel:**  是的，似乎有进步，但就像……就像权力一样，会有……人类苦难的激增，我们希望尽量减少……激增的数量，一般来说，人类将……遭受的痛苦要少得多，我对此非常乐观。我确实担心……你知道，随着 AI 变得越来越普遍和强大，会出现技术……类型的东西，那些控制它的人可以做更多的事情，也许它不会杀死我们所有人，但在某个时候，每个非常有权势的人都会想要一个脑机接口，这样他们就可以与 AGI 互动，以及它的所有优势，以更多的方式，并将它的思想与……你知道，有点像……以及它的能力，或者那个人的能力……可以比其他任何人都更好地利用这些能力，因此……你知道，这不会是一个人统治他们所有人，但它将是……你知道，我担心的事情是，它将是少数人，你知道，数百人、数千人、数万人，也许数百万人统治……剩下的任何人，以及围绕它的经济。我认为这就像……这可能是更令人担忧的事情，人机结合使个人能够对世界产生更大的影响，这种影响既可以是积极的，也可以是消极的。一般来说，人类对世界产生了积极的影响，至少对社会产生了积极的影响，但个人有可能造成如此负面的影响，而 AGI，至少正如我认为实验室所定义的那样，这不是一个失控的有感知力的东西，而只是一个可以非常高效地完成大量任务的东西，放大了某人造成极端破坏的能力。但总的来说，我认为它将被用于……你知道，逐利动机，这将减少……这将增加事物的丰富性和供应，从而减少痛苦。

**Nathan Lambert:**  是的，这就是目标。

**Lex Fridman:**  在时间线上滚动……只是停滞，保持世界的现状，这是一个积极的结果。

**Nathan Lambert:**  就像，如果我有食物管和……滚动，而且我很开心，那是一个积极的结果。

**Dylan Patel:**  同时向宇宙扩张。

**Lex Fridman:**  嗯，这是一个有趣的时代，感谢你推动人类的可能性前沿，感谢你今天的谈话，这很有趣。

**Nathan Lambert:**  感谢邀请我们。

**Dylan Patel:**  感谢邀请我们。

**Lex Fridman:**  感谢收听 Dylan Patel 和 Nathan Lambert 的这次谈话，为了支持这个播客，请查看我们在简介中的赞助商。现在，让我引用理查德·费曼的一句话与你们共勉：“对于一项成功的技术来说，现实必须优先于公关，因为大自然是不可欺骗的。”感谢收听，希望下次再见。
