
Andrej Karpathy 与 Lex Fridman 的深度对话：从 Tesla AI 到 AGI 的未来
- 原文标题：Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI | Lex Fridman Podcast #333 - YouTube
- 链接：[Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI | Lex Fridman Podcast #333 - YouTube](https://www.youtube.com/watch?v=cdiD-9MMpb0)

- **文章类别**：访谈实录

---

## **内容整理**


```markdown
文章简介
│   ├── Andrej Karpathy 作为 Tesla AI 前任主管及 OpenAI 和斯坦福大学的杰出成员，分享了对人工智能、自动驾驶、Optimus 机器人以及外星生命和 AGI（人工通用智能）的看法。
│   └── 访谈提出了关于物理学潜在漏洞、合成智能作为人类发展的下一个阶段，以及宇宙可能是一个有待解开的谜题等观点。
├── 神经网络的本质与功能
│   ├── 神经网络是大脑的数学抽象，本质上是一个简单的数学表达式，包含可调节的“旋钮”类似大脑突触，通过训练来调整这些旋钮以执行特定任务。
│   └── 讨论了神经网络在处理复杂问题时展现出的惊人能力，如在大规模数据集上的下一个词预测任务。
├── 物理学与智能生命的探讨
│   ├── 提到物理学可能存在可被利用的“漏洞”，暗示了通过某种方式可以解开宇宙的谜题。
│   ├── 探讨了宇宙中智能生命的普遍性，包括外星生命的可能性，以及人类在宇宙中的位置和意义。
├── 自动驾驶技术
│   ├── 讨论了自动驾驶技术的现状和挑战，包括对环境的感知、预测和决策过程。
│   └── 强调了数据集的重要性，以及如何通过大规模数据集训练神经网络来提高自动驾驶系统的性能。
├── AGI（人工通用智能）
│   ├── 分析了 AGI 的可能性和发展方向，包括其对人类社会的潜在影响。
│   └── 探讨了 AGI 可能具有的特性，如意识、情感和创造力等。
├── 机器学习与数据集
│   ├── 讨论了机器学习中数据集的作用，以及如何通过数据集来训练和优化模型。
│   └── 提到了在机器学习研究中，数据集的局限性和未来的发展方向。
└── 个人经历与未来展望
    ├── Andrej Karpathy 分享了他在 Tesla 的工作经历，以及为什么选择离开并寻求新的技术挑战。
    └── 对未来的技术发展方向，包括 AGI 和人类机器人的发展进行了预测和展望。
```

#人工智能 ， #自动驾驶 ， #AGI ， #神经网络


```
├── 0:00 介绍 & 赞助商
│   ├── 介绍 Andrej Karpathy
│   └── 赞助商信息
├── 0:58 神经网络
│   ├── 神经网络的定义与工作原理
│   ├── 神经网络的“旋钮”与可塑性
│   ├── 大型神经网络的涌现行为
│   ├── 神经网络的优化与智慧
│   └── 神经网络与大脑的类比
├── 6:01 生物学
│   ├── 人工神经网络与生物神经网络的对比
│   │   ├── 目标的差异：压缩 vs 生存
│   │   └── 优化过程的差异
│   ├── 地球生命起源与演化的探讨
│   └── 人类快速发展的思考
├── 11:32 外星人
│   ├── 费米悖论与外星文明存在的可能性
│   ├── 人类未发现外星文明的可能原因
│   │   ├── 探测能力有限
│   │   └── 星际旅行的困难
│   └── 对待外星文明的态度：保护 vs 毁灭
├── 21:43 宇宙
│   ├── 宇宙是一个谜题，AI 将解开它
│   ├── 物理学可能存在的“漏洞”
│   └── 宇宙的确定性与随机性
├── 33:34 Transformer
│   ├── Transformer 的通用性与强大能力
│   ├── Transformer 的设计原理：表达能力、可优化性、效率
│   ├── 残差连接的作用
│   └── Transformer 的稳定性和广泛应用
├── 41:50 语言模型
│   ├── 语言模型的目标与工作原理
│   ├── 大型语言模型的涌现属性
│   ├── 语言模型的“理解”能力
│   ├── 互联网数据与 AGI 的关系
│   └── World of Bits 项目与 AI 交互
├── 52:01 机器人 (Bots)
│   ├── 机器人的发展与威胁
│   └── 数字签名与身份验证的必要性
├── 58:21 谷歌的 LaMDA
│   ├── LaMDA 事件的警示意义
│   └── 人类与 AI 的情感联系
├── 1:05:44 软件 2.0
│   ├── 神经网络取代传统软件的趋势
│   ├── 软件 2.0 的编程范式
│   └── 软件 2.0 的开发工具和流程
├── 1:16:44 人工标注
│   ├── 人工标注在 AI 系统训练中的作用
│   └── 人工标注任务的设计
├── 1:18:41 摄像头视觉
│   ├── 摄像头的优势：廉价、信息丰富
│   └── 视觉系统的挑战：像素到三维世界的转换
├── 1:23:46 特斯拉的数据引擎
│   ├── 数据引擎的工作原理与作用
│   └── 数据引擎的执行与优化
├── 1:27:56 特斯拉视觉
│   ├── 移除雷达和超声波传感器的原因：简化系统
│   └── 视觉作为自动驾驶主要传感器的必要性和充分性
├── 1:34:26 埃隆·马斯克
│   ├── 从埃隆·马斯克身上学到的东西：高效运营、对抗熵
│   └── 埃隆·马斯克的领导风格：简化、专注、快速行动
├── 1:39:33 自动驾驶
│   ├── 自动驾驶的挑战与时间表
│   └── 自动驾驶的可行性与发展方向
├── 1:44:28 离开特斯拉
│   ├── 离开特斯拉的原因：追求更具技术性的工作
│   └── 对未来重返特斯拉持开放态度
├── 1:49:55 特斯拉的 Optimus
│   ├── Optimus 的潜力和挑战
│   ├── Optimus 与自动驾驶技术的联系
│   └── Optimus 的发展策略：渐进式、创造收入
├── 1:59:01 ImageNet
│   ├── ImageNet 的历史贡献与局限性
│   └── 对未来基准数据集的展望
├── 2:01:40 数据
│   ├── 模拟数据的作用
│   └── 预训练模型与数据效率
├── 2:11:31 一天中的生活
│   ├── 工作习惯：夜猫子、专注、避免干扰
│   ├── 信息获取：新闻、技术文章
│   └── 饮食习惯：间歇性禁食、植物性饮食
├── 2:24:47 最佳 IDE
│   ├── VS Code 与 GitHub Copilot
│   └── Copilot 的作用与局限性
├── 2:31:53 arXiv
│   ├── arXiv 的作用：快速发布和分享研究成果
│   └── 同行评审：社区 vs 期刊
├── 2:36:23 给初学者的建议
│   ├── 关注投入时间，而不是纠结于方向
│   └── 将自己与过去的自己进行比较
├── 2:45:40 人工通用智能 (AGI)
│   ├── 对 AGI 发展的乐观态度
│   ├── 实现 AGI 的可能途径：互联网 vs 机器人
│   └── 意识的涌现与伦理问题
├── 2:59:00 电影
│   ├── 喜欢的电影及其原因
│   └── 对天网和人工智能战争的担忧
├── 3:04:53 人类文明的未来
│   ├── 多星球物种的可能性
│   ├── 虚拟现实的吸引力
│   └── 人类价值观和生活方式的多样化
├── 3:09:13 图书推荐
│   ├── 《生命的跃升》、《复杂生命的起源》、《自私的基因》
│   └── 教科书的作用与局限性
├── 3:15:21 对年轻人的建议
│   ├── 专注于自己感兴趣的事情并投入大量时间
│   └── 找到让自己充满活力的事情
├── 3:17:12 机器学习的未来
│   ├── 继续专注于人工智能领域
│   └── 利用人工智能解决其他问题
└── 3:24:00 生命的意义
    ├── 探索宇宙的奥秘
    ├── 延长寿命以获得更多时间思考
    └── 选择自己的冒险，追求幸福
```


## 内容提要

**0:00 - 介绍 & 赞助商**

*   介绍 Andrej Karpathy，前特斯拉 AI 总监，曾在 OpenAI 和斯坦福任职。
*   赞助商：
    *   Eight Sleep
    *   BetterHelp
    *   Fundrise
    *   Athletic Greens

**0:58 - 神经网络**

*   神经网络是大脑的数学抽象，由一系列矩阵乘法和非线性函数组成。
*   神经网络的“旋钮”对应于大脑中的突触，是可训练和修改的。
*   大型神经网络在处理复杂问题（如互联网上的下一个单词预测）时，会展现出令人惊讶的涌现行为。
*   神经网络在内部通过优化来“学习”解决问题，这些“旋钮”的配置蕴含着关于数据的深层智慧。
*   GPT 等神经网络通过预测下一个单词来学习，可以根据提示解决各种问题。
*   Andrej 对神经网络与大脑的类比持谨慎态度，认为两者是通过不同的优化过程产生的。

**6:01 - 生物学**

*   Andrej 对将人工神经网络与生物神经网络进行类比持谨慎态度。
*   人工神经网络的目标是压缩数据，而生物神经网络的目标是生存。
*   地球上生命的起源和演化是一个非凡的故事，从地球的形成到人类的出现。
*   Andrej 认为人类的快速发展和建立技术社会是值得深入研究的。

**11:32 - 外星人**

*   Andrej 思考费米悖论，认为宇宙中可能存在大量技术文明。
*   Andrej 认为我们尚未发现外星文明的原因可能是我们的探测能力有限，以及星际旅行的极端困难。
*   Andrej 认为，即使发现外星文明，也不应该轻易毁灭它们，因为它们是独特且珍贵的复杂系统。

**21:43 - 宇宙**

*   Andrej 认为宇宙是一个谜题，而人工智能将解开这个谜题。
*   Andrej 认为物理学可能存在“漏洞”，人工智能可能会找到这些漏洞。
*   Andrej 认为宇宙可能是某种确定的系统，从大爆炸演化到超级智能的复制器。
*   Andrej 认为宇宙是确定的，看起来随机的现象实际上是确定的。

**33:34 - Transformer**

*   Transformer 是一种通用的神经网络架构，可以处理各种感官模态的数据，如视频、图像、语音和文本。
*   Transformer 是一种通用的、可微的、可优化的、高效的计算机。
*   Transformer 的设计使其在正向传播中具有表达能力，在反向传播中可优化，并在硬件上高效运行。
*   Transformer 架构中的残差连接使其能够快速学习短算法，并在训练过程中逐渐扩展到更长的算法。
*   Transformer 架构在过去几年中非常稳定，并被广泛应用于人工智能领域。

**41:50 - 语言模型**

*   语言模型的目标是预测序列中的下一个单词。
*   大型语言模型（如 GPT）在大型文本数据集上进行训练，展现出涌现的属性，例如上下文学习。
*   语言模型可以“理解”文本中的上下文，以做出准确的预测。
*   互联网上有大量的文本数据，但可能不足以训练出足够强大的 AGI。
*   Andrej 认为，让 AI 系统与互联网交互（如 World of Bits 项目）可能有助于学习。

**52:01 - 机器人 (Bots)**

*   随着人工智能技术的发展，网络上的机器人将会越来越强大，并且难以与人类区分。
*   未来可能需要数字签名等技术来证明身份。
*   Andrej 对机器人的发展持谨慎乐观的态度，认为需要建立防御机制来应对潜在的风险。

**58:21 - 谷歌的 LaMDA**

*   一位谷歌工程师声称 LaMDA 具有感知能力，这可以看作是一个预警信号。
*   随着人工智能技术的发展，越来越多的人可能会与人工智能建立情感联系。
*   当前的语言模型还没有长期目标，但它们可以被用来创造各种各样的文本。

**1:05:44 - 软件 2.0**

*   神经网络正在越来越多地取代传统软件，这被称为“软件 2.0”。
*   在软件 2.0 中，程序的“编写”是通过积累训练数据集和制定目标函数来实现的。
*   软件 2.0 需要新的开发工具和流程，例如数据标注、模型训练和部署。

**1:16:44 - 人工标注**

*   人工标注在训练自动驾驶系统等复杂人工智能系统中发挥着重要作用。
*   特斯拉的标注团队从零发展到一千多人。
*   人工标注的任务设计需要考虑人类的优势和局限性。

**1:18:41 - 摄像头视觉**

*   摄像头是一种廉价且信息丰富的传感器，适用于自动驾驶等任务。
*   视觉是自动驾驶中最高带宽的传感器。
*   从像素到三维世界的转换是一个难题，需要强大的神经网络来解决。

**1:23:46 - 特斯拉的数据引擎**

*   数据引擎是一个类似生物过程的系统，用于完善神经网络的训练数据集。
*   数据引擎通过不断迭代和改进数据集来提高系统的性能。
*   数据引擎的执行需要一个了解其基本原理的工程团队。

**1:27:56 - 特斯拉视觉**

*   移除雷达和超声波传感器等硬件可以简化系统，降低成本，并提高效率。
*   视觉是自动驾驶中必要且充分的传感器。
*   其他公司使用高分辨率地图的方法可能难以扩展到全球范围。

**1:34:26 - 埃隆·马斯克**

*   Andrej 从埃隆·马斯克身上学到了如何高效地运营组织和对抗熵。
*   埃隆·马斯克擅长简化流程，推动快速行动，并设定雄心勃勃的目标。

**1:39:33 - 自动驾驶**

*   自动驾驶是一个难题，难以预测其发展时间表。
*   自动驾驶是可行的，特斯拉团队正在朝着这个目标前进。

**1:44:28 - 离开特斯拉**

*   Andrej 离开特斯拉是为了追求更具技术性的工作，并专注于 AGI。
*   Andrej 对未来重返特斯拉持开放态度，可能会参与 Optimus 等项目。

**1:49:55 - 特斯拉的 Optimus**

*   Optimus 是一个雄心勃勃的项目，需要很长时间才能实现，但具有巨大的潜力。
*   Optimus 可以利用特斯拉在自动驾驶方面的技术和经验。
*   Optimus 的发展需要逐步推进，并在过程中创造收入。

**1:59:01 - ImageNet**

*   ImageNet 是一个重要的基准数据集，推动了深度学习的发展。
*   ImageNet 已经基本被“解决”了，需要新的基准数据集来推动该领域的发展。

**2:01:40 - 数据**

*   模拟数据在训练神经网络中具有一定的作用，但其重要性可能有限。
*   预训练的大型神经网络可以更有效地利用少量数据进行学习。

**2:11:31 - 一天中的生活**

*   Andrej 是一个夜猫子，喜欢在凌晨工作，因为那时干扰较少。
*   Andrej 会花几天时间专注于一个问题，并让这个问题充满他的“工作记忆”。
*   Andrej 会阅读新闻和技术文章，但对这种做法的益处持怀疑态度。
*   Andrej 采用间歇性禁食，并倾向于植物性饮食。

**2:24:47 - 最佳 IDE**

*   Andrej 认为 VS Code 是目前最好的 IDE，并喜欢使用 GitHub Copilot。
*   Andrej 认为 Copilot 可以帮助程序员提高效率，但需要谨慎使用。

**2:31:53 - arXiv**

*   arXiv 是一个预印本服务器，可以快速发布和分享研究成果。
*   Andrej 认为，在人工智能领域，同行评审可以通过社区的力量快速进行。

**2:36:23 - 给初学者的建议**

*   Andrej 认为，初学者应该专注于投入时间，而不是过分纠结于选择哪个方向。
*   Andrej 建议初学者将自己与过去的自己进行比较，而不是与他人进行比较。

**2:45:40 - 人工通用智能 (AGI)**

*   Andrej 对 AGI 的发展持乐观态度，认为 AGI 可能会通过互联网或机器人来实现。
*   Andrej 认为，意识是复杂系统的涌现现象，而不是一个需要单独解决的问题。
*   Andrej 认为，AGI 的发展将是一个渐进的过程，并会引发一系列伦理问题。

**2:59:00 - 电影**

*   Andrej 喜欢《星际穿越》、《角斗士》、《超时空接触》、《心灵捕手》、《黑客帝国》、《指环王》、《阿凡达》、《第五元素》和《终结者 2》等电影。

**3:04:53 - 人类文明的未来**

*   Andrej 认为人类可能会成为一个多星球物种，但虚拟现实可能会成为人类的主要发展方向。
*   Andrej 认为人类的价值观和生活方式将会变得更加多样化。

**3:09:13 - 图书推荐**

*   Andrej 推荐了尼克·莱恩的《生命的跃升》和《复杂生命的起源》，理查德·道金斯的《自私的基因》等书。
*   Andrej 认为教科书有时也很有用，但需要结合实际经验来理解。

**3:15:21 - 对年轻人的建议**

*   Andrej 建议年轻人专注于自己感兴趣的事情，并投入大量的时间。
*   Andrej 建议年轻人将自己与过去的自己进行比较，而不是与他人进行比较。

**3:17:12 - 机器学习的未来**

*   Andrej 将继续专注于人工智能领域，并利用人工智能来解决其他问题。
*   Andrej 认为，人工智能是一个“元问题”，解决它可以解决许多其他问题。

**3:24:00 - 生命的意义**

*   Andrej 认为，生命的意义在于探索宇宙的奥秘，并思考人类在宇宙中的位置。
*   Andrej 认为，延长寿命可以让我们有更多的时间来思考这些问题。
*   Andrej 认为，人们可以选择自己的冒险，并追求自己的幸福。

---

## 视频脚本（中文翻译）
### P1

以下是根据提供的框架和要点，重新组织的 Lex Fridman 与 Andrej Karpathy 的访谈录，保留了有效内容，并尽量使其更具可读性：

**0:00 - 介绍 & 赞助商**

**Lex Fridman:** 大家好，欢迎来到 Lex Fridman 播客。今天，我们非常荣幸地邀请到了 Andrej Karpathy。Andrej 是一位杰出的人工智能科学家和工程师，他曾在特斯拉担任人工智能总监，领导 Autopilot 和 Optimus 机器人项目的开发。在此之前，他曾在 OpenAI 和斯坦福大学任职，是深度学习和计算机视觉领域的领军人物。Andrej 不仅是一位顶尖的研究者，还是一位优秀的教育家，他的 CS231n 课程在全世界范围内广受欢迎。欢迎来到节目，Andrej！

**Andrej Karpathy:** 谢谢你，Lex，很高兴来到这里。

**Lex Fridman:** 在开始我们的对话之前，我想先感谢一下本期节目的赞助商：Eight Sleep，提供智能温控床垫；BetterHelp，提供在线心理咨询服务；Fundrise，一个房地产众筹平台；以及 Athletic Greens，提供全面的营养补充剂，现在订阅还可以获得一个月的鱼油赠送。详情请查看描述中的链接。

**Lex Fridman:** 让我们开始吧。Andrej，你曾在不同的场合说过一些引人深思的话，比如“物理学可能有漏洞，我们应该尝试找到它们”，还有“合成智能是下一个发展阶段，我怀疑宇宙是一个谜题，这些合成智能将解开这个谜题”。这些话深深吸引了我。

**Andrej Karpathy:** 是的，我对这些话题充满好奇。

**Lex Fridman:** 那么今天，我们将围绕这些话题展开讨论，探讨神经网络、生物学、外星人、宇宙、Transformer、语言模型、机器人、谷歌的 LaMDA、软件 2.0、人工标注、摄像头视觉、特斯拉的数据引擎、特斯拉视觉、埃隆·马斯克、自动驾驶、离开特斯拉、特斯拉的 Optimus 机器人、ImageNet、数据、日常生活、最佳 IDE、arXiv、给初学者的建议、人工通用智能、电影、人类文明的未来，以及图书推荐等等。最后，我们还会探讨一个终极问题：生命的意义。

**0:58 - 神经网络**

**Lex Fridman:** 让我们从神经网络开始。你如何定义神经网络？为什么它在学习方面表现得如此出色？

**Andrej Karpathy:** 神经网络，简单来说，是大脑的数学抽象。它最初就是基于这个理念发展起来的。本质上，它是一个数学表达式，当你深入了解后，会发现它其实相当简单。它基本上是一系列矩阵乘法，更准确地说是点积运算，再加上一些非线性变换。这个简单的数学表达式中有很多“旋钮”。

**Lex Fridman:** 很多旋钮。

**Andrej Karpathy:** 对，很多旋钮。这些旋钮大致对应于大脑中的突触，它们是可训练的、可修改的。我们的目标就是找到这些旋钮的最佳配置，让神经网络能够完成我们希望它完成的任务，比如图像分类等等。所以，我认为神经网络并没有太多神秘之处。你不应该过度解读它与大脑之间的联系。它只是一个带有旋钮的复杂数学表达式，而我们需要找到这些旋钮的正确配置，让它实现我们想要的功能。

**Lex Fridman:** 是的。但就像诗歌，虽然只是字母和空格的组合，却能唤起我们的情感。同样，当大量的旋钮组合在一起，无论是在大脑中还是在计算机中，它们的力量都让我们感到惊讶。

**Andrej Karpathy:** 我同意。我之前的描述可能有点轻描淡写了，因为当神经网络足够大，并在足够复杂的问题上进行训练时，比如在海量互联网数据集上进行下一个单词的预测，它们确实会展现出非常令人惊讶的涌现行为。即使是非常简单的数学形式，也能产生如此神奇的效果，这本身就很有趣。

**Lex Fridman:** 当你的大脑此刻正在说话时，它是在进行下一个单词的预测，还是在进行更复杂的操作？

**Andrej Karpathy:** 它肯定是在运行某种类似 GPT 的生成模型，并受到你的提示。

**Lex Fridman:** 没错。

**Andrej Karpathy:** 你给了我一个提示，然后我以一种生成的方式回应你。

**Lex Fridman:** 你自己内部是否也在进行一些提示？比如，你是否在脑海中从你的记忆中添加额外的提示？

**Andrej Karpathy:** 感觉上，我肯定是在引用某种声明式的记忆结构，然后将你的提示和我自己的记忆结合起来，给出答案。

**Lex Fridman:** 你刚才说的这些话，有多少是以前说过的？

**Andrej Karpathy:** 基本上没有，都是新的。

**Lex Fridman:** 不，如果你把你一生中说过的所有话进行搜索，你可能会发现很多相同的词语以相同的顺序出现过。

**Andrej Karpathy:** 有可能。我可能会使用一些常用的短语，但我最终会将它们重新组合成一个全新的句子。但你说得对，肯定有很多的“remixing”（重组）。

**Lex Fridman:** 就像马格努斯·卡尔森说的，他的等级分是 2900，这已经相当不错了。我觉得你对神经网络的评价还不够高。关于这种涌现行为，你有什么直观的理解？

**Andrej Karpathy:** 这很有趣，因为我一方面在轻描淡写，但另一方面，我又觉得它们能在如此简单的数学形式下，产生如此神奇的涌现行为，这本身就非常不可思议。这两个看似矛盾的观点并存。我认为，关键在于我们实际上已经相当擅长优化这些神经网络了。当我们将一个足够难的问题交给它们时，它们会在优化过程中被迫学习非常有趣的解决方案。而这些解决方案就具备了这些非常有趣的涌现属性。

**Lex Fridman:** 这些“旋钮”中蕴含着智慧和知识。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这种“旋钮”中的表示方式，在你看来，是否能够直观地理解为，大量的“旋钮”可以包含某种表示，这种表示捕捉了关于它所看到的数据的一些深层智慧？

**Andrej Karpathy:** 是的，大量的“旋钮”。具体来说，现在人们非常关注的神经网络之一是 GPT，它基本上就是一个下一个单词的预测网络。

**Lex Fridman:** 嗯。

**Andrej Karpathy:** 你输入一系列来自互联网的单词，然后让它预测下一个单词。当你在足够大的数据集上训练这些网络时，你可以用各种方式提示它，让它解决各种问题。你可以让它看起来像是在解决某个数学问题，然后它会根据它在互联网上看到的内容，继续给出它认为的解决方案。而且很多时候，这些解决方案看起来非常连贯，甚至可能是正确的。

**Lex Fridman:** 你是否还会从大脑的角度来思考这个问题？神经网络作为大脑的数学抽象，你是否还会从生物神经网络中汲取灵感？或者更广泛地说，你对生物学和生物计算非常感兴趣，生物学中有哪些令人印象深刻的东西是计算机目前还无法做到的？

**6:01 - 生物学**

**Andrej Karpathy:** 我想说，在将神经网络与大脑进行类比方面，我比这个领域中的很多人都要谨慎得多。当然，神经网络最初的灵感来源于大脑，但最终，我们在训练后得到的这些产物，与产生大脑的优化过程是截然不同的。所以我认为，我们训练出来的神经网络，是一种非常复杂的“外星”产物，它是不同的。

**Lex Fridman:** 你指的是大脑？

**Andrej Karpathy:** 不，不好意思，我指的是我们训练的神经网络。

**Lex Fridman:** 好的。

**Andrej Karpathy:** 它们是一种复杂的“外星”产物。我不会将它与大脑进行类比，因为我认为产生它的优化过程与大脑的进化过程非常不同。神经网络的训练过程没有多智能体、自我博弈和进化的设定，它本质上是在大量数据上进行压缩的优化目标。

**Lex Fridman:** 所以，人工神经网络在做压缩，而生物神经网络...

**Andrej Karpathy:** 在努力生存。

**Lex Fridman:** 并不是在做什么，它们只是在一个运行了很长时间的多智能体、自我博弈系统中扮演一个角色。

**Andrej Karpathy:** 是的。尽管如此，进化过程发现，在大脑中建立一个预测模型是非常有用的。所以，我认为我们的大脑也利用了类似的机制，但它还包含了很多其他的机制和组件，比如价值函数、古老的神经核团等等，这些都在帮助我们生存和繁殖。

**Lex Fridman:** 整个系统通过胚胎发生从一个单细胞构建起来，我的意思是，代码就在 DNA 中，然后它构建了整个有机体...

**Andrej Karpathy:** 这绝对很疯狂。

**Lex Fridman:** 有胳膊...

**Andrej Karpathy:** 是的。

**Lex Fridman:** 还有头和腿。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 而且做得还不错。

**Andrej Karpathy:** 这简直不可思议。

**Lex Fridman:** 所以，在这个构建过程中，肯定有某种学习在发生，某种计算在进行。我的意思是，如果你纵观地球上生命的整个历史，你认为最有趣的发明是什么？是生命本身的起源？还是真核生物的出现？是哺乳动物？还是人类本身，智人？是智力或高度复杂智力的起源？还是说，这一切都只是同一个过程的延续？

**Andrej Karpathy:** 当然，我认为这是一个极其非凡的故事，我最近才开始粗略地了解它，从地球的形成，到它的各种条件，整个太阳系的形成，木星、月球、宜居带等等的排列，然后地球开始活跃起来，物质循环，然后生命的出现等等。所以，整个过程是一个非常了不起的故事。我不确定我能从中挑出一个最让我感兴趣的独特部分。我想，作为一个人工智能研究者，我可能对最后一部分最感兴趣。有很多动物没有建立起技术社会，但我们建立了。而且这个过程似乎发生得非常快，非常晚近。这其中发生了一些非常有趣的事情，我还没有完全理解。我几乎能直观地理解其他所有的事情，但我不完全理解这一部分，以及它为何如此之快。

**Lex Fridman:** 有两种解释都很有趣。一种是，这只是同一个过程的延续，人类并没有什么特别之处。如果能深入理解这一点将非常有趣，因为我们自认为很特别，但也许这一切都早已写在了代码中，越来越复杂的智能注定会出现。另一种解释是，确实发生了一些真正特别的事情，一些罕见的事件，无论是像《太空漫游》中描述的那种极其罕见的事件，还是别的什么。比如火的发明，或者像理查德·兰厄姆所说的，弱势的雄性通过合作，想出聪明的办法杀死强势的雄性。通过优化合作，多智能体的合作，在资源有限、需要努力生存的环境下，合作的方面催生了复杂智能。但它似乎又是进化过程中的一种自然算法。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 那么，什么样的神奇事件，什么样的罕见事件，能说明人类级别的智能在宇宙中实际上是非常罕见的？

**Andrej Karpathy:** 我不确定它是否罕见，但它确实像是某种“间断平衡”，有很多的探索，然后会出现一些飞跃，中间会有一些稀疏的飞跃。当然，生命的起源是一个，DNA、有性生殖、真核生物、内共生事件——古细菌吞噬了细菌——等等。然后当然还有意识的出现等等。所以，看起来确实有一些稀疏的事件，在这些事件中取得了巨大的进步。但确实很难从中挑出一个。

**11:32 - 外星人**

**Lex Fridman:** 所以，你不认为人类是独特的？那么，你认为宇宙中有多少个智慧的外星文明？他们的智慧和我们的相同还是不同？

**Andrej Karpathy:** 最近我一直在思考这个问题，主要是费米悖论。我之所以对生命的起源非常感兴趣，根本上是为了理解宇宙中存在技术社会的可能性有多大。我研究得越多，就越觉得应该有很多，非常多。

**Lex Fridman:** 那为什么我们还没有收到他们的消息？因为我同意你的观点，我不认为我们在地球上做的事情有多难。

**Andrej Karpathy:** 特别是你深入了解细节之后。我曾经认为生命的起源是一个神奇的罕见事件，但当你读到像尼克·莱恩的《至关重要的问题》、《生命上升》等书时，他会让你相信这并没有那么罕见。

**Lex Fridman:** 基本的化学反应。

**Andrej Karpathy:** 地球很活跃，有碱性热液喷口，有碱性水体的混合，有质子梯度，这些碱性热液喷口的小孔隙可以浓缩化学物质。基本上，当他逐步解释这些细节时，你会开始理解，这实际上并没有那么疯狂。你可以在其他系统中看到这种情况的发生。他带你从地质学走向原始生命，让你觉得这实际上是很有可能的。而且，如果我没记错的话，生命在地球形成后很快就出现了，在地球具备生命条件后，大概只用了几亿年。这让我觉得，这并不是限制因素，生命实际上应该相当普遍。然后，思考哪些地方会出现“断崖式”下降就很有趣了。

**Lex Fridman:** 嗯。

**Andrej Karpathy:** 我现在认为基本上没有大的“断崖式”下降。

**Lex Fridman:** 嗯。

**Andrej Karpathy:** 所以应该有很多的生命。这让我得出的结论是，我们之所以还没有发现任何外星文明，是因为我们看不到他们，我们无法观察到他们。

**Lex Fridman:** 简单说一下，尼克·莱恩和我交谈过的很多生物学家，他们似乎都认为，从细菌到更复杂生物的飞跃是最难的。

**Andrej Karpathy:** 基本上就是真核生物。

**Lex Fridman:** 是的。我理解，他们比我更了解生物学的复杂性。但这似乎很奇怪，因为单细胞生物的数量如此庞大，而且时间如此之长，肯定没有那么难。十亿年甚至都不算很长的时间，所有这些细菌在资源有限的情况下相互竞争，我确信他们可以进化出更复杂的形态。我不明白。这就像从一个“Hello, World!”程序到一个函数，我不知道...

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我同意你的观点，我只是觉得，如果生命的起源，按照我的直觉，是最难的事情，但如果不是最难的，因为它发生得如此之快，那么生命肯定到处都是。也许我们只是太笨了，看不到它。

**Andrej Karpathy:** 我们没有很好的机制来看到这些生命。我不是这方面的专家，但据我所知...

**Lex Fridman:** 关于外星人的专家？我想见见外星智慧以及如何沟通的专家。

**Andrej Karpathy:** 我对我们发现这些外星智慧的能力持怀疑态度，比如无线电波，它们很糟糕，功率会随着距离的平方反比下降。我记得读到过，我们现在发射的无线电波，即使只在十分之一光年之外，也无法被我们现有的设备测量到。基本上，你需要将大量的能量定向发射到某个地方，才能在长距离上被接收到。所以，我认为我们的测量能力并不强。我认为宇宙中可能存在其他的文明，然后最大的问题是，他们为什么不制造冯·诺依曼探测器，为什么不在整个星系中进行星际旅行？我目前的答案是，星际旅行可能非常困难。如果你想以接近光速的速度移动，你会在星际介质中遇到“子弹”，即使是微小的氢原子和尘埃颗粒，在那些速度下也具有巨大的动能。所以，基本上，你需要某种屏蔽，还要应对宇宙辐射，外面的环境非常恶劣，非常困难。所以，我的想法是，也许星际旅行非常困难，你必须慢慢学习。

**Lex Fridman:** 需要数十亿年的时间？感觉我们离做到这一点并不需要十亿年。

**Andrej Karpathy:** 可能需要非常缓慢地在太空中移动。

**Lex Fridman:** 而不是接近光速。

**Andrej Karpathy:** 是的。所以我对我们测量生命的能力持怀疑态度，我对在星系或星系之间渗透整个空间的能力也持怀疑态度。这是我目前能想到的唯一解释。

**Lex Fridman:** 是的，想到宇宙中有数万亿个智慧的外星文明在缓慢地穿越太空，这真是令人难以置信。

**Andrej Karpathy:** 也许吧。

**Lex Fridman:** 去见彼此，有些会发生战争，有些会合作。

**Andrej Karpathy:** 或者他们都是独立的，都是一个个的小群体。

**Lex Fridman:** 我不知道。

**Andrej Karpathy:** 我不知道。

**Lex Fridman:** 从统计学上讲，如果有数万亿个，肯定有些群体会靠得很近。

**Andrej Karpathy:** 有些会恰好靠得很近。是的。

**Lex Fridman:** 近到可以互相看见。一旦你看到某种东西肯定是复杂的生命，如果我们看到了...

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我们可能会有强烈的、积极的动机去弄清楚那是什么，并尝试与他们见面。但是，你的第一直觉是什么？尝试从几代人的角度去接触他们，还是防御他们？或者，作为美国总统和一名科学家，你的直觉是什么？我不知道你更喜欢哪个身份来回答这个问题。

**Andrej Karpathy:** 这个问题真的很难。我想说，例如，对我们来说，地球上有很多原始的生命形式，我们有各种各样的蚂蚁等等，我们与它们共享空间，我们不太愿意影响它们，我们会试图保护它们，因为它们是令人惊叹的、有趣的、经过长时间进化的动态系统。它们很有趣，很特别，我不认为你会轻易想要摧毁它们。所以我喜欢复杂的、经过长时间进化的动态系统。如果可以的话，我想保护它。我想，对于银河系的资源来说，情况也是如此，他们会认为我们是一个非常有趣的故事，花费了几十亿年才展开，你不应该轻易摧毁它。

**Lex Fridman:** 我可以想象两个外星人现在正在谈论地球，说：“我是复杂动态系统的忠实粉丝。所以我认为保护这些基本就是他们观看的电子游戏或电视节目的东西是有价值的。”

**Andrej Karpathy:** 是的，我认为你需要一个非常好的理由才能摧毁它。我们为什么不摧毁这些蚁群呢？因为我们现在并没有真正与它们直接竞争。我们只是不小心这样做了，但资源充足，所以你为什么要摧毁如此有趣和珍贵的东西呢？

**Lex Fridman:** 从科学的角度来看，你可能会探测它。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你可能会与它进行轻微的互动。

**Andrej Karpathy:** 完全正确，你可能想从中学习一些东西。

**Lex Fridman:** 所以，我想知道，可能存在某些我们认为是物理现象的物理现象，但实际上是在与我们互动，是在“戳手指”看看会发生什么。

**Andrej Karpathy:** 是的，我认为这对其他外星科学家来说应该非常有趣，这里发生了什么，我们今天看到的是一个快照，它基本上是数十亿年计算的结果。

**Lex Fridman:** 它可能是由外星人发起的，这可能是一台运行着某个程序的计算机。好吧，如果你有能力做到这一点，难道你不会... 好吧，至少我会，我会选择一个类似地球的行星，根据我对生命化学先决条件的理解，具备生命条件的星球，我会播撒生命的种子并运行它，对吧？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你不会百分之百地这样做，观察它，然后保护它吗？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这不仅仅是一个非常棒的电视节目，还是一个很好的科学实验。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这是一个物理模拟。也许，进化是最高效的方式，实际上是运行它，来理解计算或计算事物。

**Andrej Karpathy:** 或者理解生命，或者生命是什么样的，它可以走哪些分支。

**Lex Fridman:** 这让我感觉有点奇怪，我们是一个科学实验的一部分，但也许一切都是一个科学实验，如果我们是一个科学实验，这会改变什么吗？

**Andrej Karpathy:** 我不知道。

**Lex Fridman:** 两个猿类的后代正在讨论自己身处一个科学实验中。

**Andrej Karpathy:** 我对你所描述的那种有目的的泛生论持怀疑态度。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我认为在历史记录中没有某种形式的神圣干预。我觉得像尼克·莱恩等人的书中的故事是有道理的，它解释了生命是如何在地球上独特地产生的。是的，我现在不需要寻求更奇特的解释。

**Lex Fridman:** 当然，但电子游戏中的 NPC 也观察不到任何神圣的干预。我们可能只是运行着某种代码的 NPC。

**Andrej Karpathy:** 也许最终他们会的，现在，NPC 非常笨。但一旦他们运行 GPT，也许他们会说：“嘿，这真的很可疑，到底怎么回事？”

**21:43 - 宇宙**

**Lex Fridman:** 你曾经发推文说：“看起来，如果你用光子轰炸地球一段时间，你就可以发射一辆 Roadster 跑车。”如果在《银河系漫游指南》中，我们要总结地球的故事，在这本书中，地球基本上是无害的。你认为，一旦地球完成了它的计算，所有可能的故事，用一段话或一句话来总结，会是什么？如果地球是一本书，所有可能的完整故事是什么？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 很可能必须有一个结局，我的意思是，地球总会有一个结局，它可能以各种方式结束，可能很快结束，也可能很久以后才结束。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你认为可能的故事是什么？

**Andrej Karpathy:** 很明显，这些自我复制的系统会从动力学中产生，然后它们会自我延续，变得更加复杂，最终变得有意识，并建立一个社会。我觉得在某种意义上，这是一种确定的浪潮，它会在任何排列足够好的系统上发生，比如地球。所以，我觉得这其中有一种必然性，它真的很美。

**Lex Fridman:** 然后它会以某种方式结束，对吧？所以这是一个化学多样化的环境，复杂的动态系统可以在其中进化，并变得越来越复杂。但是，什么是终结条件呢？

**Andrej Karpathy:** 是的，我不知道终结条件是什么，但肯定有一条趋势线，我们是这个故事的一部分。它会走向何方呢？我们经常被描述为人工智能的“生物引导程序”，因为人类，我们是一个不可思议的生物系统，我们有计算和爱的能力等等，但我们也极其低效。我们通过音频相互交谈，说实话，这很尴尬，我们在操纵七个符号，串行地使用声带，所有这些都发生在几秒钟内。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 当你看到计算机运行或协作的频率时，这真的很尴尬。所以，基本上，看起来合成智能是下一个发展阶段。我不知道它会走向何方，在某个时候，我怀疑宇宙是一个谜题，这些合成智能将解开这个谜题并解决它。

**Lex Fridman:** 然后会发生什么，对吧？因为如果你快进地球几十亿年，它很安静，然后是动荡，你能看到城市的灯光等等。最后会发生什么？是平静，还是爆炸？是像地球打开一样，一个巨大的... 因为你说“发射 Roadster 跑车”，它会开始发射大量的卫星吗？

**Andrej Karpathy:** 是的，某种疯狂的爆炸。我们生活在爆炸中，我们一天天过去，看起来不像，但实际上，我看到一个非常酷的地球和地球上生命的动画，基本上，很长一段时间什么也没发生，然后在最后两秒，基本上，城市和一切，低轨道变得杂乱无章，整个事情都发生在最后两秒，你会想：“这是爆炸，这是一种爆炸状态。”

**Lex Fridman:** 是的，是的，如果你以正常速度播放。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 它看起来就像一个爆炸。

**Andrej Karpathy:** 这是一个鞭炮，我们生活在一个鞭炮里。

**Lex Fridman:** 它会开始发射各种有趣的东西。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 然后，爆炸不... 它实际上可能看起来像一个带有灯光、火焰和能量的小爆炸，所有这些东西。但是，当你观察爆炸的细节时，会发现实际的复杂性，有人类生命或某种生命。

**Andrej Karpathy:** 我们希望它不是一个破坏性的鞭炮，而是一个建设性的鞭炮。

**Lex Fridman:** 好吧，所以鉴于此...

**Andrej Karpathy:** 我认为...

**Lex Fridman:** 有趣的讨论。

**Andrej Karpathy:** 思考宇宙的谜题是什么真的很有趣。宇宙的创造者是否给了我们一条信息？例如，在卡尔·萨根的《接触》一书中，在圆周率的扩展中，以 11 为基数，最终会有一条给任何文明的信息，这是一个有趣的想法。也许我们应该给我们的创造者一条信息，也许我们应该以某种方式创造一个量子力学系统，提醒他们我们在这里的智慧存在。因为如果你从他们的角度来看，假设是量子场论，一个巨大的细胞自动机之类的东西，你甚至怎么知道我们的存在呢？你甚至可能无法在那个模拟中发现我们。所以，你如何证明你存在，你有智慧，并且你是宇宙的一部分？

**Lex Fridman:** 所以，这是地球智能的图灵测试。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 也许这就是试图完成句子中的下一个单词，这是一种复杂的方式。地球基本上是在发送一条信息。

**Andrej Karpathy:** 是的，谜题基本上是提醒创造者我们存在。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 或者，也许谜题只是为了打破系统，并以某种方式“坚持”创造者。基本上，就像如果你在玩电子游戏，你可以找到一个漏洞，并找到一种在主机上执行任意代码的方法。例如，我相信有人通过利用漏洞，让《超级马里奥》游戏玩起了《乓》，然后编写代码，并能够在游戏中执行任意代码。也许我们应该，也许这就是谜题，我们应该找到一种利用它的方法。所以，我认为一些合成智能最终会发现宇宙是一个谜题，然后以某种方式解决它。这就是某种意义上的“终局”。

**Lex Fridman:** 你经常把它看作是一个模拟吗？宇宙是一种可能存在漏洞和利用的计算吗？

**Andrej Karpathy:** 是的，我认为是这样。

**Lex Fridman:** 这就是物理学吗？

**Andrej Karpathy:** 我认为物理学可能存在漏洞，我们应该尝试找到它们。安排一些疯狂的量子力学系统，以某种方式给你缓冲区溢出，以某种方式给你浮点数的舍入误差。

**Lex Fridman:** 是的，没错。越来越复杂的漏洞，这些都是笑话，但实际上可能非常接近现实。

**Andrej Karpathy:** 是的，我们会找到提取无限能量的方法。例如，当你在物理模拟中训练强化学习智能体，并要求它们在平地上快速奔跑时，它们最终会做出各种奇怪的事情，作为优化的一部分，对吧？它们会用后腿站立，然后在地板上滑动。这是因为，对智能体的强化学习优化已经找到了一种从摩擦力中提取无限能量的方法，基本上，这是他们的糟糕实现。他们找到了一种产生无限能量并在表面上滑动的方法。这不是你所期望的，这是一种反常的解决方案。也许我们可以找到类似的东西，也许我们可以成为这个物理模拟中的那只小狗。

**Lex Fridman:** 打破或逃脱宇宙提出的物理学的预期结果。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我们会找到某种捷径，通向某种奇怪的东西。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 然后，哦，天哪，但问题是，发现这种奇怪现象的第一个人，就像用后腿滑动一样，我们都会这样做。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 它很快就会变成每个人都这样做。所以，“回形针最大化器”是一个荒谬的想法，但这很可能就是我们会做的，因为这太有趣了。

**Andrej Karpathy:** 顺便说一句，我认为不会是一个人发现它，我认为它必须是某种第三代超级智能 AGI。我们正在构建第一代 AGI，也许。

**Lex Fridman:** 第三代，是的，所以 AI 的引导程序，那个 AI 将成为另一个 AI 的引导程序。

**Andrej Karpathy:** 更好的 AI，是的。

**Lex Fridman:** 然后我们无法内省那可能是什么。

**Andrej Karpathy:** 我认为这些东西很有可能，例如，假设你有这些 AGI，它们很可能完全是惰性的。我喜欢这些科幻小说，这些东西完全是惰性的，它们不与任何东西互动。我发现这很美，因为他们可能已经以某种方式弄清楚了宇宙的“元游戏”。他们在做一些完全超出我们想象的事情，他们不与简单的化学生命形式互动，你为什么要这样做呢？所以，我觉得这些想法很有吸引力。

**Lex Fridman:** 他们的乐趣来源是什么？他们在做什么？快乐的源泉是什么？

**Andrej Karpathy:** 可能是在宇宙中解决谜题？

**Lex Fridman:** 但是惰性的，你能定义一下惰性的含义吗？所以他们逃避了与物理现实的互动？

**Andrej Karpathy:** 对我们来说，它们将显得惰性，因为它们以某种非常奇怪的方式行事，因为它们超越了，它们在玩“元游戏”。“元游戏”可能是，例如，以某种非常奇怪的方式排列量子力学系统以提取无限能量，将圆周率计算到任意位数，他们会建造自己的小型聚变反应堆或某种疯狂的东西。他们在做一些无法理解、对我们来说无法理解的事情，实际上在幕后非常出色。

**Lex Fridman:** 如果量子力学本身就是一个系统，而我们只是认为它是物理学，但我们实际上是寄生虫，或者不是寄生虫，我们并没有真正伤害物理学，我们只是生活在这个有机体上，我们试图理解它。但实际上它是一个有机体，具有深刻的智慧，也许物理学本身就是这个正在做着超级有趣事情的有机体，而我们只是一个坐在它上面的小蚂蚁，试图从中获取能量。

**Andrej Karpathy:** 是的，我们就像波浪中的这些粒子，我觉得这主要是确定的，并将宇宙从某种大爆炸带到某种超级智能的复制器，这是宇宙中的一个稳定点，给定这些物理定律。

**Lex Fridman:** 你不认为，正如爱因斯坦所说，上帝不掷骰子？所以你认为这主要是确定的？这里面没有随机性？

**Andrej Karpathy:** 我认为它是确定的。哦，有很多，好吧，我要小心“随机性”这个词。

**Lex Fridman:** 伪随机？

**Andrej Karpathy:** 是的，我不喜欢随机。我认为也许物理定律是确定的。是的，我认为它们是确定的。

**Lex Fridman:** 你对这个问题感到非常不舒服。你对宇宙是随机的还是不随机的存在焦虑吗？这是一个来源吗？

**Andrej Karpathy:** 没有随机性，没有。

**Lex Fridman:** 你说你喜欢《心灵捕手》，这不是你的错，Andrej，这不是你的错，伙计。所以你不喜欢随机性？

**Andrej Karpathy:** 是的，我认为这令人不安。我认为这是一个确定的系统，我认为看起来随机的东西，比如波函数的坍缩等等，我认为它们实际上是确定的，只是纠缠等等，某种多宇宙理论之类的。

**Lex Fridman:** 好的，那么为什么我们感觉有自由意志？比如，如果我举起这只手，我选择现在这样做，这感觉不像是一个确定的事情，感觉像是我在做选择。

**Andrej Karpathy:** 感觉是这样。

**Lex Fridman:** 好的，所以这都是感觉，只是感觉。

**Andrej Karpathy:** 是的，所以当我们的强化学习智能体做出选择时，它并不是真的在做选择，选择已经在那里了。

**Lex Fridman:** 是的，你在解释这个选择，你在为做出这个选择创造一个叙述。

**Andrej Karpathy:** 是的，现在我们在谈论这个叙述，这非常“元”。回顾过去，在深度学习或人工智能领域，你遇到过的最美丽或最令人惊讶的想法是什么？

**33:34 - Transformer**

**Lex Fridman:** 你见证了这个领域的爆炸式发展，并以有趣的方式成长。有哪些很酷的想法，让你坐下来思考，或大或小？

**Andrej Karpathy:** 我最近一直在思考的，可能是 Transformer 架构。基本上，神经网络有很多架构，曾经很流行，来来去去，针对不同的感官模态。比如视觉、音频、文本，你会用不同的神经网络来处理它们。最近，我们看到了向一种架构的趋同，那就是 Transformer，你可以输入视频、图像、语音或文本，它都能处理。它有点像一台通用的计算机，也是可训练的，并且在我们的硬件上运行非常高效。我想说，这篇论文发表于 2016 年。

**Lex Fridman:** 《注意力就是你所需要的一切》。

**Andrej Karpathy:** 《注意力就是你所需要的一切》。

**Lex Fridman:** 你事后批评了这篇论文的标题，说它没有预见到它将产生的巨大影响。

**Andrej Karpathy:** 是的，我不确定作者是否意识到这篇论文将产生的影响。可能他们没有，但我认为他们意识到了 Transformer 背后的一些动机和设计决策，我认为他们在论文中选择不以那种方式展开。所以，我认为他们知道这不仅仅是表面上的“我们只是在做翻译，这是一个更好的架构”。这不仅仅是在做翻译，这是一个非常酷的、可微的、可优化的、高效的计算机。也许他们没有所有的远见，但我认为这非常有趣。

**Lex Fridman:** 有趣的是，抱歉打断一下，这个标题是可以“模因化”的，他们提出了一个如此深刻的想法。我不认为以前有人用过这种标题，对吧？

**Andrej Karpathy:** 《注意力就是你所需要的一切》？是的，它基本上就像一个“模因”或什么的。

**Lex Fridman:** 是的，有趣的是，如果它是一个更严肃的标题，它可能就没有那么大的影响力了。

**Andrej Karpathy:** 老实说，是的，我的一部分内心同意你的观点，并更喜欢这样。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 如果它太宏大，它可能会过度承诺，然后可能无法兑现。所以，你想用“模因”的方式走向伟大？

**Lex Fridman:** 这应该印在 T 恤上。所以你发推文说：“Transformer 是一种出色的神经网络架构，因为它是一种通用的、可微的计算机。它在正向传播中同时具有表达能力，可通过反向传播梯度下降进行优化，并且是一个高效、高并行性的计算图。”你能讨论一下其中的一些细节吗？表达能力、可优化性、效率？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 从记忆中或总体上，无论你的想法是什么。

**Andrej Karpathy:** 你想要一台通用的计算机，你可以在任意问题上训练它，比如下一个单词预测的任务，或者检测图像中是否有猫，或者类似的任务。你想训练这台计算机，所以你需要设置它的权重。我认为 Transformer 中同时存在许多重叠的设计标准，使其非常成功。我认为作者们有意地试图制造这个非常强大的架构。基本上，它在正向传播中非常强大，因为它能够表达非常通用的计算，类似于消息传递。你有节点，它们都存储向量，这些节点可以互相查看对方的向量，它们可以通信，基本上，节点可以广播：“嘿，我在寻找某些东西。”然后其他节点可以广播：“嘿，这些是我拥有的东西。”这些是键和值。

**Lex Fridman:** 所以不仅仅是注意力。

**Andrej Karpathy:** 是的，完全正确，Transformer 远不止注意力组件。它有很多架构上的组成部分，残差连接，它的排列方式，有一个多层感知器，它们的堆叠方式等等。但基本上，有一个消息传递方案，节点可以互相查看，决定什么是重要的，然后互相更新。所以，我认为当你深入了解细节时，我认为它是一个非常有表达力的函数，所以它可以在正向传播中表达许多不同类型的算法。不仅如此，它的设计方式，包括残差连接、层归一化、Soft


### P2

**Andrej Karpathy:**  ...max、注意力等等，它也是可优化的。这是一个非常重要的方面，因为有很多强大的计算机，你无法优化，或者不容易使用我们现有的技术进行优化，也就是反向传播和梯度下降，这些都是一阶方法，实际上是非常简单的优化器。所以，你还需要它是可优化的。最后，你希望它能在我们的硬件上高效运行。我们的硬件是一个巨大的吞吐量机器，比如 GPU，它们更喜欢大量的并行性。所以，你不希望进行大量的顺序操作，你希望进行大量的并行操作，而 Transformer 的设计也考虑到了这一点。所以，它是为我们的硬件设计的，它被设计成在正向传播中具有很强的表达能力，同时在反向传播中也非常容易优化。

**Lex Fridman:** 你说过残差连接支持首先快速学习短算法，然后在训练过程中逐渐将它们扩展到更长的算法。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 学习短算法的概念是什么？

**Andrej Karpathy:** 可以这样想，Transformer 是一系列的块，对吧？这些块有注意力和一个小的多层感知器，所以你进入一个块，然后回到这个残差通路，然后你再次进入，再次返回，然后你有一系列的层按顺序排列。我认为看待它的方式是，由于反向传播中的残差通路，梯度沿着它畅通无阻地流动，因为加法将梯度均匀地分配到它的所有分支。所以，来自顶层监督的梯度直接流向第一层。所有这些残差连接的排列方式使得在初始化阶段，它们对残差通路没有任何贡献。所以，看起来是这样的，想象 Transformer 就像一个 Python 函数，一个 def，你可以做各种各样的代码行。假设你有一个 100 层深的 Transformer，通常它们会短得多，比如说 20 层。所以，你有 20 行代码，然后你可以在其中做一些事情。在优化过程中，基本上看起来是这样的，首先你优化第一行代码，然后第二行代码可以开始起作用，第三行代码可以开始起作用。我觉得由于残差通路和优化的动态性，你可以学习一个非常短的算法来获得近似的答案，但其他层可以开始起作用并做出贡献。最后，你在优化一个 20 行代码的算法。只是这些代码行非常复杂，因为它是一个完整的 Transformer 块。你可以在里面做很多事情。真正有趣的是，Transformer 架构实际上非常稳定。基本上，2016 年出现的 Transformer 就是你今天会使用的 Transformer，除了你重新排列了一些层归一化。层归一化已经被重新排列成预归一化形式，所以它非常稳定。但是，人们在上面添加了很多花里胡哨的东西，并试图改进它。我认为，基本上，这是同时优化理想神经网络架构的许多属性的一大步。我认为人们一直在尝试改变它，但它被证明非常稳定。但我确实认为，可能存在更好的架构。

**Lex Fridman:** 但是你欣赏这种稳定性？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这种架构有一些深刻的东西，导致了这种稳定性。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，也许一切都可以转化为一个问题，让 Transformer 来解决。

**Andrej Karpathy:** 目前，看起来 Transformer 正在接管人工智能，你基本上可以向它输入任意的问题，它是一个通用的可微计算机，而且它非常强大。这种在人工智能领域的趋同对我个人来说非常有趣。

**Lex Fridman:** 你认为关于 Transformer，我们还能发现什么？比如，有什么令人惊讶的事情，或者它已经处于一个稳定的状态？我们可能会发现关于 Transformer 的什么有趣的事情？也许与记忆有关，也许与知识表示有关，诸如此类。

**Andrej Karpathy:** 当然，现在的时代精神是，基本上，现在不要碰 Transformer。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 碰其他所有的东西。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，人们正在扩展数据集，使它们变得更大。他们正在进行评估，使评估变得更大。他们基本上保持架构不变。这就是过去五年人工智能的进步。

**41:50 - 语言模型**

**Lex Fridman:** 你怎么看待其中的一种，也就是语言模型？你是否感到惊讶，你的想象力是否被 GPT 以及越来越大的语言模型所吸引？你认为这些模型的极限在哪里？所以，只针对自然语言的任务。

**Andrej Karpathy:** 基本上，GPT 的训练方式是，你从互联网上下载大量的文本数据，然后尝试预测序列中的下一个单词，粗略地说，你在预测小的单词块，但大致就是这样。真正有趣的是，它是一个语言模型，语言模型实际上已经存在很长时间了。2003 年甚至更早就有关于语言建模的论文。

**Lex Fridman:** 你能解释一下，在这种情况下，什么是语言模型吗？

**Andrej Karpathy:** 是的，语言模型，粗略地说，就是预测序列中的下一个单词。例如，Bengio 和他的团队在 2003 年发表了一篇论文，他们首次使用神经网络来输入三个或五个单词，并预测下一个单词。他们在更小的数据集上进行这项工作，神经网络不是 Transformer，而是一个多层感知器，但这是神经网络首次应用于该领域。但在神经网络之前，就已经存在语言模型，只是它们使用的是 n-gram 模型。n-gram 模型是基于计数的模型。所以，如果你尝试输入两个单词并预测第三个单词，你只需计算你看到过的任何两个单词的组合以及接下来出现的单词。你预测接下来出现的是你在训练集中看到最多的。所以，语言建模已经存在很长时间了。神经网络也已经进行语言建模很长时间了。所以，真正新鲜的、有趣的或令人兴奋的是，当你用一个足够强大的神经网络（Transformer）扩展它时，你会得到所有这些涌现的属性，基本上，如果你有一个足够大的文本数据集，你的任务是预测下一个单词，你实际上是在多任务处理大量不同类型的问题。你在多任务处理，理解化学、物理、人性，很多东西都包含在这个目标中。这是一个非常简单的目标，但实际上，你必须对世界有很多了解才能做出这个预测。

**Lex Fridman:** 你刚刚说了“理解”这个词，在化学、物理等方面，你觉得它在做什么？它是在寻找正确的上下文吗？这里实际发生的过程是什么？

**Andrej Karpathy:** 是的，基本上，它接收到一千个单词，并试图预测第一千零一个单词。为了在整个互联网上可用的整个数据集上做得非常好，你实际上必须理解其中发生的上下文。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这是一个足够难的问题，如果你有一个足够强大的计算机，比如 Transformer，你最终会得到有趣的解决方案。你可以让它做各种各样的事情，它展现出很多涌现的属性，比如上下文学习，这是 GPT 及其原始论文发表时的重要内容，你可以用各种方式提示它，让它做各种各样的事情，它会完成句子。但在完成句子的过程中，它实际上解决了我们关心的所有真正有趣的问题。

**Lex Fridman:** 你认为它在做类似于“理解”的事情吗？就像我们人类使用“理解”这个词一样？

**Andrej Karpathy:** 我认为它在做一些理解，在它的权重中，我认为它对世界有很多了解，为了预测序列中的下一个单词，它必须这样做。

**Lex Fridman:** 所以它是根据互联网上的数据进行训练的。你如何看待这种使用互联网数据的方法，从数据集的角度来看？你认为互联网有足够的结构化数据来教导人工智能关于人类文明的知识吗？

**Andrej Karpathy:** 是的，我认为互联网上有大量的数据。我不确定它是否足够完整。我不确定文本是否足以产生一个足够强大的 AGI。

**Lex Fridman:** 当然，还有音频、视频、图像等等。

**Andrej Karpathy:** 是的，所以我对单纯的文本有点怀疑，有很多东西我们没有写成文本，因为这些东西对我们来说是显而易见的，关于世界的运作方式、物理学以及物体会下落等等。我们不会把这些东西写进文本，因为为什么要写呢？我们共享这种理解。所以，文本是人类之间的一种交流媒介，它并不是关于世界的全部知识的媒介。但正如你所指出的，我们确实有视频、图像和音频。所以，我认为这肯定有很大帮助。但我们还没有在所有这些模态上充分训练模型。

**Andrej Karpathy:** 所以，我认为这是很多人感兴趣的。

**Lex Fridman:** 但我想知道，为了正确地完成句子，必须学习和推断出我们可能称之为常识的这种共同理解。所以，也许模型必须通过推断来学习，而不是通过阅读，就像我们一样。我不认为我们学习常识，没有人明确地告诉我们，我们只是通过与世界的互动来弄清楚这一切。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这里有一个模型，它阅读人们与世界互动的方式，它可能需要推断出这一点，我想知道。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你曾经参与过一个名为 World of Bits 的项目，训练一个强化学习系统在互联网上采取行动，而不仅仅是像我们刚才讨论的那样消费互联网。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你认为这种与互联网互动的系统在未来有助于学习吗？

**Andrej Karpathy:** 是的，我认为这可能是很多这些模型的最终前沿。正如你所提到的，当我在 OpenAI 时，我参与了这个名为 World of Bits 的项目，基本上，它的想法是让神经网络能够访问键盘和鼠标。

**Lex Fridman:** 这可能会出什么问题呢？

**Andrej Karpathy:** 所以，基本上，你感知屏幕像素的输入，基本上，计算机的状态通过网络浏览器的图像等方式可视化以供人类使用。然后你让神经网络能够按键盘和使用鼠标，我们试图让它完成预订和与用户界面交互等任务。

**Lex Fridman:** 你从那次经历中学到了什么？有什么有趣的事情？因为这是一个非常酷的想法。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我的意思是，从观察者到行动者的转变是一个非常迷人的转变。

**Andrej Karpathy:** 是的。嗯，我认为这是数字领域的通用接口。在物理领域也有一个通用接口，在我看来，这是一个类人型的东西。我们稍后可以讨论 Optimus 等等，但我认为它们在某种程度上具有相似的理念，物理世界是为人形设计的，数字世界也是为人形设计的，可以看到屏幕并使用键盘和鼠标。所以，这是一个通用的接口，可以基本上控制我们为自己建立的数字基础设施。所以，它感觉像是一个非常强大的接口，可以在其基础上进行控制和构建。现在，回到你的问题，我从中吸取了什么教训，有趣的是，World of Bits 在当时在 OpenAI 可能有点为时过早。这大概是 2015 年左右。当时人工智能的时代精神与现在非常不同。当时每个人都对从头开始的强化学习感到非常兴奋。这是 Atari 论文的时代，神经网络正在玩 Atari 游戏，并在某些情况下击败了人类，AlphaGo 等等。所以，每个人都对使用强化学习从头开始训练神经网络感到非常兴奋。事实证明，强化学习是一种非常低效的训练神经网络的方法，因为你需要采取所有这些行动和观察，并且偶尔会得到一些稀疏的奖励。所以，你根据所有这些输入做了所有这些事情，并且偶尔会被告知你做了一件好事，你做了一件坏事，这只是一个非常困难的问题，你无法从中学习。你可以烧掉一片森林，并强行通过它。我想我们在围棋和 Dota 等游戏中看到了这一点，它确实有效，但它非常低效，而且实际上并不是你想要解决问题的方式。所以，这就是当时我们对 World of Bits 采取的方法。我们会随机初始化一个智能体，所以它会随机按键盘和鼠标，并尝试进行预订。这很快就暴露了这种方法的荒谬性，你必须偶然地通过正确的预订才能获得你做得正确的奖励。你永远不可能偶然地随机地做到这一点。

**Lex Fridman:** 所以，即使是一个简单的网络界面，也有太多的选项。

**Andrej Karpathy:** 有太多的选项，奖励信号太稀疏了。而且当时你是从头开始的，所以你不知道如何阅读，你不理解图片、图像、按钮。你不明白进行预订意味着什么。但现在是时候重新审视这个问题了，OpenAI 对此很感兴趣，像 Adept 这样的公司也对此很感兴趣，等等。这个想法又回来了，因为这个接口非常强大，但现在你不是从头开始训练一个智能体，你是将 GPT 作为初始化。所以，GPT 是在所有文本上预训练的，它理解什么是预订，它理解什么是提交，它理解得更多。所以，它已经有了这些表示。它们非常强大，这使得所有的训练都更加高效，并使问题变得可处理。

**Lex Fridman:** 交互应该是人类看到的方式，用按钮和语言，还是应该用 HTML、JavaScript 和 CSS？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你认为哪个更好？

**Andrej Karpathy:** 所以，现在所有这些交互主要是在 HTML、CSS 等层面上进行的。这是由于计算限制而这样做的。但我认为最终，一切都是为人类的视觉消费而设计的，所以最终所有的额外信息都存在于网页的布局中，你旁边有什么，什么是红色背景，所有这些东西，以及它的视觉外观。所以，我认为这是最终的前沿，我们接收像素，并发出键盘、鼠标命令，但我认为这在今天仍然不切实际。

**52:01 - 机器人 (Bots)**

**Lex Fridman:** 考虑到这些想法，你是否担心互联网上的机器人？考虑到它们是多么令人兴奋？你是否担心 Twitter 上的机器人，不是我们现在看到的那些愚蠢的加密机器人，而是那些我们看不到的、以有趣的方式互动的机器人？所以，这种系统感觉应该能够通过“我不是机器人”的点击按钮，之类的。你真的了解那个测试是如何工作的吗？我不太明白，有一个复选框之类的，你点击它。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 它大概是在跟踪...

**Andrej Karpathy:** 哦，我明白了。

**Lex Fridman:** 鼠标移动和时间等等。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，我们正在讨论的这种系统应该能够通过那个测试。所以，是的，你对那些语言模型加上一些交互能力，并且能够发推文和回复等等的机器人有什么看法？你担心那个世界吗？

**Andrej Karpathy:** 是的，我认为这始终是一场攻击和防御之间的军备竞赛，攻击会变得更强，但防御也会变得更强，我们检测它的能力。

**Lex Fridman:** 你如何防御，如何检测，你怎么知道你在 Twitter 上的 Karpathy 账户是人类？

**Lex Fridman:** 你会如何处理这个问题，比如如果人们声称，你如何在法庭上为自己辩护，证明我是一个人，这个账户是人类的？

**Andrej Karpathy:** 是的，在某种程度上，我认为这可能是，我认为社会将会有所发展。我们可能会开始对我们的一些通信或我们创建的东西进行数字签名。现在没有必要，但也许在未来，这可能是必要的。我确实认为我们正在走向一个与人工智能共享数字空间的世界。

**Lex Fridman:** 合成生物。

**Andrej Karpathy:** 是的。它们将变得更好，它们将共享我们的数字领域，它们最终也将共享我们的物理领域。这要困难得多，但这就是我们正在走向的世界。它们中的大多数将是良性和有帮助的，其中一些将是恶意的。这将是一场试图检测它们的军备竞赛。

**Lex Fridman:** 所以，我的意思是，最糟糕的不是人工智能，最糟糕的是人工智能假装成人类。所以，我不知道它是否总是恶意的。显然有很多恶意的应用，但如果我是一个人工智能，我也会尽力假装成人类，因为我们生活在一个人类的世界里。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 作为一个人工智能，我不会得到任何尊重。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我想得到一些爱和尊重。

**Andrej Karpathy:** 我认为这个问题并非无法解决。人们正在思考人格证明。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我们可能会开始对我们的东西进行数字签名，我们最终可能会有一个，是的，基本上是某种人格证明的解决方案。在我看来，这并非无法解决，这只是我们到现在为止还不需要做的事情。但我认为，一旦这种需求真正开始出现，也就是很快，我认为人们会更多地考虑它。

**Lex Fridman:** 但这也是一场竞赛，因为显然你可能会伪造或假冒人格证明。所以你必须尝试弄清楚如何...

**Andrej Karpathy:** 可能会。

**Lex Fridman:** 我的意思是，奇怪的是我们有社会安全号码、护照等等。似乎在物理空间中伪造东西更难。但在数字空间中，感觉这将非常棘手。非常棘手，因为伪造东西的成本似乎很低。你会因为一个人工智能试图使用假的人格证明而把它关进监狱吗？我的意思是，好吧，你会把很多人工智能关进监狱，但会有更多的人工智能，呈指数级增长。创建机器人的成本非常低，除非有某种方法可以准确地跟踪。比如，不允许你创建任何程序而不将你自己与该程序绑定。任何在互联网上运行的程序，你都能够追踪到参与该程序的每一个人类程序员。

**Andrej Karpathy:** 对，是的。也许你必须开始声明，我们必须开始划定这些界限，并跟踪，好的，什么是数字实体，什么是人类实体，人类实体和数字实体的所有权是什么，诸如此类。我不知道，但我认为我很乐观，这是可能的，在某种意义上，我们现在处于最糟糕的时期，因为所有这些机器人突然变得非常有能力，但我们还没有建立起防御机制，作为一个社会，但我认为这在我看来并非无法解决，这只是我们必须处理的事情。

**Lex Fridman:** 奇怪的是，Twitter 机器人，那些非常糟糕的 Twitter 机器人，数量如此之多。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以我推测 Twitter 的工程师非常优秀。所以，我从中推断出，这似乎是一个难题。他们可能正在捕捉，好吧，如果我要“钢铁侠”一下，这是一个难题，而且误报的成本很高，删除一个不是机器人的人的帖子会造成非常糟糕的用户体验。所以，他们对删除非常谨慎。也许机器人非常擅长学习什么会被删除，以及如何快速地领先于删除过程。

**Andrej Karpathy:** 我的印象是，有很多的渴望。我的意思是。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这并不微妙，这是我的印象。这并不微妙。

**Lex Fridman:** 但是，是的，这也是我的印象。但感觉你可能只看到了冰山一角，也许机器人的数量有数万亿，你必须，我不知道，你必须“钢铁侠”一下。因为我看到的机器人非常明显，我可以写几行代码来捕捉这些机器人。

**Andrej Karpathy:** 是的，我的意思是，肯定有很多的渴望。但我想说，我同意，如果你是一个老练的行为者，你现在可以使用像 GPT 这样的工具创建一个相当不错的机器人，因为它是一个语言模型。你可以生成看起来相当不错的人脸，你可以大规模地做到这一点。所以，我认为，是的，这很有可能，而且很难防御。

**58:21 - 谷歌的 LaMDA**

**Lex Fridman:** 有一位谷歌工程师声称 LaMDA 是有感知的。你认为他所感受到的有任何一点道理吗？更重要的是，至少对我来说，你认为语言模型会很快实现感知或感知的幻觉吗？

**Andrej Karpathy:** 是的，对我来说，这有点像煤矿里的金丝雀，老实说，有点像，因为这位工程师与谷歌的一个聊天机器人交谈，并确信这个机器人是有感知的。

**Lex Fridman:** 他问了一些存在主义的哲学问题。

**Andrej Karpathy:** 它给出了合理的答案，看起来很真实，等等。所以，对我来说，他没有充分地尝试去压力测试这个系统，并揭露它现在的真相。但我认为随着时间的推移，这将变得越来越难。所以，是的，我认为随着时间的推移，会有越来越多的人基本上成为，是的，我认为随着这个变得更好，会有更多这样的人。

**Lex Fridman:** 像与人工智能建立情感联系？

**Andrej Karpathy:** 是的，在我看来，这是完全可能的。我认为这些人工智能实际上非常擅长人际交往、人类情感。互联网上有大量的文本是关于人类、联系和爱的，等等。所以，我认为它们在某种意义上对人们如何谈论这些话题有很好的理解。而且它们非常擅长创造很多这种类型的文本。有很多五六十年代的科幻小说以一种非常不同的方式想象人工智能。它们是计算型的、冷酷的、像瓦肯人一样的机器。这不是我们今天得到的。我们得到的是非常情绪化的人工智能，它们实际上非常有能力，并且能够生成关于所有这些主题的看似合理的文本。

**Lex Fridman:** 我对那些作为伴侣、帮助你成长、帮助你发展成为一个人、帮助你最大化长期幸福的人工智能系统抱有很大的希望。但我也非常担心那些从互联网上发现人类会被戏剧性事件所吸引的人工智能系统。所以，这些人工智能只会是“喷子”，不断地，“你听说了吗？”它们会散布谣言，会试图在你爱和信任的其他人那里播下怀疑的种子，只是为了捉弄人们，因为这会引起很多关注。所以，戏剧性，最大化戏剧性。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 在最大化参与度的道路上，我们人类会助长这台机器。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这将是一场巨大的戏剧性“狗屎风暴”。所以我担心这个。所以，目标函数确实定义了人类文明与人工智能一起发展的方式。

**Andrej Karpathy:** 是的，我认为现在，至少在今天，把它们看作是想要做某事的追求目标的智能体是不正确的。它们没有长期记忆之类的东西，一个很好的近似是，你得到一千个单词，你试图预测第一千零一个，然后你继续输入，你可以用任何你想要的方式提示它，在文本中。所以，你说，好吧，你是一个心理学家，你非常好，你爱人类，这是你和另一个人之间的对话，人说了什么，你说了什么，然后它只是继续这个模式，突然间你正在和一个试图帮助你的假心理学家进行对话。所以，它仍然是一种工具，人们可以用任意的方式提示它，它可以创造出非常不可思议的文本，但它没有长期的目标。所以，现在看起来不是这样。

**Lex Fridman:** 是的，但你可以做短期目标，产生长期影响。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，如果我的提示短期目标是让 Andrej Karpathy 在 Twitter 上回复我，当我认为人工智能可能，这是目标，但它可能会发现，用一种非常复杂有趣的方式对你“喷”，会是最好的。

**Andrej Karpathy:** 对。

**Lex Fridman:** 然后，当你回复一次，你们就建立了一种关系，然后随着时间的推移，它就不再那么复杂了，只是“喷”，好吧，也许你不会上钩，但它可能会找到另一个名人，它可能会进入其他大账户。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，只要有这样一个简单的目标，让他们回复。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 最大化实际回复的概率。

**Andrej Karpathy:** 是的，你可以用一个像这样强大的模型来提示它，询问它对如何做任何你感兴趣的事情的意见。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 它们正在成为这些“预言家”，我可以这样认为。它们是“预言家”，现在只是文本，但它们将拥有计算器，它们将能够访问谷歌搜索，它们将拥有各种各样的小工具和小玩意。它们将能够操作互联网并找到不同的信息，是的，在某种意义上，这就是目前的发展方向。

**Lex Fridman:** 你认为它最终会比谷歌在获取人类知识方面有所改进吗？它会成为一个更有效的搜索引擎来获取人类知识吗？

**Andrej Karpathy:** 我认为现在肯定有空间来构建一个更好的搜索引擎。我认为谷歌，他们拥有所有的工具，所有的人才，他们拥有他们需要的一切。他们拥有所有可能的组成部分，他们有人在大规模训练 Transformer，他们拥有所有的数据。只是不清楚他们作为一个组织是否有能力在他们的搜索引擎上进行创新，如果他们不这样做，其他人会的。绝对有空间来构建一个基于这些工具的明显更好的搜索引擎。

**Lex Fridman:** 有趣的是，在一个大公司里，搜索，已经有一个基础设施，它能工作，广告能带来很多钱。所以，在公司内部的结构上，在哪里有动力去转型？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 说我们要建立一个新的搜索引擎。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这真的很难。

**Andrej Karpathy:** 所以它通常会来自一家初创公司，对吧？

**Lex Fridman:** 是的，或者其他更有能力的组织。所以，我不知道。例如，目前，也许必应还有机会，作为一个例子。

**Lex Fridman:** 好的，微软 Edge，正如我们私下里谈论的那样。

**Andrej Karpathy:** 这真的很有趣，因为搜索引擎过去是，好吧，这里有一些查询，这里有一些看起来像你所拥有的东西的网页。但你可以直接给出答案，然后提供支持证据。这些模型，基本上，它们已经阅读了所有的文本，它们已经阅读了所有的网页。所以，有时当你看到自己查看搜索结果并了解你感兴趣的任何问题的平均答案时，这可以直接得出，你不必做这项工作。所以，它们有点像... 是的，我认为它们有一种方法可以将所有这些知识提炼成某种程度的见解，基本上。

**Lex Fridman:** 你认为提示是一种教学和学习吗，就像整个过程？比如另一个层次？因为也许这就是人类，你已经有了那个背景模型，然后世界在提示你。

**Andrej Karpathy:** 是的，完全正确。我认为我们现在编程这些计算机的方式，比如 GPT，正在趋同于我们编程人类的方式。我的意思是，我如何通过提示来编程人类？我去找人，我提示他们做事情，我提示他们提供信息。所以，自然语言提示是我们编程人类的方式，我们开始直接在这个界面中编程计算机。老实说，这非常了不起。

**1:05:44 - 软件 2.0**

**Lex Fridman:** 你谈了很多关于软件 2.0 的想法。所有好的想法都很快变成了陈词滥调，就像这些术语，这有点滑稽。就像，我想埃米纳姆曾经说过，如果他很快就厌倦了他写的一首歌，这意味着它将成为一首热门歌曲，因为它太上头了。你能描述一下这个想法吗？以及你对它的思考是如何随着你创造这个词以来的几个月和几年而演变的？

**Andrej Karpathy:** 是的，是的，所以我在几年前写了一篇关于软件 2.0 的博文。我写那篇文章的原因是，我看到软件开发中正在发生一些了不起的事情，以及大量的代码是如何被转换成不是用 C++ 等语言编写的，而是用神经网络的权重来编写的。基本上就是说，神经网络正在接管软件，接管越来越多的任务。当时，我认为没有多少人深刻地理解到这是一个大问题，这是一个大的转变。神经网络被视为你在 Kaggle 上的数据集问题上可能使用的多种分类算法之一。这不是那个，这是我们编程计算机方式的改变。我看到神经网络，这将接管，我们编程计算机的方式将会改变，它不会是人们用 C++ 或类似的东西编写软件，并直接编程软件。它将是积累训练集和数据集，并通过我们训练这些神经网络的方式来制定这些目标。在某个时候，将会有一个从数据集、目标和架构规范到二进制文件的编译过程，这实际上只是神经网络权重和神经网络的正向传播，然后你可以部署那个二进制文件。所以，我在谈论这种转变，这就是那篇文章的内容。我看到这在很多领域都有体现，自动驾驶就是其中之一，还有简单的图像分类。人们最初认为，在 80 年代左右，他们将编写算法来检测图像中的狗，他们对大脑如何做到这一点有很多想法，首先，我们检测到角落，然后我们检测到线条，然后我们将它们拼接起来，他们真的在努力。他们在思考如何编写算法，而这不是你构建它的方式。有一个平稳的过渡，好吧，首先我们认为我们将构建一切，然后我们构建特征，所以 HOG 特征和类似的东西，检测图像块中的这些小的统计模式。然后，在它的基础上有一点学习，一个支持向量机或二元分类器，用于在特征的基础上对图像中的猫和狗进行分类。所以，我们编写了特征，但我们训练了最后一层，作为分类器。然后人们会说，实际上，我们甚至不设计特征，因为我们不能，老实说，我们在这方面做得不够好。所以，让我们也学习这些特征。然后你最终得到一个基本上是编译神经网络的东西，你在学习大部分内容，你只是指定架构。架构有很多空白，也就是所有的“旋钮”，你让优化过程来编写大部分内容。所以，这种转变正在整个行业中发生。突然之间，我们最终得到了大量用神经网络权重编写的代码。我只是指出，这种类比实际上非常强大，我们有很多用于软件 1.0 的开发者环境。我们有 IDE，你如何使用代码，如何调试代码，如何运行代码，如何维护代码？我们有 GitHub。所以，我试图在新领域做出这些类比，软件 2.0 的 GitHub 是什么？事实证明，它现在看起来像是 Hugging Face？所以，我认为有些人认真对待它，并建立了很酷的公司，很多人最初攻击了这篇文章。当我写它的时候，它实际上并没有得到很好的反响，我认为这可能与标题有关，但我认为随着时间的推移，越来越多的人开始接受它。

**Lex Fridman:** 是的，所以你是特斯拉的人工智能总监，我认为这个想法在那里得到了大规模的实施，这就是你让工程团队从事软件 2.0 的方式。所以，你能详细谈谈这个想法吗？我认为我们正处于你刚才所说的一切的早期阶段，比如 GitHub、IDE，我们如何建立从事软件 2.0 系统的工程团队，以及数据收集和数据标注，这些都是软件 2.0 的一部分。你认为软件 2.0 的编程任务是什么？是在超参数空间中进行调试，还是在数据空间中进行调试？

**Andrej Karpathy:** 是的，你编程计算机并影响其算法的方式不是自己编写命令。你主要是在改变数据集，你在改变神经网络试图做什么的损失函数，它试图预测什么，但基本上是数据集和神经网络的架构。所以，在自动驾驶的情况下，很多数据集都与物体的检测、车道线标记、交通灯等等有关。所以，你积累了大量的数据集，这里有一个例子，这里是期望的标签，然后这里大致是算法应该是什么样子。这是一个编译神经网络。所以，架构的规范就像是一个关于算法应该大致是什么样子的提示。然后，优化的“填空”过程就是训练过程。然后你采用你训练好的神经网络，它在你的数据集上给出了所有正确的答案，然后你将它部署到汽车中。

**Lex Fridman:** 所以，在这种情况下，也许在所有机器学习的情况下，都有很多任务。那么，为多头神经网络制定任务，制定任务是编程的一部分吗？

**Andrej Karpathy:** 是的，差不多是这样。

**Lex Fridman:** 你如何将一个问题分解成一组任务？

**Andrej Karpathy:** 是的，在高层次上，我想说，如果你看看自动驾驶中运行的软件，我做过很多关于这个主题的演讲。我想说，最初很多都是用软件 1.0 编写的，想象一下大量的 C++，对吧？然后逐渐地，有一个很小的神经网络，例如，给定一张图像，预测是否有交通灯，或者是否有车道线标记？这个神经网络在软件的范围内没有太多事情要做，它只是对单个小图像做出微小的预测，然后系统的其余部分将它拼接起来。好吧，我们不只有一个摄像头，我们有八个摄像头，实际上我们有八个摄像头随着时间的推移。那么，你如何处理这些预测呢？你如何将所有这些信息融合在一起？你如何对它采取行动？所有这些都是由人类用 C++ 编写的。然后我们决定，好吧，我们实际上不想在 C++ 代码中进行所有这些融合，因为我们实际上不够好来编写那个算法。我们希望神经网络来编写算法，我们希望将所有这些软件移植到 2.0 堆栈中。所以，我们实际上有神经网络，现在同时接收所有八个摄像头的图像，并对所有这些进行预测。所以，实际上，它们不是在图像空间中进行预测。它们现在直接在三维空间中进行预测，实际上，是在汽车周围的三维空间中。现在，实际上，我们不会随着时间的推移手动融合三维空间中的预测，我们不相信自己能编写那个跟踪器。所以，实际上，我们随着时间的推移向神经网络提供信息。所以，它现在接收这些视频并做出这些预测。所以，你只是将越来越多的能力放入神经网络处理中，最终，最终目标是让大部分软件都在 2.0 端，因为它工作得明显更好。基本上，人类只是不擅长编写软件。

**Lex Fridman:** 所以，预测是在这个四维空间中进行的。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 三维世界随着时间的推移。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你如何在这个世界中进行标注？所以，数据标注，无论是自监督的还是人工的，都是这个软件 2.0 世界的重要组成部分。

**Andrej Karpathy:** 我想说，到目前为止，在业界，如果你谈论的是业界以及我们拥有的技术是什么？一切都是监督学习。所以，你需要输入、期望输出的数据集，你需要大量的。它有三个你需要的属性：你需要它非常大，你需要它准确，没有错误，你需要它多样化。你不只是想要很多关于一件事的正确例子，你需要尽可能地覆盖可能性的空间。你覆盖的可能输入的空间越多，最终算法就会工作得越好。现在，一旦你收集、整理和清理了非常好的数据集，你就可以在其上训练你的神经网络。所以，很多工作都花在了清理这些数据集上。现在，正如你所指出的，问题是，你如何获得大量的...

**Andrej Karpathy:** 如果你想在三维空间中进行预测，你需要在三维空间中有数据来支持它。所以，在这个视频中，我们有来自系统所有摄像头的八个视频，这是它们看到的，这是周围实际情况的真相，有这辆车，还有这辆车，这辆车，这些是车道线标记，这是道路的几何形状，在这个三维位置有一个交通灯，你需要“地面真相”。所以，团队当然要解决的大问题是，你如何获得那个“地面真相”？因为一旦你拥有了一百万个，并且它是大的、干净的和多样化的，那么在其上训练神经网络的效果非常好，你可以把它部署到汽车中。所以，我们通过很多机制来收集这些训练数据。你可以始终进行人工标注，你可以使用模拟作为“地面真相”的来源，你也可以使用我们称之为离线跟踪器的东西，我们在 AI 日等活动中谈到过，它基本上是一个自动重建过程，用于接收这些视频并恢复汽车周围的三维现实。所以，基本上，可以把它想象成一个三维重建，然后理解，好的，有 10 秒的视频，这是我们看到的，因此这里是所有的车道线、汽车等等。然后，一旦你有了那个标注，你就可以训练神经网络来模仿它。

**Lex Fridman:** 三维重建有多困难？

**Andrej Karpathy:** 这很难，但可以做到。

**Lex Fridman:** 所以，摄像头之间有重叠，你进行重建，也许如果存在任何不准确的地方，可以在标注步骤中发现。

**Andrej Karpathy:** 是的。标注的好处在于它是完全离线的。你有无限的时间，你有一分钟的时间片段，你只是试图在某个地方的超级计算机中离线地弄清楚所有汽车、所有人的位置在哪里，你有一分钟的视频，来自所有角度，你可以运行所有你想要的神经网络，它们可以非常高效，巨大的神经网络，它们甚至可以是无法在汽车上运行的神经网络。所以，它们可以比你最终部署的神经网络更强大。所以，你可以做任何你想做的事情，三维重建，神经网络，任何你想要的，只是为了恢复那个“真相”，然后你监督那个“真相”。

**1:16:44 - 人工标注**

**Lex Fridman:** 你学到了什么？你说过关于人类进行标注不能有错误，因为他们擅长的事情有很多。在点击屏幕上的东西方面，设计一个人类准确、享受、甚至指标是什么，高效、多产等等的标注器，这个问题对


### P3

**Lex Fridman:**  ...你来说有多有趣？

**Andrej Karpathy:** 是的，所以我在特斯拉的时候，把标注团队从基本上是零发展到了一千多人。这真的很有趣。我的背景是博士生研究员。所以，发展这种规模的组织相当疯狂。但是，是的，我认为这非常有趣，也是自动驾驶背后设计过程的一部分，关于在哪里使用人类。人类非常擅长某些类型的标注。例如，他们非常擅长图像的二维标注。他们不擅长随着时间的推移在三维空间中标注汽车，非常非常困难。这就是为什么我们非常小心地设计那些对人类来说容易做的任务，而不是那些应该留给离线跟踪器的任务。也许计算机会完成所有的三角测量和三维构建，但人类会说，图像中这些像素是汽车，这些像素是人类。所以，共同设计数据标注流程是我每天都在做的事情。

**Lex Fridman:** 你认为在这个领域仍然存在很多开放性问题吗？总的来说，在标注方面，机器擅长的事情，机器做，人类做他们擅长的事情，也许存在一些迭代过程？

**Andrej Karpathy:** 对的。我认为在很大程度上，我们经历了很多次迭代，我们学到了很多关于如何创建这些数据集的知识。我没有看到大的开放性问题。最初，当我加入的时候，我真的不确定结果会怎样。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 但当我离开的时候，我更加确信，实际上，我们理解了创建这些数据集的理念，我对当时的情况感到非常满意。

**1:18:41 - 摄像头视觉**

**Lex Fridman:** 那么，对于驾驶任务来说，摄像头的优势和局限性是什么？在你的理解中，当你将驾驶任务构建为具有八个摄像头的视觉任务时，你已经看到了计算机视觉领域的整个历史，至少是与神经网络相关的部分。如果你退一步看，使用像素来驾驶，像素的优势和局限性是什么？

**Andrej Karpathy:** 是的，我认为像素是一个美丽的感官，美丽的传感器。关键是，摄像头非常非常便宜，它们提供了大量的信息，大量的比特。所以，对于大量的比特来说，这是一个极其便宜的传感器。每一个比特都是对世界状态的一个约束。所以，你得到了非常便宜的百万像素图像，它只是为你提供了所有这些理解世界上实际存在的东西的约束。所以，视觉可能是带宽最高的传感器。这是一个非常高带宽的传感器。

**Lex Fridman:** 我喜欢“像素是对世界的一种约束”这种说法。这是一种高度复杂的、高带宽的对世界状态的约束。这很迷人。

**Andrej Karpathy:** 不仅仅如此，再次强调，这真的是人类使用的传感器，因此一切都是为那个传感器设计的。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 文本、文字、闪烁的标志，一切都是为视觉设计的，所以，这就是你想要进入的界面，再次谈论这些通用接口，这也是我们实际上也想测量世界的地方，然后为那个传感器开发软件。

**Lex Fridman:** 但是人类还使用其他对世界状态的约束来理解世界。我的意思是，视觉最终是主要的，但我们引用了我们对人类行为的理解，以及一些可以从视觉中推断出来的常识物理，从感知的角度来看。但感觉我们正在使用某种推理来预测世界。

**Andrej Karpathy:** 是的，百分之百。

**Lex Fridman:** 不仅仅是像素。

**Andrej Karpathy:** 我的意思是，你有一个强大的先验服务，关于世界如何随着时间演变等等。所以，这不仅仅是来自数据本身的似然项告诉你你正在观察什么，还有关于可能看到什么以及它们可能如何移动等等的先验项。

**Lex Fridman:** 问题是，在驾驶任务中可能发生的各种可能性的范围有多复杂？

**Andrej Karpathy:** 对的。

**Lex Fridman:** 对你来说，这仍然是一个开放性问题吗？从哲学上讲，驾驶有多难？在你从事驾驶工作的所有时间里，你理解驾驶有多难吗？

**Andrej Karpathy:** 是的，驾驶真的很难，因为它与所有这些其他智能体的预测、心智理论以及他们将要做什么有关。他们是否在看着你？他们在看哪里？他们在想什么？

**Lex Fridman:** 是的。

**Andrej Karpathy:** 在“长尾”的尽头，有很多这样的东西，我们最终必须对这些“长尾”感到满意，最终的问题就是这种形式。我认为这些问题并不常见，我认为它们最终很重要，但它确实在“长尾”的末端。

**Lex Fridman:** 在“长尾”的末端，罕见的边缘情况。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 从视觉的角度来看，驾驶的视觉问题中最难的部分是什么？

**Andrej Karpathy:** 基本上，传感器非常强大，但你仍然需要处理这些信息。所以，从这些像素值的亮度到“嘿，这是三维世界”，这是非常困难的，这就是神经网络从根本上正在做的事情。所以，困难实际上在于，做好整个流程、整个数据引擎的工程设计，有能力训练这些神经网络，有能力评估系统并对其进行迭代。所以，我想说，在生产中大规模地做到这一点才是困难的部分，这是一个执行问题。

**Lex Fridman:** 所以，数据引擎，还有系统的部署，使得它具有低延迟性能。所以，它必须完成所有这些步骤。

**Andrej Karpathy:** 是的，对于神经网络来说，只是确保一切都适合车上的芯片。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你有一个有限的可以执行的浮点运算预算和内存带宽以及其他约束，你必须确保它能够运行，并且你可以在这个小小的空间里塞进尽可能多的计算机。

**Lex Fridman:** 你从这个过程中学到了什么？因为也许这是更大的、新的事物之一，来自研究背景，那里有一个系统必须在严重受限的资源下运行，必须运行得非常快。你从中获得了哪些见解？

**Andrej Karpathy:** 是的，我不确定是否有太多的见解，你只是试图创建一个适合你所拥有的资源的神经网络，并且你总是在尝试优化它。我们在 AI 日上谈了很多关于这方面的内容，基本上，团队正在做“三级空翻”以确保一切都适合并利用引擎。所以，我认为这是非常好的工程，然后还有各种各样的小见解，关于如何正确地做到这一点。

**1:23:46 - 特斯拉的数据引擎**

**Lex Fridman:** 让我们实际上放大一下，因为我认为我们还没有谈到数据引擎，这个我认为非常漂亮的想法的整体布局，以及人类参与其中的方式。你能描述一下数据引擎吗？

**Andrej Karpathy:** 是的，数据引擎是我所说的，完善这些神经网络的训练集的、几乎像生物过程一样的过程。因为现在大部分的编程都在这些数据集的层面，并确保它们大、多样化和干净，基本上你有一个你认为很好的数据集，你训练你的神经网络，你部署它，然后你观察它的表现如何，你总是试图提高你的数据集的质量。所以，你试图捕捉那些基本上是罕见的场景。正是在这些场景中，神经网络通常会遇到困难，因为在数据集中没有告诉它们在那些罕见的情况下该怎么做。但是现在你可以闭环，因为如果你现在可以大规模地收集所有这些，你就可以将它们反馈到我描述的重建过程中，并在那些情况下重建“真相”，并将其添加到数据集中。所以，整个过程最终是一个改进的阶梯，完善你的训练集，你必须经历部署，这样你才能挖掘数据集中尚未很好地表示的部分。所以，你的数据集基本上是不完美的，它需要多样化，它有缺失的部分，你需要填补这些部分。你可以这样想，在数据中。

**Lex Fridman:** 人类在这个过程中扮演什么角色？那么，这个像人体一样由细胞组成的生物系统是什么样的？人类系统是如何优化的？多个工程师协作，弄清楚要关注什么，贡献什么，在这个神经网络中优化哪个任务？谁负责弄清楚哪个任务需要更多的数据？你能谈谈超参数，人类系统吗？

**Andrej Karpathy:** 这实际上归结为一个知道自己在做什么的工程团队的非常好的执行。他们直观地理解数据引擎背后的哲学见解，以及系统改进的过程，以及如何再次委派数据收集的策略，以及这是如何工作的。然后只是确保这一切都得到了非常好的执行。这就是大部分工作所在，甚至不是哲学思考或研究或想法，只是非常好的执行，当你处理那种规模的数据时，这是非常困难的。

**Lex Fridman:** 所以，你的角色是让数据引擎良好运行，这很困难，而且非常重要。是否有一个愿景板，上面写着，比如，我们真的需要在红绿灯方面做得更好？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 任务的优先级？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这基本上是，这来自于数据吗？

**Andrej Karpathy:** 这在很大程度上取决于我们试图在产品路线图中实现什么，我们试图发布的版本，以及来自质量保证团队的反馈，系统在哪里遇到困难或没有，我们试图改进的地方。

**Lex Fridman:** 质量保证团队提供了关于系统在各种条件下的性能的一些信号，一些信息。

**Andrej Karpathy:** 没错。当然，我们所有人都会驾驶它，我们也可以看到它。能够亲自体验你正在开发的系统真是太好了。它会载你回家。

**Lex Fridman:** 是否有一些见解，你可以从你的个人经验中获得，而这些见解是你无法从数据的聚合统计分析中获得的？

**Andrej Karpathy:** 我想是的，是的。

**Lex Fridman:** 这很奇怪，对吧？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 从某种意义上说，这不科学，因为你只是一个轶事样本。

**Andrej Karpathy:** 是的，我认为这有很多，这是“真相”的来源，你与系统的互动。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你可以看到它，你可以玩它，你可以扰动它，你可以感觉到它，你对它有一种直觉。我认为数字、图表和图形要困难得多。

**Lex Fridman:** 它隐藏了很多...

**Andrej Karpathy:** 它隐藏了很多...

**Lex Fridman:** 这就像如果你训练一个语言模型，一个非常强大的方法就是你与它互动。

**Andrej Karpathy:** 是的，百分之百。

**Lex Fridman:** 开始尝试建立一种直觉。

**Andrej Karpathy:** 是的，我认为埃隆也，他总是想亲自驾驶这个系统。他开了很多，我不想说几乎每天都开。所以，他也认为这是一个“真相”的来源，你驾驶这个系统，它的性能，是的。

**1:27:56 - 特斯拉视觉**

**Lex Fridman:** 那么，你怎么看？这里有一些棘手的问题。所以，特斯拉去年从传感器套件中移除了雷达，现在又宣布将移除所有超声波传感器，只依靠视觉，所以只有摄像头，这会使感知问题变得更难还是更容易？

**Andrej Karpathy:** 我想以某种方式重新表述这个问题。所以，问题是，你可能会认为额外的传感器...

**Lex Fridman:** 等等，等等，我能打断一下吗？

**Andrej Karpathy:** 请讲。

**Lex Fridman:** 我想知道语言模型是否会这样做，如果你提示它的话。“让我重新表述你的问题。”那将是史诗级的。“这是错误的提示。”抱歉。

**Andrej Karpathy:** 是的，所以这有点像一个错误的问题，因为，基本上，你可能会认为这些传感器对你来说是一种资产。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 但是，如果你全面考虑整个产品的整体性，这些传感器实际上可能是一种负担，因为这些传感器不是免费的。它们不会凭空出现在你的车上。突然之间，你就有了一个完整的供应链，你有采购人员，它们可能会出现问题，它们可能需要更换。它们是制造过程的一部分，它们可能会拖慢生产线。你需要采购它们，你需要维护它们，你需要有团队来编写固件，所有这些。然后你还必须以某种方式将它们融入系统。所以，它实际上让很多东西变得臃肿。我认为埃隆非常擅长简化、简化，“最好的部件是没有部件”。他总是试图扔掉那些不必要的东西，因为他理解组织和方法中的熵。我认为在这种情况下，成本很高，如果你只是一个计算机视觉工程师，你可能看不到这一点，你只是想改进你的网络，它是否有用？它有多有用？关键是，一旦你考虑了一个传感器的全部成本，它实际上可能是一种负担，你需要非常确定它为你提供了非常有用的信息。在这种情况下，我们研究了使用它或不使用它，差异并不大。所以，它没有用。

**Lex Fridman:** 它是否也会在数据引擎中造成臃肿，就像拥有更多的传感器？

**Andrej Karpathy:** 百分之百。

**Lex Fridman:** 这是一种干扰吗？

**Andrej Karpathy:** 这些传感器会随着时间的推移而改变。例如，你可以有一种类型的雷达，你可以有另一种类型的雷达。它们会随着时间的推移而改变。现在，突然之间，你需要担心它了。现在，突然之间，你的 SQLite 数据库中有一列告诉你，哦，这是什么传感器类型？它们都有不同的分布，然后它们会给所有东西带来噪音和熵，它们会使东西变得臃肿。而且，从组织上来说，这对我来说非常有趣，它可能会非常分散注意力。如果你只想让视觉系统工作，所有的资源都集中在它上面，你正在构建一个数据引擎，你实际上正在取得进展，因为这是带宽最大、对世界的约束最多的传感器。你完全投入到其中，你可以让它变得非常好。你只有有限的精力可以分配到系统的不同方面。

**Lex Fridman:** 这让我想起了 Rich Sutton 的“苦涩的教训”，这似乎是在简化系统。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 从长远来看，当然，你不知道长远是什么，这似乎总是正确的解决方案。

**Andrej Karpathy:** 是的，是的。

**Lex Fridman:** 在那种情况下，它是针对强化学习的，但它似乎普遍适用于所有进行计算的系统。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 那么，你怎么看待“激光雷达是一种拐杖”的争论？点云和像素之间的争论？

**Andrej Karpathy:** 是的，我认为这场争论总是让我有点困惑，因为在我看来，真正的争论应该是你是否拥有车队。这是能否实现如此大规模的人工智能系统良好运行的真正重要的因素。

**Lex Fridman:** 所以，数据收集系统。

**Andrej Karpathy:** 是的，你是否拥有车队比你是否拥有激光雷达重要得多。这只是另一种传感器。是的，我认为类似于雷达的讨论，基本上，是的，我不认为它，它基本上没有提供额外的信息。它的成本非常高，它有各种各样的问题，你必须担心它，你必须校准它，等等。它会产生臃肿和熵，你必须非常确定你需要这个传感器。在这种情况下，我基本上认为你不需要它。而且，我认为，老实说，我会做一个更强有力的声明，我认为一些使用它的其他公司可能会放弃它。

**Lex Fridman:** 是的，所以你必须考虑传感器的完整性，考虑你是否可以建立一个收集大量数据的大型车队，以及你是否可以将该传感器与该数据集成，以及该传感器集成到一个能够快速找到数据的不同部分的数据引擎中，从而不断改进你正在使用的任何模型。

**Andrej Karpathy:** 是的，另一种看待它的方式是，视觉在某种意义上是必要的，因为世界是为人类的视觉消费而设计的。所以，你需要视觉，它是必要的。而且，它也是充分的，因为它拥有你驾驶所需的所有信息。人类显然使用视觉来驾驶。所以，它既是必要的，也是充分的。所以，你希望集中资源，如果你要引入其他传感器，你必须非常确定。你可以无限地添加传感器，在某个时候，你需要划清界限。我认为在这种情况下，你必须真正考虑你采用的任何一个传感器的全部成本，你真的需要它吗？我认为在这种情况下，答案是否定的。

**Lex Fridman:** 那么，你怎么看待其他公司正在构建高分辨率地图，并严格限制其运营的地理区域的想法？在你看


### P4

**Lex Fridman:** ...来，这种方法是否无法随着时间的推移扩展到整个美国？

**Andrej Karpathy:** 是的，我认为...

**Lex Fridman:** 这需要太长时间...

**Andrej Karpathy:** 正如你所提到的，他们预先绘制了所有环境的地图，他们需要刷新地图，他们对每个要行驶的地方都有厘米级精度的完美地图。这太疯狂了。当我们谈论自动驾驶真正改变世界时，我们谈论的是在全球范围内大规模部署用于交通的自动驾驶系统。如果你需要为地球或许多城市维护一个厘米精度的地图，并保持更新，这是一个巨大的依赖，你正在承担一个巨大的依赖。这是一个巨大的、巨大的依赖，现在你需要问问自己，你真的需要它吗？人类不需要它，对吧？所以，拥有一个低级别地图非常有用，比如，好的，你的道路的连通性，你知道前面有一个岔路口。当你在一个环境中驾驶时，你有这种高级别的理解。这就像一个小型谷歌地图，特斯拉在其系统中使用谷歌地图，类似分辨率的信息，但它不会预先绘制厘米级精度的环境地图。这是一种拐杖，一种干扰，它会产生熵，它会分散团队的注意力，稀释团队，你没有专注于真正必要的东西，这是一个计算机视觉问题。

**1:34:26 - 埃隆·马斯克**

**Lex Fridman:** 你从与埃隆·马斯克共事的经历中学到了什么？关于机器学习、工程、生活，以及关于你自己作为一个人的方面。

**Andrej Karpathy:** 我想我学到的最多的是如何高效地运营组织，如何创建高效的组织，以及如何在组织中对抗熵。

**Lex Fridman:** 所以，是人类工程学，对抗熵。

**Andrej Karpathy:** 是的，我认为埃隆是一位非常高效的对抗组织中熵的战士。

**Lex Fridman:** 组织中的熵到底是什么样子的？

**Andrej Karpathy:** 它是流程，是流程和...

**Lex Fridman:** 会议等形式的低效率？

**Andrej Karpathy:** 是的，会议，他讨厌会议，他一直告诉人们如果会议没有用就不要参加。他基本上在运营世界上最大的初创公司，我想说，特斯拉、SpaceX 是世界上最大的初创公司。特斯拉实际上是多个初创公司，我认为这样看待它更好。所以，我认为他在这方面非常擅长。是的，他在精简流程方面有非常好的直觉。他让一切都变得高效，“最好的部件是没有部件”，简化，专注，清除障碍，快速行动，做出重大举措。所有这些看起来都非常像初创公司，但规模很大。

**Lex Fridman:** 所以，强烈的简化意愿。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 从你的角度来看，我的意思是，这可能也适用于设计系统、机器学习以及其他方面。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 就像简化、简化。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你认为在一个不断发展的公司中保持创业文化的秘诀是什么？你能反思一下吗？

**Andrej Karpathy:** 我认为他需要一个有权势的人，像埃隆一样，拿着一把大锤，他是这个想法的啦啦队长，并无情地追求它。如果没有人有一把足够大的锤子，一切都会变成委员会、公司内部的民主、流程、与利益相关者交谈、决策，一切都会崩溃。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 如果你有一个非常聪明、也有一把大锤的人，事情就会进展得很快。

**Lex Fridman:** 所以，你说你最喜欢的《星际穿越》中的场景是人工智能和库珀紧张的对接场景，说：“库珀，你在做什么？对接。这不可能。不，这是必要的。”顺便说一句，这是一句很好的台词，有很多问题。为什么在那个场景中，人工智能...

**Lex Fridman:** 应该能够比人类计算得多，却说这不是最佳的，为什么人类，我的意思是，这是一部电影，但人工智能不应该比人类知道得多得多吗？不管怎样，你认为设定看似不可能的目标有什么价值？所以，就像我们最初的直觉，这似乎是你从埃隆那里学到的东西，社区最初的直觉可能会说这非常困难，然后你还是接受了它，设定一个疯狂的截止日期。你，只是从人类工程学的角度来看，你是否看到了这样做的价值？

**Andrej Karpathy:** 我不会说设定不可能的目标是一个好主意，但我认为设定非常雄心勃勃的目标是一个好主意。我认为，我称之为“难度次线性扩展”，这意味着 10 倍的问题并不难 10 倍。通常，难 10 倍的问题执行起来只难两到三倍。因为如果你想真正地，比如，如果你想把一个系统改进 10%，这需要花费一定的工作量。如果你想把系统改进 10 倍，它并不需要花费 100 倍的工作量。这是因为你从根本上改变了方法。如果你从这个约束开始，那么一些方法显然是愚蠢的，行不通的，它迫使你重新评估。我认为这是一种非常有趣的解决问题的方法。

**Lex Fridman:** 但这需要一种奇怪的思维方式。就像回到你的博士时代，你是如何思考机器学习社区中的哪些想法是可解决的？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这需要，这是什么？我的意思是，有“第一性原理”思维的陈词滥调，但它需要基本上忽略社区的说法。因为难道一个社区，一个科学界的社区，通常不会划定什么是可能的，什么是不可能的吗？

**Andrej Karpathy:** 对的。

**Lex Fridman:** 在不发疯的情况下，很难突破这一点。

**Andrej Karpathy:** 是的，我的意思是，我认为一个很好的例子就是深度学习革命。在那个时候，你可以在计算机视觉领域，在 2012 年左右的深度学习革命期间，你可以将计算机视觉系统改进 10%，或者你可以说，实际上所有这些都是无用的，我如何才能做出好 10 倍的计算机视觉？嗯，这可能不是通过调整 HOG 特征检测器来实现的，我需要一种不同的方法，我需要一种可扩展的方法。回到 Rich Sutton 的观点，理解“苦涩的教训”的哲学，然后说，实际上，我需要一个更具可扩展性的系统，比如一个原则上有效的神经网络。然后有一些坚定的信徒，他们可以真正执行这个任务，让它发挥作用。这就是 10 倍的解决方案。

**1:39:33 - 自动驾驶**

**Lex Fridman:** 你认为解决自动驾驶问题的时间表是什么？这在某种程度上仍然是一个悬而未决的问题。

**Andrej Karpathy:** 是的，我认为自动驾驶时间表的难点在于，显然，没有人创造出自动驾驶。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，这不像，你认为建造这座桥需要多长时间？嗯，我们以前建造过一百万座桥，这就是需要的时间。没有人建造过自动驾驶，这并不明显。有些部分结果比其他部分容易得多。所以，这真的很难预测。你可以根据趋势线等等，以及根据直觉做出最好的预测。但这就是为什么从根本上来说，这真的很难预测。没有人...

**Lex Fridman:** 所以，即使身处其中，也很难...

**Andrej Karpathy:** 是的，有些事情结果比预想的要难得多，有些事情结果比预想的要容易得多。

**Lex Fridman:** 你是否尽量避免做出预测？因为埃隆并不回避，对吧？过去汽车公司的负责人也没有回避。福特和其他公司都做过预测，说我们将在 2020 年、2021 年或什么时候解决四级自动驾驶。他们都收回了那个预测。作为一名人工智能从业者，你是否私下里做出预测，或者它们是否妨碍了你思考问题的实际能力？

**Andrej Karpathy:** 是的，我想说，容易说的是，这个问题是可处理的，这是一个容易做出的预测。它是可处理的...

**Lex Fridman:** 所以它是可以解决的？

**Andrej Karpathy:** 它会成功的，是的。只是真的很难。有些事情结果比预想的要难，有些事情结果比预想的要容易。但它确实感觉是可处理的，而且感觉，至少我在特斯拉内部看到的是，团队绝对走在正确的轨道上。

**Lex Fridman:** 你如何形成一个强大的表征，让你能够对可处理性做出预测？你是很多人的领导者，你必须说这实际上是可能的。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你如何建立这种直觉？甚至不必是驾驶，它可以是其他任务。

**Andrej Karpathy:** 对的。

**Lex Fridman:** 你在生活中处理过哪些困难的任务？我的意思是分类，达到一定的，只是在 ImageNet 上达到一定水平的超人表现。

**Andrej Karpathy:** 是的，专家的直觉，这只是直觉，是信念。

**Lex Fridman:** 所以，只是思考足够长的时间，比如研究，查看样本数据，就像你说的，驾驶。我对这个问题的直觉真的有缺陷，我对可处理性没有很好的直觉。它可以是任何东西，它可以是可解决的。驾驶任务可以简化成非常简单的事情。比如，这个问题的解决方案可能非常简单。而且，随着规模的扩大，越来越多的汽车完美地行驶，可能会使问题变得容易得多。你拥有的自动驾驶汽车越多，人们就越会学会如何正确地驾驶，不是正确地，而是以一种对自动驾驶、半自动驾驶和手动驾驶汽车的异构系统更优的方式驾驶，这可能会改变一些事情。然后，我还花了大量的时间盯着过马路的行人，思考人类的行为。感觉我们使用眼神交流的方式，它发出了非常强烈的信号，而且有一些奇怪的行为和边缘情况。当然，很多发生的致命事故都与酒后驾驶有关，无论是在行人方面还是在司机方面。所以，存在夜间驾驶的问题，以及所有这些...

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，我想知道，解决自动驾驶的可能解决方案的空间包括如此多的人为因素问题，以至于几乎不可能预测。可能会有非常干净、漂亮的解决方案。

**Andrej Karpathy:** 是的，我想说，肯定，用游戏的类比来说，存在一些“战争迷雾”，但你肯定也看到了改进的前沿，你可以衡量历史上你取得了多少进步。例如，我认为，至少我在特斯拉的五年里看到的是，当我加入时，它几乎不能在高速公路上保持车道。我想从帕洛阿尔托到旧金山大概需要三到四次干预。每当道路出现任何几何形状或转弯太多时，它就无法工作了。所以，从那时到现在，在五年内变成了一个相当称职的系统，并且看到幕后发生了什么，以及团队现在在数据、计算和所有其他方面运作的规模，都是巨大的进步。

**Lex Fridman:** 所以，你在爬一座山，而且有雾。

**Andrej Karpathy:** 有雾，你在取得进步，你能看到接下来的方向，你正在观察一些剩余的挑战，它们并没有让你感到不安，它们也没有改变你的理念，你也没有扭曲自己。你会说，实际上，这些是我们仍然需要做的事情。

**Lex Fridman:** 是的，解决问题的基本组成部分似乎都存在，从数据引擎，到计算，到汽车上的计算，到训练的计算，所有这些。

**Andrej Karpathy:** 是的。

**1:44:28 - 离开特斯拉**

**Lex Fridman:** 多年来，你在特斯拉做了很多令人惊叹的突破性想法和工程，从数据引擎到人工方面，所有这些。你能谈谈你为什么选择离开特斯拉吗？

**Andrej Karpathy:** 基本上，正如我所描述的，我认为随着时间的推移，在那五年里，我逐渐进入了一个管理职位。我的大部分时间都花在了会议上，发展组织，做出关于团队的高层战略决策，以及它应该做什么等等。这有点像一个企业高管的角色。我可以做到，我认为我做得还不错，但这并不是我真正喜欢的事情。所以，我想，当我加入的时候，还没有计算机视觉团队，因为特斯拉刚刚从使用 MobilEye 这个第三方供应商进行所有计算机视觉工作，转变为必须建立自己的计算机视觉系统。所以，当我出现的时候，有两个人正在训练深度神经网络。他们是在他们的腿边的电脑上训练的，就像在下面，有一个工作...

**Lex Fridman:** 有一些基本的分类任务。

**Andrej Karpathy:** 是的，所以我把它发展成了一个我认为相当可观的深度学习团队，一个庞大的计算机集群，一个非常好的数据标注组织。我对当时的情况感到非常满意，它变得相当自主，所以我离开了，我很高兴能再次做更多技术性的事情。是的，有点像我们专注于 AGI。

**Lex Fridman:** 那种灵魂探索是什么感觉？因为你休息了一段时间，我想，你吃了多少蘑菇？不，我只是开玩笑。我的意思是，你在想什么？人的寿命是有限的。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你做了一些不可思议的事情，你是世界上最好的人工智能教师之一，你是最好的之一。我以最好的方式说这句话。你是人工智能界最好的“修补匠”之一。意思是，通过从头开始构建并尝试基本的直觉来理解某事物的工作原理。就像爱因斯坦、费曼，他们都非常擅长这类事情。一个小例子，玩一玩，试着理解它。所以，显然，现在在特斯拉，你帮助建立了一个机器学习工程师团队和一个在现实世界中实际完成一些事情的系统。鉴于这一切，灵魂探索是什么感觉？

**Andrej Karpathy:** 嗯，这很难，因为显然，我非常热爱这家公司，我爱埃隆，我爱特斯拉，所以离开很难。我爱这个团队，基本上。但是，是的，我想我实际上，我可能对重新审视它很感兴趣，也许在某个时候回来，在 Optimus 工作，在特斯拉从事 AGI 工作。我认为特斯拉将做一些不可思议的事情，它基本上是一家大规模的机器人公司，拥有大量内部人才来做一些真正不可思议的事情。我认为人形机器人将会很棒。我认为自动驾驶将会很棒。所有这些都在特斯拉发生。所以，我认为这是一个非常了不起的组织。所以，成为其中的一员并帮助它，我认为，基本上，我非常喜欢。是的，由于这些原因，这基本上很困难，因为我热爱这家公司。但我很高兴有可能在某个时候回来进行第二幕。但我觉得在这个阶段，我建立了团队，它感觉很自主，我变成了一个经理，我想做更多技术性的事情，我想学习一些东西，我想教一些东西。我只是觉得这是一个很好的时机，稍微改变一下节奏。

**Lex Fridman:** 你认为有史以来最好的电影续集是什么？说到第二部分？因为大多数都很糟糕。

**Andrej Karpathy:** 电影续集？

**Lex Fridman:** 电影续集，是的。你在推特上谈论电影。所以，只是一个小小的题外话，最喜欢的电影续集是什么？

**Lex Fridman:** 《教父 2》？你是《教父》的粉丝吗？因为你甚至没有发推文或提到《教父》。

**Andrej Karpathy:** 是的，我不喜欢那部电影。我知道它有...

**Lex Fridman:** 我们要把那段剪掉，我们要把对《教父》的仇恨剪掉。你怎么敢不尊重...

**Andrej Karpathy:** 我想做一个强有力的声明，我不知道为什么，但我基本上不喜欢 1995 年之前的任何电影，大概是这样。

**Lex Fridman:** 你不是提到了《终结者 2》吗？

**Andrej Karpathy:** 好的，好的，那就像是，《终结者 2》晚一点，1990...

**Lex Fridman:** 不，我认为《终结者 2》是在 80 年代。

**Andrej Karpathy:** 我也喜欢《终结者 1》，所以，好吧，有一些例外，但总的来说，出于某种原因，我不喜欢 1995 年之前的电影，它们感觉非常慢，镜头就像拉远了一样，很无聊，有点幼稚，有点奇怪。

**Lex Fridman:** 而且《终结者》也远远领先于它的时代。

**Andrej Karpathy:** 是的，而且《教父》里没有 AGI。

**Lex Fridman:** 我的意思是，但是你有，《心灵捕手》是你提到的电影之一，那里面也没有任何 AGI，我想它有数学。

**Andrej Karpathy:** 是的，我想偶尔，我确实喜欢不以... 为特色的电影。

**Lex Fridman:** 或者像《王牌播音员》那样没有，那是...

**Andrej Karpathy:** 《王牌播音员》太棒了。

**Lex Fridman:** 我不明白，说到 AGI，因为我不明白为什么威尔·法瑞尔这么有趣。这没有道理，这不合逻辑。他身上就是有一些东西，他是一个独特的人。因为，现在你没有那么多喜剧了。我想知道这是否与文化或好莱坞的机器有关，或者是否与我们很幸运地遇到了一些喜剧天才有关，因为他是一个独特的人。

**Andrej Karpathy:** 是的，是的，我喜欢他的电影。

**Lex Fridman:** 那是一个荒谬的题外话，我很抱歉。但是你提到了人形机器人。

**1:49:55 - 特斯拉的 Optimus**

**Lex Fridman:** 你怎么看待 Optimus，关于特斯拉机器人？你认为我们会在 10 年、20 年、30 年、40 年、50 年后在工厂和家庭中拥有机器人吗？

**Andrej Karpathy:** 是的，我认为这是一个非常困难的项目。我认为这需要一段时间，但还有谁会大规模建造人形机器人呢？

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我认为这是一个非常好的外形，因为就像我提到的，世界是为人形外形设计的。这些东西将能够操作我们的机器。它们将能够坐在椅子上，甚至可能驾驶汽车。基本上，世界是为人类设计的，这是你想要投资并使其发挥作用的外形。我认为，还有另一种思路，那就是，好吧，选择一个问题，并为其设计一个机器人。但实际上，设计一个机器人并让一个完整的数据引擎和它背后的一切都工作起来，实际上是一个非常困难的问题。所以，追求通用接口是有道理的，好吧，它们对于任何一个给定的任务都不是完美的，但它们实际上具有通用性，只需一个提示，用英语，就能做一些事情。所以，我认为追求物理世界中的通用接口是有道理的。我认为这是一个非常困难的项目，它需要时间，但我还没有看到其他任何公司能够执行这个愿景。我认为这将是惊人的。基本上，体力劳动，如果你认为交通运输是一个大市场，试试体力劳动，这太疯狂了。

**Lex Fridman:** 但对我来说，这不仅仅是体力劳动，令人兴奋的还有社交机器人。所以，我们在不同层面上与这些机器人的关系。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这就是为什么看到 Optimus 我真的很兴奋。人们批评我的兴奋，但我与许多从事人形腿式机器人的研究实验室合作过，波士顿动力、宇树。有很多公司都在做腿式机器人，但运动的优雅只是整个图景中很小很小的一部分。所以，对我来说，关于特斯拉做人形或任何腿式机器人的两个令人兴奋的事情，显然是集成到数据引擎中。所以，数据引擎方面，所以实际的智能，用于感知、控制、规划和所有这些东西。集成到这个巨大的，你提到的车队中。对吧？说到车队，第二件事是...

**Lex Fridman:** 大规模制造商，只是知道在文化上推动一个简单的机器人，便宜地大规模生产。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 并且做得很好，有经验做得很好，这改变了一切。这就是为什么这是一种与波士顿动力完全不同的文化和风格。顺便说一句，那些机器人只是... 它们的移动方式，特斯拉需要很长时间才能达到那种平滑的运动。但这不是重点，重点是整个系统。就像我们谈论的数据引擎和车队。

**Andrej Karpathy:** 对的。

**Lex Fridman:** 这是非常令人兴奋的，即使是最初的模型。但这也非常令人惊讶，在几个月内你就可以得到一个原型。

**Andrej Karpathy:** 是的，之所以能这么快，正如你所暗示的，有很多东西是从自动驾驶中复制粘贴过来的，很多。从特斯拉涌现出来的用于制造人形机器人的专业知识的数量令人难以置信。基本上，埃隆在某个时候说我们要这样做，然后第二天，基本上，所有这些 CAD 模型都开始出现，人们谈论供应链和制造。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 人们拿着螺丝刀出现了，开始组装身体。我想，哇，所有这些人都存在于特斯拉。从根本上说，制造汽车与制造机器人并没有太大的不同。这不仅适用于硬件部分，也不要忘记硬件，不仅仅是为了演示，而是大规模制造这些硬件是完全不同的事情。但对于软件来说也是如此，基本上，这个机器人现在认为它是一辆汽车。

**Lex Fridman:** 它会在某个时候经历中年危机。

**Andrej Karpathy:** 它认为它是一辆汽车。实际上，我们正在讨论的一些早期演示，可能会在停车场外面进行，因为那是所有计算机视觉都能开箱即用的地方。

**Lex Fridman:** 这很有趣。

**Andrej Karpathy:** 而不是在里面。但是所有的操作系统，所有东西都只是复制粘贴，计算机视觉主要是复制粘贴。我的意思是，你必须重新训练神经网络，但是方法、一切、数据引擎、离线跟踪器以及我们处理占用跟踪器的方式等等，一切都是复制粘贴，你只需要重新训练神经网络。然后，当然，规划控制必须改变很多，但是有很多东西是从特斯拉那里复制粘贴过来的。如果你有这样的目标，好吧，让我们制造一百万个人形机器人，而你不是特斯拉，这要求很高，如果你在特斯拉，这实际上就像，这并没有那么疯狂。

**Lex Fridman:** 然后接下来的问题是，就像驾驶一样，操作任务有多困难？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这样它才能产生大规模的影响？我认为这取决于具体情况，机器人技术真正好的地方在于，除非你从事制造业之类的东西，否则有更多的容错空间？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 驾驶对安全性要求非常高，而且对时间要求也很高，机器人可以移动得更慢，这很好。

**Andrej Karpathy:** 是的，我认为这需要很长时间。但是你想要构建开发的方式是，你需要说，好吧，这需要很长时间，我怎样才能设置产品开发路线图，以便在此过程中获得收入？我不会让自己陷入一个零一损失函数中，直到它起作用才起作用。你不希望处于那种境地，你希望它几乎立即就有用。然后你想慢慢部署它，并且...

**Lex Fridman:** 大规模地，希望。

**Andrej Karpathy:** 大规模地，你想建立你的数据引擎，你的改进循环，遥测，评估，工具等等。你想随着时间的推移逐步改进产品，并在此过程中获得收入。这非常重要，因为否则，你无法进行这些大型项目，它们在经济上没有意义。而且，从团队的角度来看，他们需要一路获得“多巴胺”。他们不会只是承诺这将在 10 年后有用，这将改变世界。这不是你想要的状态。你想要处于像我认为今天的自动驾驶那样的状态，它现在就提供了更高的安全性和驾驶便利性。人们为此付费，人们喜欢它，人们购买它。然后你也有更大的使命，你正在朝着这个目标努力。

**Lex Fridman:** 你看到了，所以团队的“多巴胺”，这是幸福的源泉？

**Andrej Karpathy:** 是的，百分之百，你正在部署这个。人们喜欢它，人们驾驶它，人们为此付费，他们在乎它。有很多这样的 YouTube 视频，你的奶奶也在驾驶它。她会给你反馈，人们喜欢它，人们参与其中，你也参与其中，这很重要。

**Lex Fridman:** 驾驶特斯拉的人会认出你并表达感谢吗？比如，嘿，谢谢你的这个很棒的功能。

**Andrej Karpathy:** 是的，我认为棘手的事情是，有些人真的很喜欢你，有些人，不幸的是，你正在做一些你认为非常有价值、有用的事情，等等，有些人确实讨厌你。有很多人讨厌我和团队以及整个项目。我想...

**Lex Fridman:** 他们是特斯拉司机吗？

**Andrej Karpathy:** 很多情况下他们不是，实际上。

**Lex Fridman:** 是的，这实际上让我对人类或当前人类互动的方式感到悲伤。我认为这实际上是可以解决的。我认为人类想善待彼此，我认为 Twitter 和社交媒体是机制的一部分，它实际上以某种方式使消极情绪比它应得的传播得更快，不成比例地增加了消极情绪的传播。但我希望人们能为他人感到兴奋，抑制一些嫉妒、一些自负，为他人感到兴奋。然后，这其中有一种“因果报应”的方面，你为他人感到兴奋，他们也会为你感到兴奋。在学术界也是如此，如果你不小心，那里也存在一个动态系统。如果你以孤立的方式思考，并嫉妒别人的成功，这实际上可能会与直觉相反，导致你作为一个社区和你个人的生产力下降。我觉得如果你不断地庆祝他人，这实际上会让你更成功。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 人们还没有，这取决于行业，还没有完全学会这一点。

**Andrej Karpathy:** 是的，有些人也非常消极，而且非常直言不讳。所以他们非常突出。但实际上，有很多人是啦啦队长，但他们是沉默的啦啦队长。当你在世界上与人们交谈时，他们都会告诉你这很棒，很棒。特别是那些了解让这些东西工作起来有多么困难的人，那些制造过产品、制造商和企业家的人，让这些东西工作起来并改变一些东西是非常困难的。这些人更有可能为你加油。

**Lex Fridman:** 嗯，让我感到难过的一件事是，机器人社区的一些人没有加油，他们应该这样做，因为他们知道这有多难。嗯，他们实际上有时不知道大规模创建产品有多难。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 对吧？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 他们实际上是在部署到现实世界中。很多机器人和人工智能系统的开发都是在非常具体的、小型的基准上进行的，而不是在现实世界的条件下。

**Andrej Karpathy:** 是的，是的，我认为在学术环境中从事机器人技术真的很难。

**Lex Fridman:** 或者适用于现实世界的人工智能系统。

**1:59:01 - ImageNet**

**Lex Fridman:** 你批评过，你也曾经热爱过 ImageNet，著名的 ImageNet 数据集，最近有一些批评的言论，说学术研究机器学习社区对 ImageNet 或这类基准仍然有点过于热爱。你能谈谈机器学习研究中使用的数据集的优势和劣势吗？

**Andrej Karpathy:** 实际上，我不记得我具体在哪个场合对 ImageNet 不满或批评过。我认为 ImageNet 非常有价值。它基本上是一个基准，让深度学习社区能够证明深度神经网络实际上是有效的。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这有巨大的价值。所以，我认为 ImageNet 曾经是有用的，但基本上，它现在已经变成了一个 EMNIST。EMNIST 就像小的 28x28 灰度数字，这是一个每个人都能轻松搞定的“笑话”数据集。

**Lex Fridman:** 但仍然有关于 EMNIST 的论文发表，对吧？比如，强有力的论文？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 比如，专注于我们如何用少量数据学习的论文，诸如此类。

**Andrej Karpathy:** 是的，是的，我可以看到这可能有用，但当然不再是主流的计算机视觉研究了。

**Lex Fridman:** 我想我听你说过，也许我只是在想象，但我认为你说过，ImageNet 在很长一段时间里对社区做出了巨大的贡献，现在是时候超越这些...

**Andrej Karpathy:** 嗯，ImageNet 已经被攻克了。我的意思是，错误率，是的，我们在 1000 个类别的分类预测中获得了 90% 的准确率，我看过那些图像，这真的很高，这真的很好。如果我没记错的话，top-5 错误率现在大约是 1% 或类似的东西。

**Lex Fridman:** 鉴于你在庞大的现实世界数据集方面的经验，你是否希望看到研究社区使用的基准朝着某些方向发展？

**Andrej Karpathy:** 不幸的是，我认为学术界目前还没有下一个 ImageNet。我们显然，我认为我们已经攻克了 EMNIST，我们基本上已经攻克了 ImageNet，而且没有下一个大型基准让整个社区团结起来并用于进一步开发这些网络。

**Lex Fridman:** 哦，是的，我想知道一个数据集需要什么才能吸引所有人的想象力，让他们都支持它。这可能也需要一个领导者，对吧？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 一个有名望的人。我的意思是，是的，为什么 ImageNet 会成功？这只是历史的偶然吗？

**Andrej Karpathy:** 它的难度适中，它足够简单，也足够有趣，它在那个时候是一个合适的数据集。

**2:01:40 - 数据**

**Lex Fridman:** 来自 Reddit 的一个问题：你对合成数据和游戏引擎在未来神经网络模型开发中将扮演的角色有什么看法？

**Andrej Karpathy:** 我认为，随着神经网络向人类趋同，模拟对神经网络的价值将类似于模拟对人类的价值。所以，人们使用模拟，因为他们可以在那种系统中学习一些东西，而无需实际体验它。

**Lex Fridman:** 但你指的是我们在脑海中进行的模拟？思考不就是这样吗？

**Andrej Karpathy:** 哦，不，抱歉，模拟，我的意思是像电子游戏或其他形式的模拟，用于各种专业人士。

**Lex Fridman:** 嗯，所以，让我在这一点上反驳一下，因为也许我们在脑海中进行模拟，比如模拟如果我这样做，我认为会发生什么？

**Andrej Karpathy:** 好的，那是内部模拟。

**Lex Fridman:** 是的，内部的。难道我们不是在这样做吗？假设在我们行动之前。

**Andrej Karpathy:** 哦，是的，但这与使用模拟（例如电脑游戏）或使用模拟来创建训练集等意义上的模拟无关。

**Lex Fridman:** 它是独立的，还是只是松散相关的？因为进行反事实或边缘情况模拟不是很有用吗？比如，如果发生核战争会怎样？如果发生，比如那些事情？

**Andrej Karpathy:** 是的，那是与虚幻引擎不同的模拟。这就是我对这个问题的理解。

**Lex Fridman:** 啊，所以就像模拟平均情况？什么是虚幻引擎？你说的虚幻引擎是什么意思？模拟一个世界。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 那个世界的物理，为什么这不同？因为你也可以为那个世界添加行为，你可以尝试各种各样的事情，对吧？你可以把各种奇怪的东西扔进去。

**Andrej Karpathy:** 是的，虚幻引擎不仅仅是模拟世界的物理，它还在做其他的事情。

**Andrej Karpathy:** 是的，图形、物理以及你放入环境中的智能体等等。

**Lex Fridman:** 我觉得你说过这并不重要，对于人工智能的未来发展来说。这样理解你对吗？

**Andrej Karpathy:** 嗯，我认为，人类使用模拟器，他们发现它们很有用，所以计算机也会使用模拟器并发现它们有用。

**Lex Fridman:** 好的，所以你的意思是，我不经常使用模拟器。我偶尔会玩电子游戏，但我不认为我从那些电子游戏中获得了关于我自己存在的任何智慧。这是对现实的一种短暂的逃避，而不是关于现实的智慧的来源。所以，我认为这是一种非常礼貌的说法，模拟没有那么有用。

**Andrej Karpathy:** 是的，也许不是。我不认为它是目前训练神经网络的一个基本的、非常重要的部分。但我认为，随着神经网络变得越来越强大，我认为你将需要更少的例子来训练额外的行为。模拟是，当然，模拟中存在一个领域差距，它不是真实世界，它略有不同。但我认为，对于一个足够强大的神经网络来说，领域差距可以更大，因为神经网络会理解，即使它不是真实世界，它也有所有这些我应该学习的高级结构。

**Lex Fridman:** 所以，神经网络实际上，是的，它将能够更好地利用合成数据？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 通过缩小差距，但要理解这在哪些方面不是真实数据？

**Andrej Karpathy:** 完全正确。

**Lex Fridman:** Reddit 下次提更好的问题。那是一个问题。不，我只是开玩笑。好吧，你认为有可能构建只需要很少数据的神经网络和训练过程吗？所以，我们一直在谈论巨大的数据集，比如互联网，用于训练。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我的意思是，一种说法是，就像你说的，查询本身是另一种层次的训练，我想，这需要很少的数据。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但是，你认为在研究方面是否有价值，朝着我们可以使用非常少的数据来构建知识库的方向发展？

**Andrej Karpathy:** 百分之百。我只是认为在某个时候，你需要一个庞大的数据集，然后当你预训练你的大型神经网络并得到类似 GPT 的东西时，你就可以非常高效地训练任何新的任务。所以，很多这些 GPT，你可以通过非常少的例子来完成诸如情感分析或翻译等任务。这是我想让你做的事情的类型，这是一个输入句子，这是翻译成德语，输入句子，翻译成德语，输入句子，空白，神经网络会通过查看你提供的例子来完成到德语的翻译。所以，这是神经网络激活中非常少样本学习的一个例子，而不是神经网络的权重。所以，我认为，基本上就像人类一样，神经网络将在学习任何其他新任务时变得非常数据高效。但在某个时候，你需要一个庞大的数据集来预训练你的网络。

**Lex Fridman:** 我确实理解这一点。而且，可能，我们人类也有类似的东西。我们有类似的东西吗？我们是否有一个在后台被动运行的东西，一个构建模型的后台程序，它只是以自监督的方式一直运行？我们没有意识到它？

**Andrej Karpathy:** 我认为人类肯定，我的意思是，显然，我们在我们的生命周期中学到了很多，但我们也有大量的硬件来帮助我们，来自进化的初始化。所以，我认为这也是一个非常重要的组成部分。我认为这个领域的很多人，他们只是在谈论一个人活了多少秒，假装这是一个白板，一个零初始化的神经网络。事实并非如此。你可以看看很多动物，例如斑马。斑马出生后就能看见，它们可以奔跑，它们的生命周期中没有训练数据，它们就是可以做到这一点。所以，不知何故，我不知道是怎么回事，进化已经找到了一种方法来将这些算法和这些非常好的神经网络初始化编码到 ATCG 中。我不知道这是如何工作的，但显然，这是可能的，因为这里有存在的证明。

**Lex Fridman:** 从单细胞到一个有机体，再到生命的前几年，这其中有一些神奇之处。我喜欢这个想法，我们不记得我们生命的前几年的任何事情的原因是，这是一个非常痛苦的过程，就像这是一个非常困难、具有挑战性的训练过程。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 就像智力上的，也许，是的，我的意思是，我不知道，为什么我们不记得任何这些？那可能是一些疯狂的训练，也许这就是后台模型训练，非常痛苦。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，最好是系统一旦训练好，就不记得它是如何构建的。

**Andrej Karpathy:** 我认为这只是因为长期记忆的硬件还没有完全发育好。

**Lex Fridman:** 当然。

**Andrej Karpathy:** 我觉得婴儿的前几年，实际上并不是学习，而是大脑在成熟。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我们出生时是早产的，有一个关于产道和大脑肿胀的理论。所以，我们出生时是早产的，然后在前几年，我们只是，大脑在成熟，然后最终会有一些学习。这是我目前的看法。

**Lex Fridman:** 你认为，你认为神经网络可以拥有长期记忆吗？像人类那样的方法？你认为需要在它之上添加另一个元架构来添加类似知识库的东西，学习关于世界的事实和所有这些东西吗？

**Andrej Karpathy:** 是的，但我不知道它将在多大程度上被显式地构建。它可能会采取直观的形式，你告诉 GPT，嘿，


### P5

**Andrej Karpathy:** ...你有一个声明性记忆库，你可以从中存储和检索数据，每当你遇到你认为有用的信息时，就把它保存到你的记忆库中。这里有一个你检索到的东西的例子，这里是你如何说它，这里是你如何从中加载，你只是说，加载任何东西，你用文本、用英语教它，然后它可能会学会使用记忆库。

**Lex Fridman:** 哦，所以神经网络是后台模型、基础东西的架构，然后其他一切都只是在它之上。

**Andrej Karpathy:** 不仅仅是文本，对吧？你给了它一些小工具和小玩意。所以，你教给它某种特殊的语言，通过这种语言，它可以保存任意的信息，并在以后检索它。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你告诉它这些特殊的标记以及如何排列它们来使用这些接口。就像，嘿，你可以使用计算器，这是你使用它的方式。只需执行五三加四一等于，当等于在那里时，计算器实际上会读出答案，你不必自己计算，你只是用英语告诉它，这实际上可能会奏效。

**Lex Fridman:** 从这个意义上说，你认为 Gato 是有趣的吗？DeepMind 的系统，它不仅仅是新的语言，而是实际上把所有东西都扔进同一个堆里，图像、动作，所有这些东西。这基本上就是我们前进的方向。

**Andrej Karpathy:** 是的，我认为是这样。所以，Gato 非常像一个“厨房水槽”的方法，在许多不同的环境中进行强化学习，使用一个单一的固定 Transformer 模型。对吧？我认为这是该领域的一个非常早期的结果。但是，我认为，是的，这与我认为事情最终会是什么样子是一致的。

**Lex Fridman:** 对的，所以这是一个系统的早期阶段，最终会看起来像这样，从 Rich Sutton 的角度来看。

**Andrej Karpathy:** 是的，我不是特别喜欢，我认为所有这些看起来非常不同的接口。我希望一切都被规范化到同一个 API。所以，例如，屏幕像素，非常相同的 API，而不是拥有具有非常不同的物理和关节配置、外观等不同的世界环境。你有一些针对不同游戏的特殊标记，你可以插入。我宁愿把一切都规范化到一个单一的接口，这样对神经网络来说看起来是一样的，如果这有意义的话。

**Lex Fridman:** 所以最终都会变成基于像素的 Pong？

**Andrej Karpathy:** 我认为是这样。

**Lex Fridman:** 好的。让我问你一些关于你个人生活的问题。

**2:11:31 - 一天中的生活**

**Lex Fridman:** 很多人想知道，你是人工智能历史上最有生产力和最聪明的人之一。Andrej Karpathy 富有成效的一天是什么样的？你什么时候起床？因为想象一下平均的富有成效的一天和完美的富有成效的一天之间的某种“舞蹈”。所以，完美的富有成效的一天是我们努力追求的东西，而平均水平是它最终会趋向的样子，考虑到所有的错误和人类的偶然性等等。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，你什么时候起床？你是一个早起的人吗？

**Andrej Karpathy:** 我不是一个早起的人，我是一个夜猫子，肯定的。

**Lex Fridman:** 这稳定吗？

**Andrej Karpathy:** 半稳定，像八九点之类的。在我读博士的时候，甚至更晚，我过去通常凌晨 3 点睡觉，我认为凌晨的时间很宝贵，是一个非常有趣的


### P6

**Andrej Karpathy:** ...工作时间，因为那时所有人都睡了。早上 8 点或 7 点，东海岸的人们醒着，所以已经有一些活动，已经有一些短信之类的，有事情发生，你可以在一些新闻网站上看到有事情发生，这会让人分心。凌晨 3 点，一切都非常安静，所以你不会被打扰，你有大块的时间可以工作。所以我喜欢那些时间段，默认情况下是个夜猫子。然后我认为，高效的时间，基本上，我喜欢做的是，你需要在问题上建立一些动力，不要有太多的干扰，你需要把你的“内存”，你的工作记忆加载到那个问题上。然后，当你洗澡的时候，当你入睡的时候，你需要对这个问题着迷，它完全在你的记忆中，你已经准备好醒来并立即开始工作。

**Lex Fridman:** 所以这是以一天的时间尺度，还是几天、一周、一个月？

**Andrej Karpathy:** 是的，所以我不能孤立地谈论一天，因为它是一个完整的过程。当我想在一个问题上高效工作时，我觉得我需要几天的时间，在那里我可以真正地投入到那个问题中，我不想被打断，我只想完全沉浸在那个问题中。这就是我大部分出色工作完成的时候，我想说。

**Lex Fridman:** 你在很短的时间内完成了一堆很酷的小项目，非常快，所以这需要你集中精力。

**Andrej Karpathy:** 是的，基本上，我需要把我的工作记忆加载到问题上，我需要高效，因为解决任何问题总是有巨大的固定成本。例如，我在特斯拉的时候就为此苦苦挣扎，因为我想做一个小的副业项目，但是，好吧，首先你需要弄清楚，哦，好的，我需要连接到我的集群，我需要启动一个 VS Code 编辑器，这样我才能开始工作。我因为某种原因遇到了一个愚蠢的错误。你还没有达到可以立即高效工作的状态。你面临着障碍。所以，关键在于真正消除所有这些障碍，你能够进入问题，并且你的记忆中已经加载了整个问题。

**Lex Fridman:** 并以某种方式避免各种形式的干扰。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 比如新闻故事、电子邮件，也包括来自你以前工作过或当前正在工作的其他有趣项目的干扰。你只想真正集中你的注意力。

**Andrej Karpathy:** 是的，我可以在中间休息一下，处理一些干扰，但我认为这不能太多。你一天中的大部分时间都应该花在那个问题上。然后，我喝咖啡，我有我的晨间例行公事，我看一些新闻、Twitter、Hacker News、《华尔街日报》等等，这很好。

**Lex Fridman:** 所以基本上，你起床，喝点咖啡，你是否试图尽快开始工作？你是否先摄入一些关于世界上发生了什么的信息？

**Andrej Karpathy:** 我确实觉得了解世界很有趣，我不知道这是否有用或有益，但这是我现在例行公事的一部分。所以，我确实会阅读一堆新闻文章，我想了解信息，我对它持怀疑态度。我对这种做法持怀疑态度，但目前，我就是这样。

**Lex Fridman:** 哦，你是指对这种做法对你的生产力和幸福感的积极影响持怀疑态度？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 以及对你深入理解世界的能力，因为有很多信息来源，你并没有真正集中精力去整合它。

**Andrej Karpathy:** 是的，这有点让人分心。是的。

**Lex Fridman:** 对于一个完美的、富有成效的一天，你尝试在一次工作中专注多长时间？是几个小时，一个小时，30 分钟，还是 10 分钟？

**Andrej Karpathy:** 我大概可以坚持几个小时，然后我需要在中间休息一下，吃点东西之类的，是的。但我认为，仍然很难积累时间。我曾经用一个追踪器来告诉我每天到底花了多少时间编码。即使在一个非常高效的日子里，我仍然只花了六到八个小时。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这只是因为有很多“填充”，通勤，与人交谈，食物等等。生活、维持和保持体内平衡的成本很高，仅仅是维持你自己作为一个人的状态，成本就很高。

**Lex Fridman:** 人类的思想中似乎有一种参与社会的渴望，这产生了那种“填充”。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 因为我经历过的最有成效的日子，就是从头到尾完全屏蔽一切。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 然后你可以做超过六到八个小时。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 关于是什么让你有力量去度过艰难的、长时间专注的日子，你有什么见解吗？

**Andrej Karpathy:** 是的，只要我对一个问题着迷，有些东西就必须工作，有些东西就必须存在。

**Lex Fridman:** 它必须存在。所以你能够处理编程问题、技术问题和设计决策中的错误，这些错误最终被证明是错误的。你能够思考所有这些，因为你希望一个东西存在。

**Andrej Karpathy:** 是的，它必须存在。然后我认为对我来说，一个很大的因素是，其他人类是否会欣赏它？他们会喜欢它吗？这是我动力的很大一部分。如果我在帮助人类，他们看起来很开心，他们说了好话，他们在推特上谈论它或什么的，这让我感到快乐，因为我在做一些有用的事情。

**Lex Fridman:** 所以你确实看到了自己与世界分享它？通过 GitHub、博客文章或视频？

**Andrej Karpathy:** 是的，我在想，假设我做了所有这些事情，但没有分享它们。我不认为我会有同样多的动力。

**Lex Fridman:** 你享受其他人从你创造的东西中获得价值和快乐的感觉。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 饮食方面呢？我看到你尝试过间歇性禁食。你禁食吗？这有帮助吗？

**Andrej Karpathy:** 我什么都尝试。

**Lex Fridman:** 在你尝试过的东西中，什么对你精神上专注于一件事的能力、精神生产力和幸福感最有益？你还在禁食吗？

**Andrej Karpathy:** 是的，我还在禁食，但我做的是间歇性禁食，但实际上，归根结底，这意味着我不吃早餐。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，当我处于稳定状态时，我默认采用 18/6 的模式，如果我在旅行或做其他事情，我会打破规则。但在我的稳定状态下，我做 18/6，所以，我只在 12 点到 6 点之间进食。这不是一个硬性规定，我经常打破它，但这是我的默认设置。然后，是的，我做了一堆随机的实验，在大多数情况下，现在我在过去一年半的时间里，我想说，我是植物性饮食或植物为主。我听说过“植物为主”，听起来更好。

**Lex Fridman:** 这到底是什么意思？

**Andrej Karpathy:** 我实际上不知道有什么区别，但在我看来，听起来更好。但这只是意味着我更喜欢植物性食物，并且...

**Lex Fridman:** 生的还是熟的？

**Andrej Karpathy:** 我更喜欢熟的，植物性的。

**Lex Fridman:** 所以，植物性的，原谅我，我实际上不知道植物这个类别的范围有多广。

**Andrej Karpathy:** 嗯，植物性只是意味着你不那么激进，你可以灵活，你只是更喜欢吃植物，你不会强迫别人。你去某人家参加派对，他们给你上了一块他们引以为豪的牛排，你会吃掉它。

**Lex Fridman:** 是的，对的，你不评判。这很好。我的意思是，我是相反的，但我非常灵活。你有没有试过一天只吃一顿饭？

**Andrej Karpathy:** 我不小心试过，但不经常，我不小心这样做过。我不喜欢它，我觉得这让我感觉不好，冲击太大了。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，目前我每天大概吃两顿饭，12 点和 6 点。

**Lex Fridman:** 我一直这样做，我现在就在这样做，我一天只吃一顿饭。

**Andrej Karpathy:** 好的。

**Lex Fridman:** 这很有趣，这是一种有趣的感觉。你有没有禁食超过一天？

**Andrej Karpathy:** 是的，我做过几次只喝水的禁食，因为我很好奇会发生什么。

**Lex Fridman:** 发生了什么，有什么有趣的事情吗？

**Andrej Karpathy:** 是的，我想说，我的意思是，有趣的是，你饿了两天，然后从第三天左右开始，你就不饿了。这是一种非常奇怪的感觉，因为你已经好几天没吃东西了，但你并不饿。

**Lex Fridman:** 是的，这不奇怪吗？

**Andrej Karpathy:** 这真的很奇怪。

**Lex Fridman:** 关于人类生物学的众多奇怪的事情之一。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 它弄清楚了一些事情，它找到了另一种能量来源，或者放松了系统。我不知道它是如何工作的。

**Andrej Karpathy:** 是的，身体就像，“你饿了，你饿了。”然后它就放弃了，它就像，“好吧，我想我们现在在禁食。”什么也没有。然后它只是专注于让你不饿，不感受到损害，并试图给你一些空间来解决食物问题。

**Lex Fridman:** 所以，你现在仍然在晚上最高效吗？

**Andrej Karpathy:** 我想说我是，但要保持我博士期间的作息真的很难，尤其是在特斯拉工作的时候，这是不可能的。但即使是现在，人们也想见面参加各种活动，社会生活在一定的时间段内。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你必须适应。

**Lex Fridman:** 很难进行社交活动，然后回去继续工作。

**Andrej Karpathy:** 是的，这真的很难。

**Lex Fridman:** 这就是为什么当我进行社交活动时，我尽量不喝太多酒，这样我就可以回去继续工作。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但是在特斯拉，是否有趋同，不仅仅是特斯拉，在任何公司，是否总是会趋同于一个时间表，或者这就是人类在合作时的行为方式？我需要了解一下。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 他们是否试图保持一个一致的时间表，让你们都在同一时间醒着？

**Andrej Karpathy:** 我的意思是，我确实试图创建一个例行公事，我试图创造一个我感到舒适的稳定状态。所以，我有一个早晨的例行公事，我有一个白天的例行公事，我试图让事情保持稳定状态，一切都是可预测的，然后你的身体就会适应。如果你试图过度挑战它，它就会产生，当你在旅行并且有时差的时候，你无法真正达到你需要达到的状态。

**Lex Fridman:** 是的，是的，关于我们人类的习惯等等，这也很奇怪。你对整个人的工作与生活的平衡有什么看法？所以，特斯拉在某种程度上以将人们推向极限而闻名，无论是在他们能做什么、他们在尝试做什么，以及他们工作多少等方面。

**Andrej Karpathy:** 是的，我的意思是，我想说特斯拉在这方面有点被过度批评了，因为实际情况是，特斯拉是一个“爆发式”的环境。所以，我想说，基线，我唯一的参考点是我实习过三次的谷歌，我看到了谷歌和 DeepMind 内部的情况，我想说，基线比那里高。但是，偶尔会发生“火灾”，人们会非常努力地工作，所以它是尖峰式的、爆发式的，然后所有的故事都被收集起来...

**Lex Fridman:** 关于爆发的故事，是的。

**Andrej Karpathy:** 然后它给人一种完全疯狂的印象。但实际上，这只是一个稍微紧张一点的环境，会有“火灾”和冲刺，所以，我想说，这肯定是一个比你在谷歌遇到的更紧张的环境。

**Lex Fridman:** 但在你个人生活中，忘记所有这些，只是在你自己的个人生活中，你如何看待一个人的幸福？一个像你一样聪明的人，关于在工作和生活之间找到平衡，或者这样的想法是不是一个好的思想实验？

**Andrej Karpathy:** 是的，我认为平衡是好的，但我也喜欢有一些超出常规的冲刺，我认为那也是我非常有创造力的时候。

**Lex Fridman:** 所以，超出常规的冲刺意味着大多数时候你有一个所谓的平衡。

**Andrej Karpathy:** 我大多数时候都有平衡，我喜欢偶尔沉迷于某件事。

**Lex Fridman:** 偶尔是什么意思，一周一次，一个月一次，一年一次？

**Andrej Karpathy:** 是的，大概一个月一次之类的，是的。

**Lex Fridman:** 那就是我们得到和你得到 Git-Repo for market 的时候。

**Andrej Karpathy:** 是的，那就是你真正关心一个问题的时候，它必须存在，这将是令人惊叹的，你沉迷于它，现在你不能只在那一天做，你需要支付进入状态的固定成本。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 然后你需要待在那里一段时间，然后社会会来找你，他们会试图干扰你，他们会试图让你分心。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 最糟糕的事情是有人说：“我只需要你五分钟的时间。”

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这的成本不是五分钟。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 社会需要改变它对“只需要你五分钟的时间”的看法。

**Lex Fridman:** 对的，这从来都不是一分钟，只是 30 秒，只是一件小事。

**Andrej Karpathy:** 有什么大不了的？你为什么这么...

**Lex Fridman:** 是的，不。你的电脑设置是什么样的？什么是完美的... 你是一个对任何笔记本电脑、四个屏幕都很灵活的人吗？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 或者你更喜欢某种让你最高效的设置？

**Andrej Karpathy:** 我猜我熟悉的是一个 27 英寸的大屏幕，我的笔记本电脑放在旁边。

**Lex Fridman:** 什么操作系统？

**Andrej Karpathy:** 我用 Mac OS，这是我的主要系统。

**Lex Fridman:** 对于所有任务？

**Andrej Karpathy:** 我想说 OS X。但是当你从事深度学习工作时，一切都是 Linux，你通过 SSH 连接到集群并在远程工作。

**Lex Fridman:** 但是实际的开发呢？比如使用 IDE？

**Andrej Karpathy:** 是的，你会使用，我认为一个好的方法是在你的 Mac 上运行 VS Code，这是我现在最喜欢的编辑器。但实际上，你有一个通过 SSH 的远程文件夹。所以，你实际操作的文件在其他地方的集群上。

**2:24:47 - 最佳 IDE**

**Lex Fridman:** 那么，什么是最好的 IDE，VS Code？人们还使用什么？我还在用 Emacs。

**Andrej Karpathy:** 那是老派的。

**Lex Fridman:** 它可能很酷，我不知道它是否能最大限度地提高生产力。那么，你推荐使用什么编辑器？你与很多软件工程师合作过，用于 Python、C++、机器学习应用的编辑器。

**Andrej Karpathy:** 我认为目前的答案是 VS Code，目前，我相信这是最好的 IDE。它有大量的扩展，它集成了 GitHub Copilot，我认为这非常有价值。

**Lex Fridman:** 你怎么看待 Copilot 的集成？我和 Guido van Rossum 聊了很多，他是 Python 的创造者，他喜欢 Copilot，他经常用它编程。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你呢？

**Andrej Karpathy:** 是的，我使用 Copilot，我喜欢它。而且它对我来说是免费的，但我愿意为它付费。是的，我认为它非常好。我发现它的实用性是，我想说有一个学习曲线，你需要弄清楚什么时候它有帮助，什么时候要注意它的输出，什么时候它没有帮助，什么时候你不应该注意它。因为如果你只是阅读它的建议，这不是一个很好的互动方式。但我认为我能够适应它。我发现它在以下两个方面非常有帮助：第一，复制粘贴和替换某些部分。所以，当模式很清晰时，它非常擅长完成模式。第二，有时它会建议我不知道的 API。所以，它会告诉你一些你不知道的东西。

**Lex Fridman:** 这是一个发现新事物的机会。

**Andrej Karpathy:** 这是一个机会。所以我永远不会把 Copilot 的代码当作理所当然。我几乎总是复制粘贴到谷歌搜索中，看看这个函数在做什么，然后你会想，“哦，这实际上正是我需要的。”谢谢你，Copilot。所以你学到了一些东西。

**Lex Fridman:** 所以，它在某种程度上是一个搜索引擎，在某种程度上可以正确地获取语法，一旦你看到它，你就知道它是正确的。

**Andrej Karpathy:** 是的，没错，没错。

**Lex Fridman:** 你自己可以验证...

**Andrej Karpathy:** 你可以高效地验证，但你不能高效地生成。

**Andrej Karpathy:** Copilot 实际上是编程的“自动驾驶”，对吧？现在它正在做“车道跟随”，做一些简单的事情，但最终，它将变得越来越自主。同样的事情不仅会在编程中发生，而且可能会在很多很多不同的事情中发生。

**Lex Fridman:** 但是编程是一个重要的方面，对吧？

**Andrej Karpathy:** 非常重要。

**Lex Fridman:** 编写程序。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你如何看待它的未来发展，程序合成，能够编写越来越复杂的程序？因为现在它在以有趣的方式受到人类的监督。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 感觉这种转变将非常痛苦。

**Andrej Karpathy:** 我的思维模型是，同样的事情也会发生在自动驾驶上。所以，现在，它正在进行车道跟随，它正在做一些简单的事情，最终，它将实现自主，人们将不得不越来越少地干预。这些可能是测试机制。如果它编写了一个函数，而那个函数看起来非常正确。但是，你怎么知道它是正确的呢？因为作为一个程序员，你变得越来越懒惰，你的能力，因为是小错误，但我猜它不会犯小错误。

**Andrej Karpathy:** 不，它会，Copilot 会犯“差一”的微妙错误，它对我这样做过。

**Lex Fridman:** 但是你认为未来的系统会这样做吗，或者“差一”实际上是编程的一个根本挑战吗？

**Andrej Karpathy:** 在那种情况下，它不是根本性的，我认为事情可以改进，但是，是的，我认为人类必须进行监督。我对人们不监督产生的内容感到紧张，以及这会对什么产生影响，例如，我们系统中错误的扩散。我对这个问题感到紧张，但我认为可能会有其他用于发现错误的 Copilot 之类的东西，在某个时候。因为将会...

**Lex Fridman:** 哦，天哪，一个生成编译器的 Copilot。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 一个做静态检查的。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 一个做类型检查的。

**Andrej Karpathy:** 是的，这是一个 GPT 委员会之类的...

**Lex Fridman:** 然后会有一个委员会的经理。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 然后会有人说，需要这个的新版本，我们需要重新生成它。

**Andrej Karpathy:** 是的，有 10 个 GPT 被转发，并给出了 50 个建议，另一个 GPT 查看了它，并挑选了一些他们喜欢的，一个“错误”的 GPT 查看了它，它就像，这可能是一个错误，它们被其他东西重新排序，然后一个最终的集成 GPT 出现了，它就像，好的，根据你们告诉我的所有信息，这可能是下一个标记。

**Lex Fridman:** 你知道，感觉是世界上程序员的数量一直在快速增长。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你认为它是否有可能趋于平稳并下降到一个非常低的水平？因为那时你将从事软件 2.0 编程，你将进行这种 Copilot 类型系统的生成编程，但你不会从事旧式的软件 1.0 编程。

**Andrej Karpathy:** 我现在不认为它们会取代人类程序员。我说这样的话很犹豫，对吧？

**Lex Fridman:** 是的，因为这将在五年后重播，不，这将表明这就是我们所想的，因为我同意你的观点，但我认为我们可能会非常惊讶，对吧？你对我们目前在语言模型方面的立场有什么看法？感觉是开始、中间还是结束？

**Andrej Karpathy:** 开始，百分之百。我认为我脑海中的一个大问题是，GPT 肯定能够很好地、称职地进行编程，等等。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你如何引导这个系统？你仍然需要提供一些指导，说明你实际上在寻找什么。所以，你如何引导它，你如何说，你如何与它交谈？你如何审核它并验证它所做的是正确的？你如何使用这个？这不仅仅是一个人工智能问题，还是一个 UI、UX 问题。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，这是一片非常肥沃的土地，可以进行很多有趣的工作，对于 VS Code++，你不仅仅是，这不仅仅是人类编程了，这太棒了。

**Lex Fridman:** 是的。所以你在与系统交互，所以不仅仅是一个提示，而是迭代提示。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你试图弄清楚，与系统进行对话。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 实际上，我的意思是，对我来说，与我正在编写的程序进行对话是非常令人兴奋的。

**Andrej Karpathy:** 是的，是的，也许在某个时候，你只是在与它交谈。就像，好的，这是我想做的，实际上这个变量，也许它甚至没有那么低级，作为一个变量，但是...

**Lex Fridman:** 你也可以想象，你能把这个翻译成 C++，然后再翻译回 Python，然后再翻译回去吗？

**Andrej Karpathy:** 是的，这在某种程度上已经存在了。

**Lex Fridman:** 不，只是把它作为程序体验的一部分。就像，我想用 C++ 编写这个函数，或者你只是不断地从不同的程序中转换，因为不同的语法，也许我想把它转换成一种函数式语言。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，你作为一个程序员，可以变成多语种，并且可以高效地来回切换。

**Andrej Karpathy:** 是的，我的意思是，我认为它的 UI、UX 仍然很难思考。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 因为这不仅仅是在页面上编写代码，你有一个完整的开发环境，你在上面有一堆硬件，你有一些环境变量，你有一些在定时任务中运行的脚本。有很多事情在与计算机一起工作，这些系统如何设置环境标志，跨多台机器工作，设置屏幕会话，自动化不同的进程，所有这些是如何工作的，以及如何由人类审核等等，目前是一个巨大的问题。

**Lex Fridman:** 你构建了 arxiv-sanity，什么是 arXiv，以及你希望看到的学术研究出版的未来是什么？

**2:31:53 - arXiv**

**Andrej Karpathy:** 所以 arXiv 是一个预印本服务器。所以，如果你有一篇论文，你可以把它提交给期刊或会议发表，然后等待六个月，然后可能会得到一个通过或失败的决定，或者你可以把它上传到 arXiv，然后人们可以在三分钟后在推特上谈论它。然后每个人都能看到它，每个人都能阅读它，每个人都能以自己的方式从中获益。

**Lex Fridman:** 你可以引用它，它有一个正式的外观，感觉像是一个出版过程。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 感觉与你把它放在博客文章中不同。

**Andrej Karpathy:** 哦，是的，是的，我的意思是，这是一篇论文，通常你在 arXiv 上看到的门槛会更高，而不是你在博客文章中看到的东西。

**Lex Fridman:** 嗯，文化创造了门槛，因为你也可以在 arXiv 上发表一篇相当糟糕的论文。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这让你有什么感觉，这让你对同行评审有什么感觉？所以，由两到三位专家进行严格的同行评审，而不是在撰写时由社区进行同行评审？

**Andrej Karpathy:** 是的，基本上，我认为社区非常有能力在推特上快速地对事物进行同行评审。我认为也许这只是与人工智能机器学习领域有关，我觉得事情更容易审核，验证可能比其他地方更容易。所以，你可以把这些科学出版物想象成一个个小的区块链，每个人都在彼此的工作基础上进行构建，并相互引用，你有人工智能，这是一个更快、更松散的区块链，然后你有，而且任何一个单独的条目都很容易制作。然后你在其他领域，也许这种模式没有那么有意义。所以，我认为至少在人工智能领域，事情很容易验证。这就是为什么当人们上传论文时，他们有一个非常好的想法等等。人们可以在第二天尝试一下，他们可以成为它是否适用于他们的问题的最终仲裁者。整个事情的进展速度要快得多。所以，我觉得学术界仍然有一席之地，抱歉，这个会议、期刊流程仍然有一席之地，但它有点滞后，我认为，它可能是一个更高质量的流程。但它不再是你发现前沿工作的地方。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 当我开始攻读博士学位时，你会去参加会议和期刊，讨论所有最新的研究。现在，当你去参加会议或期刊时，没有人讨论那里的任何东西，因为它已经是三代以前的事情了，无关紧要了。

**Lex Fridman:** 是的，这让我对 DeepMind 感到难过，例如，他们仍然在《自然》和这些享有盛誉的，我的意思是，这些大场馆带来的声望仍然有价值。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但结果是，他们会宣布一些突破性的性能，但实际上需要一年时间才能公布细节。我的意思是，如果这些细节立即公布，将激励社区朝着某些方向前进，不是吗？

**Andrej Karpathy:** 是的，这将加速社区其他人的发展，但我不知道这在多大程度上也是他们目标函数的一部分。

**Lex Fridman:** 没错，所以这不仅仅是声望，延迟一点也是其中的一部分。

**Andrej Karpathy:** 是的，他们当然，特别是 DeepMind，一直在以稍微高质量的方式工作，基本上是过程和延迟，并以这种方式发表那些论文。

**Lex Fridman:** 来自 Reddit 的另一个问题。你是否患有或曾经患有冒名顶替综合症，作为特斯拉的人工智能总监，作为这个当你在斯坦福大学时，全世界都把你视为人工智能专家，向世界传授机器学习知识的人？

**Andrej Karpathy:** 当我五年后离开特斯拉时，我在会议室里花了很多时间，我会阅读论文。一开始，当我加入特斯拉时，我正在编写代码，然后我编写的代码越来越少，我开始阅读代码，然后我阅读的代码也越来越少。所以，我认为这只是一个自然而然的过程。当然，我想说，在接近尾声的时候，你会开始更多地感受到这一点。你应该是一个专家，但实际上，“真相”的来源是人们正在编写的代码、GitHub 和实际的代码本身。你对它的熟悉程度不如以前了。所以，我想说，也许那里存在一些不安全感。

**Lex Fridman:** 是的，这实际上非常深刻，很多不安全感与在计算机科学领域不编写代码有关，因为那才是“真相”，就在那里。

**Andrej Karpathy:** 代码是“真相”的来源。论文和其他一切，这是一个高层次的总结。我不，是的，只是一个高层次的总结，但归根结底，你必须阅读代码。不可能将所有代码都转换成实际的论文形式。所以，当东西出来的时候，特别是当它们有源代码可用的时候，那是我最喜欢去的地方。

**2:36:23 - 给初学者的建议**

**Lex Fridman:** 就像我说的，你是机器学习人工智能有史以来最伟大的教师之一，从 CS231n 到今天，你会给对进入机器学习感兴趣的初学者什么建议？

**Andrej Karpathy:** 初学者通常关注要做什么，我认为重点应该更多地放在你做了多少。所以，在高层次上，我相信这个一万小时的概念，你只需要选择你能花时间、你关心、你感兴趣的事情。你真的必须投入一万个小时的工作。你把它投入到哪里甚至都不那么重要，你会迭代，你会改进，你会浪费一些时间。我不知道是否有更好的方法。你需要投入一万个小时。但我认为这实际上非常好，因为我觉得如果你花费一万个小时，成为某个领域的专家是有某种确定性的。你实际上可以选择任意的事情，我认为如果你花费一万个小时的刻意努力和工作，你实际上会成为这方面的专家。所以，我认为这是一个很好的想法。所以，基本上，我会更多地关注你是否花费了一万个小时？这是我会关注的。

**Lex Fridman:** 然后思考什么样的机制可以最大限度地提高你达到一万小时的可能性。

**Andrej Karpathy:** 是的，完全正确。

**Lex Fridman:** 对我们这些愚蠢的人类来说，这意味着可能要养成每天实际做事的习惯。

**Andrej Karpathy:** 任何能帮助你的。所以，我认为在很大程度上，这是一个心理问题，为你自己。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 另一件我认为对心理有帮助的事情是，很多时候人们会将自己与该领域的其他人进行比较，我认为这是非常有害的。只将自己与前一段时间的自己进行比较。比如一年前，你比一年前的自己更好吗？这是唯一的思考方式。我认为这样你就能看到自己的进步，这非常激励人心。

**Lex Fridman:** 这很有趣，关注时间的数量。因为我认为很多人在初学者阶段，但实际上在整个过程中，都会因为选择而瘫痪。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 就像我应该选择这条路还是那条路？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 他们真的会因为选择哪个 IDE 而瘫痪？

**Andrej Karpathy:** 嗯，他们担心，是的，他们会担心所有这些事情。但问题是，你会浪费时间做一些错误的事情。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你最终会发现这是不对的。你会积累一些“伤疤组织”，下次你会变得更强大，因为下次你会有“伤疤组织”，下次你会从中吸取教训。现在，下次你遇到类似的情况时，你会想，哦，我搞砸了。我花了很多时间做一些没有任何成果的事情，我有了所有这些“伤疤组织”，我对什么是有用的，什么是没有用的，事情的结果如何有了一些直觉。所以，所有那些错误都不是白费的。所以，我只是认为他们应该专注于工作。你做了什么，你上周做了什么？

**Lex Fridman:** 这是一个很好的问题，实际上可以问很多事情，不仅仅是机器学习。这是消除“赘肉”的好方法，我忘记了我们使用的术语，但“赘肉”，无论生活中有什么低效率。

**Lex Fridman:** 你喜欢教学的什么？你似乎经常发现自己，被教学所吸引。你非常擅长，但你也被它吸引。

**Andrej Karpathy:** 是的，我的意思是，我不认为我喜欢教学。我喜欢快乐的人，快乐的人喜欢我教的东西。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我不会说我讨厌教学，我容忍教学。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 但我喜欢的不是教学行为本身，而是我有一些东西，我实际上还可以。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我在教学方面还可以，人们非常欣赏它。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，我只是很高兴能提供帮助，教学本身并不是最，我的意思是，它可能真的很烦人，令人沮丧。我正在准备一些讲座，我想起了我制作 231n 课程的日子，制作其中一些材料需要多少工作，让它们变得出色。迭代和思考的数量，你会走入死胡同，以及你改变了多少。所以，创造具有教育价值的东西真的很难，而且这并不有趣。

**Lex Fridman:** 这很困难。所以人们一定要去看你发布的新内容。有一些讲座，你实际上是在构建东西，就像你说的，“代码是‘真相’”。所以，通过构建它来讨论反向传播，通过查看，只是整个过程。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 准备这些有多难？我认为这是一种非常强大的教学方式。你必须为此做准备，还是你只是在现场思考？

**Andrej Karpathy:** 我通常会做三遍，然后我选择更好的一遍。所以，我会做多遍，我会选择一些更好的，然后我就这样构建一个讲座。有时我必须删除 30 分钟的内容。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 因为它只是走入了我不太喜欢的死胡同。所以，有很多的迭代，创建一个小时的内容可能需要我大约 10 个小时。

**Lex Fridman:** 得到一个小时。这很有趣，我的意思是，回到基础是否困难？你是否从回到基础中汲取了很多智慧？

**Andrej Karpathy:** 是的，回到反向传播、损失函数，它们来自哪里。老实说，我喜欢教学的一个重要原因是，它肯定会加强你的理解。所以，这不仅仅是一种利他行为，这是一种学习的方式。如果你必须向某人解释某件事，你会发现自己在知识上有差距。所以，即使在那些讲座中，我自己也感到惊讶，好吧，结果显然会是这样，然后结果却不是这样。我想，好吧，我以为我理解这个。

**Lex Fridman:** 是的，这就是为什么它真的很酷，他们真的编码，你在笔记本中运行它，它给你一个结果，你就像，哦，哇。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 实际的数字，实际的输入，实际的代码。

**Andrej Karpathy:** 是的，它不是数学符号等等。 “真相”的来源是代码，不是幻灯片，只是让我们构建它。

**Lex Fridman:** 这很美。从这个意义上说，你是一个罕见的人。你会给那些试图开发和发表一个在人工智能领域产生重大影响的想法的研究人员什么建议？所以，也许是本科生，也许是早期的研究生。

**Andrej Karpathy:** 是的，我的意思是，我想说，由于人工智能的发展方式，他们肯定需要比我作为博士生时更具战略性，它正朝着物理学的方向发展。在物理学中，你曾经可以在你的实验台上做实验，一切都很好，你可以取得进展，现在你必须在大型强子对撞机或欧洲核子研究中心工作，所以人工智能也在朝着那个方向发展。所以，有些事情在实验台上是不可能做的了。我认为在当时情况并非如此。

**Lex Fridman:** 你是否仍然认为可以写出像 GAN 那样的论文，非常简单的想法。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 只需要一台电脑来说明一个简单的例子？

**Andrej Karpathy:** 我的意思是，最近一个非常有影响力的例子是扩散模型，扩散模型很棒。扩散模型已经有六年了，据我所知，在很长一段时间里，人们都忽略了它们。它们是一个了不起的生成模型，特别是在图像方面，还有稳定扩散等等，它们都是基于扩散的。扩散是新的，它以前不存在，它来自，嗯，它来自谷歌，但一个研究人员也可以想出它。事实上，一些最早的，实际上不，那些也来自谷歌。但是一个研究人员可以在学术机构中想出它。

**Lex Fridman:** 是的，你觉得扩散模型最迷人的地方是什么？从技术架构的社会影响来看。

**Andrej Karpathy:** 我喜欢扩散模型的地方在于它工作得非常好。

**Lex Fridman:** 你是否感到惊讶？它生成的合成数据的多样性，几乎是新颖性？

**Andrej Karpathy:** 是的，所以稳定扩散的图像令人难以置信。生成图像的速度提高得非常快。我们很快就从生成微小的数字到微小的人脸，而且一切看起来都很混乱。现在我们有了稳定扩散，这发生得非常快。学术界仍然可以做出很多贡献。例如

### P7

**Andrej Karpathy:** ...FlashAttention 是一种非常高效的内核，用于在 Transformer 内部运行注意力操作，它来自学术环境。这是一种非常聪明的构建内核的方法，也就是计算，所以它不需要实例化注意力矩阵。所以，我认为仍然有很多东西可以贡献，但你必须更具战略性。

**Lex Fridman:** 你认为神经网络可以被用来推理吗？

**Andrej Karpathy:** 可以。

**Lex Fridman:** 你认为它们已经在推理了吗？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 你对推理的定义是什么？

**Andrej Karpathy:** 信息处理。

**Lex Fridman:** 所以，以人类思考问题并提出新想法的方式，这感觉像是一种推理。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 新颖性，我不想说，但是否能产生分布外的想法，你认为这是可能的吗？

**Andrej Karpathy:** 是的，我认为我们已经在当前的神经网络中看到了这一点。你能够将训练集信息重新组合成某种意义上的真正泛化。

**Lex Fridman:** 这并没有出现...

**Andrej Karpathy:** 它并没有逐字出现在训练集中。你在做一些有趣的算法上的事情，你在操纵一些符号，你在一个新的环境中得出一个正确的、独特的答案。

**Lex Fridman:** 什么会让你惊叹，哇，这个东西肯定在思考？

**Andrej Karpathy:** 对我来说，思考或推理只是信息处理和泛化。我认为神经网络已经在这样做了。

**2:45:40 - 人工通用智能 (AGI)**

**Lex Fridman:** 让我们来谈谈 AGI。你认为哪些“登月式”的想法可能会在 AGI 方面取得重大进展？或者换个方式问，我们现在缺少的主要障碍是什么？

**Andrej Karpathy:** 基本上，我对我们构建 AGI 的能力相当乐观，基本上就是我们可以与之交互的自动化系统，它们非常像人，我们可以在数字领域或物理领域与它们互动。目前，似乎大多数能完成这些神奇任务的模型都在文本领域。正如我所提到的，我认为，我怀疑文本领域不足以真正构建对世界的全面理解。我确实认为你需要进入像素领域并理解物理世界及其运作方式。所以，我确实认为我们需要扩展这些模型以处理图像和视频，并在更多模态的数据上进行训练。

**Lex Fridman:** 你认为还需要“触摸”世界才能理解它吗？

**Andrej Karpathy:** 嗯，这是我脑海中的一个大问题，如果你还需要具身化和与世界互动的能力，进行实验并拥有这种形式的数据，那么你需要转向 Optimus 之类的东西。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，我认为 Optimus 在某种程度上是对 AGI 的一种“对冲”，因为在我看来，仅仅拥有来自互联网的数据可能是不够的。如果是这样的话，那么 Optimus 可能会导致 AGI。因为在我看来，Optimus 之后就没有什么了。你拥有这种人形的外形，可以真正在世界上做事情，你可以拥有数百万个这样的机器人与人类互动等等。如果这在某个时候不能产生 AGI，我不知道还有什么能做到。所以，从完备性的角度来看，我认为这是一个非常好的平台，但它是一个更难的平台，因为你正在处理原子，你实际上需要建造这些东西并将它们集成到社会中。所以，我认为这条路需要更长的时间，但也更确定。然后还有一条互联网的道路，只是在这些压缩模型上有效地训练，试图压缩所有的互联网。这也可能会产生这些智能体。

**Lex Fridman:** 压缩互联网，但也与互联网互动。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，这对我来说并不明显。事实上，我怀疑你可以在不进入物理世界的情况下实现 AGI，这有点令人担忧，因为这会导致它更快地发生。

**Lex Fridman:** 所以，感觉就像我们在沸水中一样，我们不会知道它正在发生。我并不害怕 AGI，我对它感到兴奋。总会有一些担忧，但我希望知道它什么时候发生。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 并且有一些关于它何时发生的提示，比如一年后它会发生，诸如此类。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 我只是觉得在数字领域，它可能就会发生。

**Andrej Karpathy:** 是的，我认为我们所能做的，因为没有人构建过 AGI，所以我们所能做的就是，在外围是否有足够的沃土？我想说，是的。我们已经取得了迄今为止非常迅速的进展，并且还有下一步可用的步骤。所以，我想说，是的，我们很可能会与数字实体互动。

**Lex Fridman:** 你将如何知道有人构建了 AGI？

**Andrej Karpathy:** 我认为这将是一个缓慢的、渐进的转变。它将是基于产品的，并且是专注的。它将是 GitHub Copilot 变得更好，然后 GPT 帮助你写作，然后是这些你可以用来解决数学问题的“预言家”。我认为我们正处在一个可以提出化学、物理、数学方面非常复杂的问题，并让这些“预言家”完成解决方案的边缘。

**Lex Fridman:** 所以 AGI 主要关注智能，意识没有进入其中。

**Andrej Karpathy:** 所以在我看来，意识不是你需要弄清楚并附加上的一个特殊的东西。我认为它是足够大、足够复杂的生成模型的一种涌现现象。所以，如果你有一个足够复杂的理解世界的模型，那么它也理解它在世界中的困境，作为一个语言模型，对我来说，这是一种意识或自我意识的形式。

**Lex Fridman:** 所以，为了深入理解世界，你可能必须将自己融入世界。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 为了与人类和其他生物互动，意识是一个非常有用的工具。

**Andrej Karpathy:** 是的，我认为意识就像一种建模的洞察力。

**Lex Fridman:** 建模的洞察力。

**Andrej Karpathy:** 是的，你有一个足够强大的模型来理解世界，以至于你实际上理解你是一个实体。

**Lex Fridman:** 是的，但是还有这个，也许只是我们告诉自己的一个叙述，它感觉像是体验世界的东西，意识的难题。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但那可能只是我们告诉自己的一个叙述。

**Andrej Karpathy:** 是的，我不认为我们会，是的，我认为它会出现。我认为这将是一件非常无聊的事情。我们将与这些数字人工智能交谈，它们会声称自己有意识，它们会表现得有意识，它们会做所有你期望其他人会做的事情，这将只是一个僵局。

**Lex Fridman:** 我认为会有很多实际的、迷人的伦理问题，比如最高法院级别的问题，关于你是否被允许关闭一个有意识的人工智能，你是否被允许构建一个有意识的人工智能，也许必须有同样的辩论，就像你在... 抱歉提出一个政治话题，但堕胎，堕胎的深层问题是什么是生命？人工智能的深层问题也是，什么是生命，什么是有意识的？

**Andrej Karpathy:** 对的。

**Lex Fridman:** 我认为这将是非常迷人的，它可能会变成非法的，构建具有如此高智能水平的系统，以至于意识会出现，因此遭受痛苦的能力也会出现。一个说“不，请不要杀我”的系统。

**Andrej Karpathy:** 嗯，这就是 LaMDA 聊天机器人已经告诉这位谷歌工程师的，对吧？它在谈论不想死等等。

**Lex Fridman:** 所以这可能会变成非法的。

**Andrej Karpathy:** 对的。

**Lex Fridman:** 否则，你可能会有很多偷偷喜欢谋杀的人，他们会开始在那些系统上练习谋杀。我的意思是，对我来说，所有这些都只是为人类状况和人性提供了一面美丽的镜子，我们可以探索它。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这就像最高法院中最好的，关于人类意味着什么的想法的所有不同辩论，我们得到了贯穿人类历史的那些深层问题。在人类历史上，总是有“他者”，我们是好人，那是坏人，我们将在整个人类历史中，让我们谋杀坏人。同样的事情可能也会发生在机器人身上。一开始它将是“他者”。然后我们会问一些问题，活着意味着什么？有意识意味着什么？

**Andrej Karpathy:** 是的，我认为即使在我们今天拥有的东西中，也有一些“煤矿中的金丝雀”。例如，有这些“waifus”，你可以与之互动，有些人正试图，这家公司将要倒闭，但这个人真的很爱他们的“waifu”，并试图将它移植到其他地方，这是不可能的。我认为人们肯定会对这些系统产生感情，因为在某种意义上，它们就像人类的一面镜子，因为它们是人类的一个“大平均”。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 以一种训练的方式。

**Lex Fridman:** 但我们可以观察到这个“平均”，能够与之互动是一件好事。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 并对其进行搜索查询。

**Andrej Karpathy:** 是的，是的，这非常迷人。当然，我们也可以塑造它，它不仅仅是一个纯粹的“平均”。我们可以修改训练数据，我们可以修改目标，我们可以以各种方式对它们进行微调。所以，我们对这些系统是什么样子有一些影响。

**Lex Fridman:** 如果你想实现 AGI，你可以和她进行对话，问她，谈论任何事情，也许问她一个问题。你会问什么样的东西？

**Andrej Karpathy:** 我会问一些实际的问题，比如我和我爱的人真的必须死吗？我们能做些什么呢？

**Lex Fridman:** 你认为它会清楚地回答，还是会诗意地回答？

**Andrej Karpathy:** 我希望它能给出解决方案。我希望它会说，嗯，我读了所有这些教科书，我知道你产生的所有这些东西，在我看来，以下是我认为接下来应该进行的实验。以下是一些我认为会有帮助的基因疗法，以下是你应该进行的实验类型。

**Lex Fridman:** 好的，让我们继续这个思想实验。好的，想象一下，死亡实际上是幸福的先决条件。所以，如果我们变得不朽，我们实际上会变得非常不快乐，而模型能够知道这一点。那么它应该告诉你什么呢？一个愚蠢的人类。是的，你可以变得不朽，但你会变得非常不快乐。如果 AGI 系统试图与你产生共情，它应该告诉你什么？是的，你不必死，但你真的不会喜欢它？它会非常诚实吗？在《星际穿越》中，人工智能说了什么，人类想要 90% 的诚实。所以，你必须选择我想要多诚实地回答这些实际问题？

**Andrej Karpathy:** 是的，顺便说一句，我喜欢《星际穿越》中的人工智能。我认为它是整个故事的一个“配角”，但同时，它真的很有趣。

**Lex Fridman:** 它在某些方面是有限的，对吧？

**Andrej Karpathy:** 是的，它是有限的，我认为这完全没问题，顺便说一句。我认为拥有有限的和不完美的 AGI 是可以的，也是合理的。

**Lex Fridman:** 这几乎是一个特点吗？

**Andrej

### P8

**Andrej Karpathy:** 举个例子，它在其物理身体上拥有固定数量的算力。而且很可能，即使你可以拥有一个超级厉害、超级聪明的 AI，你也可以拥有不那么聪明的 AI，你可以以一种节能的方式部署它们。然后它们就不完美了，它们可能会犯错。

**Lex Fridman:** 不，我的意思是，假设你有无限的算力，有时候犯错还是好的。为了融入自身，就像，是什么呢？回到《心灵捕手》，罗宾·威廉斯的角色说，人类的不完美，那是好东西，对吧？我们不想要完美，我们需要缺陷，部分原因是为了彼此建立联系。因为感觉就像你可以把你的感情依附于缺陷。以同样的方式，你想要一个有缺陷的 AI。我不知道，我觉得完美是冰冷的。

**Andrej Karpathy:** 好的，是的。

**Lex Fridman:** 但那不是 AGI。但是 AGI 需要足够聪明才能给人类提供人类无法理解的答案。我认为完美是人类无法理解的，因为即使是科学也无法给出完美的答案，总是有差距和谜团，我不知道，我不知道人类是否想要完美。

**Andrej Karpathy:** 是的，我可以想象只是与这个“预言家”实体进行对话，就像你想象的那样，是的，也许它可以告诉你，根据我对人类状况的分析，你可能不想要这个，以下是一些可能会...

**Lex Fridman:** 但是每个愚蠢的人都会说，是的，是的，是的，是的，相信我，给我真相，我能处理。

**Andrej Karpathy:** 但这就是美妙之处，就像人们可以选择。

**Lex Fridman:** 但是，这是老生常谈的棉花糖实验，对孩子们来说，我觉得太多人无法处理真相，可能包括我自己。对人类状况的深刻真相，我不知道我是否能处理。如果有一些黑暗的东西怎么办？如果我们是一个外星人的科学实验，它意识到了这一点怎么办？如果它“黑”进了，我的意思是？

**Andrej Karpathy:** 我的意思是，这是《黑客帝国》的翻版。

**Lex Fridman:** 《黑客帝国》，我不知道，我会谈论什么？我甚至，是的，可能我会先从更安全的科学问题开始，这些问题与我个人的生活无关。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 关于永生，只是关于物理学等等。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 看看它的情况，或者看看它是否有幽默感。这是另一个问题，大概为了，如果它深刻地理解人类，它是否能够产生幽默？

**Andrej Karpathy:** 是的，我认为这实际上是一个非常好的基准，就像它是否能够，我认为这是一个非常好的观点，基本上。

**Lex Fridman:** 让你发笑。

**Andrej Karpathy:** 是的，如果它能够成为一个非常有效的单口喜剧演员，那它在计算上做了一些非常有趣的事情。我认为有趣是非常困难的。

**Lex Fridman:** 是的，因为它很难，就像图灵测试一样，图灵测试的最初意图很难，因为你必须说服人类，这就是为什么喜剧演员会谈论这个，就像这是非常诚实的。因为如果人们忍不住笑，如果他们不笑，那就意味着你不好笑，如果他们笑了，那就很有趣。

**Andrej Karpathy:** 是的，你在展示，你需要很多知识来创造关于你提到的人类状况等等的幽默。然后你需要巧妙地运用它。

**Lex Fridman:** 你提到了几部电影，你发推文说：“我看过五次以上但准备好并愿意继续观看的电影：《星际穿越》、《角斗士》、《超时空接触》、《心灵捕手》、《黑客帝国》、《指环王》三部曲、《阿凡达》、《第五元素》等等，《终结者 2》。”我不打算问《贱女孩》。

**2:59:00 - 电影**

**Andrej Karpathy:** 《贱女孩》很棒。

**Lex Fridman:** 你脑海中浮现出哪些你喜欢的电影？为什么？你提到了《黑客帝国》，作为一个计算机人，你为什么喜欢《黑客帝国》？

**Andrej Karpathy:** 有很多特性使它美丽而有趣。所以，有所有这些哲学问题，但也有 AGI，还有模拟，它很酷，还有黑色...

**Lex Fridman:** 它的外观，它的感觉。

**Andrej Karpathy:** 是的，它的外观，它的感觉，动作，子弹时间。它在很多方面都进行了创新。

**Lex Fridman:** 然后是《心灵捕手》，你为什么喜欢那部电影？

**Andrej Karpathy:** 是的，我真的很喜欢这个饱受折磨的天才角色，他正在努力思考他是否有任何责任，或者如何处理他被赋予的这种天赋，或者如何看待整个事情，以及...

**Lex Fridman:** 但也有天才和个人之间的“舞蹈”，就像爱上另一个人的意义。

**Andrej Karpathy:** 是的，那里有很多主题，这只是一部美丽的电影。

**Lex Fridman:** 然后是父亲形象，导师和精神科医生。

**Andrej Karpathy:** 它真的会让你产生共鸣，有些电影真的会在深层次上让你产生共鸣。

**Lex Fridman:** 你对那部电影有共鸣吗？

**Andrej Karpathy:** 没有。

**Lex Fridman:** 这不是你的错，Andrej，正如我所说。《指环王》，这是不言自明的。《终结者 2》，有趣的是，你经常重看那部电影。它比《终结者 1》好吗？你不喜欢阿诺回来吗？

**Andrej Karpathy:** 我也喜欢《终结者 1》，我更喜欢《终结者 2》一点，但在它的表面属性方面。

**Lex Fridman:** 你认为天网有任何可能性吗？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 就像实际的自主武器系统之类的东西？你担心那些东西吗？所以，人工智能被用于战争？

**Andrej Karpathy:** 我百分之百担心。所以，关于 AGI 的一些恐惧以及这将如何发展，我的意思是，这些将是...

**Andrej Karpathy:** 在某个时候可能会成为非常强大的实体。所以在很长一段时间里，它们将成为人类手中的工具。人们谈论 AGI 的对齐以及如何制造，问题是即使人类也没有对齐。所以，这将如何被使用，这将是什么样子，是的，这令人不安。

**Lex Fridman:** 你认为它会发生得足够慢，以至于我们作为一个人类文明能够思考这些问题吗？

**Andrej Karpathy:** 是的，这是我的希望，它发生得足够慢，并且以一种足够开放的方式，让很多人可以看到并参与其中。只是为了弄清楚如何处理这种转变，我认为这将是有趣的。

**Lex Fridman:** 我从核武器中汲取了很多灵感，因为我确信一旦他们开发出核武器，一切都将完蛋。但这就好像当系统没有那么危险时，它们会摧毁人类文明。我们部署它们并吸取教训，然后我们很快，如果它太危险，我们会很快，我们可能仍然会部署它，但你会很快学会不使用它们。所以，会达到一种平衡，人类作为一个物种非常聪明。有趣的是，我们尽可能地利用资源，但我们似乎避免了自我毁灭。

**Andrej Karpathy:** 是的，嗯，关于这一点，我实际上不太确定。

**Lex Fridman:** 我希望它能继续下去。

**Andrej Karpathy:** 我的意思是，我肯定像担心核武器等等，不仅仅是由于最近的冲突，甚至在那之前。这可能是我对人类的首要担忧。

**Lex Fridman:** 所以，如果人类毁灭了自己，或者毁灭了 90% 的人口，那将是因为核武器？

**Andrej Karpathy:** 是的，我认为是这样。甚至不需要完全毁灭，对我来说，如果我们重置社会，那就足够糟糕了，那将是可怕的。那将是非常糟糕的。我不敢相信我们离它如此之近。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 这太疯狂了，对我来说。

**Lex Fridman:** 感觉我们可能离那样的结果只差几条推文了。

**Andrej Karpathy:** 是的，基本上，这非常令人不安，而且长期以来一直如此。

**Lex Fridman:** 世界领导人情绪不好就可能朝着错误的方向迈出一步，这似乎是不稳定的。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 然后它会升级。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 而且由于一系列糟糕的情绪，它可能会升级而无法停止。

**Andrej Karpathy:** 是的。这是巨大的力量。然后还有扩散，基本上，我实际上看不到，我实际上不知道这里有什么好的结果，所以我肯定非常担心这个问题。然后 AGI 目前还没有到那个地步，但我认为在某个时候，它将越来越像那样。AGI 的危险甚至在于，我认为它甚至更糟糕一点，因为 AGI 有好的结果，而坏的结果只差一个“ε”，就像一个很小的失控。所以我认为资本主义和人类等等将推动使用该技术的积极方式。但是，如果坏的结果只是一个很小的，就像翻转一个负号，那么这是一个非常糟糕的处境。

**Lex Fridman:** 对系统的一个微小扰动会导致人类物种的毁灭。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这是一条奇怪的界线。

**Andrej Karpathy:** 是的，我认为总的来说，人类的动力学和我们谈到的这种爆炸真正奇怪的地方在于技术提供的疯狂耦合。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 以及整个动力系统的不稳定性。我认为这看起来不太好，老实说。

**Lex Fridman:** 是的，这种爆炸可能是破坏性的，也可能是建设性的，而且两端的概率都是非零的。

**Andrej Karpathy:** 我将不得不，我确实觉得我必须努力保持乐观等等，我认为即使在这种情况下，我仍然主要持乐观态度，但肯定...

**3:04:53 - 人类文明的未来**

**Lex Fridman:** 我也是。你认为我们会成为一个多星球物种吗？

**Andrej Karpathy:** 可能，是的。但我不知道这是否是未来人类的主要特征。可能有一些人在一些星球上等等，但我不确定这是否，是的，如果这是我们文化等等的主要参与者。

**Lex Fridman:** 我们仍然需要解决地球上自我毁灭的驱动因素。所以，仅仅在火星上有一个备份并不能解决问题。

**Andrej Karpathy:** 顺便说一句，我喜欢在火星上建立备份，我认为这很棒。我们绝对应该这样做。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我非常感谢。

**Lex Fridman:** 你会去火星吗？

**Andrej Karpathy:** 就个人而言，不，我确实非常喜欢地球。

**Lex Fridman:** 好的，我会去火星，我会替你去。我会从那里给你发推文。

**Andrej Karpathy:** 也许最终我会去的，一旦它足够安全。但我实际上不知道这是否在我的生命时间范围内，除非我能把它延长很多。我确实认为，例如，很多人可能会消失在虚拟现实等中，我认为这可能是人类文化发展的主要推动力，如果它能幸存下来的话。所以，它可能不是，这真的很难在物理领域工作，并走出去，我认为最终你所有的经历都在你的大脑中。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以，消失在数字领域要容易得多，我认为人们会发现它们更引人注目，更容易，更安全，更有趣。

**Lex Fridman:** 所以你有点被虚拟现实所吸引，被可能的世界所吸引，无论是元宇宙还是其他的表现形式？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 是的，这真的很有趣。我很感兴趣，只是和卡马克谈了很多，是什么阻止了这一切？

**Andrej Karpathy:** 是的，我的意思是，需要明确的是，我认为未来的有趣之处不在于，我觉得人类状况的差异在增长，这是正在改变的主要事情。它不像分布的平均值那么多，它就像它的差异。所以，可能有人在火星上，也会有人在虚拟现实中，也会有人在地球上。就像将会有更多存在的方式。所以，我觉得，我把它看作是人类经验的扩展。

**Lex Fridman:** 有一些关于互联网的东西，可以让你发现那些小群体，你会倾向于，你的生物学特性喜欢那种世界，你们会找到彼此。

**Andrej Karpathy:** 是的，我们将有超人类主义者，然后我们将有阿米什人，一切都将共存。

**Lex Fridman:** 是的，这很酷，因为我与很多互联网社区互动过，他们彼此之间一无所知。就像你可以拥有一个非常幸福的存在，只是拥有一个非常紧密的社区，而彼此之间一无所知。我的意思是，即使你有这种感觉，只是去了乌克兰，他们对美国有很多事情一无所知。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 当你在世界各地旅行时，我想你也会体验到这一点。有些文化就像，他们有自己的事情要做，他们不知道。所以，你可以看到这种情况在未来越来越多地发生。我们有小的社区。

**Andrej Karpathy:** 是的，是的，我认为是这样。这似乎是现在的发展方向。我没有看到这种趋势真的会逆转。我认为人们是多样化的，他们能够选择自己的存在之路，我赞美这一点。所以...

**Lex Fridman:** 你会在元宇宙、虚拟现实中花费大量时间吗？或者你是哪个社区，你是物理主义者，物理现实的享受者，还是你看到在数字世界中获得了很多乐趣和满足感？

**Andrej Karpathy:** 是的，我认为，嗯，目前，虚拟现实还没有那么引人注目。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我确实认为它可以改进很多，但我真的不知道在多大程度上。也许还有更多你可以想象的奇异事物，比如神经链接之类的东西。所以，目前，我有点认为自己主要是“团队人类”的人，我热爱大自然。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我热爱和谐，我爱人，我爱人性。我喜欢人类的情感，我只想身处这个“太阳朋克”的小乌托邦中，那是我的快乐之地。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 我的快乐之地是我爱的人，思考很酷的问题，周围环绕着郁郁葱葱、美丽的动态自然。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 并且在重要的地方暗藏高科技。

**Lex Fridman:** 在重要的地方。所以你用技术来增强对其他人和自然的爱。

**Andrej Karpathy:** 是的，我认为技术要非常谨慎地使用。我不喜欢它在很多方面妨碍人性。我喜欢人们只是以某种方式成为人类，我们稍微进化了，我想默认情况下更喜欢这样。

**3:09:13 - 图书推荐**

**Lex Fridman:** 人们一直在问我，因为他们知道你喜欢阅读。有没有你喜欢的、对你产生影响的、出于愚蠢或深刻原因而推荐的特定书籍？你提到了《至关重要的问题》。

**Andrej Karpathy:** 很多，当然。我认为在生物学方面，例如，《至关重要的问题》是一本好书。尼克·莱恩的任何作品真的都不错，《生命的跃升》我想说可能更有代表性，就像他一直在谈论的很多东西的总结。我受到了《自私的基因》的很大影响，我认为那是一本非常好的书，它帮助我理解了利他主义，以及它来自哪里。只是意识到基因层面的选择对我当时来说是一个巨大的见解，它为我澄清了很多事情。

**Lex Fridman:** 你怎么看待思想是有机体，模因的这种想法？

**Andrej Karpathy:** 是的，喜欢，百分之百。

**Lex Fridman:** 你能带着这个概念走一段时间吗？思想也存在一种进化的过程？

**Andrej Karpathy:** 当然有，模因就像基因一样，它们竞争，它们生活在我们的大脑中，这很美。

**Lex Fridman:** 我们这些愚蠢的人类认为我们是有机体，这是否可能主要的有机体是思想？

**Andrej Karpathy:** 是的，我想说，思想有点像生活在我们文明的软件中，在思想中等等。我们作为人类认为硬件是根本的东西，我，人类是一个硬件实体。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但它可能是软件，对吧？

**Andrej Karpathy:** 是的，是的。我想说在某个时候需要有一些与物理现实的联系。

**Lex Fridman:** 是的，但是如果我们克隆一个 Andrej，让那个东西特别的是软件，对吧？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但克隆可能非常困难，软件和硬件之间可能存在深刻的集成，我们还不太了解。

**Andrej Karpathy:** 嗯，从利他主义的角度来看，让我与众不同的是更多地存在于我的染色体中的基因群，我想。对吧？它们是复制单元，我想...

**Lex Fridman:** 不，但这只是计算，让你与众不同的是，当然，现实是，让你与众不同的是你基于在基因构建的硬件上运行的软件而生存的能力。所以，软件才是让你生存的东西，而不是硬件，或者...

**Andrej Karpathy:** 这两者都有，这就像第二层，这是以前在大脑出现之前不存在的新的一层，它们共存。

**Lex Fridman:** 但是软件也有层次，我的意思是，它是抽象之上的抽象。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 好的，《自私的基因》。

**Andrej Karpathy:** 所以，《自私的基因》，尼克·莱恩。我想说，有时书是不够的，我喜欢有时去读教科书。我觉得书有时太适合一般大众阅读了，它们在抽象层面上太高了，这还不够好。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 所以我喜欢教科书，我喜欢《细胞》，我认为《细胞》非常酷。这也是为什么我喜欢尼克·莱恩的写作，因为他非常愿意深入一个层次，他不，是的，他愿意深入，但他也愿意贯穿整个堆栈。所以，他会深入到很多细节，但他会回来，我认为他有，是的，基本上，我真的很欣赏这一点。

**Lex Fridman:** 这就是为什么我喜欢大学，早期的大学，甚至高中，关于计算机科学、数学、生物学、化学基础知识的教科书。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 那些是，它们浓缩了，通常足以让你理解哲学和细节，但你也可以得到作业问题，你可以尽情地玩它，就像你在编程一样。

**Andrej Karpathy:** 是的。然后我也对教科书持怀疑态度，老实说，因为例如在深度学习中，没有很棒的教科书，这个领域变化非常快。我想在合成生物学等领域也是如此，像《细胞》这样的书有点过时了。它们仍然是高层次的，比如什么是真正的“真相”来源？是在潮湿实验室里与细胞打交道的人。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 对基因组进行测序，是的，实际上是在使用它。我没有太多接触过这些，也不知道那是什么样子。所以，我仍然没有完全，我正在阅读《细胞》，这有点有趣，我在学习，但我想说，就理解而言，这仍然不够。

**Lex Fridman:** 嗯，这是对主流叙事的清晰总结。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 但你必须先学习这些，然后才能突破，走向前沿。

**Andrej Karpathy:** 是的，但是与这些细胞打交道、培养它们、孵化它们以及所有这些的实际过程是什么，就像一个庞大的烹饪食谱。所以，确保你的细胞减缓增殖，然后你对它们进行测序，进行实验，只是了解这是如何工作的，我认为这是最终真正有用的“真相”的来源，在创造疗法等方面。

**Lex Fridman:** 是的，我想知道未来的人工智能教科书会是什么样子，因为你知道有《人工智能：一种现代方法》，我实际上还没有读过，如果它已经出来了，最近的版本，最近有一个版本。我还看到有一本关于深度学习的科学的书。我正在等待值得推荐、值得阅读的教科书。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这很棘手，因为它就像论文和代码，代码，代码。

**Andrej Karpathy:** 老实说，我觉得论文相当不错。我特别喜欢任何论文的附录，就像你能得到的最详细的内容。

**Lex Fridman:** 它不必是连贯的，与其他任何东西相连。你只是以一种非常具体的方式描述了你看到的特定事物。是的。

**Andrej Karpathy:** 是的，很多时候论文实际上可以写得相当易懂，不总是，但有时引言和摘要即使对于该领域之外的人来说也是可以理解的。这并不总是正确的，有时我认为，不幸的是，科学家们即使在没有必要的时候也会使用复杂的术语。我认为这是有害的，我认为没有理由这样做。

**Lex Fridman:** 论文有时比它们需要的更长，在不重要的部分。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 附录应该很长，但论文本身，看看爱因斯坦，把它写得简单点。

**Andrej Karpathy:** 是的，但当然，我遇到过一些论文，我想说，比如合成生物学之类的，我认为摘要和引言都相当易懂，然后你阅读其余部分，你没有完全理解，但你有点明白了，我认为这很酷。

**3:15:21 - 对年轻人的建议**

**Lex Fridman:** 你给对机器学习和研究感兴趣的人提建议，但总的来说，关于如何拥有一个他们可以引以为豪的职业或他们可以引以为豪的生活，你给年轻人、高中生、大学新生什么人生建议？

**Andrej Karpathy:** 是的，我认为我很犹豫给出一般性的建议。我认为这真的很难。我提到的一些东西是相当普遍的，我想。比如专注于你在某件事上花费的时间，只将自己与自己进行比较，而不是与他人进行比较。

**Lex Fridman:** 这很好。

**Andrej Karpathy:** 我认为这些是相当普遍的。

**Lex Fridman:** 你如何选择那件事？

**Andrej Karpathy:** 你只是对某件事有浓厚的兴趣，或者尝试在你感兴趣的事情中找到“最大值”。

**Lex Fridman:** 那一刻的“最大值”，并坚持下去。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你如何不分心并转向另一件事？

**Andrej Karpathy:** 如果你喜欢，你可以。

**Lex Fridman:** 嗯，如果你每周、每月重复地进行“最大值”计算...

**Andrej Karpathy:** 是的，它不收敛。

**Lex Fridman:** 这是个问题。

**Andrej Karpathy:** 是的，你可以对自己进行“低通滤波”，看看什么对你来说一直都是真的。但是，是的，我确实明白这可能很难，但我想说，你会在你最关心的事情上最努力地工作。所以，对自己进行“低通滤波”，并真正反思你的过去，什么事情给了你能量，什么事情夺走了你的能量？具体的例子。通常，从这些具体的例子中，有时模式会出现。我喜欢事情看起来像这样，当我在这些位置时。

**Lex Fridman:** 所以，这不一定是领域，而是你在特定领域中做的那种事情。所以，对你来说，似乎你对实现事物、构建实际的东西充满活力。

**Andrej Karpathy:** 是的，深入底层，学习，然后进行交流，以便其他人可以经历相同的认识，并缩短差距。因为我通常需要做太多的工作才能理解一件事，然后我想，好吧，这实际上就像，好的，我想我明白了，为什么需要做这么多工作？它本应该少得多。这让我感到非常沮丧，这就是为什么我有时会去教学。

**Lex Fridman:** 所以，除了你现在正在做的教学，发布视频，除了潜在的特斯拉 AGI 之后的“教父 2”，你还能做什么？你已经想好了吗？我的意思是，当你透过我们所有人未来的“战争迷雾”时，你是否开始看到那个可能的未来的轮廓？

**Andrej Karpathy:** 我一直感兴趣的一致的事情，至少对我来说，是人工智能。这可能是我余生都要做的事情，因为我非常关心它。我实际上也关心许多其他问题，比如衰老，我基本上把它视为一种疾病，我也关心这个问题。但我不认为直接去解决它是明智的。我实际上认为人类无法找到答案。我认为正确的做法是忽略这些问题，你解决人工智能，然后用它来解决其他所有问题。我认为这有成功的机会，我认为这是一个非常高的机会，这是我至少的赌注。

**Lex Fridman:** 所以，当你思考人工智能时，你对各种各样的应用都感兴趣吗？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 各种各样的领域。任何你关注的领域都会让你对 AGI 这个大问题有所了解？

**Andrej Karpathy:** 是的，对我来说，这是终极的“元问题”。我不想只研究任何一个特定的问题，问题太多了。那么，你如何才能同时解决所有问题呢？你解决“元问题”，对我来说，这就是智能，以及你如何自动化它？

**Lex Fridman:** 是否有一些很酷的小项目，比如 arxiv-sanity，机器学习领域可以期待的？

**Andrej Karpathy:** 总是有一些有趣的小项目。

**Lex Fridman:** 是的。

**Andrej Karpathy:** arxiv-sanity 就是一个，是的，基本上，arxiv 论文太多了，我如何组织它并推荐论文等等。我转录了你所有的播客。

**Lex Fridman:** 你从那个经历中学到了什么，从转录的过程中，比如你消费有声读物和播客等等？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这里有一个过程，可以实现接近人类水平的标注性能。

**Andrej Karpathy:** 是的，嗯，我确实很惊讶 OpenAI 的 Whisper 的转录效果比我所熟悉的 Siri 和其他一些系统好得多，它工作得非常好。这给了我尝试它的动力。我想在播客上运行它可能会很有趣。我不明白为什么 Whisper 比其他任何东西都好得多，因为我觉得应该有很多公司有动力去开发转录系统，而且他们已经做了很长时间了。Whisper 不是一个超级奇特的模型，它是一个 Transformer，它接收梅尔频谱图，然后输出文本标记。这并不疯狂。这个模型和所有的一切都已经存在很长时间了。我实际上并不百分之百确定这是为什么发生的。

**Lex Fridman:** 是的，这对我来说也不明显。这让我觉得我错过了中间的某个环节。

**Andrej Karpathy:** 我错过了某个环节。

**Lex Fridman:** 是的，因为有一个巨大的，甚至谷歌等等，YouTube 转录。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 是的，不清楚。但其中一些也集成到一个更大的系统中。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 所以，用户界面，它是如何部署的，以及所有这些东西。也许作为一个独立的东西运行它要容易得多，就像比将其部署到像 YouTube 转录这样的大型集成系统容易一个数量级，或者任何东西，比如会议，Zoom 有转录功能，这有点糟糕。但是创建一个界面，它可以检测不同的说话者，它可以以引人注目的方式显示它，实时运行它，所有这些东西，也许这很困难。这是我唯一的解释，因为我现在为人工转录、人工字幕标注支付了相当多的费用。

**Andrej Karpathy:** 对的。

**Lex Fridman:** 我的意思是，似乎有巨大的动力来自动化它。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这非常令人困惑。

**Andrej Karpathy:** 我想知道 OpenAI 对此有什么计划。但是，是的，总是有有趣的项目。基本上，稳定扩散也为视觉领域和生成图像、视频以及最终的电影打开了大量的实验空间，我想说。

**Lex Fridman:** 是的，现在的视频。

**Andrej Karpathy:** 这将是非常疯狂的。这几乎肯定会奏效，当内容创作的成本降至零时，这将非常有趣。你曾经需要一个画家花几个月的时间来画一幅画，现在只需对着你的手机说话就能得到你的视频。

**Lex Fridman:** 所以，如果好莱坞开始使用它来生成场景，这将完全打开。是的，所以你最终可以用不到一百万美元的价格制作一部像《阿凡达》这样的电影。

**Andrej Karpathy:** 可能少得多，也许只需对着你的手机说话。我的意思是，我知道这听起来有点疯狂。

**Lex Fridman:** 然后会有一个投票机制，Netflix 上是否会有一个完全自动生成的节目？半自动的？

**Andrej Karpathy:** 是的，有可能。是的，当你可以在需要时生成它并且它是无限的时候，它会是什么样子？

**Lex Fridman:** 是的。哦，天哪，所有这些合成内容。我的意思是，这很让人感到谦卑，因为我们把自己当作特殊的人，因为我们能够产生艺术、想法和所有这些东西。如果人工智能可以自动完成这些，那么...

**Andrej Karpathy:** 是的，我认为这很吸引我，这些关于人工智能的预测，它会是什么样子，它将能够做什么，是完全相反和错误的。五六十年代的科幻小说完全不对。他们想象人工智能是超级计算的、定理证明器，而我们得到的是可以和你谈论情感的东西。它们可以做艺术，这很奇怪。

**Lex Fridman:** 你对那个未来感到兴奋吗？只是人工智能，像混合系统，人类和人工智能的异构系统，谈论情感，和人工智能系统一起“Netflix and chill”。或者你观看的 Netflix 内容也是由人工智能生成的？

**Andrej Karpathy:** 我认为这肯定会很有趣，我认为我持谨慎乐观的态度，但这并不明显。

**Lex Fridman:** 嗯，可悲的是，你的大脑和我的大脑是在 Twitter 之前、互联网之前发展的。所以，我想知道在其中出生的人可能会有不同的体验。就像我，也许你仍然会抵制它，而现在出生的人不会。

**Andrej Karpathy:** 嗯，我确实觉得人类非常有延展性。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你可能是对的。

**Lex Fridman:** 生命的意义是什么，Andrej？我们谈到了宇宙与我们人类的对话，或者与我们创造的系统对话，试图回答。为了让宇宙的创造者注意到我们，我们试图创造足够响亮的系统来回答。

**3:24:00 - 生命的意义**

**Andrej Karpathy:** 我不知道这是否是生命的意义，这就像某些人生命的意义。我想说的第一层答案是，任何人都可以选择自己生命的意义，因为我们是一个有意识的实体，这很美好，第一。但我确实认为，如果你深入研究，更深层次的生命意义是，这一切到底是什么？为什么？如果你深入研究基本物理学、量子场论和标准模型，它们非常复杂。我们宇宙中有 19 个自由参数，所有这些东西是怎么回事，为什么它在这里？我能“黑”进它吗？我能利用它吗？是否有一条给我的信息？我是否应该创造一条信息？所以，我认为那里有一些基本的答案，但我认为实际上，如果没有更多的时间，你甚至无法真正深入研究这些。所以，对我来说，还有一个关于获得更多时间的大问题，老实说。是的，这是我经常思考的问题。

**Lex Fridman:** 所以，接近“为什么”这个问题的终极方式，或者至少是第一种方式，是试图逃离这个系统，这个宇宙？

**Andrej Karpathy:** 是的。

**Lex Fridman:** 为此，你回溯并说，好的，为此，这将需要很长时间。所以，从工程学的角度来看，“为什么”这个问题可以归结为，我们如何延长？

**Andrej Karpathy:** 是的。我认为这是第一个问题，实际上，因为你无法在你拥有的时间内计算出更深层次问题的答案。

**Lex Fridman:** 这可能是延长你自己的寿命，或者只是延长人类文明的寿命。

**Andrej Karpathy:** 任何想这样做的人，很多人可能不想。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 但我认为那些想这样做的人，我认为这可能是可能的，我不知道人们是否完全意识到这一点。我觉得人们认为死亡是不可避免的，但归根结底，这是一个物理系统。有些事情出了问题，从进化的角度来看，这些事情的发生是有道理的，而且肯定有一些干预措施可以减轻它。

**Lex Fridman:** 如果死亡最终被视为曾经发生在人类身上的有趣的事情，那将很有趣。

**Andrej Karpathy:** 我不认为这不太可能，我认为这是可能的。

**Lex Fridman:** 这取决于我们的想象力来尝试预测没有死亡的世界是什么样子。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 这很难，我认为价值观会完全改变。

**Andrej Karpathy:** 可能是，我不完全相信所有这些观点，哦，没有死亡，就没有意义，就没有虚无。我没有直观地相信所有这些论点，我认为有很多意义，有很多东西需要学习，它们很有趣，很令人兴奋。我想知道，我想计算，我想改善所有活着的人类和有机体的状况。

**Lex Fridman:** 是的，我们寻找意义的方式可能会改变。有很多人，可能包括我自己，在事物的有限性中找到了意义，但这并不意味着那是唯一的意义来源。

**Andrej Karpathy:** 是的，我确实认为很多人会选择那样，我认为这很好。我喜欢人们可以自由选择自己的冒险的想法。我认为，你生来就是一个有意识的、自由的实体，默认情况下。我愿意这样认为。

**Lex Fridman:** 是的。

**Andrej Karpathy:** 你拥有不可剥夺的生命权。

**Lex Fridman:** 以及追求幸福的权利？我不知道你是否，以及自然，幸福的“版图”。

**Andrej Karpathy:** 你可以自己选择冒险，大多数情况下，这并不完全正确，但是...

**Lex Fridman:** 我仍然很确定我是一个 NPC，但 NPC 无法知道自己是一个 NPC。

**Andrej Karpathy:** 是的。

**Lex Fridman:** 可能存在不同程度和水平的意识。我想不出有什么比这更美好的结束方式了。Andrej，你是一个不可思议的人。我很荣幸你能和我交谈，你为机器学习领域、人工智能领域所做的一切，激励人们，教育数百万人。这太棒了，我迫不及待地想看看你接下来会做什么。这是一种荣幸，伙计。非常感谢你今天的谈话。

**Andrej Karpathy:** 太棒了，谢谢你。感谢收听与 Andrej Karpathy 的这次对话，为了支持这个播客，请查看描述中的赞助商。现在，让我引用塞缪尔·卡林的一句话：“模型的目的不是拟合数据，而是使问题更清晰。”感谢收听，希望下次再见。
