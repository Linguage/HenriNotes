从机器学习模型的视角看机器学习研究
- 原文标题：何恺明 NeurIPS 2024 Talk 分享：从机器学习模型的视角看机器学习研究
- 链接：[何恺明 NeurIPS 2024 Talk 分享](https://mp.weixin.qq.com/s/QtfAJ-I5KZfWSBmCwEam3A)

- **文章类别**：学术分享

---

**内容整理**：

### 文章信息
- **论文标题**：从机器学习模型的视角看机器学习研究
- **作者**：何恺明
- **会议名称**：NeurIPS 2024 NewInML Workshop
- **见刊时间**：2024年12月27日
- **论文链接**：[PDF链接](https://people.csail.mit.edu/kaiming/neurips2024workshop/neurips2024_newinml_kaiming.pdf)
- **是否开放获取**：开放获取

### 摘要
何恺明教授在演讲中探讨了机器学习研究的过程，并通过四个类比帮助理解机器学习的本质及其研究方向。这些类比包括将研究比作随机梯度下降、寻找“惊喜”、未来作为测试集，以及研究的可扩展性。

### 关键词
- 机器学习研究
- 随机梯度下降
- 期望收益
- 过拟合
- 可扩展性

### 正文内容整理
1. **研究的类比**
   - **研究是混乱环境中的随机梯度下降**：
     - 研究过程充满不确定性和噪声，类似于SGD在非凸损失函数中寻找全局最小值。
     - 大学习率象征快速探索，而小学习率则反映深入研究。
     - 研究不仅是对已知领域的深入挖掘，也包括对未知领域的探索。

   - **机器学习关注期望，研究寻找“惊喜”**：
     - 机器学习模型旨在最大化期望收益，而研究则是寻找那些挑战现有常识的新发现。
     - 偶然的发现可能引发新的理论，经过验证后可能成为未来的“期望”。

   - **未来是真正的测试集**：
     - 研究的价值在于其对未来的影响，未来可以视为研究的“测试集”。
     - 研究者需减少“过拟合”，并在真实场景中验证成果。

   - **机器学习研究的扩展规律**：
     - 随着计算能力提升，研究者需关注工作的可扩展性。
     - 理解扩展规律有助于解决复杂的现实问题。

### 主要结论
何恺明教授通过类比和实例，强调了机器学习研究的复杂性和动态性，鼓励研究者在探索中保持敏感，关注未来的应用和发展。

### 研究亮点
- 将研究过程与随机梯度下降相类比，揭示了研究中的探索与实验的重要性。
- 强调寻找“惊喜”作为研究的核心目标，推动知识的拓展。
- 提出未来作为测试集的概念，提醒研究者关注实际应用中的有效性。
- 讨论了研究的可扩展性，强调在技术发展中保持竞争力的重要性。

希望这些内容能够帮助大家更好地理解机器学习研究的本质及其未来发展方向。