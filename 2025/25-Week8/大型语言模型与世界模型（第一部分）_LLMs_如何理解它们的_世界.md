大型语言模型与世界模型（第一部分）：LLMs 如何理解它们的“世界”？  
  原文标题：LLMs and World Models, Part 1 - How do Large Language Models Make Sense of Their “Worlds”?  
  链接：https://aiguide.substack.com/p/llms-and-world-models-part-1  

- **文章类别**：博客文章  

---

**内容整理**：  

### 文章框架  
```
├── 引言
│   ├── 文章背景与主题介绍
│   ├── 链接到第二部分
├── AI 的脆弱性与早期问题
│   ├── 早期机器学习系统的局限性
│   │   ├── 图像分类问题（皮肤病变分类案例）
│   │   ├── 语言模型的逻辑推理问题
│   │   ├── 强化学习系统的脆弱性（Atari 游戏案例）
│   │   └── 总结：依赖启发式规则而非因果理解
│   └── 人类理解的关键：世界模型
├── LLMs 与世界模型的辩论
│   ├── LLMs 的优势与争议
│   │   ├── LLMs 的表现优于早期系统
│   │   ├── 争议：LLMs 是否学习了世界模型？
│   │   ├── OpenAI 联合创始人 Ilya Sutskever 的观点
│   │   └── 其他研究者的反驳
│   └── 社区分歧：2022 年 NLP 研究者调查
├── 世界模型的定义与用途
│   ├── 世界模型的多种定义
│   │   ├── 内部表征与外部世界的模拟
│   │   ├── 保留环境因果结构的表征
│   │   └── 行为有效的结构化表征
│   ├── 世界模型的用途
│   │   ├── 人类世界模型的示例（复杂场景理解）
│   │   └── 世界模型在虚构世界中的应用
├── 世界模型的分类
│   ├── 静态查找表
│   ├── 地图
│   ├── 机械天体仪
│   └── 模拟器
├── LLMs 中的模型类型
│   ├── 基于共现的嵌入空间
│   ├── 情境模型
│   └── 对因果模拟模型的探讨
└── 结论与展望
    ├── 对 LLMs 世界模型的质疑
    └── 第二部分预告
```

### 文章内容整理  

#### 引言  
文章由 Melanie Mitchell 撰写，探讨了大型语言模型（LLMs）是否发展出了类似人类的“世界模型”，以理解其“世界”。这是两部分系列文章的第一部分，第二部分链接为 [LLMs and World Models, Part 2](https://aiguide.substack.com/p/llms-and-world-models-part-2)。  

#### AI 的脆弱性与早期问题  
文章首先回顾了早期机器学习系统的局限性，指出这些系统往往依赖于“启发式规则”或“表面特征”，而非真正的概念理解。  
- **图像分类问题**：一个深度神经网络被训练用于区分皮肤病变照片中的良性与恶性病变，但该网络错误地将照片中出现的尺子作为恶性病变的标志，因为它在训练数据中发现恶性病变照片更常出现尺子。  
- **语言模型的逻辑推理问题**：2019 年的一项研究发现，一个神经语言模型在判断句子逻辑关系时，依赖于句子之间的词汇重叠，而非真正的逻辑推理。  
- **强化学习系统的脆弱性**：一个深度强化学习系统学会了玩 Atari 游戏 Breakout，但当游戏设置稍有变化（如球拍位置改变）时，其性能大幅下降，说明该系统并未真正理解游戏的基本概念。  
这些案例表明，早期机器学习系统依赖于训练数据中的启发式规则，而非因果理解。  

文章进一步指出，人类理解的关键在于拥有“世界模型”——压缩的、可模拟的模型，能够捕捉世界的因果结构并做出预测。  

#### LLMs 与世界模型的辩论  
文章转向当前的大型语言模型（LLMs），这些模型在性能上远超早期系统，但其成功的原因引发了争议：  
- **LLMs 的优势与争议**：LLMs 是否通过记忆和检索训练数据来解决问题，还是学习了更复杂的启发式规则，或者是否发展出了类似人类的“世界模型”？  
- **Ilya Sutskever 的观点**：OpenAI 联合创始人 Ilya Sutskever 认为 LLMs 学习了世界模型，他指出，通过预测文本中的下一个词，LLMs 学习了世界的各个方面，包括人类的情感、动机等，形成了一种压缩的、抽象的、可用的表征。  
- **其他研究者的反驳**：其他研究者认为 LLMs 的成功更多是基于对训练数据的记忆和近似检索。例如，ASU 的 Subbarao Kambhampati 和 Meta 的 Yann LeCun 都对 LLMs 的世界模型能力表示怀疑。LeCun 进一步指出，仅通过语言训练的系统无法达到人类智能。  
- **社区分歧**：2022 年的一项 NLP 研究者调查发现，对于“仅通过文本训练的生成模型是否能够理解自然语言”这一问题，研究者的观点几乎是对半分。  

#### 世界模型的定义与用途  
文章探讨了“世界模型”的定义和用途：  
- **多种定义**：  
  - 内部表征模拟外部世界。  
  - 保留环境因果结构的表征。  
  - 行为有效的结构化表征，捕捉现实世界中的实体、关系和过程。  
- **世界模型的用途**：世界模型帮助人类快速理解复杂场景，例如一张包含行人、狗和手机的街景照片。人类可以通过世界模型理解行为的因果关系、预测未来事件、规划行动，并回答反事实问题。  

#### 世界模型的分类  
MIT 教授 Jacob Andreas 提出了一种世界模型的分类方法，按模型能够回答的问题类型排序：  
- **静态查找表**：仅存储固定查询的答案，无法泛化。  
- **地图**：如太阳系的二维地图，能够回答简单问题，但无法处理动态变化。  
- **机械天体仪**：通过运动部件模拟行星轨道，能够处理动态问题，但无法回答复杂的反事实问题。  
- **模拟器**：如包含引力的详细模拟器，能够回答复杂的因果问题和反事实问题。  

#### LLMs 中的模型类型  
文章探讨了 LLMs 中可能存在的模型类型：  
- **基于共现的嵌入空间**：如 Word2Vec，通过词汇共现关系形成空间表征，类似于地图。  
- **情境模型**：LLMs 能够跟踪故事中的行为者和动作，类似于机械天体仪，但缺乏对更广泛世界的因果知识。  
- **因果模拟模型**：目前没有证据表明 LLMs 能够捕捉详细的因果模拟模型。  

#### 结论与展望  
文章总结了对 LLMs 是否发展出世界模型的质疑，并预告第二部分将探讨支持 LLMs 拥有世界模型的证据。  

### 文章标签  
#LLMs ， #世界模型 ， #人工智能 ， #机器学习