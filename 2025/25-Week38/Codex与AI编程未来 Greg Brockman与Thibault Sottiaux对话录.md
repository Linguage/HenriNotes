## Codex与AI编程未来 Greg Brockman与Thibault Sottiaux对话录

## 概述

本期OpenAI播客邀请了OpenAI联合创始人Greg Brockman与Codex工程负责人Thibault Sottiaux，围绕AI在代码开发中的演化、Codex系统的进化乃至“未来的AI工程师”进行了深入探讨。两位核心人物回顾了AI自动写代码的诞生，从GPT-3早期实验直至今天GPT-5 Codex可以持续数小时完成复杂重构任务。他们分析了“harness（执行系统）”的关键作用、agentic coding（具代理性的自动编程）、代码审核突破、开发环境集成、未来数十亿AI代理协同编程的可能社会形态，并系统讨论了AI协作与安全性、监督和算力稀缺等核心挑战。会议还展望了2030年代码生产及学习模式，呼吁“学会编程，更要学会用AI编程”。

---

## 主题梳理

## 一、从GPT-3初试锋芒到代码AI协作日常

- 最早在GPT-3时代，开发团队发现AI补全文档字符串及函数定义后能自发输出完整、基本可用的Python代码。Greg Brockman回忆道，团队最初的愿景是“让AI生成千行代码”，而现实进步远超想象。
    
- 他们强调，科技进步总是让人快速习惯新能力，很多新的AI功能，比如数年前还难以想象的数小时持续型代码协作，现在已成为许多工程师每日使用的“日常工具”。
    
- 这段成长始于需求驱动：一方面源自OpenAI自身想用AI提升代码生产效率，另一方面也由万千开发者的真实需求反馈推动（例如GitHub Copilot上线后的广泛应用）。
    
- Greg 提及，编程领域成为OpenAI第一个专注深耕的高优先领域，不断训练专门的GPT模型，推动AI编程能力进化到新的高度。
    

## 二、harness与agentic coding：AI代码生产方式革命

- “Harness”是AI驱动代码开发（agentic coding）不可或缺的基础设施。Thibault Sottiaux将之类比为AI的大脑与harness的“身体”协同：harness不仅负责输入输出，更集成各种工具与环境，完成实际的编程交互循环（agent loop）。
    
- 从最初只会补全文档的“傻瓜”AI，到现在能在在线/本地图形界面、终端命令行、异步代理等多种环境下流畅运行，harness系统及其不断演化成为Codex进化的核心。
    
- 代码开发体验的剧变：过去开发者需要将复杂上下文（代码片段、堆栈、调试信息等）粘贴给ChatGPT，现在AI agent可自行获取与补全环境上下文，自主调试和解决问题，开发者只需监督与轻度引导。
    
- 研发团队多次迭代：从“10X”终端试验工具到“异步云端代理+本地协作”模式，再到如今多种场景无缝协同，强调AI须“深度融入开发者现有工作流”，而不是单一新工具。
    

## 三、AI代码审核、重构与企业应用的飞跃

- AI代码审核（code review）功能进化显著，Codex在OpenAI内部已成为必不可少的代码安全与效率保障。Greg强调，过去自动code review往往让人烦不胜烦，因其“噪音”多、低价值；如今AI审核准确率达90%以上，甚至能发现核心开发者需耗时数小时深入思考才能发现的问题。
    
- GPT-5 Codex已能数小时持续处理复杂重构（refactor）、测试迁移等大规模任务，成为企业软件工程的生产力放大器。实际案例显示，OpenAI开发团队曾在一夜间依赖Codex审核/修复25个PR，显著提升交付质量。
    
- 企业级代码迁移（如COBOL系统迁移）、安全修复、自动生成新工具等都预示着AI开发将在企业级和底层架构领域爆发强劲变革。
    

## 四、AI工程师与未来的协作模型

- 当前AI已成为“真正的协作者”——不仅能提供补全，更能在命令行、VS Code插件、云端并行代理等多端协同，和人类开发者共同完成大项目甚至全自动部署。
    
- OpenAI提出“agentic软件工程师”目标：让AI成为拥有独立算力、自主决策、可被远程团队调度和监督管理的真正数字劳动力伙伴。Greg比喻：“未来每天早上你喝咖啡时，AI正分担你不愿意做的琐碎任务，而你专注于创意和设计。”
    
- 未来协作还包括多代理系统（multi-agent），大规模云端并行、团队监督与权限安全分级（如AI仅在沙箱内操作、手动审批高风险权限），最大程度保障安全与可控性。
    

## 五、AI软件开发的挑战与前瞻：算力、分工与人机共用

- 未来最大挑战之一是“算力短缺”（compute scarcity）：如果每个人类都需要一名全天不断运行的AI助手，全球或需百亿级GPU资源，各类算力及利用效率策略将成为制高点。
    
- 安全性是AI自动开发最大难题之一。需要建立“可扩展监督”（scalable oversight）机制——人类如何高效管控多个AI agent、如何在无需人工查看全部代码情况下维护足够安全性与信任。
    
- 进一步展望未来代码开发、基础设施升级（如AI自动查找修复bug、优化系统架构）、人机共同推进科学突破（如AI参与药物、材料等领域实验创新）都已现雏形。
    

---

## 框架与心智模型（Framework & Mindset）

## 1. AI赋能编程工作范式新框架

- **代理型（Agentic）协作心智模型**：AI已不只承担“自动补全”，而是主动参与完整的开发生命周期。开发者需重新定义分工：“AI负责琐碎重复、机械环节，人更专注创意、设计、决策和指导”。
    
- **智能与便利权衡模型**：未来设计AI“理想开发助手”时，需平衡模型智能（intelligence）与交互便捷（convenience）。快速补全工具要求低延迟，而大规模智能agent则侧重任务复杂度、抗压能力与安全性，如何“达到门槛后带来质变”是衡量其是否真正“用得成、离不开”的关键。
    
- **算力结构与供需逻辑**：个人AI协作者将带来全球性算力需求压力，“提高智能”与“提高可用性”必须兼顾。这也推高了对物理基础设施、云服务与个人终端逐步融合与优化的需求。
    

## 2. 安全与可控AI协作机制框架

- **可扩展监督体系**：AI用于代码开发时，需区分“哪些任务可独立、哪些需人工审批”。借助沙箱、权限分层、渐进授权等机制，最大限度保障自动化与安全的平衡。
    
- **记忆与反馈回路加强模型**：AI agent当前“上下文记忆”有限，未来必须增强agent持续“自我成长”与“任务逐步积累历史”的能力，让第二次第三次遇见同一任务时表现更优。
    
- **“共同成长”学习模型**：AI与开发者同台竞技时，开发者需不断学习AI“如何思考和解决问题”，并及时反馈、修正其盲点。人类利用AI发现新工具、新库、新写法，反哺自身成长。
    

---

## 基本信息

- Title: Codex and the future of coding with AI — the OpenAI Podcast Ep. 6
    
- Author: OpenAI
    
- URL: [https://www.youtube.com/watch?v=OXOypK7_90c](https://www.youtube.com/watch?v=OXOypK7_90c)
    

1. [https://www.youtube.com/watch?v=OXOypK7_90c](https://www.youtube.com/watch?v=OXOypK7_90c)