## 标题

Tom Blomfield和AI驱动的Vibe Coding实践指南

---

## 概述

本视频由 Y Combinator 合伙人 Tom Blomfield 讲述，围绕如何使用现代大型语言模型（LLM）推动“Vibe Coding”实践展开。作者将过往一个月用 Claude Code、Windsurf、Aqua 等 AI 工具开发 side project 的经验精炼成方法论，分享了从工具选择、计划制定、版本控制、测试到代码重构等完整流程，展示 AI 在开发工作流中的最佳协作方式。核心结论是：AI 尚无法“单步”产出复杂产品，但通过正确的方法、“分段”推进、灵活实验，可以显著提升开发效率；精良的工程流程和主动反馈管理，将让 AI 成为靠谱的协作伙伴。

---

## 按主题梳理

## 1. Vibe Coding与创作者经验分享

- Tom 首先介绍 “Vibe Coding”的概念——不同于传统编程，仅依赖自然语言和 AI 协作，将开发流程与 prompt 工程高度融合。通过不断尝试最新 LLM 工具，他发现好的实践和职业软件工程师的方法并不冲突，而是互补增强。
    
- 视频特别引入 Y Combinator 的创业者分享实战心得：例如切换 AI 工具（如 Cursor、Windsurf）时，可以同时在前端和后端分别推进，两边比较产出，选择表现最优的方案。用 AI 驱动开发时，建议把 AI 理解为“新型编程语言”，通过“补全足够上下文”，获得更理想输出。
    
- 资深开发者强调：测试优先原则十分关键。先手工撰写测试用例（而不是直接用 LLM 生成），通过测试 guard rail 再让 LLM 生成代码，确保产出代码符合要求。遇到 AI 死循环，需重置思路，退而求其次，避免“代码垃圾层”堆积。
    

## 2. 工具选择、计划制定和“分段式”推进

- 对于初学者，Tom 推荐使用如 Replit、Lovable 等 UI 友好的工具；有一定经验的人则可直上 Windsurf、Cursor、Claude Code 等专业类 AI 编程工具。
    
- 选定工具后，第一步不是立即写代码，而是与 LLM 共同制定一份详尽的项目计划，存放在项目根目录 Markdown 文件中，随时引用和修改。在具体实现时，务必分步执行、每次只聚焦于一个模块，完成并测试通过后，再进行下一个环节。
    
- 实践建议：将过于复杂或暂不实现的需求标记为“WON’T DO”、“待定”，保证计划的关注点持续明确。整体流程强调“分阶段推进”、“过程可溯源”，培养与 AI 的协同节奏。
    

## 3. 版本控制、测试与回滚

- Tom 强烈建议用 Git 做好严密的版本控制。与 AI 协作代码时，如果遇到长时间无法解决问题，马上 reset 到已知良好版本，避免反复 prompt 让 LLM 在同一份“有待修复”代码上优化，导致质量下滑。
    
- 实操中发现，AI 工具自带的 revert 或撤销并不完全可靠。每次新功能开发或 bug 修复都要先保存一个 git 快照。若 LLM 反复修改（比如 debug）但效果不佳，应将最终好用的方案单独拿出，新建 clean 代码库批量实施，拒绝“补丁式碎片累积”。
    
- 写测试用例时，务必关注集成测试（integration test），模拟用户的真实操作链路，弥补 LLM 对“单元级”测试（unit test）偏好的不足。高覆盖率测试可以及时发现 LLM 导致的逻辑无关更改和回归问题。
    

## 4. 多元协作：编码、非编码任务、Bug修复

- LLM 不仅能写程序，还能完成如 DNS 配置、Heroku 部署、图标处理等 DevOps 与设计相关任务。例如，Claude 生成 favicon 图片再自动格式转换处理，明显节省人工流程。
    
- 遇到 bug 时，建议直接将错误日志、堆栈、控制台输出粘贴到 LLM，无需多余解释，AI 能自动诊断和修复大多数问题。复杂 bug 要引导 LLM 分步推理、列出可能原因，每一轮失败都建议 code reset 避免历史污染。“加日志（logging）”和“切换模型”是应急常用法宝，不同 LLM 在不同场景下成功率各异。
    
- 写项目自定义“AI 指令文档（如 cursor rules、windsurf rules）”，用具体 markdown 或配置文件描述项目约束，可显著提升 LLM 的协作效率。
    

## 5. 功能开发、文档管理与架构选型

- 对于较复杂的新功能开发，建议“外部新建代码库，单独完成基本功能后再集成进主项目”，减少老项目复杂度的干扰。优质的小文件和高内聚模块有助于水平迁移和复用，并让 LLM 与人都能高效理解与调整。
    
- 选择技术框架时优先考虑训练数据丰富、约定俗成的生态（如 Ruby on Rails），LLM 在这些主流框架表现更稳定。对如 Rust、Elixir 这样训练数据有限的语言或框架，AI 产出效果仍有待提升。
    
- 文档查阅方面，Tom 发现 LLM 在线检索官方 API 文档表现尚不理想，建议将所需文档本地下载管理，并指明路径，确保 LLM 高效准确查阅。
    
- AI 还能担当“老师”角色，像代码审查那样逐行讲解实现逻辑，有助于个人或团队成员提升技能。
    

## 6. 使用截图、语音输入提升体验，频繁重构与试错

- LLM 现已支持粘贴截图用于检测 UI bug 或获取设计灵感，还能通过声音（如 Aqua 工具）把语音直接输入开发环境，大幅提升输入效率和交互灵活性。
    
- 每完成新功能、测试通过后，都应主动重构（refactor），并可直接请 LLM 指点代码中可优化片段。保持小文件、模块化是提升人机协作效率的普适经验。
    
- Tom 总结：“不断实验、持续更新工具与模型，对生产力提升影响巨大。”比如，Gemini 在全局索引与规划表现最好，而 Sonet 3.7 在实际代码实现上更具优势。模型迭代极快，建议定期尝试不同最新模型，选择与项目、bug 类型契合的最佳工具。
    

---

## 框架 & 心智模型

## 1. Vibe Coding工作流标准化

- Vibe Coding的精髓是将软件开发流程分割为一系列“工程化节点”，每一步都与 AI 主动对话。步骤包括：需求澄清（与 LLM 对话形成项目全貌）、任务拆解（形成可执行清单）、逐步实现（每步后测试与提交）、bug 跟踪与溯源（始终回滚到清洁基线）、周期性重构（人机协作不断优化结构），以及定期复盘和探索新的 LLM 工具提升实践品质。
    
- 相比传统开发，Vibe Coding要求极强的“上下文意识”与 “流程驱动”。用户不再一味希望 LLM 一步到位，而是以“代码工程师”的标准，不断提供高质量上下文、明确目标、反馈效果，以持续提升协作效率。
    
- 整个流程主张：“需求—>详尽计划—>阶段开发&测试—>提交—>bug 流转—>反复验证—>重构与模块化—>探索新工具—>复盘总结”，其核心是“工程化 + 复盘迭代”。每一阶段都不是 “交给 LLM 自动完成”，而是“以开发者思维驱动 LLM 持续协作”。
    
- Tom 强调，优秀的 Vibe Coding 实践也是优秀开发者心智模型在 AI 时代的升级版本：“工程规范”、“风险隔离”、“验证反馈”、“持续学习”这四大要素，构成了未来高效开发协作的心智底座。
    

---

## 基本信息

- **Title**：How To Get The Most Out Of Vibe Coding | Startup School
    
- **Author**：Y Combinator（主讲：Tom Blomfield）
    
- **视频链接**：[https://www.youtube.com/watch?v=BJjsfNO5JTo](https://www.youtube.com/watch?v=BJjsfNO5JTo)
    

1. [https://www.youtube.com/watch?v=BJjsfNO5JTo](https://www.youtube.com/watch?v=BJjsfNO5JTo)