# 为什么大语言模型无法真正构建软件

## 概述

本文探讨了当前大语言模型（LLM）在软件开发领域的能力与局限。作者通过自身丰富的面试软件工程师经验，指出LLM虽然能生成和修改代码，但缺乏人类工程师最核心的能力——构建和维护清晰的“心智模型”（mental model）。因此，LLM在面对复杂、非线性的问题时，难以像人类一样有效地迭代和解决问题。作者认为，未来LLM或许能有所突破，但目前它们只能作为辅助工具，真正的主导权仍在工程师手中。

## 软件工程师的工作循环

- 软件工程师的核心工作流程可以归纳为以下循环：
    
    - 构建对需求的心智模型（mental model of the requirements）：即理解和抽象出需求的本质。
        
    - 编写代码以实现这些需求（write code that does that）：将抽象的需求转化为具体的实现。
        
    - 构建对代码实际行为的心智模型（mental model of what the code actually does）：理解代码的真实运行逻辑和效果。
        
    - 识别需求与实现之间的差异，并更新代码或需求（identify the differences, and update the code or the requirements）：通过对比和分析，持续修正和完善。
        
- 有效的工程师之所以优秀，关键在于他们能够持续构建和维护清晰的心智模型。这种能力让他们在面对复杂系统时，能够准确判断问题所在，并做出合理的调整。
    
- 在实际工作中，工程师会不断测试自己的工作。当测试失败时，他们会回到自己的心智模型，判断是代码有误还是测试本身有问题，或者需要收集更多信息再做决策。即使遇到挫折，工程师也能通过与他人交流或重新梳理思路，最终带着更清晰的理解重新开始。
    

## LLM的能力与局限

- LLM在代码生成方面表现出色，也能根据明确的问题对代码进行修改。它们可以阅读代码、编写和运行测试、添加日志，甚至使用调试工具。
    
- 但LLM的根本短板在于无法维护清晰的心智模型。具体表现为：
    
    - 它们容易混淆自己生成的代码与实际需求，假设代码一定正确。
        
    - 当测试失败时，LLM往往无法判断是代码还是测试有问题，只能“猜测”如何修复。
        
    - 在遇到复杂或混乱的情况时，LLM可能会选择“推倒重来”，而不是基于更深刻的理解进行调整。
        
- 这种行为与优秀工程师的做法正好相反。人类工程师会利用心智模型进行有针对性的修正，而LLM则缺乏这种能力。
    

## LLM未来会变得更好吗？

- 作者认为，随着模型能力提升，LLM或许会有所进步，但要真正胜任软件工程师的角色，需要在模型的构建和优化方式上有根本性突破。
    
- 人类在解决问题时，能够灵活管理“上下文”：
    
    - 可以暂时搁置全部细节，专注于当前问题，解决后再回到原有任务。
        
    - 能够在全局与局部之间自由切换，既能把握大局，也能深入细节。
        
    - 不会无限制地扩展“上下文窗口”，否则会导致信息过载。
        
- 当前LLM存在的主要问题包括：
    
    - **新近性偏见（recency bias）**：模型更关注最近输入的信息，容易忽略前文重要内容。
        
    - **幻觉（hallucination）**：模型会凭空“编造”本不应存在的细节。
        
- 虽然业界正在尝试为模型增加“记忆”能力，让其能像人类一样管理信息，但目前来看，LLM在面对复杂任务时，仍无法真正“理解”全局，也无法同时维护多个相似的心智模型，更无法像人类一样判断是该修改代码还是需求。
    

## 现阶段的最佳实践

- LLM对软件工程师依然有很大帮助，尤其是在以下场景：
    
    - 快速生成代码片段。
        
    - 合成需求文档和技术文档。
        
    - 处理需求明确、问题简单的任务，可以“一次成型”。
        
- 但对于复杂任务，LLM无法准确维护足够的上下文，难以通过多轮迭代达到理想结果。因此，工程师必须承担起确保需求清晰、代码正确的责任。
    
- 作者强调，Zed团队相信未来人类与智能体可以协作开发软件，但至少目前，主导权仍然掌握在工程师手中，LLM只是辅助工具。
    

## 框架与心智模型（Framework & Mindset）

- 软件开发的核心心智模型：
    
    - **需求-实现-验证-修正循环**：始终围绕需求与实现的差异进行迭代。
        
    - **心智模型的构建与维护**：不断在脑海中更新对系统的理解，确保每一步决策都有坚实的认知基础。
        
    - **灵活的上下文管理**：能够根据问题的复杂度，动态调整关注点和信息量，避免信息过载。
        
    - **主动求助与反思**：遇到瓶颈时，及时寻求外部帮助或重新梳理思路，而不是盲目重来。
        
- LLM的局限心智模型：
    
    - **线性处理与短期记忆**：只能处理有限的上下文，难以全局把控。
        
    - **缺乏自省与判断**：无法像人类一样反思和判断复杂问题的本质。
        

## 基本信息

- Title: Why LLMs Can’t Really Build Software
    
- Author: Zed Blog 团队
    
- Date: 2024年（具体日期网页未注明）
    
- URL: https://zed.dev/blog/why-llms-cant-build-software