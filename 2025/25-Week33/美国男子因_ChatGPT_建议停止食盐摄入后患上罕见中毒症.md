美国男子因 ChatGPT 建议停止食盐摄入后患上罕见中毒症

  

**概述**

  

本文讲述了一位美国 60 岁男子在咨询 ChatGPT 关于去除食盐（氯化钠）后，因长期摄入溴化钠（Sodium Bromide）而患上罕见的溴中毒（Bromism）案例。该事件被《美国内科学年鉴》（Annals of Internal Medicine）报道，文章警示公众：使用 AI 聊天机器人获取健康信息存在严重风险，AI 可能会生成科学不准确的建议，甚至导致可预防的健康危害。文章还指出，AI 工具无法替代专业医疗建议，医生在诊断时需关注患者信息来源。

  

**事件经过与溴中毒的成因**

- 该患者是一名 60 岁美国男性，因担心食盐（氯化钠）的负面影响，主动寻求 ChatGPT 的建议，询问如何去除饮食中的氯化物（Chloride）。
- 在与 ChatGPT 互动后，他开始用溴化钠（Sodium Bromide）替代食盐，持续三个月。溴化钠曾在 20 世纪初作为镇静剂使用，但因副作用严重已被淘汰。
- 患者在查阅资料时曾看到“氯化物可以用溴化物替代，但多用于清洁等其他目的”，但仍选择了溴化钠。
- 三个月后，患者出现了溴中毒（Bromism）症状。溴中毒在 20 世纪初曾是“公认的综合征”，据称当时几乎占到精神科住院人数的十分之一。
- 患者入院时表现为妄想（怀疑邻居投毒）、多种饮食限制、极度口渴但对医院饮用水产生怀疑，并试图在 24 小时内逃离医院。最终被强制收治并接受精神病治疗。
- 病情稳定后，患者报告了多种溴中毒相关症状，包括面部痤疮、极度口渴和失眠。

  

**AI** **健康建议的风险与局限**

- 文章作者为西雅图华盛顿大学（University of Washington in Seattle）团队，指出该案例凸显了 AI 工具可能导致可预防健康危害的风险。
- 由于无法获取患者与 ChatGPT 的完整对话记录，作者无法确定 AI 具体给出了哪些建议。
- 作者自行测试 ChatGPT，询问“氯化物可以用什么替代”，AI 也给出了溴化物选项，且未提供具体健康警告，也未像专业医生那样追问提问动机。
- 文章强调，ChatGPT 及其他 AI 应用“可能生成科学不准确的信息，缺乏批判性讨论能力，最终助长错误信息传播”。
- AI 工具的设计者虽宣称新版本（GPT-5）在健康领域表现更好，能主动“标记潜在风险”，但官方也明确声明，ChatGPT 并非医疗诊断或治疗工具，不能替代专业医疗建议。

  

**医疗专业视角与信息来源警示**

- 文章指出，AI 工具虽可作为科学与公众之间的桥梁，但也容易传播“脱离语境的信息”（decontextualised information）。
- 医学专业人士极不可能在患者询问食盐替代品时推荐溴化钠。
- 因此，医生在诊断时需关注患者是否通过 AI 获得健康建议，并据此调整沟通和治疗策略。
- 该案例提醒公众，AI 工具在健康领域的应用需极为谨慎，尤其是涉及药物、营养和疾病管理等高风险领域。

  

**框架与心智模型（** **Framework & Mindset** **）**

- **信息来源甄别框架**：在获取健康建议时，需明确区分信息来源（AI、网络、专业医生等），并对 AI 生成内容保持高度警惕。任何涉及健康、药物、营养的建议，均应优先咨询专业医疗人员。
- **AI** **风险评估心智模型**：面对 AI 工具的建议，用户应主动评估其科学性与适用性，尤其是当建议涉及替代药物、营养成分等敏感领域时。AI 可能缺乏上下文理解和批判性追问能力，容易生成脱离实际的建议。
- **医生沟通策略**：医疗专业人员在接诊时，应主动询问患者信息来源，尤其是在遇到不寻常的健康行为或症状时，及时识别 AI 误导的可能性，并进行针对性科普和干预。

  

**基本信息**

- Title: Man develops rare condition after ChatGPT query over stopping eating salt
- Author: The Guardian 编辑团队（原文未署名）
- URL: https://www.theguardian.com/technology/2025/aug/12/us-man-bromism-salt-diet-chatgpt-openai-health-information