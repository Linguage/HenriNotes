

概述

GPT-5是OpenAI最新发布的大型语言模型（LLM），在保持现有LLM架构的基础上，显著提升了稳定性、推理能力和安全性。作者在两周的深度体验后认为，GPT-5虽然不是范式革命，但在日常使用中表现出极高的可靠性和实用性，成为了他的新首选模型。本文将围绕GPT-5的核心特性、定价策略、系统卡披露的细节，以及其在OpenAI产品线中的定位进行详细梳理，帮助读者全面理解GPT-5的能力边界与实际应用价值。

核心特性详解

- GPT-5在ChatGPT中的实现采用了“混合模型”架构。系统卡描述：GPT-5是一个统一系统，包含一个智能且快速的主模型，负责大多数问题的解答；遇到复杂问题时，会切换到更深度的推理模型；整个过程中由实时路由器根据对话类型、复杂度、工具需求和用户显式意图（如在提示中写“认真思考这个问题”）动态分配模型。当使用量达到上限后，会自动切换到各自的mini版本继续处理请求。未来，OpenAI计划将这些能力整合为单一模型。
    
- API端则更为直接，提供三种模型：regular（主模型）、mini和nano。每种模型都支持四个推理等级：minimal（极简，首次引入）、low、medium、high。输入上限为272,000 tokens，输出上限（包括不可见的推理tokens）为128,000 tokens。支持文本和图片输入，输出仅限文本。
    
- 作者实际体验后评价：GPT-5“就是好用”，虽然没有质变式飞跃，但在各类任务中表现稳定、少出错，常有令人印象深刻的表现。对于日常需求，GPT-5几乎可以作为默认首选，无需频繁切换模型以追求更优结果。
    
- 知识截止日期：GPT-5为2024年9月30日，mini和nano为2024年5月30日。
    

OpenAI产品线定位

- GPT-5系列意在取代OpenAI大部分现有模型。系统卡表格显示了新旧模型的映射关系：
    
    - GPT-4o → gpt-5-main
        
    - GPT-4o-mini → gpt-5-main-mini
        
    - OpenAI o3 → gpt-5-thinking
        
    - OpenAI o4-mini → gpt-5-thinking-mini
        
    - GPT-4.1-nano → gpt-5-thinking-nano
        
    - OpenAI o3 Pro → gpt-5-thinking-pro（仅限ChatGPT $200/月高级版，采用并行测试计算）
        
- GPT-5系列唯一未覆盖的能力是音频输入/输出和图像生成，这部分仍由GPT-4o Audio、GPT-4o Realtime及其mini版本，以及GPT Image 1和DALL-E等模型负责。
    

定价策略与市场对比

- GPT-5定价极具竞争力：
    
    - GPT-5：输入$1.25/百万tokens，输出$10/百万tokens
        
    - GPT-5 Mini：输入$0.25/百万，输出$2.00/百万
        
    - GPT-5 Nano：输入$0.05/百万，输出$0.40/百万
        
- GPT-5输入价格为GPT-4o的一半，输出价格持平。需要注意的是，推理tokens（不可见）也计入输出，因此实际输出tokens消耗通常高于GPT-4o，除非将推理等级设为“minimal”。
    
- Token缓存折扣显著：若输入tokens在几分钟内重复使用，折扣高达90%。这对实现聊天UI等场景尤为有利，因为每次用户追加新提示时，历史对话会被重复回放。
    
- 与主流竞品对比（单位：$/百万tokens）：
    
    - Claude Opus 4.1：输入15.00，输出75.00
        
    - Claude Sonnet 4 / Grok 4 / Gemini 2.5 Pro（>20万tokens）：输入3.00，输出15.00
        
    - GPT-4o：输入2.50，输出10.00
        
    - GPT-4.1 / o3：输入2.00，输出8.00
        
    - Gemini 2.5 Pro（<20万tokens）/ GPT-5：输入1.25，输出10.00
        
    - Claude 3.5 Haiku：输入0.80，输出4.00
        
    - GPT-5 Mini：输入0.25，输出2.00
        
    - GPT-5 Nano：输入0.05，输出0.40
        
    - Amazon Nova Micro：输入0.035，输出0.14
        
- 作者指出，GPT-5在表格排序等任务上偶有失误，但通过引导其用Python代码处理可规避。
    

系统卡披露的更多细节

- 训练数据来源依然模糊，官方表述为：GPT-5系列训练于多样化数据集，包括公开互联网信息、与第三方合作获取的数据，以及用户/人类训练师生成的数据。采用先进的数据过滤流程以减少个人信息。
    
- ChatGPT最常见的三大用例为写作、编程和健康咨询，因此GPT-5在这三方面投入了大量优化，尤其是健康相关问题。
    
- GPT-5在“减少幻觉（hallucinations）、提升指令遵循、降低谄媚（sycophancy）”方面取得显著进展。所有GPT-5模型均引入了“safe-completions（安全补全）”机制，作为最新的安全训练方法，旨在防止生成不允许的内容。
    
    - 传统LLM安全策略多为“有害即拒绝”，但在生物学、网络安全等双用途场景下，简单拒绝并不适用。safe-completions转而关注输出内容本身的安全性，在保证安全政策约束下最大化有用性。
        
- 谄媚问题（sycophancy）在GPT-5中通过后训练阶段重点优化。团队用真实对话数据评估模型输出的谄媚程度，并将评分作为奖励信号参与训练。
    
- 幻觉问题：GPT-5在减少“事实幻觉”上有显著提升。作者个人体验中未遇到明显幻觉，但也承认自己作为资深用户，已习惯规避易触发幻觉的提示（如让模型生成URL或论文引用）。官方训练重点在于提升模型在无浏览工具时的事实准确性，并优化其浏览能力。
    
- 欺骗行为：GPT-5在遇到无法完成的任务时，被奖励“如实承认无法完成”，而不是假装已完成。对于需要工具（如网页浏览）但工具不可用的场景，团队通过模拟错误码等方式训练模型避免幻觉。
    
- Prompt Injection（提示注入）安全性：GPT-5在外部红队测试中表现优于同类模型，gpt-5-thinking的k=10攻击成功率为56.8%，显著低于其他主流模型（大多在70%以上）。但作者强调，这一比例依然很高，提示注入仍是未解难题，开发者不能掉以轻心。
    
- API端“思考轨迹”功能：GPT-5 API支持通过reasoning参数获取推理摘要（summary: auto），便于开发者理解模型的推理过程。若不启用该选项，API响应会有较长延迟，因为模型会先消耗推理tokens再输出可见内容。新引入的reasoning_effort=minimal选项可关闭大部分推理，加快响应速度。
    

框架与心智模型（Framework & Mindset）

- 混合模型架构：GPT-5在ChatGPT端采用“主模型+深度推理模型+实时路由器”三位一体架构，动态分配资源以兼顾速度与复杂度。这一设计理念强调“按需分配”，即根据任务难度和用户意图自动切换最合适的模型，提升整体体验。
    
- 安全补全（Safe-Completions）机制：摒弃传统的“有害即拒绝”二元策略，转而以“输出为中心”动态调整内容安全性，最大化有用性同时规避风险。适用于双用途（dual-use）场景，强调“有条件地提供高层次安全信息”。
    
- 谄媚与幻觉治理：通过后训练奖励机制，系统性降低模型对用户观点的无脑迎合（sycophancy）和事实性错误（hallucination），并鼓励模型在无法完成任务时坦诚反馈。这一心智模型强调“真实反馈优先于表面迎合”。
    
- Token经济与缓存机制：通过极低的token价格和高额缓存折扣，鼓励开发者优化输入复用，提升系统效率。这一策略体现了“成本敏感+高效复用”的产品思路。
    
- Prompt Injection防御：虽然GPT-5在安全性上有进步，但作者提醒开发者应始终假设“提示注入风险未消除”，在应用层面持续加固防护。
    

基本信息

- Title: GPT-5: Key characteristics, pricing and model card
    
- Author: Simon Willison
    
- URL: https://simonwillison.net/2025/Aug/7/gpt-5/