MIT开发出模仿人类发声的AI模型  
  原文标题：Teaching AI to communicate sounds like humans do  
  链接：https://news.mit.edu/2025/teaching-ai-communicate-sounds-humans-do-0109  

- **文章类别**：新闻报道  

---

**内容整理**：

### 文章框架
```
├── 研究背景与动机
│   ├── 人类通过声音模仿传递信息
│   └── AI模型的开发灵感来源于人类发声机制
├── AI模型的开发
│   ├── 模型设计
│   │   ├── 人类发声器官的模拟
│   │   └── 认知启发式算法
│   ├── 模型功能
│   │   ├── 生成人类发声模仿
│   │   └── 从人类发声反推真实声音
│   └── 模型版本迭代
│       ├── 基线模型
│       ├── 交际模型
│       └── 完整模型（考虑发声努力）
├── 实验与结果
│   ├── 人类对AI生成声音的偏好
│   └── 模型的局限性
├── 应用前景
│   ├── 声音设计与虚拟现实
│   ├── 语言学习与教育
│   └── 艺术与音乐创作
└── 研究团队与支持
    ├── 研究团队成员
    └── 研究资助与发表
```

### 文章内容
#### 研究背景与动机
- 人类通过声音模仿来传递信息，例如描述汽车发动机的声音或模仿猫的叫声，这种模仿类似于用画笔快速勾勒图像来传达视觉信息。
- MIT计算机科学与人工智能实验室（CSAIL）的研究人员受到人类发声机制的启发，开发了一种能够生成人类发声模仿的AI模型。

#### AI模型的开发
- **模型设计**：
  - 研究人员构建了一个模拟人类发声器官的模型，模拟声带振动如何通过喉咙、舌头和嘴唇的形状变化来产生声音。
  - 使用认知启发式AI算法控制该发声模型，使其能够生成人类发声的模仿。
- **模型功能**：
  - 该模型能够从现实世界的声音中生成类似人类发声的模仿，例如树叶沙沙声、蛇的嘶嘶声或救护车的警报声。
  - 模型还可以反向运行，从人类发声模仿中推断出真实世界的声音。
- **模型版本迭代**：
  - **基线模型**：仅生成尽可能接近真实声音的模仿，但与人类行为匹配不佳。
  - **交际模型**：考虑声音对听众的独特性，例如模仿摩托艇的声音时，重点模仿发动机的轰鸣声。
  - **完整模型**：进一步考虑发声的努力程度，避免过于快速、响亮或极端音调的发声，使生成的声音更接近人类行为。

#### 实验与结果
- 在实验中，参与者对AI生成的声音和人类生成的声音进行了偏好判断，AI模型在某些情况下（如模仿摩托艇声音）获得了高达75%的偏好率。
- 模型的局限性包括对某些辅音（如“z”）的处理不佳，以及无法完全模仿人类语言、音乐或跨语言的声音模仿。

#### 应用前景
- 该模型可用于声音设计、虚拟现实中的AI角色开发，帮助学生学习新语言，甚至为音乐家提供通过发声搜索声音数据库的功能。
- 研究团队还计划探索该模型在语言发展、婴儿语言学习以及鸟类模仿行为中的应用。

#### 研究团队与支持
- **研究团队成员**：MIT CSAIL博士生Kartik Chandra、Karima Ma，本科生Matthew Caren，以及其他两位CSAIL成员。
- **研究资助与发表**：研究由赫兹基金会和美国国家科学基金会资助，论文发表于SIGGRAPH Asia会议。

### 文章标签
#人工智能 ， #声音模仿 ， #MIT ， #虚拟现实

---