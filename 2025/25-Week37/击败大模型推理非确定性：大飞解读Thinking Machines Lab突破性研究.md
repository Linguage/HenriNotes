**击败大模型推理非确定性：大飞解读Thinking Machines Lab突破性研究**

---

**概述**

本期内容聚焦由OpenAI 前CTO 米拉·穆拉蒂（Mira Murati）创立的 Thinking Machines Lab 所发布关于大语言模型推理“非确定性”技术难题的最新突破。视频详细剖析了为何即使输入和随机种子完全相同，大模型推理输出依然会不同的根本原因，并深入解读了该团队提出的“批次不变性内核”（Batch-Invariant Kernel）解决方案及其实验验证。结论认为，大模型推理结果的不可复现，是由批次归约顺序变化引发的浮点数误差累计所致，真正的“批次不变内核”能够极大提升AI系统的可重复性，对于金融、医疗等高可靠性场景具有里程碑意义。

---

**主题梳理**

**1. 背景与非确定性现象**

- Thinking Machines Lab 的成立背景极为特殊。2025年7月，这家公司尚未推出任何产品就完成了20亿美元的种子轮融资，估值高达120亿美元。创始团队包括前OpenAI高管以及产业顶级工程师，吸引了A16z、英伟达、AMD、思科等巨头资本的关注。
    
- 公司博客“Connectionism”（联结主义）首篇即直面“大模型推理非确定性”——很多AI开发者发现，哪怕输入相同、seed 固定，大模型推理多次输出依然可能不同。这一现象常见于主流开源推理引擎 vLLM、SGLang 等，即使是在本地硬件上运行依然复现。
    
- 业界通常归咎于GPU并发或浮点数误差，但Thinking Machines Lab通过实验发现，这些并非导致非确定性的根本原因。实际根源在于GPU内部并行计算的“批次归约顺序”——即矩阵运算与归约（reduction）操作，因批次大小及内核调度策略变化而改变顺序，进而累积浮点误差，导致推理结果不一致。
    

**2. 浮点数非结合性与批次不变性缺失**

- 浮点数的数学性质极具特殊性，即“非结合性”：(a+b)+c≠a+(b+c)(a+b) + c \neq a + (b+c)(a+b)+c=a+(b+c)。在大模型推理中，矩阵乘法、RMSNorm（均方根归一化）、注意力机制（Attention）的核心步骤均会大量使用浮点加法与乘法，小数精度在大数量级数值操作下极易损失。
    
- 服务器按负载将请求“打包”成不同大小的批次，批次容量变化会导致内核归约策略变化。例如，批次小则采用单核完整归约，大时采用并行分割归约。若每次请求批次不同，最终每步归约顺序都可能不同，即使前 n 步生成内容一致，后续也会因极小的数值差异引发输出分歧。实验显示，1000次推理居然得出80种不同完成结果，且分歧都出现在关键token之前内容完全一致的前提下。
    

**3. 批次不变内核（Batch-Invariant Kernel）解决方案**

- 思路核心在于：无论批次大小如何，始终用固定归约顺序完成关键操作，舍弃部分算力，换取推理结果一致性。
    
- 具体实现如下：
    
    - **RMSNorm**：无论批次大小，都强制用数据并行，每个核心处理一个批次元素的归约任务，哪怕批次小部分核心闲置，依然坚持顺序不变。
        
    - **矩阵乘法**：禁用Split-K策略，不管矩阵大小都不拆分归约维度，且统一张量指令尺寸（如128×128×32 block），避免因算力调度不同导致顺序变化。
        
    - **注意力机制**：固定KV拆分块大小，不管总长度如何都以256为单位分割，确保KV缓存归约顺序唯一；同时统一预填充和解码阶段数据格式，杜绝多源（多块）拼接带来的顺序变化。
        
- 实验验证显示：开启批次不变内核，1000次同条件推理结果全部一致，非确定性被彻底消除。虽然原生实现性能折损较大（最高2倍），但优化后仅剩20%以内性能损耗，可接受范围远优于一致性带来的巨大价值。
    

**4. 研究意义与未来影响**

- 推理结果可重复性是AI走向产业级高可靠应用的根基；批次不变内核为科学、公正、可靠、可复现提供了底层保障。医疗、金融、强化学习（On-policy RL）等领域对推理一致性要求极高，且依赖结果的可解释性与一致性，正是此前大模型用作在线策略训练“不可落地”的核心障碍。
    
- 该成果让训练和推理过程输出完全一致，KL散度可长期保持为0，推动在线策略强化学习等应用落地。实验发现，未用批次不变内核时，RL训练318步奖励崩溃；启用后无须复杂离线校正，奖励表现稳定，将是RL训练方式的新突破点。
    
- 框架名称“Connectionism”（联结主义），体现团队希望推动AI研究科学化、工程化，联结基础理论与实际落地的愿景。正如团队所言，这并非对现有技术的小修小补，而是AI产业迈向更可靠、可工程化新阶段的关键一步。
    

---

**框架与心智模型（Framework & Mindset）**

- **可重复性优先原则**：AI系统落地应以可重复性为第一优先级，哪怕牺牲一定算力或速度，确保每次结果可复现，工程团队需审视底层内核乃至GPU内指令级行为而不仅仅调参。
    
- **确定性追踪（Determinism Tracking）方法论**：从输入端到输出端，针对所有可能因并行、缓存、拆块、归约造成顺序变化的步骤，逐一固定操作策略，建立严格的“批次不变性”保障机制，优先考虑归约顺序的全链路一致性，力保浮点数累计误差可控、可追踪。
    
- **科学工程结合（Science-Engineering Integration）观念**：
    
    - 理论探索须与产业实践联结，不能脱离实用可落地检验。
        
    - AI可靠性指标不能只关注性能和规模，必须权重“可重复性”。
        
    - 团队合作、社区开放、跨学科协作，是推动AI健康发展的关键动力。
        
- **前瞻性权衡（Forward Trade-off）哲学**：
    
    - 楚材晋用，将企业级AI可靠性需求，与基础科学问题反推到底层系统工程，不惧过程复杂，只追求最终一致性，战略上预判领域未来的主流标准与痛点方向。
        

---

**基本信息**

- Title: 【人工智能】击败大模型推理的非确定性 Thinking Machines Lab突破详解
    
- Author: 最佳拍档（大飞）
    
- URL: [https://www.youtube.com/watch?v=eYq6Zc1M6pU](https://www.youtube.com/watch?v=eYq6Zc1M6pU)
    

1. [https://www.youtube.com/watch?v=eYq6Zc1M6pU](https://www.youtube.com/watch?v=eYq6Zc1M6pU)