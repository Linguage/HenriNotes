AGI与“广泛浅层智能”的区别
- 原文标题：AGI versus “broad, shallow intelligence”
- 链接：[Substack](https://garymarcus.substack.com/p/agi-versus-broad-shallow-intelligence?utm_source=post-email-title&publication_id=888615&post_id=154758805&utm_campaign=email-post-title&isFreemail=true&r=208yzy&triedRedirect=true&utm_medium=email )

- **文章类别**：博客文章 

---

**内容整理**： 

**文章框架**：


```markdown

AGI versus “broad, shallow intelligence”
    ├── 引言
    │   └── AGI尚未实现，当前AI被定义为“广泛但肤浅的智能”（BSI）
    ├── AGI的定义
    │   ├── AGI能够解决普通人类也能解决的认知问题
    │   ├── AGI具有与人类相当的灵活性和可靠性
    │   └── AGI能够从经验中推广到全新情境
    ├── LLMs的局限性
    │   ├── LLMs在某些领域表现出色，但在其他领域不足
    │   ├── LLMs缺乏深度推理和可靠性
    │   ├── LLMs产生错误和幻觉（hallucinations）
    │   └── LLMs缺乏事实核查和常识检查的能力
    ├── BSI的特点
    │   ├── BSI在应用范围上广泛
    │   ├── BSI在理解和可靠性方面不足
    │   └── BSI的答案往往表面化，缺乏深度理解
    ├── 对未来AI的期望
    │   ├── 追求深度理解而非表面化的语言模式
    │   ├── 开发可靠的AI系统作为研究优先级
    │   └── 超越BSI，开发更安全、更可靠的AI
    └── 结论
        └── 警惕过度依赖不可靠的AI，以及对AGI实现的过度乐观态度
 
```

**文章标签**：

#人工智能 #AGI #广泛浅层智能 #GaryMarcus

**文章内容**：
Gary Marcus在其博客文章中探讨了人工通用智能（AGI）与当前所谓的“广泛浅层智能”（BSI）之间的区别。文章开篇指出，尽管有人声称我们已经接近或达到了AGI，但包括AGI概念的共同创造者在内的多位专家都认为我们尚未实现真正的AGI。

文章进一步阐释了AGI的定义，即一种具有灵活性和普遍性的智能，其资源丰富性和可靠性可与人类智能相媲美甚至超越。Marcus引用了François Chollet和Shane Legg的观点，强调AGI应能够解决普通人在没有事先训练的情况下能够解决的问题，而当前的AI模型还无法做到这一点。

接着，文章对比了AGI与BSI。BSI，即大型语言模型（LLMs）所代表的智能类型，虽然在应用范围上较为广泛，能够尝试解决多种问题，但其回答常常缺乏深度，存在“幻觉”或错误，无法进行基本的事实核查和合理性检查，可靠性不足。Marcus通过举例说明了LLMs在理解和应用知识时的表面性，它们往往只是模仿互联网上找到的类似问题的答案，而没有真正理解背后的概念。

文章还讨论了BSI带来的问题，包括其不可预测性导致在大多数情况下仍需人类介入，以及无法保证其安全性、人类兼容性或按照人类的要求行事。Marcus强调，依赖这种浅层且不可靠的AI可能会引发巨大问题。

基于此，Marcus提出了“广泛浅层智能”（BSI）这一称呼，用以准确描述当前LLMs的特性，并明确了我们应努力超越的目标。他主张，我们追求的系统应能够通过概念推理而非仅仅依赖语言模式来回答问题，从而实现真正的深度理解。

在结语部分，Marcus表达了对AGI的期待，并强调将研究重点从BSI转向更安全、更可靠的AI体系是人类面临的重大研究优先事项。他呼吁读者对那些声称AGI已经解决或即将到来的言论保持怀疑，并思考这些系统是否真的能够在多个领域提供可靠的答案，是否比前一代系统有原则性的深度提升，还是仅仅是在同一模式下稍作改进的“万金油”式近似，缺乏深度理解。

整体而言，这篇文章为理解AGI与当前AI技术之间的差距提供了深刻的见解，并对未来的研究方向提出了明确的建议。


---

## More
# 总结

网页主要探讨了目前的人工智能（AI）尚未达到人类通用智能（AGI）的水平，而是属于广泛但肤浅的智能（BSI），即虽然AI在多个领域有应用，但缺乏深度理解和可靠性。

# 摘要

文章由Gary Marcus撰写，发表于2025年1月14日，讨论了当前AI的局限性以及对未来AGI的期望。Marcus引用了AI领域的思想家François Chollet和Shane Legg的观点，强调AGI的定义是AI能够解决没有接受特定训练的普通人类也能解决的认知问题。尽前的AI，尤其是大型语言模型（LLMs），虽然在某些方面表现出超人的能力，但在其他方面则远远低于人类，缺乏从经验中推广到全新情境的能力，经常产生错误和幻觉（hallucinations），缺乏事实核查和常识检查的能力，因此不能被认为是AGI。文章提出，当前的AI应该被称为“广泛但肤浅的智能”（BSI），因为它们在应用范围上虽然广泛，但在理解和可靠性方面仍然表现出来处深。Marcus呼吁，我们应该追求深度理解，而不是仅仅依赖于表面的语言模式，以便开发出可靠的AI系统。他还提醒，过度依赖于不可靠的AI可能会带来巨大的问题，因此，超越BSI并开发更安全、更可靠的AI应该是人类的主要研究优先级。

# 观点

1. 目前的AI，包括大型语言模型（LLMs），还没有达到AGI的水平，因为它们在解决认知问题方面不如普通人类，缺乏深度推理和可靠性。
2. AGI的定义是能够解决普通人类也能解决的认知问题，而且应该具有与人类相当或更高水平的灵活性、资fulness和可靠性。
3. LLMs虽然在某些领域表现出色，但在其他领域表现出明显的不足，经常产生错误，缺乏从经验中推广到全新情境的能力，因此不能被认为是AGI。
4. 文章提出将当前的AI称为“广泛但肤浅的智能”（BSI），因为它们在应用范围上虽然广泛，但在理解和可靠性方面仍然表现出来处深。
5. 追求深度理解而不是仅仅依赖于表面的语言模式是开发可靠AI系统的关键。
6. 过度依赖于不可靠的AI可能会带来巨大的问题，因此，超越BSI并开发更安全、更可靠的AI应该是人类的主要研究优先级。

