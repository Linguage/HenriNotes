AI领域的新动态：训练成本下降、桌面AI超级计算机、更严格的AI出口限制和改进的对比损失函数
- 原文标题：Tumbling Training Costs, Desktop AI Supercomputer, Tighter AI Export Restrictions, Improved Contrastive Loss
- 链接：[点击查看](https://info.deeplearning.ai/tumbling-training-costs-desktop-ai-supercomputer-tighter-ai-export-restrictions-improved-contrastive-loss?ecid=ACsprvtyGfKCXqezFW9DMR9T9owcpeoP8Pp-nN6VkYshSEe3j5S2MyZTlAOvQpL1Wpum5BAMvr6S&utm_campaign=The%20Batch&utm_medium=email&_hsenc=p2ANqtz-8hzjg-Yh9ISKEAHezo2eI6MQ7yDKixPHJWgJ4fly1YXTA-TVHYhYbs1V-dFl_pDqo0LPcPaCyCq3ZhR7pIRmDr7sUZeQ&_hsmi=342693150&utm_content=342693150&utm_source=hs_email) 

- **文章类别**：新闻报道 

---

**内容整理**： 

**文章框架**：
```
├── AI产品管理的未来
│   ├── 软件开发成本降低对产品管理的影响
│   ├── AI产品管理所需的技能
│   └── AI产品管理的机遇与挑战
├── DeepSeek-V3模型
│   ├── 模型性能与特点
│   ├── 训练方法与成本
│   └── 模型的影响
├── 美国扩大AI出口限制
│   ├── 新规内容与影响
│   ├── 限制的层级与细节
│   └── 对全球AI生态的潜在影响
├── 桌面AI超级计算机Project Digits
│   ├── 产品特点与功能
│   ├── 技术规格
│   └── 产品意义
└── X-Sample对比损失函数
    ├── 研究团队与方法
    ├── X-CLR的工作原理
    └── 研究结果与意义
```

**文章标签**：

#AI产品管理 ， #AI模型 ， #出口限制 ， #桌面超级计算机 ， #对比损失函数 

**AI产品管理的未来**
- **软件开发成本降低对产品管理的影响**：随着软件开发成本的降低，尤其是原型开发变得更加便宜，对能够决定构建什么的人的需求将会增加。AI产品管理的未来一片光明。产品经理（PM）需要决定构建什么，而软件开发者负责编写代码。AI使构建过程本身变得更快速、更便宜，这将显著增加对能够提出清晰规格以构建有价值事物的人的需求。
- **AI产品管理所需的技能**：
    - **技术熟练度**：PM需要了解哪些产品在技术上是可行的，以及AI项目的生命周期，如数据收集、构建、监控和维护AI模型。
    - **迭代开发**：AI开发比传统软件更具迭代性，需要更多的中途调整，PM需要了解如何管理这样的过程。
    - **数据熟练度**：AI产品通常从数据中学习，并且可以设计成比传统软件生成更丰富的数据形式。
    - **管理模糊性的能力**：由于AI的性能难以提前预测，PM需要对此感到舒适，并拥有管理它的策略。
    - **持续学习**：AI技术发展迅速，PM需要跟上最新的技术进步、产品想法以及它们如何融入用户生活。
- **AI产品管理的机遇与挑战**：许多公司的工程师与PM比例为6:1，随着编码效率的提高，团队将需要更多的产品管理工作。然而，软件工程师比产品经理更快地理解和接受AI，导致大多数公司难以找到既懂得开发产品又了解AI的人，预计这种短缺将增长。

**DeepSeek-V3模型**
- **模型性能与特点**：DeepSeek-V3是一个开源的大型语言模型，在关键基准测试中超越了Llama 3.1 405B和GPT-4o，并在编码和数学方面取得了卓越的分数。模型权重是开源的，除了涉及军事用途、伤害未成年人、生成虚假信息等限制的应用。模型包含6710亿个参数，其中370亿个在任何时刻都是活跃的。
- **训练方法与成本**：开发人员在大约15万亿个标记上训练了该模型，其中包括比DeepSeek-V2更大比例的编码和数学数据。他们在多种任务上对模型进行了微调，并使用强化学习算法进一步提高了其在不同领域的性能。训练成本仅为560万美元，不到训练Llama 3.1 405B所需时间的1/10。
- **模型的影响**：如果DeepSeek的结果可以复制，那么训练基础模型的经济将发生重大变化。如果现在构建一个GPT-4o级别的模型的成本约为500万美元，那么更多的团队将能够训练这样的模型，与AI巨头竞争的成本可能会大幅下降。

**美国扩大AI出口限制**
- **新规内容与影响**：美国提出了新的限制，将极大地扩大之前的限制，创建一个新的国际层级，以获取先进芯片和模型。新规将创建一个三级系统，限制向大多数国家出口AI芯片和模型，除了一个选定的亲密盟友小组。这些规则还将引入美国首次对大型AI模型的封闭权重出口限制。
- **限制的层级与细节**：
    - **第一层级**：澳大利亚、日本、台湾、英国和欧洲大部分地区将保留几乎不受限制的访问权限。然而，这些国家必须将75%的AI计算能力保留在盟国境内。不超过10%可以转移到这个集团之外的任何一个国家，以确保先进的AI开发仍然集中在亲密的美国盟友中。
    - **第二层级**：传统美国盟友和贸易伙伴，如以色列、沙特阿拉伯和新加坡，在2025年第一季度面临5.07亿单位的总处理能力（TPP）的初始上限——大约相当于3.2万个Nvidia H100芯片的计算能力。到2027年，上限将增加到10.2亿TPP。在美国运营的公司可以申请更高的限制：2025年第一季度为6.33亿TPP，到2027年第一季度增加到50.64亿TPP。
    - **第三层级**：中国、俄罗斯和大约二十多个国家被阻止接收先进AI芯片、模型权重和与这些系统相关的专业知识。
    - 美国商务部的出口控制机构必须批准出口使用超过10^26次计算操作训练的模型或封闭模型的权重转移。这些规则针对未来系统，因为目前没有已知的模型在训练期间使用了这么多计算。
    - 美国公司必须至少将50%的总AI计算能力保留在美国境内。他们还必须跟踪其模型的分发，实施安全措施，并接受定期审计。
- **对全球AI生态的潜在影响**：新限制可能会对全球AI生态系统产生重大影响。它们可能会迫使第二层级和第三层级国家的开发人员构建资源消耗较少的模型，并促使他们更紧密地合作，降低美国制造技术的全球价值。它们还可能损害美国芯片供应商的利益，这些供应商已经警告说，这些规则可能会削弱美国在全球经济中的竞争力。它们还可能迫使正在建设大型数据中心以处理AI计算的公司重新考虑他们的计划。

**桌面AI超级计算机Project Digits**
- **产品特点与功能**：Nvidia的Project Digits是一款个人超级计算机，旨在帮助开发人员在本地微调和运行大型模型。它足够小，可以单手握住，将于5月上市，起价3000美元。它可以运行多达2000亿参数的模型——大约是典型消费硬件舒适容纳的五倍大小——只要它们被量化到4位精度。两个单元可以连接起来运行像Meta的Llama 3.1 405B这样的模型。
- **技术规格**：
    - 运行Nvidia的DGX操作系统，这是一种Ubuntu Linux的变体。
    - 系统基于GB10系统级芯片，结合了Nvidia Blackwell GPU架构（其最新B100 GPU的基础）和Grace CPU架构（设计用于管理数据中心中的AI工作负载），通过高带宽NVLink互连连接。
    - 配备128 GB的统一内存和4 TB的固态存储。
    - 系统连接到Nvidia的DGX Cloud服务，使开发人员能够将模型从本地机器部署到云基础设施。
- **产品意义**：通常在Nvidia A100或H100 GPU上训练模型，这些GPU的价格至少为8000美元或20000美元，分别配备40 GB到80 GB的内存。这些高昂的要求促使许多开发人员从云提供商那里购买计算基础设施。Project Digits以3000美元的价格和128 GB的内存，旨在赋予机器学习工程师在自己的机器上训练和运行更大模型的能力。
  

**X-Sample对比损失函数**
- **研究团队与方法**：Meta、纽约大学、布朗大学、Genentech和加拿大高级研究所的Vlad Sobal及其同事引入了X-Sample对比损失（X-CLR），这是一种自监督损失函数，使视觉模型能够学习更细致地捕捉示例之间的相似性和差异的嵌入。
- **X-CLR的工作原理**：与SimCLR等对比损失函数不同，X-CLR不是简单地标记示例为相似或不相似，而是分配相似性分数，使模型能够学习产生与这些分数相匹配的嵌入。研究者使用X-CLR在从网络抓取的图像-文本对的数据集上训练了一个嵌入模型：CC-3M（300万文本-图像对）和CC-12M（1200万文本-图像对）。模型类似于CLIP，除了文本编码器是一个在句子对上预训练的句子变换器，视觉编码器是一个在ImageNet上预训练的ResNet-50。
    - 句子变换器为所有示例嵌入文本标题。系统根据文本嵌入之间的余弦相似性计算相似性分数。
    - 类似地，ResNet-50计算图像嵌入，并计算它们之间的相似性分数。
    - 研究者冻结了句子变换器，并使用文本相似性分数作为损失函数中的标签。损失函数最小化了文本嵌入的相似性分数与相应图像嵌入的相似性分数之间的差异。    
- **研究结果与意义**：使用X-CLR训练的系统在ImageNet分类中优于竞争对手，尤其是在训练数据较少时。与SimCLR和CLIP相比，X-CLR在CC-3M数据集上训练后，在ImageNet上的准确率为58.2%，而SimCLR模型为57.0%，CLIP为41.0%。在CC-12M上训练后，X-CLR的准确率为59.4%，SimCLR为58.9%，CLIP为58.8%。X-CLR利用图像及其标题进行自监督学习，但与CLIP不同，X-CLR使用连续的相似性信号（而不是离散的）来匹配图像-图像对。
