MI300X、H100与H200训练性能对比：CUDA护城河依然坚固
- 原文标题：MI300X vs H100 vs H200 Benchmark Part 1: Training – CUDA Moat Still Alive
- 链接：https://semianalysis.com/2024/12/22/mi300x-vs-h100-vs-h200-benchmark-part-1-training/#executive-recommendation-to-amd 

- **文章类别**：博客文章 

---

**内容整理**： 

## MI300X、H100与H200训练性能对比：CUDA护城河依然坚固

### 文章框架

```markdown
- 引言
    - SemiAnalysis对MI300X、H100和H200进行了为期五个月的独立分析和训练基准测试
    - 旨在比较三者的训练性能、用户体验、可用性等，并给出对AMD的改进建议
- 关键发现
    - AMD的软件体验存在诸多问题，导致MI300X的实际训练性能远低于其纸面规格
    - NVIDIA的开箱即用性能和体验出色，而AMD的开箱即用体验则困难重重
    - MI300X的总拥有成本（TCO）较低，但按TCO计算的训练性能在AMD公共稳定版软件上不如H100/H200
- AMD与NVIDIA的竞争概述
    - MI300X在纸面规格上具有优势，但实际市场表现未达预期
    - AMD的市场份额增长未达预期，其软件栈问题导致产品竞争力受限
- 通用矩阵乘法（GEMM）性能
    - GEMM性能是衡量Transformer架构训练性能的重要指标
    - 在BF16和FP8精度下，MI300X的GEMM性能均低于H100/H200
- 流行的GEMM基准测试不准确
    - 指出当前流行的GEMM基准测试存在的问题，如未正确清除L2缓存等
- HBM内存带宽性能
    - MI300X的HBM内存带宽优于H100/H200，但在实际训练中影响有限
- AMD定制构建和开发构建
    - 为了获得较好的性能，需要使用AMD提供的定制Docker镜像和开发构建
    - 这些定制构建需要从源代码构建依赖项，过程复杂且耗时
- 单节点训练性能
    - 在多种模型测试中，H100/H200的性能优于MI300X公共发布版和夜间版
    - MI300X在非因果注意力层的模型上表现不佳
- 多节点训练性能
    - H100在多节点训练中性能优势明显，MI300X的扩展性较差
- AMD PYTORCH_TUNABLE_OPS标志是糟糕的用户体验
    - 该标志需要用户进行大量手动调优，且存在诸多已知问题
- 扩展NVLink/xGMI拓扑
    - 比较了H100/H200的NVLink和MI300X的xGMI在扩展性上的差异
- 集体通信操作概述
    - 介绍了在大规模模型训练中常用的集体通信操作及其重要性
- 单节点NCCL集体通信
    - 在各种集体通信操作中，NVIDIA的性能均优于AMD
- 多节点RCCL/NCCL集体通信和扩展网络基准测试
    - 在多节点环境下，MI300X的集体通信性能远低于H100/H200
- AMD用户体验不佳，MI300X开箱即用性差
    - 由于AMD内部测试不足，导致MI300X存在大量软件问题，影响用户体验
- 探索AMD性能提升的方法
    - 对AMD提出了一些性能提升的建议，如改进GEMM库的启发式模型等
- AMD的分叉库问题
    - 许多AMD库是基于NVIDIA开源或生态系统库分叉而来，影响了用户体验
- 对AMD软件改进的详细建议
    - 从多个方面对AMD的软件开发和测试流程提出了改进建议
- H100/H200/MI300X网络物料清单分析和按TCO的性能
    - 对不同网络配置下的GPU集群进行了成本和性能分析
```

### 详细内容

#### 引言
SemiAnalysis团队对AMD的MI300X、NVIDIA的H100和H200进行了为期五个月的独立分析和训练基准测试。测试涉及与NVIDIA和AMD的互动，旨在提供一个无偏的评估，反映真实用户在实际使用中可能遇到的情况。文章不仅比较了三者的训练性能，还涵盖了用户体验、可用性等方面，并给出了对AMD的改进建议。

#### 关键发现
- **性能与体验**：AMD的软件体验存在诸多问题，导致MI300X的实际训练性能远低于其纸面规格。NVIDIA的开箱即用性能和体验出色，而AMD的开箱即用体验则困难重重。在大多数基准测试中，AMD公共稳定版的PyTorch在训练吞吐量上仍落后于NVIDIA的H100和H200。
- **成本与性能**：MI300X的总拥有成本（TCO）较低，但按TCO计算的训练性能在AMD公共稳定版软件上不如H100/H200。如果使用AMD的定制开发构建，情况会有所改变，但那时NVIDIA的下一代产品可能已经上市。
- **性能差距**：在BF16精度下，H100和H200的GEMM性能约为720 TFLOP/s，而MI300X仅为约620 TFLOP/s，比其市场宣传的1307 TFLOP/s低得多，比H100/H200慢14%。在FP8精度下，H100/H200达到约1280 TFLOP/s，MI300X仅为约990 TFLOP/s，慢22%。

#### AMD与NVIDIA的竞争概述
MI300X在纸面规格上具有优势，如更高的FP16计算能力和更大的HBM内存带宽，但实际市场表现未达预期。AMD的市场份额增长未达预期，其软件栈问题导致产品竞争力受限。尽管AMD的市场指导乐观，但2024年数据中心GPU销售的全年指导反复未能达到预期。

#### 通用矩阵乘法（GEMM）性能
GEMM性能是衡量Transformer架构训练性能的重要指标。测试了多种实际使用的矩阵形状，结果显示，在BF16和FP8精度下，MI300X的GEMM性能均低于H100/H200。此外，还发现AMD的`torch.matmul`和`F.Linear` API在性能上存在差异，这是由于AMD使用了不同的底层GEMM库。

#### 流行的GEMM基准测试不准确
当前流行的GEMM基准测试存在两个主要问题：未正确清除L2缓存，以及仅取最大性能值而非迭代过程中的中位数/平均TFLOP/s。正确的基准测试应使用OpenAI的`do_bench`函数，该函数默认提供L2缓存清除和中位数/平均值计算。

#### HBM内存带宽性能
MI300X的HBM内存带宽优于H100/H200，但在实际训练中影响有限。尽管更大的HBM内存容量和带宽可以设置更大的批量大小，但在超过一定大小后，模型收敛时间会变长。

#### AMD定制构建和开发构建
为了获得较好的性能，需要使用AMD提供的定制Docker镜像和开发构建。这些定制构建需要从源代码构建依赖项，过程复杂且耗时。与NVIDIA提供的预构建、开箱即用的体验相比，AMD的用户体验较差。

#### 单节点训练性能
在多种模型测试中，H100/H200的性能优于MI300X公共发布版和夜间版。MI300X在非因果注意力层的模型上表现不佳，如Mistral 7B v0.1。此外，AMD的FP8训练在早期存在诸多问题，经过多次修复后，性能才有所提升。

#### 多节点训练性能
在多节点训练中，H100的性能优势明显，MI300X的扩展性较差。这主要是由于AMD的RCCL（集体通信库）性能较弱，以及AMD在网络和交换硬件方面的垂直整合度较低。

#### AMD PYTORCH_TUNABLE_OPS标志是糟糕的用户体验
AMD的`PYTORCH_TUNABLE_OPS`标志需要用户进行大量手动调优，且存在诸多已知问题，如内存
泄漏、程序崩溃等。这与NVIDIA的体验形成鲜明对比，NVIDIA的GEMM库（cuBLASLt）开箱即用，且其启发式模型能够为大多数形状选择正确的算法。

#### 扩展NVLink/xGMI拓扑
H100和H200的NVLink提供了450GByte/s的带宽，支持8个GPU的连接。而MI300X的xGMI虽然在纸面上提供448GByte/s的带宽，但实际上是一个点对点拓扑，每个GPU只能以64GByte/s的速度与其他GPU通信。此外，NVIDIA的NVLink支持网络内归约（NVLS），而AMD的xGMI不支持类似功能。

#### 集体通信操作概述
在大规模模型训练中，集体通信操作如all_reduce、all_gather、reduce_scatter和all_to_all至关重要。这些操作用于数据并行、张量并行和ZeRO/FSDP并行等技术。测试结果显示，NVIDIA在各种集体通信操作中的性能均优于AMD。

#### 单节点NCCL集体通信
在单节点环境下，NVIDIA的NCCL集体通信性能优于AMD的RCCL。这主要是由于NVIDIA的NVLink拓扑和网络内归约技术的优势。

#### 多节点RCCL/NCCL集体通信和扩展网络基准测试
在多节点环境下，MI300X的集体通信性能远低于H100/H200。NVIDIA的InfiniBand SHARP技术提供了网络内归约功能，而AMD的RoCEv2 Ethernet不支持类似功能。此外，NVIDIA的Spectrum-X Ethernet在网络拥塞控制和自适应路由方面表现出色，而AMD的网络解决方案则相对较弱。

#### AMD用户体验不佳，MI300X开箱即用性差
由于AMD内部测试不足，MI300X存在大量软件问题，影响用户体验。例如，AMD的PyTorch原生Flash Attention内核在一段时间内性能极低，导致Transformer/GPT模型训练速度极慢。此外，AMD的PyTorch注意力层与`torch.compile`存在兼容性问题，导致程序崩溃。

#### 探索AMD性能提升的方法
文章对AMD提出了一些性能提升的建议，如改进GEMM库的启发式模型，使其能够为大多数形状选择正确的算法，而不是让用户在运行时进行大量调优。此外，还建议AMD减少对环境标志的依赖，提供默认配置，以提高用户体验。

#### AMD的分叉库问题
许多AMD库是基于NVIDIA开源或生态系统库分叉而来，这影响了用户体验。AMD应该更多地贡献自己的软件，而不是依赖于NVIDIA的平台。例如，AMD应该致力于使PyTorch原生FP8训练在自己的硬件上良好工作，而不是通过分叉NVIDIA的库来支持FP8训练。

#### 对AMD软件改进的详细建议
文章从多个方面对AMD的软件开发和测试流程提出了改进建议。包括增加软件工程资源、提高现有工程师的薪酬、采购更多GPU用于内部开发、创建公共性能仪表板、改变环境标志的使用方式、与Meta合作以改进ROCm的生产训练工作负载等。

#### H100/H200/MI300X网络物料清单分析和按TCO的性能
文章还对不同网络配置下的GPU集群进行了成本和性能分析。包括1k GPU以太网、1k GPU InfiniBand、16k GPU以太网和16k GPU InfiniBand集群的网络物料清单分析，以及使用51.2T Radix和25.6T Radix交换机对后端网络的影响。最后，文章提供了按TCO计算的性能分析，比较了H100/H200/MI300X在每小时有效训练petaflop的成本。
