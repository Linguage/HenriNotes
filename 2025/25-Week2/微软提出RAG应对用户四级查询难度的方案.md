微软提出RAG应对用户四级查询难度的方案
- 原文标题：RAG怎么面对用户的4级查询难度？微软给出方案！
- 链接：[https://mp.weixin.qq.com/s/k-r4rfDftlsoSGkGoXOlGw](https://mp.weixin.qq.com/s/k-r4rfDftlsoSGkGoXOlGw)

- **文章类别**：博客文章

---

**内容整理**：

```markdown
├── 引言
│   ├── 大语言模型（LLMs）通过整合外部数据提升任务完成能力
│   ├── 外部数据增强使模型在特定领域专业知识、时间相关性及输出可控性和可解释性方面得到提升
│   ├── 检索增强生成（RAG）和微调等技术受关注并广泛应用，但在专业领域部署面临挑战
├── 用户查询任务的四级分类
│   ├── Level-1 显式事实查询（Explicit Fact Queries）
│   │   ├── 定义：可通过明确文本片段直接回答问题，依赖单一数据源
│   │   ├── 举例：2024年夏季奥运会举办地
│   │   ├── 挑战：数据处理、检索困难，评估RAG性能复杂
│   ├── Level-2 隐式事实查询（Implicit Fact Queries）
│   │   ├── 定义：需整合多个数据来源，建立逻辑关联进行推断
│   │   ├── 举例：实验样本量大于1000的数量、医疗记录中提到的三个症状等
│   │   ├── 挑战：信息分散、复杂推理需求、自适应检索量、推理与检索协调、多跳推理
│   │   ├── 解决方案：迭代RAG、基于图/树的问答、NL2SQL、智能检索与推理结合、动态信息整合
│   ├── Level-3 明确推理依据的查询（Interpretable Rationale Queries）
│   │   ├── 定义：需理解和应用推理依据，依据在外部资源中明确提供
│   │   ├── 举例：胸痛患者诊断治疗、客户服务工作流程应对
│   │   ├── 挑战：提示优化成本高、有限的可解释性、数据处理和检索问题、多步推理复杂性
│   │   ├── 解决方案：提示调整技术、链式思维（CoT）提示、利用LLM本身进行提示优化、构建Agent工作流
│   └── Level-4 隐性推理依据的查询（Hidden Rationale Queries）
│       ├── 定义：推理依据未明确记录，需从外部数据中观察模式和结果推断
│       ├── 举例：经济形势对公司未来发展的影响
│       ├── 挑战：逻辑检索困难、数据不足
│       ├── 解决方案：离线学习、上下文学习（ICL）、微调（Fine-Tuning）
├── 给LLMs整合外部数据的三种主要形式
│   ├── 通过查询提取部分领域数据作为LLM的上下文输入
│   ├── 使用特定领域数据训练小模型辅助指导外部信息整合并输入到LLM中
│   └── 直接用外部领域知识对通用大型语言模型进行微调使其成领域专家模型
└── 结语
    ├── 强调选择合适策略给LLM进行知识注入需对数据源有透彻理解
    └── 提供参考文献链接及相关推荐阅读
```


### 表格化内容

#### 用户查询任务的四级分类

| 级别      | 查询类型                                       | 定义                         | 举例                                           | 挑战                                | 解决方案                                        |
| ------- | ------------------------------------------ | -------------------------- | -------------------------------------------- | --------------------------------- | ------------------------------------------- |
| Level-1 | 显式事实查询（Explicit Fact Queries）              | 可通过明确的文本片段直接回答问题，依赖单一数据源   | 2024年夏季奥运会举办地                                | 数据处理困难、数据检索困难、评估RAG性能复杂           | -                                           |
| Level-2 | 隐式事实查询（Implicit Fact Queries）              | 需整合多个数据来源，建立逻辑关联进行推断       | 实验样本量大于1000的数量、医疗记录中提到的三个症状、公司X和公司Y的人工智能策略区别 | 信息分散、复杂推理需求、自适应检索量、推理与检索协调、多跳推理   | 迭代RAG、基于图/树的问答、NL2SQL、智能检索与推理结合、动态信息整合      |
| Level-3 | 明确推理依据的查询（Interpretable Rationale Queries） | 需理解和应用推理依据，依据在外部资源中明确提供    | 胸痛患者诊断治疗、客户服务工作流程应对                          | 提示优化成本高、有限的可解释性、数据处理和检索问题、多步推理复杂性 | 提示调整技术、链式思维（CoT）提示、利用LLM本身进行提示优化、构建Agent工作流 |
| Level-4 | 隐性推理依据的查询（Hidden Rationale Queries）        | 推理依据未明确记录，需从外部数据中观察模式和结果推断 | 经济形势对公司未来发展的影响                               | 逻辑检索困难、数据不足                       | 离线学习、上下文学习（ICL）、微调（Fine-Tuning）             |

#### 给LLMs整合外部数据的三种主要形式

| 形式 | 描述 |
|------|------|
| 通过查询提取部分领域数据作为LLM的上下文输入 | 直接将部分领域数据作为上下文输入到LLM中，适用于可以在较短文本中简洁解释的数据场景，但面临有限的上下文窗口和中间可能的信息丢失 |
| 使用特定领域数据训练小模型辅助指导外部信息整合并输入到LLM中 | 训练一个小模型来辅助指导外部信息整合，减少训练时间和能够吸收大量数据，但其有效性取决于模型的能力，可能限制LLM在更复杂任务中的表现 |
| 直接用外部领域知识对通用大型语言模型进行微调使其成领域专家模型 | 利用外部领域知识对通用大型语言模型进行微调，使其成为领域专家模型，但对LLM的影响在很大程度上取决于所使用数据的设计，使用领域外的事实数据进行微调可能会导致LLM生成更多错误输出 |



