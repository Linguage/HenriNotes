大型语言模型（LLMs）能否通过不断要求“写出更好的代码”来提升代码质量？
- 原文标题：Can LLMs write better code if you keep asking them to “write better code”?
- 链接：https://minimaxir.com/2025/01/write-better-code/ 

- **文章类别**：博客 

---
**内容整理**： 

这篇文章探讨了通过不断要求大型语言模型（LLMs）“写出更好的代码”是否能够提升代码质量。文章通过一系列实验，展示了如何通过迭代提示（iterative prompting）来优化代码，并分析了这种方法的有效性和局限性。以下是文章的主要内容梳理：

### 背景介绍
- 2023年11月，OpenAI在ChatGPT中加入了DALL-E 3生成图像的功能，引发了一个短暂的网络迷因，用户通过不断要求模型“让图像更具有X特征”来生成图片。尽管这些图片最终都趋于相似且无趣，但这种模糊的提示对最终图像产生了一定影响。
- 作者提出，如果将类似的技术应用于代码生成，可能会有更客观的衡量标准，因为代码遵循严格的规则，质量可以更客观地衡量。

### 实验设计
- 作者选择了Claude 3.5 Sonnet作为实验对象，因为它在遵循提示方面表现出色。
- 实验的编程问题是：给定一个包含100万个1到100,000之间的随机整数的列表，找出数字之和为30的最小和最大数字之间的差异。
- 作者首先给出了一个简单的Python代码实现，然后通过不断要求Claude“写出更好的代码”来迭代优化代码。

### 实验过程与结果
- **初始代码**：Claude生成的初始代码是正确的，但存在一些可以优化的地方，例如`digit_sum()`函数中的类型转换导致不必要的开销。
- **第一次迭代**：Claude将代码重构为一个Python类，并预计算所有可能的数字之和，存储在字节数组中，以避免重复计算。这一优化使代码速度提高了2.7倍。
- **第二次迭代**：Claude引入了多线程和向量化操作，使用numpy库来加速计算。然而，这一实现存在一些问题，如进程间通信导致的开销，以及代码中的错误。修复这些问题后，代码速度比基础实现快了5.1倍。
- **第三次迭代**：Claude声称提供了“更复杂和优化的版本”，但实际上代码没有显著的算法改进，反而在数字之和的计算上退回到了类型转换的方法。这次迭代的代码性能略有下降，比基础实现快了4.1倍。
- **第四次迭代**：Claude提供了“具有前沿优化和企业级特性”的实现。这次它使用了numba库来调用JIT编译器，直接优化代码以适应CPU。此外，它还引入了Python的asyncio进行并行化，以及一些企业级特性，如Prometheus的结构化指标记录、信号处理器和使用rich库的基准测试结果展示。尽管代码变得更加复杂，但性能得到了极大的提升，运行时间约为6毫秒，比基础实现快了100倍。

### 结论与反思
- 通过迭代提示来优化代码确实可以使代码变得更好，但“更好”的定义可能因人而异。作者最初只希望获得算法上的改进，而不是一个完整的SaaS解决方案。
- 作者指出，尽管LLMs可以提出有趣的想法和工具建议，但它们生成的代码可能需要人类的干预来修复错误。LLMs不会很快取代软件工程师，因为需要强大的工程背景来识别真正的好主意，并考虑特定领域的其他约束。
- 作者还提到，尽管LLMs在代码优化方面表现出色，但它们并没有探索一些统计角度的优化，例如去除重复数字或对数字列表进行排序以减少搜索范围。
- 最后，作者指出，尽管Python不是开发者在超优化性能时考虑的语言，但现代方法如使用Rust和PyO3 crate可以在Python中使用Rust代码，以最小的开销获得性能优势。作者确认Claude 3.5 Sonnet可以生成符合PyO3标准的Python和Rust代码，但这将是另一个博客文章的主题。

文章通过实验展示了LLMs在代码优化方面的潜力和局限性，并强调了人类在这一过程中的不可或缺的作用。