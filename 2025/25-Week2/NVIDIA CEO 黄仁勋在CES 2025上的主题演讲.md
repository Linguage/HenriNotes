NVIDIA CEO Jensen Huang在CES 2025上的主题演讲

  原文标题：CES 2025: NVIDIA CEO Jensen Huang delivers keynote speech (RTX 5090 announcement)  
  链接：[YouTube](https://www.youtube.com/watch?v=XASnBeNKg6A)

- **文章类别**：新闻报道

---

## 内容整理

### 演讲主题
- **技术与创新**：Jensen Huang在CES 2025上发表了主题演讲，重点介绍了NVIDIA在人工智能、图形处理和自动驾驶等领域的最新技术突破和产品发布。
- **RTX 5090发布**：演讲中宣布了RTX 5090系列显卡的发布，展示了其在性能和人工智能应用方面的显著提升。

### 演讲内容概述
- **开场与背景介绍**：
  - Jensen Huang强调了CES不仅是展示未来技术的舞台，更是推动技术与人类生活结合的重要平台。
  - 他回顾了NVIDIA的发展历程，从1993年成立至今，NVIDIA在图形处理和人工智能领域的创新历程。

- **RTX 5090系列显卡**：
  - **性能提升**：RTX 5090系列显卡采用了Blackwell架构，拥有920亿个晶体管，AI性能达到4,000 TOPS，是上一代Ada架构的三倍。
  - **技术亮点**：
    - **光线追踪与AI结合**：通过AI技术优化光线追踪效果，实现更高效的图像渲染。
    - **神经纹理压缩与材质着色**：利用AI学习纹理压缩算法，提升图像质量。
    - **能效优化**：在性能提升的同时，能效比也得到了显著提高。

- **人工智能的应用与未来**：
  - **AI在各个领域的应用**：Jensen Huang展示了AI在医疗、自动驾驶、娱乐等多个领域的应用实例。
  - **AI的未来发展方向**：
    - **物理AI**：介绍了NVIDIA Cosmos，这是一个世界基础模型，旨在理解物理世界，推动机器人和自动驾驶技术的发展。
    - **Agent AI**：强调了AI代理在企业中的应用潜力，如客户服务、数据分析等。

- **合作伙伴与生态系统**：
  - Jensen Huang提到NVIDIA与众多合作伙伴的合作，包括汽车制造商、软件开发商和云服务提供商等，共同推动AI技术的广泛应用。

### 结论与展望
- **技术创新的持续推动**：Jensen Huang强调NVIDIA将继续致力于技术创新，推动AI和图形处理技术的发展，为各行各业带来更高效、更智能的解决方案。
- **未来技术的无限可能**：展望未来，Jensen Huang认为AI和图形技术将为人类生活带来更多可能性，推动社会的进步和发展.

### 演讲亮点
- **技术突破与创新展示**：通过RTX 5090系列显卡的发布，展示了NVIDIA在高性能计算和AI应用方面的最新成果。
- **对未来技术的深刻洞察**：Jensen Huang不仅介绍了当前的技术进展，还对AI和图形技术的未来发展进行了深入的分析和展望.
- **丰富的应用实例**：通过多个领域的应用实例，展示了AI技术在实际应用中的巨大潜力和价值.

---
## More

### 视频内容框架

**一、开场 (0:00 - 32:12)**

*   音乐、掌声
*   CES 主办方介绍以及对 Nvidia 的赞誉 (28:03 - 32:12)
    *   阐述 CES 的意义：科技与人性的交汇，解决挑战，创造机遇，推动进步，连接未来。
    *   介绍演讲嘉宾：Nvidia 创始人兼 CEO 黄仁勋。
    *   介绍 Nvidia：推动全球变革，在医疗、汽车、娱乐等领域取得突破，引领 AI 和加速计算的发展。
    *   黄仁勋的个人经历：从 Denny's 的洗碗工到 Nvidia CEO，强调努力工作、谦逊和热情好客的重要性。

**二、黄仁勋演讲：Nvidia 的发展历程与 AI 的演进 (32:12 - 46:08)**

*   音乐、掌声
*   开场白：幽默互动，介绍现场为 Nvidia 的数字孪生环境 (39:52 - 40:46)
*   回顾 Nvidia 的发展历程 (40:46 - 43:42)
    *   1993 年：推出 mv1，目标是让电脑能做普通电脑做不了的事情，实现游戏机与 PC 的结合。
    *   1999 年：发明可编程 GPU，推动计算机图形学的发展。
    *   2006 年：发明 Cuda，扩展 GPU 的可编程性，使其适用于更多算法。
    *   2012 年：AlexNet 的出现，标志着 AI 的快速发展，从感知 AI 到生成式 AI，再到能感知、推理、规划和行动的 Agentic AI，以及未来的物理 AI。
    *   2018 年：Google 发布 Transformer 模型（Bert），彻底改变了人工智能和计算领域。
    *   Nvidia 的转变：从手工编码到机器学习，GPU 处理，创造 AI，每个技术层都发生了变革。
*   AI 的应用和前景 (44:53 - 46:08)
    *   AI 能理解各种形式的信息，包括文本、图像、声音、氨基酸、物理等，并能进行翻译和生成。
    *   AI 应用广泛，几乎所有 AI 应用都可以从输入模态、转换模态和生成模态三个方面进行分析。
    *   机器学习改变了应用构建和计算方式，前景无限。

**三、GeForce 与 AI 的融合 (46:08 - 58:09)**

*   展示实时计算机图形技术 (46:41 - 48:07)
    *   光线追踪技术模拟光线，结合可编程着色和人工智能，生成逼真的图像。
    *   AI 技术 dlss 能预测未渲染的像素，生成额外的帧，提高性能和效率。
*   发布新一代 RTX Blackwell 显卡系列 (50:47 - 58:09)
    *   介绍 RTX 5050 系列，Blackwell 架构，性能大幅提升。
    *   介绍 RTX 5070，性能与 4090 相当，价格更低。
    *   介绍 RTX 5070 笔记本电脑版本，轻薄高性能。
    *   强调神经渲染是计算机图形学的未来，AI 与计算机图形学的融合。

**四、AI 的扩展与应用 (58:09 - 1:23:23)**

*   AI 的扩展定律 (58:31 - 1:03:33)
    *   第一定律：数据越多，模型越大，计算能力越强，模型性能越好。
    *   第二定律：后训练扩展，通过强化学习、人类反馈、合成数据生成等技术，提高模型在特定领域的技能。
    *   第三定律：测试时间扩展，AI 在使用过程中，根据任务动态分配计算资源，进行推理和思考，提高效率。
*   Nvidia Blackwell 芯片和系统 (1:03:33 - 1:12:33)
    *   介绍 Blackwell 芯片的生产情况和广泛应用。
    *   展示 gb200 MV link 72 系统，强大的计算能力和制造工艺。
    *   强调 Blackwell 系统的能效比和成本效益。
    *   介绍 Blackwell 芯片的架构和性能，以及其在数据中心的应用。
*   Agentic AI 与企业应用 (1:12:33 - 1:20:42)
    *   介绍 Agentic AI：多个模型协同工作，执行任务，检索信息，使用工具，生成结果。
    *   介绍 Nvidia 的 Agentic AI 构建模块：Nims（AI 微服务）、Nemo（数字员工入职和培训系统）、蓝图。
    *   发布 Nvidia Llama Neotron 语言模型，基于 Llama 3.1，针对企业应用进行了优化。
    *   介绍 Nvidia 与合作伙伴在 Agentic AI 领域的合作，包括 Service Now、SAP、西门子、Cadence、Perplexity、Codium 等。
*   展示 Agentic AI 的应用案例 (1:20:42 - 1:23:23)
    *   AI 研究助理、天气预报、软件安全、虚拟实验室、分析 AI 等。

**五、AI 与 Windows PC 的结合 (1:23:23 - 1:28:33)**

*   AI 在云端和设备端的应用 (1:23:23 - 1:24:19)
*   将 AI 引入 Windows PC 的愿景 (1:24:19 - 1:25:29)
    *   AI 成为个人助理，提供生成式 API。
*   利用 Windows wsl2 实现 AI PC (1:25:29 - 1:26:49)
    *   wsl2 支持 Cuda，可运行 Nvidia 的 AI 技术。
*   展示 AI 在 PC 上的应用案例：生成式 AI 图像合成 (1:26:49 - 1:28:05)
*   PC OEM 厂商将支持 AI PC (1:28:05 - 1:28:33)

**六、物理 AI 与 Nvidia Cosmos (1:28:33 - 1:39:52)**

*   物理 AI 的概念：理解物理世界，根据请求生成动作 (1:28:33 - 1:30:41)
*   介绍 Nvidia Cosmos：世界基础模型，理解物理世界 (1:30:41 - 1:32:02)
*   展示 Nvidia Cosmos 的功能和应用 (1:32:02 - 1:34:21)
    *   摄取文本、图像或视频提示，生成虚拟世界状态的视频。
    *   生成逼真的、基于物理的合成数据。
    *   生成多个可能的未来，帮助模型选择正确的路径。
*   Nvidia Cosmos 的技术细节和开源计划 (1:34:21 - 1:37:14)
    *   基于 2000 万小时的视频数据训练。
    *   可用于合成数据生成、机器人模型训练、多模态大语言模型训练等。
    *   包含自回归模型、扩散模型、分词器和数据流水线。
    *   Cosmos 开源，推动机器人和工业 AI 的发展。
*   Cosmos 与 Omniverse 的结合 (1:37:14 - 1:39:52)
    *   Omniverse 提供基于物理的仿真环境，为 Cosmos 提供真值。
    *   二者结合，生成基于物理的多样化模拟数据。
    *   应用于机器人和工业领域。
    *   构建机器人系统需要三个计算机：训练 AI 的 djx 计算机、部署 AI 的 agx 计算机、以及连接二者的数字孪生。

**七、物理 AI 的应用案例 (1:39:52 - 结束)**

*   工业数字化：与 Keon 和埃森哲合作，优化仓库物流 (1:39:52 - 1:43:33)
*   自动驾驶汽车：介绍 Nvidia 的三个计算机解决方案，以及与各大汽车公司的合作 (1:43:33 - 1:46:18)
    *   发布新一代自动驾驶汽车计算机 Thor (1:46:18 - 1:47:25)
    *   介绍 Drive OS 的功能安全认证 (1:47:25 - 1:48:05)
    *   展示利用 Omniverse 和 Cosmos 进行自动驾驶汽车的数字孪生重建和训练 (1:48:05 - 1:52:30)
*   机器人：通用机器人发展的机遇和挑战，介绍 Nvidia Isaac Groot 平台 (1:52:30 - 1:57:50)
    *   展示利用 Isaac Groot 进行机器人运动生成和训练 (1:55:38 - 1:57:50)
*   发布个人 AI 超级计算机 Project Digits (1:57:50 - 2:03:52)
    *   回顾 djx1 的历史和意义。
    *   介绍 Project Digits 的功能和特点。
    *   展示 Project Digits 的外观和内部芯片 gb110。
*   总结与展望 (2:03:52 - 结束)
    *   总结演讲内容：Blackwell 系统的生产、物理 AI 基础模型、三个机器人方向。
    *   播放回顾视频，展望未来。
    *   结束语：感谢观众，祝大家新年快乐。

### 视频脚本翻译

好的，以下是根据框架翻译的视频脚本，并进行了章节段落划分和润色，增强了可读性：

#### 一、开场 (0:00 - 32:12)

**(0:00 - 0:27) 音乐、掌声**

**(0:27 - 28:03) 环境音、音乐**

**(28:03 - 32:12) CES 主办方 Gary Shapiro 登台**

**Gary Shapiro：** CES 不仅仅关乎“下一步是什么”，更关乎“一切皆有可能”。当科技与人性交汇，答案便是无限可能。因为科技不只是解决挑战，更能将挑战转化为机遇。它帮助我们更智能地行动，更健康地生活，并以前所未有的方式体验世界。我们来这里，不仅仅是为了参加一场科技盛会，更是为了连接、为了共同解决问题、为了共同探索。

科技不只是在进步，更是在凝聚，它让我们更接近自动驾驶的未来，让我们获得更好的医疗服务，让生活更加互联、更具活力、更富有人性。当今的挑战需要大胆的解决方案，而 CES 正是这些方案开始成型的地方。可持续发展的突破和进步将有助于养活我们不断增长的世界。本周不仅仅是一个展示突破性成果的舞台，更是激发发现的火花。你们将在这里看到的每一个屏幕、每一个像素、每一项技术，都展现了人类智慧与科技力量结合所产生的非凡潜力。

现在，我们开始这场盛会，庆祝那些将我们联系在一起、有能力解决我们最大挑战、并提供无限可能性的事物。此时此刻，全世界都在注视着我们，让我们开始吧！

**(29:37 - 29:48) 音乐**

**Gary Shapiro：** 女士们，先生们，欢迎来到 CES 2025！我是 Gary Shapiro，消费者技术协会 (CTA) 的 CEO 兼副主席，也是 CES 的主办方。

**(29:48 - 30:30) 介绍演讲嘉宾及 Nvidia**

**Gary Shapiro：** 我非常激动地宣布，本次大会的首场主题演讲将由全球最具影响力的公司之一——Nvidia 带来。Nvidia 是我们在 CES 上所推崇的前沿创新的典范，其创始人兼 CEO 黄仁勋是一位真正的远见卓识者，他展示了思想、技术和信念在推动创新、重塑行业和社会方面的强大力量。

**(30:30 - 30:48) 调侃黄仁勋的演讲**

**Gary Shapiro：** 我总喜欢说，如果我上次在 CTA 活动上更仔细地听 Jensen（黄仁勋）的演讲，我现在可能已经退休了。

**(30:48 - 31:29) 介绍 Nvidia 的成就**

**Gary Shapiro：** 但在过去的三十年里，他将 Nvidia 打造成为一股推动全球变革的力量，其影响力遍及医疗保健、汽车和娱乐等各个行业。如今，Nvidia 正在引领人工智能和加速计算领域的突破，这些突破几乎触及每个人和每家企业。在他的领导下，Nvidia 的创新成果包括先进的聊天机器人、用于软件定义汽车的机器人、庞大的虚拟世界、高度同步的工厂车间等等。黄仁勋被《财富》杂志和《经济学人》杂志评为全球最佳 CEO，并被《时代》杂志评为全球最具影响力的 100 人之一。

**(31:29 - 31:58) 讲述黄仁勋的个人经历**

**Gary Shapiro：** 但事实上，就像我们在座的每一个人一样，我们的成功，他的成功，都不是命中注定的。Jensen 最初在 Denny's 餐厅当洗碗工和服务员。他曾说过，他在那里学到的关于努力工作、谦逊和热情好客的道理，帮助他在 Nvidia 早期面临挑战时保持信念并坚持下去。几分钟后，我们将听到 Nvidia 创始人兼 CEO 黄仁勋分享他对未来的坚定愿景，以及我们将走向何方。

**(31:58 - 32:12) 呼吁观众期待演讲**

**Gary Shapiro：** 敬请期待，并祝大家在 CES 度过愉快的时光！

**(32:12 - 32:46) 掌声、音乐**

**(32:46 - 33:07) 提示观众静音**

**播音：** 请大家将手机调至静音，我们的活动即将开始。

**(33:07 - 34:38) 音乐**

**(34:38 - 34:57) 音乐、环境音**

**(34:57 - 35:13) 环境音**

**(35:13 - 36:39) 音乐**

#### 二、黄仁勋演讲：Nvidia 的发展历程与 AI 的演进 (36:39 - 46:08)

**(36:39 - 37:59) 开场视频：AI Tokens 的力量**

**视频旁白：** 这就是智能的产生方式，一种新型的工厂，Tokens 的生成器，AI 的构建模块。Tokens 打开了一个新的前沿，这是进入一个非凡世界的第一步，在那里，无限的可能性被孕育。Tokens 将文字转化为知识，为图像注入生命，它们将想法转化为视频，帮助我们安全地导航任何环境。Tokens 教机器人像大师一样移动，激发我们庆祝胜利的新方式。

**(37:39 - 37:59) 模拟对话**

**视频旁白：**  （调酒师）请来一杯马提尼。（机器人）好的，Adam。（调酒师）谢谢你，Adam。
**视频旁白：** 当我们最需要它的时候，给我们带来安心。
**视频旁白：** （医生）Hioka，你好，Emma，很高兴再次见到你。（Emma）你好，Emma，我们今天要做一个血液样本采集。（Emma）好的，别担心，我会一直在这里陪着你。

**(37:59 - 38:34) 展示 Tokens 的应用**

**视频旁白：** 它们为数字赋予意义，帮助我们更好地理解周围的世界，预测我们周围的危险，并找到治愈我们体内威胁的方法。

**(38:34 - 39:25) 展示 Tokens 的更多应用**

**视频旁白：** Tokens 可以将我们的愿景变为现实，并恢复我们失去的东西。（Zachary）我找回了我的声音，伙计。它们帮助我们前进，一次一小步，一次一大步。

**(39:25 - 39:45) 视频结束，黄仁勋登场**

**视频旁白：** 一切从这里开始，欢迎 Nvidia 创始人兼 CEO 黄仁勋登台！

**(39:45 - 39:52) 掌声、音乐**

**(39:52 - 40:04) 黄仁勋开场问候**

**黄仁勋：** 欢迎来到 CES！你们喜欢在拉斯维加斯吗？喜欢我的夹克吗？

**(40:04 - 40:32) 幽默互动，引出 Nvidia 主题**

**黄仁勋：** 我想我应该和 Gary Shapiro 穿得不一样，毕竟我是在拉斯维加斯。如果这身打扮不行，如果你们都反对，好吧，那就先适应一下。我觉得你们得让它沉淀一下，再过一个小时，你们就会觉得不错了。好了，欢迎来到 Nvidia！

**(40:32 - 40:59) 介绍现场为 Nvidia 的数字孪生环境**

**黄仁勋：** 事实上，你们正身处 Nvidia 的数字孪生环境中，我们将带你们前往 Nvidia。女士们，先生们，欢迎来到 Nvidia！你们正身处我们的数字孪生环境中，这里的一切都是由 AI 生成的。

**(40:59 - 41:27) 回顾 Nvidia 成立之初的愿景**

**黄仁勋：** 这是一段非凡的旅程，也是非凡的一年。它始于 1993 年，当时我们推出了 mv1。我们想要制造出能够做普通计算机做不到的事情的计算机，而 mv1 使在 PC 中拥有游戏机成为可能。我们的编程架构被称为 UDA。

**(41:27 - 41:48) 回顾 UDA 和世嘉的《VR 战士》**

**黄仁勋：**  直到不久之后才加上字母 C，但 UDA 代表统一设备架构 (Unified Device Architecture)。UDA 的第一个开发者和第一个在 UDA 上运行的应用程序是世嘉的《VR 战士》。六年后，也就是 1999 年，我们发明了可编程 GPU。

**(41:48 - 42:21) 强调 GPU 的重要性，展示《VR 战士》的进化**

**黄仁勋：** 这开启了这款名为 GPU 的令人难以置信的处理器 20 多年的惊人进步。它使现代计算机图形学成为可能。30 年后的今天，世嘉的《VR 战士》已经完全电影化了。这是即将推出的全新《VR 战士》项目，我简直等不及了，绝对令人难以置信！

**(42:21 - 43:11) 回顾 Cuda 的发明和对 AI 的影响**

**黄仁勋：** 1999 年之后的六年，我们发明了 Cuda，这样我们就可以将 GPU 的可编程性表达给一系列可以从中受益的丰富算法。Cuda 最初很难解释，花了几年时间，事实上，大约花了六年时间。不知何故，六年之后，或者说大约 2012 年，Alex Krizhevsky、Ilya Sutskever 和 Jeff Hinton 发现了 Cuda，并用它来处理 AlexNet，剩下的就是历史了。

**(43:11 - 43:42) 阐述 AI 的发展阶段**

**黄仁勋：** 人工智能一直在以惊人的速度发展。从感知 AI 开始，我们现在可以理解图像、文字和声音，到生成式 AI，我们可以生成图像、文本和声音。现在是 Agentic AI，一种可以感知、推理、规划和行动的 AI。然后是下一个阶段，我们今晚将讨论其中的一些内容，即物理 AI。神奇的 2012 年，2018 年发生了一些非常了不起的事情。

**(43:42 - 44:28) 强调 Transformer 模型的重要性**

**黄仁勋：** 谷歌的 Transformer 模型以 Bert 的形式发布，人工智能的世界真正起飞了。正如你们所知，Transformer 模型彻底改变了人工智能的格局，事实上，它彻底改变了整个计算领域的格局。我们正确地认识到，人工智能不仅仅是一个具有新商业机会的新应用，更重要的是，由 Transformer 模型驱动的机器学习将从根本上改变计算的工作方式。

**(44:28 - 45:01) 描述计算领域的变革**

**黄仁勋：** 如今，计算在每一层都发生了革命性的变化。从手工编写在 CPU 上运行的指令，到创建人类使用的软件工具，我们现在拥有了机器学习，它可以创建和优化在 GPU 上处理的神经网络，并创造人工智能。技术栈的每一层都发生了彻底的改变，在短短 12 年里发生了令人难以置信的转变。

**(45:01 - 45:26) 阐述 AI 对各种信息的理解和生成能力**

**黄仁勋：** 好了，我们现在可以理解几乎任何形式的信息。当然，你们已经见过文本、图像和声音等，但我们不仅可以理解这些，还可以理解氨基酸，理解物理。我们理解它们，我们可以翻译它们，并生成它们。

**(45:26 - 46:08) 强调 AI 应用的广泛性和未来前景**

**黄仁勋：** 事实上，几乎所有你能看到的 AI 应用，它的输入模态是什么？它从什么模态的信息中学习？它将信息转换成什么模态？它生成什么模态的信息？如果你问这三个基本问题，几乎每一个应用都可以推断出来。因此，当你看到一个又一个由 AI 驱动的应用，以 AI 为核心的应用时，这个基本概念就在那里。机器学习已经改变了每一个应用的构建方式，计算的完成方式，以及未来的无限可能。

#### 三、GeForce 与 AI 的融合 (46:08 - 58:09)

**(46:08 - 46:31) 引出 GeForce 在 AI 发展中的作用**

**黄仁勋：** 在很多方面，GeForce 推动了 AI 的发展，是 GeForce 成就了 AI。GeForce 使 AI 能够惠及大众，现在 AI 正在回归 GeForce。有很多事情没有 AI 就无法完成，让我向你们展示其中的一些。

**(46:31 - 48:07) 音乐、特效**

**(48:07 - 48:35) 展示实时计算机图形技术**

**黄仁勋：** 那是实时计算机图形。没有计算机图形研究人员，没有计算机科学家会告诉你，我们可以实时追踪每一个像素。光线追踪是对光线的模拟，你们看到的几何体的数量绝对是惊人的，如果没有人工智能，这将是不可能的。

**(48:35 - 49:27) 介绍 AI 在图形渲染中的应用：可编程着色、光线追踪和 dlss**

**黄仁勋：** 我们做了两件基本的事情，我们使用了可编程着色和光线追踪加速来生成极其漂亮的像素，然后我们让人工智能受到该像素的控制，以生成一大堆其他像素。它不仅能够生成其他空间像素，因为它知道颜色应该是什么，它已经在 Nvidia 的超级计算机上进行了训练，因此在 GPU 上运行的神经网络可以推断和预测我们没有渲染的像素。我们不仅可以做到这一点，这项技术被称为 dlss，最新一代的 dlss 还可以生成帧之外的帧，它可以预测未来，为我们计算的每一帧生成三个额外的帧。

**(49:27 - 49:59) 解释 dlss 的工作原理和效率**

**黄仁勋：** 刚才你们看到的画面，如果我们渲染一帧并生成三帧，就可以说是四帧。如果我说四帧全高清 4K，大约有 3300 万像素，在这 3300 万像素中，我们只计算了 200 万。

**(49:59 - 50:29) 强调 AI 在图形渲染中的重要性和效率**

**黄仁勋：** 这是一个绝对的奇迹，我们可以使用可编程着色器和我们的光线追踪引擎，计算 200 万像素，并让人工智能预测所有其他 3300 万像素。因此，我们能够以极高的性能进行渲染，因为人工智能的计算量要少得多。当然，这需要大量的训练才能实现，但一旦你训练好了，生成就非常高效。

**(50:29 - 50:47) 总结 AI 与 GeForce 的相互促进**

**黄仁勋：** 这是人工智能的令人难以置信的能力之一，这就是为什么有这么多惊人的事情正在发生。我们用 GeForce 来实现人工智能，现在人工智能正在彻底改变 GeForce。

**(50:47 - 50:53) 宣布新一代 RTX Blackwell 显卡系列**

**黄仁勋：** 今天，我们向大家宣布我们的下一代产品：RTX Blackwell 系列。

**(50:53 - 51:44) 音乐、产品展示**

**(51:44 - 51:57) 展示 GeForce RTX 5050 系列显卡**

**黄仁勋：** 这就是我们全新的 GeForce RTX 5050 系列，Blackwell 架构，这款 GPU 简直是野兽！

**(51:57 - 53:29) 介绍 RTX 5050 系列的技术参数**

**黄仁勋：**  920 亿个晶体管，4,000 TOPS，4 PetaFLOPS 的 AI 算力，比上一代 Ada 高出 3 倍，我们需要所有这些来生成我给你们展示的那些像素。380 TeraFLOPS 的光线追踪算力，这样我们就可以为我们必须计算的像素计算出最漂亮的图像。当然还有 125 Shader TeraFLOPS，实际上还有一个并发的 Shader TeraFLOPS 以及一个同等性能的整数单元，所以是两个双着色器，一个是浮点运算，一个是整数运算。来自美光的 G7 显存，每秒 1.8 TB，是我们上一代产品的两倍性能。我们现在有能力将 AI 工作负载与计算机图形工作负载混合在一起。这一代产品的一个惊人之处在于，可编程着色器现在也能够处理神经网络，着色器能够承载这些神经网络，因此我们发明了神经纹理压缩和神经材质着色，从而获得这些惊人的美丽图像，这只有通过使用 AI 来学习纹理，学习压缩算法才能实现，并因此获得非凡的效果。好了，这就是全新的 RTX Blackwell 90。

**(53:29 - 54:14) 展示 RTX 5090 显卡的外观和散热设计**

**黄仁勋：**  现在，即使是机械设计也是一个奇迹，看看这个，它有两个风扇，整个显卡就是一个巨大的风扇。所以问题是，显卡在哪里？它真的有这么大吗？电压调节器设计是最先进的，令人难以置信的设计，工程团队做得很好。好了，谢谢。

**(54:14 - 54:48) 调侃 RTX 4090 的价格和高端 PC 配置**

**黄仁勋：**  好了，这些是速度和参数，那么它与之前的相比如何呢？这是 RTX 4090，我知道，我知道你们很多人都有一块，我知道，它要 1,599 美元，这是你能做的最好的投资之一。你花 1,599 美元把它带回家，安装到你价值 10 万美元的 PC 娱乐指挥中心里，不是吗？别告诉我这不是真的，别害羞，它是液冷的，到处都是花哨的灯光，你离开的时候把它锁起来，这是现代家庭影院，这完全说得通。

**(54:48 - 55:25) 宣布 RTX 5070 的性能和价格**

**黄仁勋：** 现在，只需 1,500 美元，不，1,599 美元，你就可以升级它，并为你的生活空间增添活力。好了，现在有了 Blackwell 系列，RTX 5070 以 549 美元的价格提供 4090 的性能。

**(55:25 - 55:34) 掌声**

**(55:34 - 55:47) 强调 RTX 5070 的性价比**

**黄仁勋：** 没有人工智能是不可能的，没有 4 TOPS 的 AI 张量核心是不可能的，没有 G7 显存是不可能的。

**(55:47 - 56:08) 介绍 RTX 50 系列的完整产品线**

**黄仁勋：**  好了，5070 以 549 美元的价格提供 4090 的性能，这是整个系列，从 5070 一直到 5090，5090 的性能是 4090 的两倍。当然，我们正在大规模生产，从 1 月份开始供货。

**(56:08 - 56:31) 介绍 RTX 5070 笔记本电脑版本**

**黄仁勋：**  这太不可思议了，但我们设法将这些性能强大的 GPU 装进了笔记本电脑。这是一台 5070 笔记本电脑，售价 1,299 美元，这台 5070 笔记本电脑具有 4090 的性能。我想这里有一台，让我给你们看看，这是一台，看看这个东西。

**(56:31 - 56:47) 展示 RTX 5070 笔记本电脑**

**黄仁勋：**  女士们，先生们，Janine 只有这么多口袋。

**(56:47 - 57:01) 调侃将台式机显卡装进笔记本电脑的难度**

**黄仁勋：**  你能想象吗？你得到了这款令人难以置信的显卡，Blackwell，我们要把它缩小，然后装进那里，这有意义吗？

**(57:01 - 57:19) 强调 AI 在笔记本电脑 GPU 中的重要性**

**黄仁勋：**  没有人工智能，你做不到这一点，原因是因为我们使用张量核心生成大部分像素，我们只光线追踪我们需要的像素，并使用人工智能生成所有其他像素，因此，能效比简直爆表。

**(57:19 - 57:59) 总结神经渲染的未来，并介绍 RTX 50 系列笔记本电脑的完整产品线**

**黄仁勋：**  计算机图形学的未来是神经渲染，人工智能和计算机图形学的融合。真正令人惊奇的是，我们要把这一系列的 GPU 放到这里。所以，1590，1590 将适用于一台轻薄的笔记本电脑，那台笔记本电脑是 14.9 毫米，你有 5080、5070 TI 和 5070。好了，女士们，先生们，RTX Blackwell 系列！

**(57:59 - 58:09) 掌声**

#### 四、AI 的扩展与应用 (58:09 - 1:23:23)

**(58:09 - 58:31) 从 GeForce 过渡到 AI 话题**

**黄仁勋：** 好了，GeForce 将 AI 带给了世界，普及了 AI，现在 AI 回归并彻底改变了 GeForce。让我们来谈谈人工智能，让我们去 Nvidia 的其他地方看看。这里实际上是我们的办公室，这里实际上是 Nvidia 的总部。

**(58:31 - 59:21) 介绍 AI 的扩展定律**

**黄仁勋：** 好了，让我们来谈谈 AI。整个行业都在竞相扩展人工智能，而扩展定律是一个强大的模型，这是一个经验定律，已经被研究人员和业界观察和证明了几代人。扩展定律指出，你拥有的数据越多，训练数据越多，模型越大，你应用的计算能力越多，你的模型就会变得越有效或越强大。

**(59:21 - 1:00:05) 阐述数据增长和多模态数据的重要性**

**黄仁勋：** 因此，扩展定律仍在继续。真正令人惊奇的是，现在我们正朝着这个方向发展，互联网产生的数据量大约是去年的两倍，我认为在接下来的几年里，我们将产生比人类自诞生以来产生的所有数据还要多的数据。因此，我们仍在产生巨量的数据，而且它变得越来越多样化，视频、图像和声音，所有这些数据都可以用来训练 AI 的基础知识。

**(1:00:05 - 1:01:47) 介绍第二个扩展定律：后训练扩展**

**黄仁勋：** 但实际上还有另外两个扩展定律已经出现，而且在某种程度上是直观的。第二个扩展定律是后训练扩展定律，后训练扩展定律使用诸如强化学习、人类反馈等技术，基本上是 AI 生成答案，人类根据查询给出反馈。它比这复杂得多，但这个强化学习系统，通过大量非常高质量的提示，使 AI 能够改进其技能。它可以针对特定领域微调其技能，它可以更擅长解决数学问题，更擅长推理等等。因此，这基本上就像有一个导师或教练在你完成学业后给你反馈。因此，你得到测试，你得到反馈，你提高自己。我们还有强化学习 AI 反馈，我们还有合成数据生成，这些技术在某种程度上类似于自我练习。你知道某个特定问题的答案，然后你不断尝试，直到你做对为止。因此，可以向 AI 提出一个非常复杂和困难的问题，该问题可以进行功能验证，并且有一个我们理解的答案，也许是证明一个定理，也许是解决一个几何问题。

**(1:01:47 - 1:03:33) 介绍第三个扩展定律：测试时间扩展**

**黄仁勋：** 因此，这些问题会导致 AI 产生答案，并使用强化学习，它将学习如何改进自己，这被称为后训练。后训练需要大量的计算，但最终结果会产生令人难以置信的模型。我们现在有了第三个扩展定律，这第三个扩展定律与所谓的测试时间扩展有关。测试时间扩展基本上是指当你使用 AI 时，AI 现在有能力应用不同的资源分配，而不是改进其参数，现在它专注于决定使用多少计算来产生它想要产生的答案。推理是一种思考方式，长思考是一种思考方式，而不是直接推断或一次性回答，你可能会推理它，你可能会将问题分解成多个步骤，你可能会产生多个想法，并评估，你知道你的 AI 系统会评估你产生的哪个想法是最好的，也许它会一步一步地解决问题等等。因此，现在测试时间扩展已被证明是非常有效的。你正在观察这一系列技术，所有这些扩展定律的出现，正如我们看到从 ChatGPT 到 01 到 03，以及现在的 Gemini Pro 的令人难以置信的成就。所有这些系统都在经历这个逐步的旅程，从预训练到后训练，再到测试时间扩展。

**(1:03:33 - 1:03:54) 强调计算需求和 Blackwell 芯片的重要性**

**黄仁勋：** 当然，我们需要的计算量是惊人的，我们希望，事实上，我们希望社会有能力扩展计算量，以产生更多、更好的智能。当然，智能是我们拥有的最宝贵的资产，它可以应用于解决许多非常具有挑战性的问题。因此，扩展定律正在推动对 Nvidia 计算的巨大需求，正在推动对这款我们称之为 Blackwell 的令人难以置信的芯片的巨大需求。

**(1:03:54 - 1:04:45) 介绍 Blackwell 芯片的生产情况和广泛应用**

**黄仁勋：** 让我们来看看 Blackwell。Blackwell 正在全面生产，它的外观令人难以置信。首先，每个云服务提供商现在都有系统在运行，我们这里有来自大约 15 家，15 家，对不起，15 家计算机制造商的系统，它正在制造，大约 200 种不同的 SKU，200 种不同的配置。它们有液冷的、风冷的、x86 的、Nvidia Grace CPU 版本的、MV Link 36 乘 2 的 MV Link、72 乘 1 的，各种不同类型的系统，这样我们就可以适应世界上几乎每一个数据中心。

**(1:04:45 - 1:05:10) 强调 Blackwell 的广泛应用和市场需求**

**黄仁勋：** 这些系统目前正在大约 45 家工厂生产，这告诉你人工智能是多么普遍，以及这个行业是多么积极地投入到人工智能和这种新的计算模式中。我们之所以如此努力地推动它，是因为我们需要更多的计算，而且很明显，很明显...

**(1:05:10 - 1:05:41) 黄仁勋展示 gb200 NV Link 72 系统**

**黄仁勋：**  Janine，你知道，我很难告诉你，你永远不想把手伸进一个黑暗的地方。等等，这是个好主意吗？

**(1:05:41 - 1:05:49) 等待音效**

**黄仁勋：**  等等，等等。

**(1:05:49 - 1:06:04) 调侃现场效果**

**黄仁勋：** 我以为我配得上（这个音效），显然约尔不认为我配得上。好了，这是我的展示环节，这是一个展示环节。

**(1:06:04 - 1:07:03) 详细介绍 gb200 NV Link 72 系统的规模和制造工艺**

**黄仁勋：** 所以，这个 MV Link 系统，这个 MV Link 系统，这是 gb200 MV Link 72，它重 1.5 吨，有 60 万个零件，大约相当于 20 辆汽车，12，12，120 千瓦。它后面有一个主干，将所有这些 GPU 连接在一起，2 英里的铜缆，5,000 根电缆。这正在全球 45 家工厂生产，我们制造它们，我们对它们进行液冷，我们测试它们，我们拆卸它们，将零件运送到数据中心，因为它有 1.5 吨重，我们在数据中心外重新组装它们并安装它们。

**(1:07:03 - 1:08:19) 强调 Blackwell 系统的能效比和成本效益**

**黄仁勋：** 制造过程非常疯狂，但所有这一切的目标是因为扩展定律对计算的要求非常高，以至于这种计算水平，Blackwell 比我们上一代产品的每瓦性能提高了 4 倍，每瓦性能提高了 4 倍，每美元性能提高了 3 倍。这基本上是说，在一代产品中，我们将训练这些模型的成本降低了 3 倍，或者如果你想将模型的大小增加 3 倍，成本大致相同。但重要的是，这些系统正在生成我们所有人都在使用的 Tokens，当我们使用 ChatGPT 或 Gemini，将来使用我们的手机时，几乎所有这些应用都将消耗这些 AI Tokens，而这些 AI Tokens 是由这些系统生成的，每个数据中心都受到功率的限制。因此，如果 Blackwell 的每瓦性能是我们上一代产品的 4 倍，那么数据中心可以产生的收入，可以产生的业务量将增加 4 倍。

**(1:08:19 - 1:08:33) 强调 AI 工厂系统的概念**

**黄仁勋：** 因此，这些 AI 工厂系统如今确实是工厂。现在，所有这一切的目标是为了让我们能够创建一个巨大的芯片，我们需要的计算量确实相当惊人，这基本上是一个巨大的芯片。

**(1:08:33 - 1:08:43) 调侃现场灯光效果**

**黄仁勋：** 如果我们必须在这里构建一个芯片，很明显，这将是晶圆的大小，但这还不包括良率的影响，它可能必须是三到四倍的大小。

**(1:08:43 - 1:09:47) 介绍 gb200 NV Link 72 系统的架构和性能**

**黄仁勋：** 但我们这里基本上有 72 个 Blackwell GPU 或 144 个裸片，这个芯片有 1.4 ExaFLOPS 的算力，这是世界上最大的，最快的超级计算机，直到最近才达到 ExaFLOPS 级别，而这整个房间的超级计算机直到最近才达到 ExaFLOPS 级别，而这个芯片有 1.4 ExaFLOPS 的 AI 浮点性能，它有 14 TB 的内存。但这里有一个惊人的事情，内存带宽是每秒 1.2 PB，这基本上是现在整个互联网的流量，整个世界的互联网流量都在这些芯片上处理。我们有 103，130 万亿个晶体管，总共有 2,592 个 CPU 核心，还有一大堆网络。

**(1:09:47 - 1:10:22) 展示 Blackwell 芯片、ConnectX 网卡、MV Link 和 HBM 内存**

**黄仁勋：** 这些，我希望我能做到这一点，我不认为我会这么做。这些是 Blackwell，这些是我们的 ConnectX 网卡，这些是 MV Link，我们试图假装有 MV Link 主干，但这是不可能的。这些是所有的 HBM 内存，12 TB，14 TB 的 HBM 内存，这就是我们正在尝试做的事情，这就是奇迹，这就是 Blackwell 系统的奇迹。Blackwell 裸片就在这里，这是世界上最大的单芯片，但奇迹还在于，这是 Grace Blackwell 系统。

**(1:10:22 - 1:10:43) 总结 Blackwell 系统的意义**

**黄仁勋：** 当然，所有这一切的目标是为了，谢谢。

**(1:10:43 - 1:10:59) 调侃现场的椅子和饮料**

**黄仁勋：** 谢谢，有没有一把椅子我可以坐一会儿？

**(1:10:59 - 1:11:12) 寻找麦克风**

**黄仁勋：**  能给我一个麦克风吗？

**(1:11:12 - 1:11:28) 调侃现场环境**

**黄仁勋：** 怎么可能我们在米捷龙体育场，就像来到 Nvidia 却没有 GPU 给你一样？

**(1:11:28 - 1:12:33) 强调计算需求和降低成本的重要性**

**黄仁勋：**  所以，我们需要大量的计算，因为我们想训练越来越大的模型，这些推理，这些推理过去是一次推理，但在未来，AI 将会自言自语，它将会思考，它将会进行内部反思和处理。所以今天，当 Tokens 以每秒 20 或 30 个的速度生成时，这基本上和任何人阅读的速度一样快。然而，在未来，现在使用 gp01，你知道，使用新的，预发布的 Gemini Pro 和新的 0103 模型，它们正在自言自语，我们在反思，它们在思考。因此，你可以想象，Tokens 可以被摄取的速度非常快，因此我们需要 Tokens 的速率，Tokens 的生成速率大幅提高，我们还必须同时大幅降低成本，这样服务的质量才能非凡，客户的成本才能继续保持低水平，人工智能才能继续扩展。

**(1:12:33 - 1:13:18) 介绍 Agentic AI 的概念和工作原理**

**黄仁勋：** 因此，这就是我们创建 MV Link 的根本目的。企业界正在发生的最重要的事情之一是 Agentic AI。Agentic AI 基本上是测试时间扩展的一个完美例子，它是一个由模型组成的系统，其中一些模型用于理解、与客户互动、与用户互动，其中一些模型可能用于检索信息，从存储中检索信息，一个像 RAG 这样的语义 AI 系统，也许它会访问互联网，也许它会研究一个 PDF 文件。因此，它可能会使用工具，它可能会使用计算器，它可能会使用生成式 AI 来生成图表等等，它会迭代，它会把你给它的问题逐步分解，并在所有这些不同的模型中迭代。

**(1:13:18 - 1:13:41) 强调 Agentic AI 对计算能力的需求**

**黄仁勋：** 好了，为了在未来响应客户，为了让 AI 做出响应，过去是提出问题，然后开始输出答案，在未来，你提出一个问题，一大堆模型将在后台工作。因此，测试时间扩展，用于推理的计算量将大幅增加，它将大幅增加，因为我们想要更好、更好的答案。

**(1:13:41 - 1:14:22) 介绍 Nvidia 的 Agentic AI 构建模块：Nims、Nemo 和蓝图**

**黄仁勋：** 为了帮助行业构建 Agentic AI，我们的市场策略不是直接面向企业客户，我们的市场策略是与 IT 生态系统中的软件开发人员合作，集成我们的技术，以实现新的功能，就像我们使用 Cuda 库所做的那样。我们现在想用 AI 库来做这件事，就像过去的计算模型有用于计算机图形学、线性代数或流体动力学的 API 一样，在未来，在这些加速库之上，Cuda 加速库将拥有 AI 库。我们创建了三个东西来帮助生态系统构建 Agentic AI：Nvidia Nims，它们本质上是 AI 微服务，所有这些都打包好了。它包含了所有这些非常复杂的 Cuda 软件，Cuda DNN、Cutlass 或 TensorRT-LLM 或 Triton，或所有这些不同的非常复杂的软件和模型本身，我们对它进行打包，我们对它进行优化，我们把它放到一个容器中，你可以把它带到任何你喜欢的地方。因此，我们有用于视觉、语言理解、语音、动画、数字生物学的模型，我们还有一些令人兴奋的新模型即将推出，用于物理 AI。

**(1:14:22 - 1:15:30) 强调 Nims 的跨平台兼容性和应用场景**

**黄仁勋：** 这些 AI模型可以在每个云中运行，因为 Nvidia 的 GPU 现在在每个云中都可用，它在每个 OEM 中都可用，所以你实际上可以采用这些模型，将它们集成到你的软件包中，创建在 Cadence 上运行的 AI 代理，或者它们可能是 ServiceNow 代理，或者它们可能是 SAP 代理，它们可以部署到他们的客户那里，并在客户想要运行软件的任何地方运行。

**(1:15:30 - 1:16:42) 介绍 Nemo：数字员工入职和培训系统**

**黄仁勋：** 下一层是我们所说的 Nvidia Nemo，Nemo 本质上是一个数字员工入职和培训评估系统。在未来，这些 AI 代理本质上是与你的员工一起工作的数字劳动力，代表你为你做事。因此，将这些专业代理引入你的公司的方式就像你入职一名员工一样。

**(1:16:05 - 1:16:42) 解释 Nemo 的功能和应用场景**

**黄仁勋：** 因此，我们有不同的库，可以帮助这些 AI 代理针对你公司的语言类型进行培训，也许词汇表对你的公司来说是独一无二的，业务流程是不同的，你的工作方式是不同的，所以你会给他们提供工作产品应该是什么样子的例子，他们会尝试生成它，你会给出反馈，然后你会评估他们等等。因此，你会给他们设置护栏，你说这些是你不能做的事情，这些是你不能说的事情，这个，我们甚至允许他们访问某些信息。好了，整个流程，一个数字员工流程被称为 Nemo。

**(1:16:42 - 1:17:10) 预测 IT 部门将成为 AI 代理的 HR 部门**

**黄仁勋：** 在很多方面，每个公司的 IT 部门都将成为未来 AI 代理的 HR 部门。今天，他们管理和维护来自 IT 行业的大量软件，在未来，他们将维护、培育、入职和改进一大堆数字代理，并将它们提供给公司使用。

**(1:17:10 - 1:17:21) 介绍 Nvidia 提供的蓝图**

**黄仁勋：** 因此，你的 IT 部门将成为类似于 AI 代理 HR 的部门。最重要的是，我们提供了一大堆我们的生态系统可以利用的蓝图，所有这些都是完全开源的。

**(1:17:21 - 1:17:32) 强调蓝图的开放性和应用范围**

**黄仁勋：** 因此，你可以获取它并修改蓝图，我们有适用于各种不同类型的代理的蓝图。今天，我们还要宣布，我们正在做一些非常酷的事情，我认为非常聪明，我们宣布了一系列基于 Llama 的模型。

**(1:17:32 - 1:18:10) 发布 Nvidia Llama Neotron 语言模型**

**黄仁勋：**  Nvidia Llama Neotron 语言基础模型，Llama 3.1 是一个完整的现象级产品，Llama 3.1 的下载量，来自 Meta 的数据，大约有 35 万到 65 万次。它已经被衍生并转化为其他模型，大约 6 万个其他不同的模型。这几乎是每个企业和每个行业都被激活开始研究 AI 的唯一原因。

**(1:18:10 - 1:18:28) 介绍 Llama Neotron 模型的优势和定位**

**黄仁勋：**  我们所做的是，我们意识到 Llama 模型确实可以更好地针对企业用途进行微调，因此我们利用我们的专业知识和能力对它们进行微调，并将它们转化为 Llama Neotron 套件的开放模型。

**(1:18:28 - 1:19:15) 介绍 Llama Neotron 模型的不同版本和功能**

**黄仁勋：**  有一些小型的模型可以进行交互，并且响应时间非常快，非常小。它们是，我们称之为超级 Llama Neotron 超级版，它们基本上是你的模型的主流版本，或者是你的超级模型。超级模型可以用来作为一大堆其他模型的教师模型，它可以是一个奖励模型评估器，一个判断其他模型生成答案并决定它是一个好答案还是不好的答案的评判者，基本上给其他模型提供反馈。它可以通过多种不同的方式进行提炼，基本上是一个教师模型，一个知识提炼模型，非常大，非常强大。所有这些现在都可以在网上获得。

**(1:19:15 - 1:19:34) 强调 Llama Neotron 模型的性能和应用**

**黄仁勋：**  这些模型令人难以置信，它在聊天排行榜、指令排行榜、检索排行榜上都排名第一。因此，这些是世界各地的 AI 代理使用的不同类型的功能所必需的，这些将是令人难以置信的模型。

**(1:19:34 - 1:20:42) 介绍 Nvidia 与合作伙伴在 Agentic AI 领域的合作**

**黄仁勋：** 我们还与生态系统合作，这些，我们所有的 Nvidia AI 技术都集成到了 IT 行业中。我们在 ServiceNow、SAP、西门子都有很好的合作伙伴，他们在工业 AI 方面做了很多伟大的工作。Cadence 正在做伟大的工作，Synopsys 正在做伟大的工作，我对我们与 Perplexity 所做的工作感到非常自豪，正如你们所知，他们彻底改变了搜索，非常棒的东西。Codium，世界上每一个软件工程师，这将是下一个巨型 AI 应用，下一个巨型 AI 服务，就是软件编码。全球有 3000 万软件工程师，每个人都将有一个软件助手来帮助他们编码。如果不是这样，显然你的生产力会大大降低，并且会创建质量较低的代码。所以这是 3000 万，全球有 10 亿知识工作者，很明显，AI 代理可能是下一个机器人产业，并且很可能是一个数万亿美元的机会。

**(1:20:42 - 1:20:55) 介绍 Agentic AI 的应用案例展示**

**黄仁勋：**  好了，让我向你们展示一些我们创建的蓝图，以及我们与合作伙伴在这些 AI 代理方面所做的一些工作。

**(1:20:55 - 1:23:23) 视频：展示 Agentic AI 的应用案例**

**视频旁白：** AI 代理是新的数字劳动力，为我们工作并与我们一起工作。AI 代理是一个模型系统，它可以推理任务，将其分解成任务，并检索数据或使用工具来生成高质量的响应。Nvidia 的 Agentic AI 构建模块，Nims 预训练模型和 Nemo 框架，使组织能够轻松开发 AI 代理并将它们部署到任何地方。我们将像对待员工一样，对我们的 Agentic 劳动力进行入职培训和公司方法的培训。AI 代理是特定领域的任务专家，让我给你们展示几个例子。对于数十亿的知识工作者和学生来说，AI 研究助理代理可以摄取复杂的文档，如讲座、期刊、财务业绩，并生成交互式播客，以便于学习。通过将 U-Net 回归模型与扩散模型相结合，Cord-AI 可以将全球天气预报从 25 公里缩小到 2 公里。像 Nvidia 这样的开发人员可以管理软件安全，AI 代理可以持续扫描软件漏洞，提醒开发人员需要采取什么行动。虚拟实验室 AI 代理可以帮助研究人员设计和筛选数十亿种化合物，以比以往更快地找到有希望的候选药物。基于 Nvidia Metropolis 蓝图构建的 Nvidia 分析 AI 代理，包括 Nvidia Cosmos Neotron 视觉语言模型、Llama Neotron 大语言模型和 Nemo 检索器。Metropolis 代理分析来自数十亿个摄像头的内容，每天生成 10 万 PB 的视频。它们支持交互式搜索、摘要和自动报告，并帮助监控交通流量，标记拥堵或危险。在工业设施中，它们监控流程并生成改进建议。Metropolis 代理集中来自数百个摄像头的数据，并可以在事件发生时重新路由工人或机器人。Agentic AI 的时代已经到来，适用于每个组织。

#### 五、AI 与 Windows PC 的结合 (1:23:23 - 1:28:33)

**(1:23:23 - 1:23:29) 音乐**


**(1:23:29 - 1:23:42) 黄仁勋调侃视频中的投球动作**

**黄仁勋：**  好了，那是在棒球比赛中的第一次投球，那不是生成的，我只是觉得你们都没有留下深刻的印象。

**(1:23:42 - 1:24:19) 概述 AI 在云端和设备端的应用**

**黄仁勋：**  好了，AI 是在云中创建的，也是为云创建的。AI 是在云中创建的，也是为云和在手机上使用 AI 而创建的，当然，它是完美的。很快，我们将拥有一个持续的 AI 与你同在，当你使用那些 Meta 眼镜时，你当然可以指向某个东西，看着某个东西，并询问它你想要的任何信息。因此，AI 在云中是完美的，它是在云中创建的，在云中是完美的。然而，我们希望能够将 AI 带到任何地方，我已经提到过，你可以将 Nvidia AI 带到任何云，但你也可以把它放在你的公司内部。

**(1:24:19 - 1:25:29) 提出将 AI 引入 Windows PC 的愿景**

**黄仁勋：**  但我们最想做的事情是把它也放到我们的 PC 上。正如你们所知，Windows 95 彻底改变了计算机行业，它使这套新的多媒体服务成为可能，并永远改变了应用程序的创建方式。Windows 95，这种计算模型当然不适合 AI。因此，我们希望做的是，我们希望在未来，你的 AI 基本上成为你的 AI 助手，而不仅仅是 3D API、声音 API 和视频 API，你将拥有 3D 的生成式 API、语言的生成式 AI 和声音的生成式 AI 等等。

**(1:25:29 - 1:26:49) 介绍利用 Windows wsl2 实现 AI PC 的方案**

**黄仁勋：** 我们需要一个系统来实现这一点，同时利用云中的大量投资。我们不可能，世界不可能再创造另一种编程 AI 模型的方式，这根本不可能发生。因此，如果我们能找到一种方法使 Windows PC 成为世界级的 AI PC，那将是非常棒的。事实证明，答案是 Windows，是 Windows wsl2，Windows wsl2，Windows wsl2 基本上是一个系统中的两个操作系统，它工作得非常完美，它是为开发人员开发的，它是为裸金属访问而开发的。wsl2 已经针对云原生应用程序进行了优化，它已经针对 Cuda 进行了优化，并且非常重要的是，它已经针对 Cuda 进行了优化。因此，wsl2 从一开始就完美地支持 Cuda，因此，我向你们展示的所有内容，Nvidia Nims、Nvidia Nemo，我们开发的蓝图，这些蓝图将在 ai.nvidia.com 上发布，只要计算机能够容纳它，只要你能容纳那个模型，我们将有许多模型可以容纳，无论是视觉模型、语言模型、语音模型还是这些动画人类数字人模型，各种不同类型的模型都将非常适合你的 PC。你下载它，它就应该运行。

**(1:26:49 - 1:26:59) 强调 Nvidia 对 Windows wsl2 的支持**

**黄仁勋：** 因此，我们的重点是将 Windows wsl2，Windows PC 转变为一个目标，一个我们将支持和维护的一流平台，只要我们还活着。

**(1:26:59 - 1:27:07) 介绍 AI 在 PC 上的应用案例展示**

**黄仁勋：**  对于世界各地的工程师和开发人员来说，这是一件令人难以置信的事情。让我向你们展示一些我们可以用它做的事情，这是我们为你们制作的一个蓝图示例。

**(1:27:07 - 1:28:05) 视频：展示 AI 在 PC 上的应用案例：生成式 AI 图像合成**

**视频旁白：**  生成式 AI 可以从简单的文本提示中合成令人惊叹的图像，但仅使用文字来控制图像合成可能具有挑战性。借助 Nvidia Nim 微服务，创作者可以使用简单的 3D 对象来指导 AI 图像生成。让我们看看概念艺术家如何使用这项技术来开发场景的外观。他们首先布置由手工创建或由 AI 生成的 3D 资产，然后使用图像生成 Nim（例如 Flux）来创建符合 3D 场景的视觉效果。添加或移动对象以优化构图，更改摄像机角度以构建完美的镜头，或使用新的提示重新构想整个场景。在生成式 AI 和 Nvidia Nim 的辅助下，艺术家可以快速实现他们的愿景。

**(1:28:05 - 1:28:33) 总结 AI PC 的前景和 OEM 厂商的支持**

**视频旁白：**  适用于您的 PC 的 Nvidia AI。全球有数亿台 Windows PC，因此我们可以让它们为 AI 做好准备。OEM，所有的 PC，我们与之合作的基本上是所有世界领先的 PC OEM，都将让他们的 PC 为此做好准备。因此，AI PC 即将进入您附近的家庭。

#### 六、物理 AI 与 Nvidia Cosmos (1:28:33 - 1:39:52)

**(1:28:33 - 1:28:40) 调侃 Linux**

**黄仁勋：** Linux 还不错。

**(1:28:40 - 1:30:41) 引出物理 AI 的概念**

**黄仁勋：**  好了，让我们来谈谈物理 AI。说到 Linux，让我们来谈谈物理 AI。想象一下，物理 AI，想象一下，而你的大语言模型，你在左边给出你的上下文，你的提示，它一次生成一个 Tokens 来产生输出，这基本上就是它的工作原理。令人惊奇的是，中间的这个模型相当大，有数十亿个参数，上下文长度非常大，因为你可能决定加载一个 PDF，在我的例子中，我可能会在问它一个问题之前加载几个 PDF。这些 PDF 被转换成 Tokens，Transformer 的基本注意力特征使每一个 Token 都能找到它与其他每一个 Token 的关系和相关性。因此，你可能有数十万个 Tokens，计算负载呈二次方增长，它会执行此操作，所有参数，所有输入序列，通过 Transformer 的每一层进行处理，它会产生一个 Token，这就是我们需要 Blackwell 的原因。然后，当当前 Token 完成时，它会将当前 Token 放入输入序列，并获取整个内容并生成下一个 Token，它一次执行一个。这是 Transformer 模型，这就是它如此有效，计算要求如此之高的原因。

**(1:30:41 - 1:31:39) 提出物理 AI 的设想和挑战**

**黄仁勋：**  如果不是 PDF，而是你周围的环境呢？如果不是提示一个问题，而是一个请求，去那里拿起那个盒子并把它带回来呢？如果不是以文本形式生成 Tokens，而是生成动作 Tokens 呢？我刚才描述的是机器人技术未来的一个非常合理的事情，这项技术即将到来。但我们需要做的是，我们需要创建有效的世界模型，你知道，与作为语言模型的 GPT 相反，这个世界模型必须理解世界的语言，它必须理解物理动力学，如重力、摩擦力和惯性，它必须理解几何和空间关系，它必须理解因果关系。如果你掉落东西，如果掉到地上，如果你戳它，它会翻倒，它仍然需要理解对象的持久性。如果你把一个球滚到厨房柜台上，当它从另一边滚下去时，球并没有进入另一个量子宇宙，它仍然在那里。因此，所有这些类型的理解，我们所知道的直观理解，今天的大多数模型都很难做到。

**(1:31:39 - 1:32:02) 宣布 Nvidia Cosmos：世界基础模型**

**黄仁勋：**  因此，我们想要创造一个世界，我们需要一个世界基础模型。今天，我们宣布一件非常重要的事情，我们宣布 Nvidia Cosmos，一个旨在理解物理世界的世界基础模型。

**(1:32:02 - 1:34:21) 视频：展示 Nvidia Cosmos 的功能和应用**

**视频旁白：** AI 的下一个前沿是物理 AI。模型性能与数据可用性直接相关，但物理世界数据的捕获、管理和标记成本很高。Nvidia Cosmos 是一个世界基础模型开发平台，旨在推进物理 AI。它包括自回归世界基础模型、基于扩散的世界基础模型、先进的分词器，以及一个 Nvidia Cuda 和 AI 加速的数据流水线。Cosmos 模型摄取文本、图像或视频提示，并生成虚拟世界状态作为视频。Cosmos 生成优先考虑自动驾驶汽车和机器人用例的独特需求，如真实世界的环境、照明和对象持久性。开发人员使用 Nvidia Omniverse 构建基于物理的、地理空间精确的场景，然后将 Omniverse 渲染输出到 Cosmos，后者生成逼真的、基于物理的合成数据。

**(1:33:15 - 1:33:52) 视频：展示 Nvidia Cosmos 的更多应用**

**视频旁白：** 无论是不同的物体还是环境，天气或一天中的时间等条件，或边缘情况。开发人员使用 Cosmos 生成世界，用于强化学习 AI 反馈，以改进策略模型，或测试和验证模型性能，甚至跨多传感器视图。

**(1:33:52 - 1:34:21) 视频：强调 Cosmos 的实时性和应用前景**

**视频旁白：** Cosmos 可以实时生成 Tokens，将远见和多重宇宙模拟的力量带给 AI 模型，生成每一个可能的未来，以帮助模型选择正确的路径。通过与世界开发者生态系统的合作，Nvidia 正在帮助推进下一波物理 AI。

**(1:34:21 - 1:34:26) 介绍 Nvidia Cosmos**

**黄仁勋：** Nvidia Cosmos，Nvidia Cosmos，Nvidia Cosmos，世界上第一个世界基础模型。

**(1:34:26 - 1:35:08) 介绍 Cosmos 的训练数据和应用领域**

**黄仁勋：** 它是在 2000 万小时的视频上训练的，这 2000 万小时的视频主要关注物理动力学方面的内容，包括自然、自然主题、人类行走、手的移动、操纵物体、快速的摄像机移动等等。它的目的不是为了生成创意内容，而是为了训练 AI 理解物理世界。有了这种物理 AI，我们可以做很多下游的事情。

**(1:35:08 - 1:36:04) 阐述 Cosmos 的应用前景：合成数据生成、机器人模型训练等**

**黄仁勋：** 因此，我们可以进行合成数据生成来训练模型，我们可以对它进行提炼，并将其有效地转化为种子，即机器人模型的开端。你可以让它生成多个基于物理的、物理上合理的未来场景，基本上是做一个奇异博士。因为这个模型理解物理世界，当然，你看到了一大堆生成的图像，这个模型理解物理世界，它当然也可以做字幕。因此，它可以获取视频，并对其进行非常好的字幕处理，并且该字幕和视频可以用于训练大语言模型，多模态大语言模型。因此，你可以使用这项技术，使用这个基础模型来训练机器人以及更大的语言模型。

**(1:36:04 - 1:36:41) 介绍 Cosmos 平台的技术组成**

**黄仁勋：** 因此，这就是 Nvidia Cosmos，该平台有一个用于实时应用的自回归模型，有一个用于非常高质量图像生成的扩散模型，它是一个令人难以置信的分词器，基本上是学习真实世界的词汇表，还有一个数据流水线。

**(1:36:41 - 1:36:52) 宣布 Cosmos 开源**

**黄仁勋：** 因此，如果你想获取所有这些，然后在你自己的数据上训练它，这个数据流水线，因为涉及到如此多的数据，我们已经为你加速了所有端到端的内容。因此，这是世界上第一个 Cuda 加速和 AI 加速的数据处理流水线，所有这些都是 Cosmos 平台的一部分。今天，我们宣布 Cosmos 是开放许可的，它可以在 GitHub 上获得。

**(1:36:52 - 1:37:14) 表达对 Cosmos 开源的期望**

**黄仁勋：** 我们希望，我们希望这一刻，这里有一个小型、中型和大型的模型，用于非常快的模型，主流模型，还有教师模型，基本上不是知识转移模型。Cosmos 的世界基础模型是开放的，我们真的希望它能像 Llama 3 对企业 AI 所做的那样，为机器人和工业 AI 的世界做出贡献。

**(1:37:14 - 1:38:25) 阐述 Cosmos 与 Omniverse 结合的意义**

**黄仁勋：** 当你将 Cosmos 连接到 Omniverse 时，奇迹就会发生。从根本上说，原因是这样的，Omniverse 是一个基于物理的，不是基于物理的，而是基于物理的，它是算法物理的，基于原理物理模拟的系统，它是一个模拟器。当你将它连接到 Cosmos 时，它提供了基础，可以控制和调节 Osmos 生成的真值。因此，Osmos 的输出是以真值为基础的，这与将大语言模型连接到 RAG（检索增强生成）系统的想法完全相同，你希望将 AI 生成建立在真值的基础上。因此，两者的结合为你提供了一个基于物理的模拟，一个基于物理的多重宇宙生成器。

**(1:38:25 - 1:39:52) 总结 Cosmos + Omniverse 对机器人和工业 AI 的意义**

**黄仁勋：** 应用，用例真的非常令人兴奋，当然，对于机器人，对于工业应用，很明显，这个 Cosmos 加 Omniverse 加 Cosmos 代表了构建机器人系统所需的第三台计算机。每个机器人公司最终都必须构建三台计算机，机器人系统可以是一个工厂，机器人系统可以是一辆汽车，它可以是一个机器人，你需要三台基本的计算机。一台计算机当然是用来训练 AI 的，我们称之为 djx 计算机，用来训练 AI。另一台当然是，当你完成后部署 AI 时，我们称之为 agx，它在汽车、机器人或 AMR 中，或者在体育场馆或其他地方，这些计算机位于边缘，它们是自主的。但是要将两者连接起来，你需要一个数字孪生，这就是你看到的所有模拟，数字孪生是训练好的 AI 去练习的地方，去改进的地方，去做它的合成数据生成、强化学习 AI 反馈等等的地方。因此，它是 AI 的数字孪生，这三台计算机将进行交互式工作。Nvidia 对工业界的战略，我们已经谈论了一段时间，就是这个三计算机系统，你知道，我们没有三体问题，我们有一个三计算机解决方案。因此，这就是 Nvidia 机器人技术。

**(1:39:52 - 1:39:59) 掌声**

#### 七、物理 AI 的应用案例 (1:39:59 - 结束)

**(1:39:59 - 1:40:48) 工业数字化：与 Keon 和埃森哲合作优化仓库物流**

**黄仁勋：** 好了，让我给你们举三个例子。所以，第一个例子是，我们如何将所有这些应用于工业数字化。数百万的工厂，数十万的仓库，这基本上是 50 万亿美元制造业的支柱，所有这些都必须成为软件定义的，所有这些都必须有自动化，未来，所有这些都将注入机器人技术。我们正在与全球领先的仓库自动化解决方案提供商 Keon 以及全球最大的专业服务提供商埃森哲合作，他们在数字制造方面有很大的关注点，我们正在合作创造一些真正特别的东西，我稍后会向你们展示。但我们的市场策略与我们所有的其他软件平台和所有技术平台基本相同，通过开发者和生态系统合作伙伴，我们有越来越多的生态系统合作伙伴连接到 Omniverse。原因很明显，每个人都想将未来的产业数字化，在 50 万亿美元的全球 GDP 中，存在着如此多的浪费，如此多的自动化机会。

**(1:40:48 - 1:43:33) 视频：展示与 Keon 和埃森哲合作的仓库自动化方案**

**视频旁白：**  Keon，供应链解决方案公司，埃森哲，专业服务领域的全球领导者，以及 Nvidia 正在将物理 AI 带入价值 1 万亿美元的仓库和配送中心市场。管理高性能仓库物流涉及到处理复杂的决策网络，这些决策受到不断变化的变量的影响。这些变量包括每日和季节性需求变化、空间限制、劳动力可用性以及各种机器人和自动化系统的集成。如今，预测实体仓库的运营 KPI 几乎是不可能的。为了应对这些挑战，Keon 正在采用 Mega，这是一个 Nvidia Omniverse 蓝图，用于构建工业数字孪生，以测试和优化机器人车队。首先，Keon 的仓库管理解决方案将任务分配给数字孪生中的工业 AI 大脑，例如将货物从缓冲区位置移动到穿梭存储解决方案。机器人的大脑位于实体仓库的模拟中，该模拟使用开放 USD 连接器将 CAD、视频和图像聚合到 3D 激光雷达点云和 AI 生成的数据，从而数字化到 Omniverse 中。机器人车队通过感知和推理它们的 Omniverse 数字孪生环境、规划它们的下一步行动并采取行动来执行任务。机器人大脑可以通过传感器模拟看到结果状态，并决定它们的下一步行动。循环继续，而 Mega 精确地跟踪数字孪生中所有事物的状态。现在，Keon 可以大规模模拟无限的场景，同时测量运营 KPI，如吞吐量、效率和利用率，所有这些都在对实体仓库进行更改之前。与 Nvidia 一起，Keon 和埃森哲正在重塑工业自主的未来。

**(1:43:33 - 1:44:14) 总结仓库自动化方案的意义**

**黄仁勋：** 这太不可思议了，一切都在模拟中。在未来，每个工厂都将有一个数字孪生，该数字孪生与真实工厂的运作方式完全相同。事实上，你可以将 Omniverse 与 Cosmos 结合使用，生成一大堆未来的场景，然后由 AI 决定哪些场景对于任何 KPI 来说都是最优的，这将成为编程约束，如果你愿意的话，程序，将被部署到真实工厂中的 AI。

**(1:44:14 - 1:45:35) 自动驾驶汽车：介绍 Nvidia 的解决方案和合作伙伴**

**黄仁勋：** 下一个例子是自动驾驶汽车，自动驾驶汽车革命已经到来。经过这么多年的 Waymo 的成功和特斯拉的成功，很明显，自动驾驶汽车终于到来了。我们为这个行业提供的产品是三台计算机，用于训练 AI 的训练系统，模拟系统和合成数据生成系统，Omniverse 和现在的 Cosmos，以及汽车内部的计算机。每家汽车公司可能会以不同的方式与我们合作，使用一台、两台或三台计算机。我们正在与全球几乎所有主要的汽车公司合作，当然还有 Waymo、Zoox 和特斯拉，他们在他们的数据中心。比亚迪，世界上最大的电动汽车公司，捷豹路虎有一款非常酷的车即将推出，梅赛德斯奔驰将从今年开始生产一系列搭载 Nvidia 的汽车。我非常高兴地宣布，今天丰田和 Nvidia 将合作开发他们的下一代自动驾驶汽车。还有很多非常酷的公司，Lucid、Rivian、小米，当然还有沃尔沃。Wabbi 正在制造自动驾驶卡车，我们本周还宣布 Aurora 将使用 Nvidia 来制造自动驾驶卡车。

**(1:45:35 - 1:45:59) 强调自动驾驶汽车的市场规模和前景**

**黄仁勋：** 每年生产 1 亿辆汽车，全球道路上有 10 亿辆汽车，每年行驶 1 万亿英里，所有这些都将是高度自主的或即将完全自主的。

**(1:45:59 - 1:46:18) 预测自动驾驶汽车将成为第一个万亿美元的机器人产业**

**黄仁勋：** 因此，这将是一个非常大的，非常大的行业，我预测这很可能成为第一个价值数万亿美元的机器人产业。对于我们来说，这项业务，注意到仅仅在一些开始进入世界的汽车中，我们的业务已经达到了 40 亿美元，今年可能会达到 50 亿美元的运行速度，所以这已经是一项非常重要的业务了。这将是非常大的。

**(1:46:18 - 1:47:25) 发布新一代自动驾驶汽车计算机 Thor**

**黄仁勋：** 今天，我们宣布我们的下一代汽车处理器，我们的下一代汽车计算机叫做 Thor。我这里有一个，等一下。这是 Thor，这是一个机器人计算机，这是一个机器人计算机。它需要传感器和大量的传感器信息，处理它，你知道，十几个摄像头，高分辨率雷达，激光雷达，它们都进入这个芯片，这个芯片必须处理所有这些传感器，将它们转换成 Tokens，把它们放到一个 Transformer 中，并预测下一个路径。这款自动驾驶汽车计算机现在正在全面生产，Thor 的处理能力是我们上一代 Orin 的 20 倍，Orin 确实是当今自动驾驶汽车的标准。

**(1:47:25 - 1:47:40) 强调 Thor 作为通用机器人计算机的潜力**

**黄仁勋：** 因此，这确实非常非常令人难以置信。Thor 正在全面生产，顺便说一下，这款机器人处理器也可以用于一个完整的机器人。因此，它可以是一个 AMR，它可以是一个人形机器人，它可以是大脑，它可以是机械臂，这款处理器基本上是一个通用的机器人计算机。

**(1:47:40 - 1:48:05) 介绍 Drive OS 的功能安全认证**

**黄仁勋：**  我们驾驶系统的第二个部分，我感到非常自豪的是对安全的奉献，Drive OS。我很高兴地宣布，它现在是第一个软件定义的、可编程的 AI 计算机，该计算机已通过 asold D 认证，这是汽车功能安全的最高标准，唯一和最高的。

**(1:48:05 - 1:49:01) 强调 Drive OS 的技术成就**

**黄仁勋：** 因此，我真的非常非常自豪这个 asold ISO 26262，它是大约 15,000 工程师年的工作成果，这简直是非凡的工作。因此，Cuda 现在是一个功能安全的计算机。所以如果你正在构建一个机器人，Nvidia Cuda...

**(1:49:01 - 1:52:30) 视频：展示利用 Omniverse 和 Cosmos 进行自动驾驶汽车的数字孪生重建和训练**

**黄仁勋：**  好了，所以，现在我想，我告诉过你们，我将向你们展示在自动驾驶汽车的背景下，我们将如何使用 Omniverse 和 Cosmos。你知道，今天，我不会向你们展示一大堆汽车在路上行驶的视频，我也会向你们展示一些，但我想向你们展示我们如何使用汽车自动重建数字孪生，使用 AI，并利用这种能力来训练未来的模型。让我们播放它。

**视频旁白：** 自动驾驶汽车革命已经到来。像所有机器人一样，建造自动驾驶汽车需要三台计算机：Nvidia dgx 用于训练 AI 模型，Omniverse 用于试驾和生成合成数据，以及 Drive agx，汽车中的超级计算机。建造安全的自动驾驶汽车意味着要处理边缘场景，但真实世界的数据是有限的。因此，合成数据对于训练自动驾驶汽车至关重要。由 Nvidia Omniverse AI 模型和 Cosmos 提供支持的数据工厂，生成合成驾驶场景，将训练数据提高了几个数量级。首先，omnimap 融合地图和地理空间数据，构建可驾驶的 3D 环境。可以从回放驱动日志或 AI 交通生成器生成驾驶场景变化。接下来，神经重建引擎使用自动驾驶汽车传感器日志来创建高保真 4D 仿真环境。它以 3D 方式重播以前的驾驶，并生成场景变化以放大训练数据。最后，edify 3DS 自动搜索现有的资产库或生成新的资产，以创建模拟就绪的场景。Omniverse 场景用于调节 Cosmos，以生成大量的照片级真实数据，从而减少模拟到真实的差距，并且通过文本提示，可以生成驾驶场景的近乎无限的变化。借助 Cosmos Neotron 视频搜索，可以对大规模扩展的合成数据集与记录的驾驶进行管理，以训练模型。Nvidia 的 AI 数据工厂将数百次驾驶扩展到数十亿有效英里，为安全和先进的自动驾驶设定了标准。

**(1:52:30 - 1:52:41) 总结数字孪生重建和训练的意义**

**黄仁勋：**  这太不可思议了，我们将数千次驾驶转化为数十亿英里，我们将拥有大量的自动驾驶汽车训练数据。

**(1:52:41 - 1:52:50) 强调真实数据采集的重要性**

**黄仁勋：**  当然，我们仍然需要在路上行驶的实际汽车，当然，只要我们还活着，我们就会不断收集数据。

**(1:52:50 - 1:53:03) 强调合成数据生成的重要性**

**黄仁勋：**  然而，使用这种多重宇宙的、基于物理的、基于物理基础的合成数据生成，这样我们就可以生成数据来训练基于物理的、精确的或合理的 AI，这样我们就可以拥有大量的数据来进行训练。

**(1:53:03 - 1:54:31) 机器人：通用机器人发展的机遇和挑战**

**黄仁勋：**  自动驾驶汽车行业已经到来，这是一个令人兴奋的时刻，非常非常非常期待接下来的几年，我想你们会看到，就像计算机图形学以如此惊人的速度被彻底改变一样，你们会看到自动驾驶汽车开发的步伐在接下来的几年里将大大加快。我想，我想，下一步是机器人技术。所以，机器人，我的朋友们，通用机器人的 ChatGPT 时刻即将到来。事实上，我一直在谈论的所有使能技术都将使我们在接下来的几年里看到非常快速的突破，令人惊讶的突破。现在，通用机器人之所以如此重要，是因为带有履带和轮子的机器人需要特殊的环境来适应它们，而世界上有三种机器人，我们可以制造的机器人不需要绿地，棕地适应是完美的。如果我们能够建造这些令人惊叹的机器人，我们就可以将它们部署在我们为自己建造的世界中。

**(1:54:31 - 1:54:55) 提出三种无需特殊环境的机器人类型**

**黄仁勋：** 这三种机器人是：一，Agentic 机器人和 Agentic AI，因为你知道，它们是信息工作者，所以只要它们能够适应我们办公室里的电脑，那就太好了。二，自动驾驶汽车，因为我们花了 100 多年的时间建造道路和城市。三，人形机器人。

**(1:54:55 - 1:55:38) 强调解决人形机器人技术的意义和挑战**

**黄仁勋：** 如果我们拥有解决这三种机器人的技术，这将是世界上最大的技术产业。因此，我们认为机器人时代即将来临。关键能力是如何训练这些机器人，在人形机器人的情况下，模仿信息是相当难以收集的。原因在于，在汽车的情况下，你只需驾驶它，我们一直在驾驶汽车。在这些机器人的情况下，模仿信息，人类演示是相当费力的。因此，我们需要想出一个聪明的方法来获取数百个演示，数千个人类演示，并以某种方式使用人工智能和 Omniverse 来综合生成数百万个综合生成的动作，AI 可以从这些动作中学习如何执行任务。

**(1:55:38 - 1:57:50) 视频：展示利用 Isaac Groot 进行机器人运动生成和训练**

**视频旁白：** 世界各地的开发人员正在构建下一波物理 AI，即具身机器人。开发通用机器人模型需要大量的真实世界数据，而这些数据的捕获和管理成本很高。Nvidia Isaac Groot 帮助应对这些挑战，为人形机器人开发人员提供四样东西：机器人基础模型、数据流水线、模拟框架和 Thor 机器人计算机。Nvidia Isaac Groot 用于合成运动生成的蓝图是一个用于模仿学习的模拟工作流程，使开发人员能够从少量人类演示中生成指数级庞大的数据集。首先，Groot 远程操作使熟练的工人能够使用 Apple Vision Pro 进入他们机器人的数字孪生。这意味着操作员即使没有实体机器人也可以捕获数据，并且他们可以在无风险的环境中操作机器人，从而消除物理损坏或磨损的可能性。为了教机器人执行单个任务，操作员通过一些远程操作演示来捕获运动轨迹，然后使用 Groot Mimic 将这些轨迹倍增成更大的数据集。接下来，他们使用基于 Omniverse 和 Cosmos 构建的 Groot Gen 进行域随机化和 3D 提升，生成指数级更大的数据集。Omniverse 和 Cosmos 多重宇宙模拟引擎提供了一个大规模的数据集来训练机器人策略。一旦策略被训练好，开发人员就可以在 Isaac Sim 中执行软件在环测试和验证，然后再部署到真正的机器人上。通用机器人的时代即将到来，由 Nvidia Isaac 提供支持。

**(1:57:50 - 1:58:10) 介绍 Nvidia Isaac Groot 平台**

**黄仁勋：** 我们将拥有大量的机器人训练数据，Nvidia Isaac Groot，Nvidia Isaac Groot，这是我们的平台，为机器人行业提供技术平台技术元素，以加速通用机器人的开发。

**(1:58:10 - 1:58:54) 回顾 djx1 的历史和意义**

**黄仁勋：**  好了，我想向你们展示最后一件事，如果没有我们大约十年前开始的这个令人难以置信的项目，所有这些都不可能实现。公司内部称之为 Project Digits，深度学习 GPU 智能训练系统 Digits。在我们推出它之前，我把它缩小到 dgx，并使它与 RTX、agx、ovx 以及我们公司所有其他的 x 保持一致。它真的彻底改变了，djx1 在哪里？djx1 彻底改变了人工智能。

**(1:58:54 - 1:59:33) 强调 djx1 对 AI 研究的推动作用**

**黄仁勋：** 我们之所以构建它，是因为我们想让研究人员和初创公司能够拥有一个开箱即用的人工智能超级计算机。想象一下过去建造超级计算机的方式，你真的必须建造你自己的设施，你必须去建造你自己的基础设施，并真正地把它设计成现实。因此，我们为人工智能开发、为研究人员和初创公司创建了一个超级计算机，它实际上是一个开箱即用的。我在 2016 年向一家名为 OpenAI 的初创公司交付了第一个，Elon 在那里，Ilya Sutskever 在那里，Nvidia 的许多工程师也在那里，我们庆祝了 djx1 的到来。

**(1:59:33 - 2:00:12) 强调 AI 的普及和对 AI 超级计算机的需求**

**黄仁勋：** 显然，它彻底改变了人工智能和计算。但现在人工智能无处不在，它不仅仅存在于研究和初创实验室中，你知道，正如我在演讲开始时提到的，我们希望人工智能，这现在是计算的新方式，这是软件的新方式，每个软件工程师，每个工程师，每个创意艺术家，每个今天使用计算机作为工具的人都需要一台 AI 超级计算机。

**(2:00:12 - 2:00:44) 发布个人 AI 超级计算机 Project Digits**

**黄仁勋：**  所以我只是希望，我只是希望 djx1 更小一些。所以，想象一下，女士们，先生们，这是 Nvidia 最新的人工智能超级计算机，它最终被称为 Project Digits。如果你有一个好名字，请联系我们。

**(2:00:44 - 2:01:31) 介绍 Project Digits 的功能、特点和芯片**

**黄仁勋：**  这是令人惊奇的事情，这是一台人工智能超级计算机，它运行整个 Nvidia AI 堆栈，所有 Nvidia 软件都可以在这个 dgx Cloud 上运行，它运行良好，它位于某个地方，它是无线的，或者连接到你的电脑，如果你愿意，它甚至可以是一个工作站，你可以访问它，你可以像云超级计算机一样访问它，Nvidia 的 AI 可以在它上面运行。它基于我们一直在开发的名为 gb110 的超级秘密芯片，这是我们制造的最小的 Grace Blackwell。

**(2:01:31 - 2:01:38) 展示 Project Digits 的内部芯片**

**黄仁勋：**  我有，你知道吗，让我们向大家展示一下内部。

**(2:01:38 - 2:02:07) 音乐、展示**

**(2:02:07 - 2:02:50) 介绍 gb110 芯片的合作伙伴和生产情况**

**黄仁勋：**  这不仅仅是，它太可爱了。这是里面的芯片，它正在生产中，这个绝密芯片，我们与联发科合作开发了 CPU，Grace CPU，他们是世界领先的 SOC 公司，他们与我们合作构建了这个 CPU，这个 CPU，并将其与芯片到芯片的 MV Link 连接到 Blackwell GPU。这个小东西正在全面生产，我们预计这台计算机将在 5 月左右上市。

**(2:02:50 - 2:03:52) 展示 Project Digits 的不同配置和连接方式**

**黄仁勋：**  因此，它即将到来，这简直令人难以置信，我们能做什么，我认为你真的，我试图弄清楚，我是需要更多的手还是更多的口袋。好了，所以，想象一下，这就是它的样子，谁不想要一个呢？如果你使用 PC、Mac，你知道，任何东西，因为，你知道，它是一个云平台，它是一个放在你桌子上的云计算平台，如果你愿意，你也可以把它当作 Linux 工作站使用。如果你想要双位数，这就是它的样子，你知道，你把它连接起来，你用 ConnectX 把它们连接起来，它有 GPU Direct，所有这些都是开箱即用的，它就像一台超级计算机，我们的整个超级计算堆栈都可用。因此，Nvidia Project Digits。

**(2:03:52 - 2:04:00) 掌声**

**(2:04:00 - 2:04:39) 总结演讲内容：Blackwell 系统的生产、物理 AI 基础模型、三个机器人方向**

**黄仁勋：** 好了，让我告诉你们我告诉过你们的内容。我告诉你们，我们正在生产三种新的 Blackwell，不仅是 Grace Blackwell 超级计算机，MV Link 72 正在世界各地生产，我们现在有三种新的 Blackwell 系统正在生产。一个令人惊叹的 AI 基础模型，世界基础模型，世界上第一个物理 AI 基础模型，它是开放的，可用于激活世界各地的机器人等行业。还有三个，三个机器人，我们正在研究 Agentic AI、人形机器人和自动驾驶汽车。

**(2:04:39 - 2:04:51) 感谢观众和合作伙伴**

**黄仁勋：**  这是令人难以置信的一年，我要感谢所有人的合作，感谢所有人的到来。

**(2:04:51 - 2:05:09) 播放回顾视频，展望未来**

**黄仁勋：**  我为你们制作了一个简短的视频，回顾过去的一年，展望未来一年，请播放。

**(2:05:09 - 2:07:39) 音乐、视频**

**(2:07:39 - 2:07:47) 音乐**

**(2:07:47 - 2:08:52) 结束语：感谢观众，祝大家新年快乐**

**黄仁勋：** 祝大家在 CES 度过愉快的时光，新年快乐，谢谢！

**(2:08:52 - 结束) 音乐**
