为什么我不认同Sam Altman关于AGI基本已解决的观点  
  原文标题：Why I don’t share Sam Altman’s confidence that AGI is basically a solved problem  
  链接：[Gary Marcus](https://garymarcus.substack.com/p/sam-altman-thinks-that-agi-is-basically?utm_source=post-email-title&publication_id=888615&post_id=154267593&utm_campaign=email-post-title&isFreemail=true&r=208yzy&triedRedirect=true&utm_medium=email  )

- **文章类别**：博客文章  

---

**内容整理**：

Gary Marcus在他的博客文章中对Sam Altman关于通用人工智能（AGI）的观点进行了反驳。Sam Altman在一篇新的博客文章中声称，我们现在已经知道如何构建传统意义上的AGI，而Gary Marcus则认为并非如此。以下是Gary Marcus反驳的主要观点：

1. **分布偏移问题**：Gary Marcus指出，尽管大型语言模型（LLMs）在相似的项目上泛化得很好，但在不熟悉的领域中可靠性仍然存在问题，即使是微小的变化有时也会破坏它们。这一问题在苹果2024年的推理论文中得到了验证，而Gary Marcus早在1998年就提出了这一问题。

2. **数学问题上的分布偏移**：一篇关于Putnam数学问题的最近论文显示，即使在变量名称等微小变化的情况下，数学问题的解决能力也会下降30%。这表明，尽管问题不同，但分布偏移问题依然存在。

3. **常识推理问题**：常识推理仍然是一个棘手的问题，Gary Marcus和Ernie Davis最近对此进行了回顾，指出常识推理的不稳定性。

4. **模型的脆弱性**：即使是o1这样的模型，其结果在某些基准测试中也可能很脆弱或难以复制。例如，在某些情况下，o1的表现可能并不比GPT-4更好。

5. **数据增强的局限性**：在o1的最佳表现案例中，可能进行了大量的数据增强，这在更开放的领域中是不可能的。在这些领域，o1的表现可能并不比GPT-4更好。

6. **模型的泛化能力**：o3的展示存在问题，没有提供一个干净的跨领域泛化测试，这表明我们可能会在半封闭领域之外遇到分布偏移问题。

7. **纯LLM扩展的边际收益递减**：许多领域内的领先人物已经承认，我们可能已经达到了纯LLM扩展的边际收益递减期。接下来会发生什么还是个未知数。

8. **幻觉问题**：由于缺乏明确、可访问、可靠的数据库式记录，幻觉问题依然存在。这导致了不准确的新闻摘要、诽谤、虚构来源、错误建议和不可靠性。

Gary Marcus强调，尽管他不是100%确定AGI不在眼前，但他目前还没有看到对这些长期存在的问题中的任何一个的原理性解决方案。他认为，如果新的证据出现，他会像往常一样进行评估。但他目前还没有看到任何解决方案，这让他对AGI的前景持谨慎态度。

文章还提到了一些评论，例如Aaron Turner指出，Sam Altman和OpenAI已经将自己逼入了死胡同，他们选择了LLM路线，并且多年来一直向投资者表示他们在通往AGI的道路上，现在他们没有其他选择，只能继续乐观地宣传。George Burch则认为，除非有可以独立验证的、符合科学标准的演示，否则AGI仍然是科幻小说，而LLM则放弃了科学。