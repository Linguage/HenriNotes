- 原文标题：Building effective agents  
- 链接：[Anthropic](https://www.anthropic.com/research/building-effective-agents  )
- **文章类别**：博客文章  
---

## 摘要

这篇 Anthropic 的博文深入探讨了构建有效 AI Agent 的实用方法。文章强调，成功的关键不在于复杂框架，而在于简单、可组合的模式。作者区分了两种 Agent 系统：“工作流”（预定义代码路径）和“Agent”（LLM 自主决策）。

文章详细介绍了包括提示链、路由、并行化、协调器-工作器、评估器-优化器等多种工作流模式，并指出了各自的适用场景。对于 Agent，文章强调了其在处理开放式、步骤不确定的问题上的优势，但也提醒注意其潜在的成本和错误风险。

核心建议包括：保持 Agent 设计简洁、优先考虑透明度、精心设计 Agent-计算机接口（ACI，通过完善的工具文档）。文章还强调了从简单方案入手，逐步增加复杂性，并持续评估和迭代的重要性。框架可以作为起点，但应避免过度抽象。通过遵循这些原则，可以构建出强大、可靠且易于维护的 AI Agent。

### 关键词
#人工智能代理， #大型语言模型， #工作流设计， #工具工程

## 文章框架

```markdown
├── 引言
│   ├── 文章背景
│   └── 主题介绍
├── 代理系统的定义
│   ├── 不同客户对代理的定义
│   └── Anthropic对代理系统的分类
├── 何时（不）使用代理
│   ├── 简单解决方案优先
│   ├── 代理与工作流的适用场景
│   └── 单步LLM调用的优化
├── 框架的使用建议
│   ├── 常见框架介绍
│   ├── 框架的优缺点
│   └── 直接使用LLM API的建议
├── 构建模块、工作流和代理
│   ├── 基础模块：增强型LLM
│   ├── 工作流模式
│   │   ├── Prompt Chaining
│   │   ├── Routing
│   │   ├── Parallelization
│   │   ├── Orchestrator-Workers
│   │   └── Evaluator-Optimizer
│   └── 代理系统
├── 结合和定制这些模式
├── 总结与核心原则
│   ├── 简洁性
│   ├── 透明性
│   └── 工具开发与测试
├── 附录1：代理的实际应用
│   ├── 客户支持
│   └── 编程代理
└── 附录2：工具的Prompt工程
```



---

## 构建有效的 Agent

2024年12月20日

在过去的一年里，我们与数十个团队合作，在各个行业构建大型语言模型（LLM）Agent。 一致的是，最成功的实现并没有使用复杂的框架或专门的库。 相反，他们使用简单、可组合的模式进行构建。

在这篇文章中，我们分享了我们与客户合作和自己构建 Agent 的经验，并为开发者提供关于构建有效 Agent 的实用建议。

### **什么是 Agent？**

"Agent" 可以用几种方式定义。 一些客户将 Agent 定义为完全自主的系统，这些系统在较长时间内独立运行，使用各种工具来完成复杂的任务。 其他人则使用该术语来描述遵循预定义工作流的更规范的实现。 在 Anthropic，我们将所有这些变体归类为 Agent 系统，但在工作流和 Agent 之间进行了重要的架构区分：

*   **工作流**是通过预定义代码路径编排 LLM 和工具的系统。
*   另一方面，**Agent** 是 LLM 动态指导其自身流程和工具使用的系统，控制它们如何完成任务。

下面，我们将详细探讨这两种类型的 Agent 系统。 在附录 1（“实践中的 Agent”）中，我们描述了客户发现使用这些类型的系统特别有价值的两个领域。

**何时（以及何时不）使用 Agent**

在使用 LLM 构建应用程序时，我们建议找到尽可能简单的解决方案，并且仅在需要时增加复杂性。 这可能意味着根本不构建 Agent 系统。 Agent 系统通常会牺牲延迟和成本来获得更好的任务性能，您应该考虑这种权衡何时有意义。

当需要更多复杂性时，工作流为定义明确的任务提供可预测性和一致性，而当需要大规模的灵活性和模型驱动的决策时，Agent 是更好的选择。 然而，对于许多应用程序来说，使用检索和上下文示例优化单个 LLM 调用通常就足够了。

### 何时以及如何使用框架

有许多框架可以使 Agent 系统更容易实现，包括：

*   LangChain 的 LangGraph；
*   Amazon Bedrock 的 AI Agent 框架；
*   Rivet，一个拖放式 GUI LLM 工作流构建器；和
*   Vellum，另一个用于构建和测试复杂工作流的 GUI 工具。

这些框架通过简化标准底层任务（如调用 LLM、定义和解析工具以及将调用链接在一起）来简化入门。 但是，它们通常会创建额外的抽象层，这些抽象层可能会掩盖底层的提示和响应，从而使它们更难调试。 它们也可能使人倾向于在更简单的设置就足够时增加复杂性。

我们建议开发者首先直接使用 LLM API：许多模式可以用几行代码实现。 如果您确实使用了框架，请确保您了解底层代码。 关于底层情况的错误假设是客户错误的常见来源。

有关一些示例实现，请参阅我们的 cookbook。

### 构建块、工作流和 Agent

在本节中，我们将探讨我们在生产中看到的 Agent 系统的常见模式。 我们将从我们的基础构建块——增强型 LLM——开始，并逐步增加复杂性，从简单的组合工作流到自主 Agent。

**构建块：增强型 LLM**

Agent 系统的基本构建块是经过增强的 LLM，例如检索、工具和记忆。 我们当前的模型可以主动使用这些功能——生成自己的搜索查询、选择适当的工具并确定要保留的信息。

（图片：增强型 LLM）

我们建议关注实现的两个关键方面：根据您的特定用例定制这些功能，并确保它们为您的 LLM 提供一个简单、文档齐全的接口。 虽然有很多方法可以实现这些增强，但一种方法是通过我们最近发布的模型上下文协议（Model Context Protocol），它允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。

在本文的其余部分，我们将假设每个 LLM 调用都可以访问这些增强功能。

**工作流：提示链**

提示链将任务分解为一系列步骤，其中每个 LLM 调用处理前一个调用的输出。 您可以在任何中间步骤上添加程序检查（请参阅下图中的“门”），以确保流程仍在轨道上。

（图片：提示链工作流）

**何时使用此工作流：**此工作流非常适合任务可以轻松、干净地分解为固定子任务的情况。 主要目标是通过使每个 LLM 调用成为更简单的任务来权衡延迟以获得更高的准确性。

提示链有用的示例：

*   生成营销文案，然后将其翻译成不同的语言。
*   编写文档大纲，检查大纲是否符合特定条件，然后根据大纲编写文档。

**工作流：路由**

路由对输入进行分类并将其定向到专门的后续任务。 此工作流允许分离关注点，并构建更专业的提示。 没有此工作流，针对一种输入进行优化可能会损害其他输入的性能。

（图片：路由工作流）

**何时使用此工作流：** 路由非常适合复杂任务，其中存在最好单独处理的不同类别，并且分类可以由 LLM 或更传统的分类模型/算法准确处理。

路由有用的示例：

*   将不同类型的客户服务查询（一般问题、退款请求、技术支持）定向到不同的下游流程、提示和工具。
*   将简单/常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难/不常见问题路由到功能更强大的模型（如 Claude 3.5 Sonnet），以优化成本和速度。

**工作流：并行化**

LLM 有时可以同时处理一项任务，并以编程方式聚合它们的输出。 这种工作流，即并行化，体现在两个关键变体中：

*   **分段：** 将任务分解为并行运行的独立子任务。
*   **投票：** 多次运行同一任务以获得不同的输出。

（图片：并行化工作流）

**何时使用此工作流：** 当划分的子任务可以并行化以提高速度，或者当需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。 对于具有多个考虑因素的复杂任务，LLM 通常在每个考虑因素由单独的 LLM 调用处理时表现更好，从而可以集中关注每个特定方面。

并行化有用的示例：

*   **分段：**
    *   实施护栏，其中一个模型实例处理用户查询，而另一个模型实例筛选它们是否存在不当内容或请求。 这往往比让同一个 LLM 调用同时处理护栏和核心响应表现更好。
    *   自动化评估以评估 LLM 性能，其中每个 LLM 调用评估模型在给定提示上的性能的不同方面。
*   **投票：**
    *   审查一段代码是否存在漏洞，其中几个不同的提示会审查代码并在发现问题时标记代码。
    *   评估给定内容是否不合适，多个提示评估不同方面或需要不同的投票阈值来平衡误报和漏报。

**工作流：协调器-工作器**

在协调器-工作器工作流中，中央 LLM 动态分解任务，将它们委派给工作器 LLM，并综合它们的结果。

（图片：协调器-工作器工作流）

**何时使用此工作流：** 此工作流非常适合您无法预测所需子任务的复杂任务（例如，在编码中，需要更改的文件数量以及每个文件中更改的性质可能取决于任务）。 虽然它在拓扑上相似，但与并行化的主要区别在于它的灵活性——子任务不是预定义的，而是由协调器根据特定输入确定的。

协调器-工作器有用的示例：

*   每次对多个文件进行复杂更改的编码产品。
*   搜索任务，涉及从多个来源收集和分析信息以获取可能的
相关信息。

**工作流：评估器-优化器**

在评估器-优化器工作流中，一个 LLM 调用生成响应，而另一个 LLM 调用在循环中提供评估和反馈。

（图片：评估器-优化器工作流）

**何时使用此工作流：** 当我们有明确的评估标准，并且迭代改进提供可衡量价值时，此工作流特别有效。 良好匹配的两个迹象是，首先，当人类表达他们的反馈时，LLM 响应可以得到明显改善； 其次，LLM 可以提供此类反馈。 这类似于人类作者在制作精美文档时可能经历的迭代写作过程。

评估器-优化器有用的示例：

*   文学翻译，其中存在翻译 LLM 最初可能无法捕捉到的细微差别，但评估器 LLM 可以提供有用的评论。
*   复杂的搜索任务，需要多轮搜索和分析才能收集全面的信息，其中评估器决定是否需要进一步搜索。

**Agent**

随着 LLM 在关键能力方面的成熟——理解复杂输入、参与推理和规划、可靠地使用工具以及从错误中恢复，Agent 正在生产中出现。 Agent 通过来自人类用户的命令或与人类用户的交互式讨论开始他们的工作。 一旦任务明确，Agent 就会独立规划和操作，可能会返回给人类以获取更多信息或判断。 在执行期间，Agent 在每个步骤中从环境中获得“基本事实”（例如工具调用结果或代码执行）以评估其进度至关重要。 然后，Agent 可以在检查点或遇到障碍时暂停以获取人类反馈。 任务通常在完成后终止，但通常也包括停止条件（例如最大迭代次数）以保持控制。

Agent 可以处理复杂的任务，但它们的实现通常很简单。 它们通常只是在循环中使用基于环境反馈的工具的 LLM。 因此，清晰而周到地设计工具集及其文档至关重要。 我们在附录 2（“提示工程您的工具”）中扩展了工具开发的最佳实践。

（图片：自主 Agent）

**何时使用 Agent：** Agent 可用于难以或无法预测所需步数的开放式问题，以及您无法硬编码固定路径的问题。 LLM 可能会运行很多轮，您必须对其决策有一定的信任度。 Agent 的自主性使其成为在受信任环境中扩展任务的理想选择。

Agent 的自主性意味着更高的成本，以及复合错误的可能性。 我们建议在沙盒环境中进行广泛测试，并采取适当的护栏措施。

Agent 有用的示例：

以下示例来自我们自己的实现：

*   用于解决 SWE-bench 任务的编码 Agent，它涉及根据任务描述对许多文件进行编辑；
*   我们的“计算机使用”参考实现，其中 Claude 使用计算机来完成任务。

（图片：编码 Agent 的高级流程）

**组合和定制这些模式**

这些构建块不是规定性的。 它们是开发者可以塑造和组合以适应不同用例的常见模式。 与任何 LLM 功能一样，成功的关键在于衡量性能和迭代实现。 重复一遍：只有在它明显改善结果时，您才应该考虑增加复杂性。

### 总结

在 LLM 领域取得成功并不是要构建最复杂的系统。 而是要构建适合您需求的系统。 从简单的提示开始，通过全面的评估优化它们，并且仅在更简单的解决方案不足时才添加多步 Agent 系统。

在实现 Agent 时，我们尝试遵循三个核心原则：

*   保持 Agent 设计的简单性。
*   通过明确显示 Agent 的规划步骤来优先考虑透明度。
*   通过全面的工具文档和测试，精心设计您的 Agent-计算机接口 (ACI)。

框架可以帮助您快速入门，但在您转向生产时，请毫不犹豫地减少抽象层并使用基本组件进行构建。 通过遵循这些原则，您可以创建不仅强大而且可靠、可维护且受其用户信任的 Agent。

### 致谢

由 Erik Schluntz 和 Barry Zhang 撰写。 这项工作借鉴了我们在 Anthropic 构建 Agent 的经验以及我们的客户分享的宝贵见解，对此我们深表感谢。

### 附录 1：实践中的 Agent

我们与客户的合作揭示了 AI Agent 的两个特别有前途的应用，它们展示了上述模式的实用价值。 这两个应用都说明了 Agent 如何为需要对话和行动、具有明确成功标准、启用反馈循环并整合有意义的人类监督的任务增加最大价值。

**A. 客户支持**

客户支持将熟悉的聊天机器人界面与通过工具集成增强的功能相结合。 这是更开放式 Agent 的自然选择，因为：

*   支持交互自然地遵循对话流程，同时需要访问外部信息和操作；
*   可以集成工具以提取客户数据、订单历史记录和知识库文章；
*   可以以编程方式处理诸如发放退款或更新工单之类的操作；和
*   可以通过用户定义的解决方案明确衡量成功。

一些公司已经通过仅对成功解决收费的基于使用情况的定价模型证明了这种方法的可行性，这表明了他们对 Agent 有效性的信心。

**B. 编码 Agent**

软件开发领域已经显示出 LLM 功能的巨大潜力，其功能从代码完成发展到自主解决问题。 Agent 特别有效，因为：

*   代码解决方案可以通过自动化测试进行验证；
*   Agent 可以使用测试结果作为反馈来迭代解决方案；
*   问题空间是明确定义的和结构化的；和
*   可以客观地衡量输出质量。

在我们自己的实现中，Agent 现在可以仅根据拉取请求描述解决 SWE-bench Verified 基准测试中的真实 GitHub 问题。 然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

### 附录 2：提示工程您的工具

无论您构建哪种 Agent 系统，工具都可能是您的 Agent 的重要组成部分。 工具使 Claude 能够通过在我们的 API 中指定它们的确切结构和定义来与外部服务和 API 交互。 当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含一个工具使用块。 工具定义和规范应该与您的整体提示一样受到提示工程的关注。 在这个简短的附录中，我们将描述如何提示工程您的工具。

通常有几种方法可以指定相同的操作。 例如，您可以通过编写差异或重写整个文件来指定文件编辑。 对于结构化输出，您可以在 markdown 或 JSON 中返回代码。 在软件工程中，像这样的差异是表面上的，并且可以无损地从一种转换为另一种。 但是，某些格式比其他格式更难让 LLM 编写。 编写差异需要在编写新代码之前知道块头中有多少行正在更改。 在 JSON 中编写代码（与 markdown 相比）需要对换行符和引号进行额外的转义。

我们对决定工具格式的建议如下：

*   给模型足够的标记来“思考”，然后它才会把自己逼入绝境。
*   保持格式接近模型在互联网上自然看到的文本。
*   确保没有格式“开销”，例如必须准确计算数千行代码，或对它编写的任何代码进行字符串转义。

一条经验法则是考虑人类-计算机接口 (HCI) 需要多少努力，并计划投入同样多的努力来创建良好的 Agent-计算机接口 (ACI)。 以下是一些关于如何做到这一点的想法：

*   设身处地为模型着想。 根据描述和参数，使用此工具是否显而易见，或者您是否需要仔细考虑？ 如果是这样，那么对于模型来说可能也是如此。 一个好的工具定义通常包括示例用法、边缘情况、输入格式要求以及与其他工具的明确边界。
*   如何更改参数名称或描述以使事情更明显？ 将此视为为团队中的初级开发者编写出色的文档字符串。 当使用许多类似的工具时，这一点尤其重要。
*   测试模型如何使用您的工具：在我们的工作台中运行许多示例输入以查看模型犯了哪些错误，并进行迭代。
*   防呆您的工具。 更改参数，使其更难出错。

在为 SWE-bench 构建我们的 Agent 时，我们实际上花了更多时间优化我们的工具而不是整体提示。 例如，我们发现模型在使用相对文件路径的工具后，如果 Agent 已经移出根目录，则会出错。 为了解决这个问题，我们更改了工具以始终需要绝对文件路径——我们发现模型完美地使用了这种方法。
