# AGI是一个工程问题

## 文章概要

本文作者Vinci Rufus提出一个核心观点：通往人工通用智能（AGI）的关键不在于继续扩大大型语言模型（LLM）的规模，而在于进行系统的工程设计。当前的LLM已经显现出收益递减的迹象，单纯地增加模型大小和训练数据已难以带来质的飞跃。

文章将AI发展与半导体行业进行类比，指出AI正处在一个类似的拐点。就像当年从追求更高时钟频率转向多核架构一样，AI也需要从追求“更大模型”转向构建“更智能的系统”。

作者认为，真正的AGI需要构建类似于人脑的系统，包含多个专门的模块协同工作。为此，我们需要重点发展以下几个工程领域：

1.  **上下文管理基础设施**：超越LLM有限的注意力窗口，构建能够持久化、动态检索、整合和处理跨领域信息的上下文管理系统，并能处理冲突信息。
2.  **记忆即服务**：为AI构建真正的记忆系统，使其能够像人类一样更新信念、整合经验、遗忘无关细节并生成关于记忆来源和可靠性的元知识。
3.  **具有概率组件的确定性工作流**：构建可靠的、可预测的系统框架，在需要时调用概率性（如LLM）组件。这包括问题路由、多步骤执行、输出验证和能力组合。
4.  **作为模块化组件的专用模型**：未来不是单一全能模型，而是成百上千个针对特定领域（如符号计算、视觉空间推理、时序规划）优化的专用模型协同工作。

作者进一步强调，构建AGI本质上是一个分布式系统工程问题，而非机器学习模型训练问题。这需要构建容错管道、强大的监控和可观测性、可靠的部署系统和全面的测试框架。

文章最后提出了一个三阶段的构建路径：基础层（上下文、记忆、工作流、代理协调）、能力层（专用模型、符号推理、规划、跨模态整合）和涌现层（各组件协同工作产生的超越部分之和的能力）。

结论是，现有的模型已经足够强大，真正缺失的是将其整合成通用智能的系统工程。通往AGI的竞赛，最终是系统架构和工程能力的竞赛，而非GPU集群规模的竞赛。

## 文章标签

#AGI #系统工程 #上下文管理 #AI记忆 #专用模型

## 文章链接

[https://www.vincirufus.com/posts/agi-is-engineering-problem/](https://www.vincirufus.com/posts/agi-is-engineering-problem/)