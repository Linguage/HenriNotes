# AI伦理简报第169期从有益到有害代理型AI的隐性成本

## 文章概要

这期由蒙特利尔AI伦理研究所（MAIEI）发布的《AI伦理简报》探讨了AI代理（Agentic AI）系统带来的隐忧及其更广泛的伦理和社会影响。

首先，文章聚焦于AI代理系统的隐私风险。这类系统旨在代表用户执行任务，如预订、通讯和日程管理，因此需要访问用户在各种应用、浏览器、日程和通讯平台上的数据。Signal总裁Meredith Whittaker警告称，这打破了应用程序和操作系统间的“血脑屏障”，创建了一个不透明的数据管道，将用户的私密数字行为与远程云服务器连接起来。这不仅可能削弱用户同意和平台完整性，还可能被用于监控和数据滥用。同时，有观点指出，将自动化任务完成与真正的人类能动性（包含同情、善良、同理心）混为一谈，是一个根本性错误。研究也显示，工人更偏好能增强而非取代人类控制力的AI工具。

其次，文章讨论了AI训练数据获取方式的治理转变。Cloudflare宣布了一项新政策，对所有新客户域名默认阻止AI机器人爬取，这标志着从“选择退出”到“补偿”模式的转变。此举旨在迫使AI公司就数据使用进行谈判或支付许可费，从而为内容创作者争取利益，但也可能导致数据代表性不均等问题。

接着，文章审视了英国国家医疗服务体系（NHS）部署AI早期预警系统以改善孕产妇护理的计划。该计划雄心勃勃，旨在使所有NHS医院实现“AI化”，利用AI进行诊断、决策支持和患者服务。然而，报告也警示了其中的风险：包括AI系统可能复制偏见导致误诊、自动化失败的前车之鉴（如Post Office Horizon丑闻）、数据治理和患者自主权问题、以及在追求“更快”市场准入时可能存在的监管漏洞。将AI集成到关键的医疗系统中需要极其谨慎，以平衡创新、安全、公平和公众信任。

此外，本期简报的“AI政策角”探讨了日本的《AI促进法》。该法案旨在将日本打造为“对AI最友好的国家”，采取轻触式监管，依靠自愿合规而非惩罚性措施来推动AI研发和应用，反映了其独特的治理思路。

最后，一项KPMG与墨尔本大学的研究揭示了加拿大的AI素养危机，在47个国家中排名第44位。这凸显了在国家层面建立公共AI素养战略和基础设施的紧迫性。

总的来说，本期简报全面分析了AI代理在便利性背后的隐私与能动性侵蚀、AI数据获取的经济与法律博弈、AI在医疗等关键领域的机遇与挑战、不同国家的AI治理策略以及公众AI素养的重要性，提出了关于技术未来和人类价值观的深刻问题。

## 文章标签

#AI伦理 #AI代理 #数据隐私 #AI治理 #NHS #日本AI法 #AI素养

## 文章链接

[https://brief.montrealethics.ai/p/the-ai-ethics-brief-169-from-helpful?utm_source=post-email-title&publication_id=29999&post_id=167704348&utm_campaign=email-post-title&isFreemail=true&r=50w2ld&triedRedirect=true](https://brief.montrealethics.ai/p/the-ai-ethics-brief-169-from-helpful?utm_source=post-email-title&publication_id=29999&post_id=167704348&utm_campaign=email-post-title&isFreemail=true&r=50w2ld&triedRedirect=true)