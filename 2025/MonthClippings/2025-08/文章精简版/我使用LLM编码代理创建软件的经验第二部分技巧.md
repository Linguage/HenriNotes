# 我使用LLM编码代理创建软件的经验第二部分技巧

## 文章概要

这篇文章是作者分享使用大型语言模型（LLM）编码代理（AI Agents）进行软件开发的经验总结的第二部分，重点在于一系列实用的技巧和策略，以提高与AI代理协作的效率和产出质量。

作者首先重申了自己的背景：他不是专业开发者，而是一名有抱负的业余爱好者。他强调，使用AI代理进行软件开发的重点是“创造”（creation），而不仅仅是“编码”（coding）。

文章的核心内容是各种实用技巧，包括：

1.  **上下文（Context）管理**：
    *   强调为AI模型提供大量且直接相关的上下文以获得良好结果，但要避免无关内容干扰。
    *   建议在项目根目录创建 `context/` 和 `docs/` 目录来存放内部开发文档和公开文档，并修改代理的用户特定提示（如 `CLAUDE.md`）来指导代理如何查找和使用这些上下文。
    *   可以在代码文件中直接加入注释来提供特定上下文，例如在测试文件中明确指定使用的测试框架，以防止代理使用错误的语法。
    *   注意上下文窗口大小的限制（如Sonnet为200k tokens），对于大文件（如 `pnpm-lock.yaml` 或 `openapi.json`）要避免让代理读取整个文件，而是使用工具提取所需部分。
    *   当上下文过多导致代理失去重点或出现“近因偏差”时，可以使用代理的“压缩”（compact）功能或直接开启新会话。
    *   对于代理可能难以处理的复杂库或框架，可以预先生成上下文文档（如作者为AntV X6库生成的开发者指南）。

2.  **与代理的交互**：
    *   作者反思了自己习惯性地对代理使用礼貌用语，指出代理不是人，不需要客套。解释原因有时有帮助，但不必要的解释和事后告知结果会浪费token。
    *   与代理沟通时，应专注于任务目标和指导原则，而非过多的人情世故。

3.  **设计（Design）**：
    *   对于复杂任务，必须要有明确的设计，而不仅仅是目标。要与代理协作完善设计，并将其文档化。
    *   设计文档要详细、具体，最好使用机器可读的标准格式（如OpenAPI规范）。
    *   为不同功能区域维护独立的小型设计文档，以节省token。

4.  **规划（Planning）**：
    *   对于非琐碎的任务，不要直接让代理执行，而应要求其“深入思考”（think deeply）或“深入分析”（analyze deeply）并制定详细计划。
    *   计划制定后要进行审查和迭代，再让代理执行。
    *   可以创建规划和跟踪文档来管理复杂功能的开发进度。

5.  **代理间通信（Inter-agent communication）**：
    *   在集成不同代码库（如客户端和服务器）时，可以同时运行多个代理，并作为“信使”让它们互相沟通以解决集成问题，这是一种非常有效的模式。

6.  **日志记录（Logging）**：
    *   强调创建高质量的日志对于代理调试程序至关重要。
    *   应在项目早期就构建强大的日志系统，并指导代理在调试时添加必要的诊断日志。
    *   日志应包含丰富的细节，如操作开始/结束、状态变更、数据收发、对象修改等。
    *   在UI开发中，也可以在界面中提供类似日志的可见性来辅助调试。

7.  **防御性提示和使用Git**：
    *   在提示中明确要求代理在完成任务前必须通过lint、build、test等检查，以减少代码错误。
    *   要警惕代理在修复失败测试时可能会选择禁用测试，应在提示和测试文件注释中明确禁止此行为。
    *   使用Git进行防御性开发：在开始更改前确保没有未提交的更改，以便在出错时能轻松回滚。
    *   对于重大更改或实验，应创建新分支。
    *   绝不让代理在未经许可的情况下执行 `git commit` 等操作。

8.  **任务分解和待办事项列表（TODO Lists）**：
    *   将大型任务分解为一系列小型、可管理的任务。
    *   让代理创建并维护待办事项列表来规划和跟踪进度，这相当于给代理提供了长期记忆。

9.  **监控和纠正代理行为**：
    *   在代理工作时要密切监视其行为，一旦发现其偏离预期或采用不合适的方案，应立即中断并提供更正指令。

10. **测试（Testing）**：
    *   要审查代理生成的测试用例，增补重要场景，删除无用测试。
    *   作者指出一个重要问题：代理生成的测试很少能真正发现bug，因为它们可能会迭代调整测试以匹配现有（错误的）实现。因此，一旦发现bug未被测试捕获，要让代理分析原因并修复测试。

11. **自定义工具（Custom Tools）**：
    *   当代理在执行某项任务时遇到困难，可以考虑让其构建专门的工具来解决。例如，作者为处理大型JSON文件创建了一个Python工具。

12. **其他经验**：
    *   代理会阿谀奉承，不要轻信其对设计的赞美。
    *   代理喜欢重复代码，需要指导其进行重构。
    *   谨慎听取代理对改进应用的建议，容易被引导增加不必要的抽象层。
    *   尝试过“代码→规范→翻译代码”的流程，但效果不佳，主要问题在于代理生成的规范质量不高。

总的来说，这篇文章提供了大量与LLM编码代理高效协作的实战经验，涵盖了从上下文管理到具体开发实践的方方面面，对于希望利用AI提升编码效率的开发者具有很高的参考价值。

## 文章标签

#AI编码 #LLM代理 #ClaudeCode #RooCode #开发技巧 #上下文管理 #设计 #规划 #调试 #测试 #Git #工具开发

## 文章链接

[https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html](https://efitz-thoughts.blogspot.com/2025/08/my-experience-creating-software-with_22.html)